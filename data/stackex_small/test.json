[
  {
    "id": "_unix.125936",
    "source": "Create partition on CentOS server? <eos> I have a headless CentOS server that I'd like to create a new partition on so I have a separate boot and data partition. I have an existing server with the setup that I want to achieve and running fdisk -l looks like this:Disk /dev/cciss/c0d0: 299.9 GB, 299966445568 bytes255 heads, 63 sectors/track, 36468 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytes           Device Boot      Start         End      Blocks   Id  System/dev/cciss/c0d0p1   *           1          13      104391   83  Linux/dev/cciss/c0d0p2              14       36468   292824787+  8e  Linux LVMDisk /dev/cciss/c0d1: 899.8 GB, 899898718208 bytes255 heads, 63 sectors/track, 109406 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytes           Device Boot      Start         End      Blocks   Id  System/dev/cciss/c0d1p1   *           1      109406   878803663+  83  LinuxHere's the same command on my server:Disk /dev/cciss/c0d0: 587.1 GB, 587128266752 bytes255 heads, 63 sectors/track, 71380 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytes           Device Boot      Start         End      Blocks   Id  System/dev/cciss/c0d0p1   *           1          13      104391   83  Linux/dev/cciss/c0d0p2              14       71380   573255427+  8e  Linux LVMI've been told it's not as straightforward as creating a partition and setting mount-points to it because of the additional logical volume layer on CentOS. How can I create a partition without causing problems to the  data structure?",
    "target": "centos;partition"
  },
  {
    "id": "_softwareengineering.150021",
    "source": "Governance models for multi-institution open source projects <eos> I'm working on an open source project that has full time professional developers from several universities, plus a couple of other organisations. The product has something like a dozen deployments, various variations, plugins, related components etc. Generally development so far has been driven by institutions scratching their own itch, but with an effort to merge improvements back to a central code base.As it's starting to mature, I'm interested in possible models of open source governance to follow. (So this question isn't what are some good things to do, it's specifically what existing, tested models are worth looking at and possibly following)Specific aspects that such models might cover:How decisions about big-impact changes are made (and what happens if someone makes big changes without discussing them first)Who manages the product's public image (product marketing, for want of a better term)Who represents the product in any comparisons with competing productsWhether enhancements become core, plugins, related products etcWhether and how roadmaps are created and publishedHow variations on the product are handled (in this case, versions for different academic disciplines)Expectations and obligations of participants in the projectExpectations and obligations of the institutions for which those developers workWe'll be looking for something as lightweight and informal as practical.",
    "target": "open source;management;community;distributed development"
  },
  {
    "id": "_unix.325979",
    "source": "How to find the min of a column in every nth intervals of a file, using sed, sort, tail? <eos> I want to find the minimum of the 5th column of a file in every 12th interval of that and save the associated line into a new file. To find the minimum of the last 12th line I can usetail -n 12  $FILEname | sort -g -k 5,5 | head -1|  awk '{print}'> tmp.outBut how can I perform such a process iteratively?I have triedwhile read $FILEnamedo ....donewhich was not successful.The file looks like4.7 0.17    0.529   0   4.48464.7 0.17    0.529   1   4.54374744.7 0.17    0.529   2   5.632297394.7 0.17    0.529   3   4.6723851574.7 0.17    0.529   4   4.6989224684.7 0.17    0.529   5   4.6999771954.7 0.17    0.529   6   4.6999693294.7 0.17    0.529   7   3.699997174.7 0.17    0.529   8   4.69999984.7 0.17    0.529   9   2.74.7 0.17    0.59    10  3.99999984.7 0.17    0.59    11  4.699999999985   1   0.59    0   4.495698465   1   0.59    1   4.543305745   1   0.59    2   4.637396535   1   0.59    3   3.672339575   1   0.59    4   4.69892024685   1   0.59    5   4.6999125955   1   0.59    6   4.69993295   1   0.59    7   4.699999997175   1   0.59    8   4.699999985   1   0.59    9   3.25475   1   0.529   10  4.699999999985   1   0.529   11  4.69999999998with almost 2000 lines.",
    "target": "text processing;awk;sed"
  },
  {
    "id": "_opensource.665",
    "source": "Are Copyleft and Share-Alike synonyms? <eos> Copyleft and Share-Alike are two very similar types of licences. Here is how Wikipedia defines them:Copyleft (a play of the word copyright) is the practice of offering people the right to freely distribute copies and modified versions of a work with the stipulation that the same rights be preserved in derivative works down the line. (Source)Share-alike is a copyright licensing term, originally used by the Creative Commons project, to describe works or licences that require copies or adaptations of the work to be released under the same or similar licence as the original. Copyleft licences are free content or free software licences with a share-alike condition. (Source)Are there any meaningful distinctions between these concepts, or is the only real difference their heritage and most common uses (software vs media)?",
    "target": "terminology;copyleft"
  },
  {
    "id": "_codereview.54123",
    "source": "Creating a function when user clicks on element to toggle another element <eos> I use a lot of when user clicks on element then another element will be displayed as visible/hidden... aka toggle. So I'm trying to make a general function to abide the DRY principal.Before jumping into the code, I just wanted to state that there are still bugs. I just want to know before continuing if writing a function like the one below is necessary or if I should just ignore the DRY in this case and have lots of separate toggle functions. Or if it's necessary, would there be a more efficient method? JSFiddle*Brief Description of Code -There are 4 parametersThe first two are mandatory, the last two are optionalThe index parameter is a string of numbers ex. 1.0,1The reason I need the last two parameters is because I have elements that can't be easilytargeted. For example, they don't have an #id. So to grab those generic elements, I use getElementsByTagNameThen I'll use the index parameter to get the element in the array.index parameter: The number before '.' is the index of the clickElementand the number after '.' is the index of the toggleElement. clickElement = 1. toggleElement = 0. function toggleClick(clickElement, toggleElement, condition, index) {     var toggleIndex;    var clickIndex;    if(condition === false){        if(index.indexOf('.') != -1){            //indexOf returns -1 if '.' is not found.             // Checks to see if two index is entered            indexArray = index.split('.');            clickIndex = indexArray[0];            toggleIndex = indexArray[1];            clickElement = document.getElementsByTagName(clickElement)[clickIndex];            toggleElement = document.getElementsByTagName(toggleElement)[toggleIndex];        }else{            //If there is no '.', that means only one index was entered.            // By function requirement, it should be the index of clickElement            clickElement = document.getElementsByTagName(clickElement)[index];        }    }    $(clickElement).click(function(){            $(toggleElement).toggle();        });    } This is one of my first functions, and so I need some guidance on whether I'm writing bad code. Yes, this might be broad because there may be many different ways to write this function.  But I just need to know if there's a more efficient way or if my way is okay.",
    "target": "javascript;jquery;event handling"
  },
  {
    "id": "_webapps.59994",
    "source": "How can I find out when I subscribed to a YouTube channel? <eos> I am trying to find out when I subscribed to a certain YouTube channel. I don't think I did. I have searched and cannot find any way. Is there any way to learn when or how long I have been subscribed to a YouTube channel?",
    "target": "youtube"
  },
  {
    "id": "_unix.270961",
    "source": "How do I create and automatically sync a merged directory from multiple other directories without duplicating files? <eos> If I have some number of source directories, e.g. dir1, dir2... dir5, how can I create an automatically syncing merged destination directory that has all the files and directories of the source directories but doesn't involve duplicating files?For example, I have the following source directory structure...dir1/  - a  - bdir2/  - b   <-- Note the duplicate name, this one is more recent than dir1\\b  - c  - dir2.1/   <-- Subdirectories present too.      - zdir3/  - d... which when merged would look like this:merge/ - dir2.1/     - z - a - b   <-- Which one to show is based on modified time; most recent first. - c - d(Assume there could be dozens of directories with thousands of files and subdirectories.)All the files and directories in the source list should remain in place and unchanged and the merged destination directory should take up no addition storage; i.e. It's possibly just all symlinks managed by some daemon using inotify. The source directories are also having files and subdirectories added and removed frequently and this needs to be reflected, as soon as possible, in the merged directory too.Some usage examples:I create a new file, dir3/e, and it automatically and immediately (or within a few seconds) appears in the merge directory.I remove the file dir1/a and it automatically and immediately (or within a few seconds) disappears from the merge directory.I edit dir3/d by opening merge/dI call touch on dir1/b so it it has a newer modified date than dir2/b and so merge/b automatically updates to point to dir1/b as it is the most recent.I remove dir1/b and now merge/b will point to the older file dir2/b.I attempt to create a file in merge but get an error because doing so makes no sense!",
    "target": "linux;debian;directory"
  },
  {
    "id": "_codereview.31633",
    "source": "Writing an effective method that reflects good OO design and fixes this broke method <eos> I'm working on my personal project and have recently had a bit of trouble with a method I wrote during the week.This method compares user input from the same JComboBox. A before and after, if you will.  It then makes an appropriate adjustment to a 2nd ComboBox depending on the user's input into the first box. It took me a bit of effort to figure this out.  When I finally did, I was pretty happy with myself. Until I realized that the method uses a class variable and ruins any concept of good object-oriented design.    /**** missileBalancer compares the users input before and after selection and adjusts the contents of the OH missile count box as necessary.** @param JComboBox combobox is the combobox concerning the OP counts, JComboBox combobox1 is the combobox concerning the OH counts, prevOH is the masterOH count.** @return** @throws**/public void missileBalancer(JComboBox combobox, JComboBox combobox1, int prevOP){    int difference = 0;    int newOH = 0;    int newOP = (int) combobox.getSelectedItem(); //Current OP count    int oldOH = (int) combobox1.getSelectedItem();//Current OH count --Adjusting this by the appropriate amount is the goal of this method    int oldOP = prevOP;    //oldOP is the OP that we are testing against it needs to be set by the program into a var that we can use in our test.    if(newOP < oldOP){        oldPac3 = newOP;//We need to keep track of our count outside of the method.    }else if(newOP > oldOP){    difference = newOP - oldOP;     newOH = oldOH - difference;    combobox1.setSelectedItem(newOH);    if(newOH < 0){//You cannot set selected item to a jcombobox with a negative number so in all cases where newOH is less than zero we simply set the selected item to 0.        combobox1.setSelectedItem(0);    }    oldPac3 = newOP;        }}//End Missile BalancerThe problem is with the user of the oldPac3 variable. The method cannot always use this variable. I have variables for oldGemT and oldGemC, that this method needs to modify as appropriate. I can think of a couple ways to make this work, but I don't think any of them are very clean. I want the code for this method to be concise and elegant. Any help or some guidance in the right direction would be great.This is the rewritten method. It does what needs doing, but I think it is ugly. I'm posting it because I don't want to give the impression that I'm looking for other people to solve my problems for me. I really just want to write better code. /**** missileBalancer compares the users input before and after selection and adjusts the contents of the OH missile count box as necessary.** @param JComboBox combobox is the combobox concerning the OP counts, JComboBox combobox1 is the combobox concerning the OH counts, prevOH is the masterOH count.** @return** @throws**/public void missileBalancer(JComboBox combobox, JComboBox combobox1, int prevOP){    int difference = 0;    int newOH = 0;    int newOP = (int) combobox.getSelectedItem(); //Current OP count    int oldOH = (int) combobox1.getSelectedItem();//Current OH count --Adjusting this by the appropriate amount is the goal of this method    int oldOP = prevOP;    //oldOP is the OP that we are testing against it needs to be set by the program into a var that we can use in our test.    if(newOP < oldOP){        if(combobox.equals(pac_3OpCount)){        oldPac3 = newOP;//We need to keep track of our count outside of the method.        }        else if(combobox.equals(gemCOpCount)){            oldGemC = newOP;        }        else if(combobox.equals(gemtOpCount)){            oldGemT = newOP;        }    }else if(newOP > oldOP){    difference = newOP - oldOP;     newOH = oldOH - difference;    combobox1.setSelectedItem(newOH);    if(newOH < 0){//You cannot set selected item to a jcombobox with a negative number so in all cases where newOH is less than zero we simply set the selected item to 0.        combobox1.setSelectedItem(0);    }    if(combobox.equals(pac_3OpCount)){        oldPac3 = newOP;//We need to keep track of our count outside of the method.        }        else if(combobox.equals(gemCOpCount)){            oldGemC = newOP;        }        else if(combobox.equals(gemtOpCount)){            oldGemT = newOP;        }       }       }//End Missile Balancer",
    "target": "java;object oriented"
  },
  {
    "id": "_unix.128156",
    "source": "Remote syslog command line Client <eos> I use logger pretty regularly, but is there a FOSS command line tool for remote submission of syslog messages over the network? Right now, I have to configure a facility/priority pair to submit to a remote server on the rsyslogd side. I'd like to cut out the middleman and not have to modify my local syslog daemon's configuration. Does such a tool exist?",
    "target": "syslog;logger"
  },
  {
    "id": "_webapps.14066",
    "source": "Feedburner does not get links right <eos> Feedburner doesn't get my feed links right. I tried resyncing and pinging and everything at my disposal but it doesn't seem to work. Then I emailed my problem to feedburner-feedback@google.com and I got no response. I just can't stand to see my feed getting wrong links.e.g: http://www.codingtales.com/post/getting-started-with-mvvm is the link in the actual feed (http://www.codingtales.com/rss) while feedburner links go to http://www.codingtales.com/getting-started-with-mvvm.",
    "target": "feedburner"
  },
  {
    "id": "_softwareengineering.309419",
    "source": "What was the first mechanical Turing-complete machine ever constructed? <eos> We know that Charles Babbage designed the first Turing-complete mechanical machine - the Analytical Engine - in the 1800s, but it was never actually built (not yet anyway).In recent history, at least one mechanical Turing machine has been built.  (This example is in fact a Universal Turing Machine, albeit with finite storage space.) But was this the first one, or are there earlier examples?What was the first mechanical Turing-complete machine constructed, who built it and when?Edit: By mechanical, I mean no electronics are used.",
    "target": "history;computer architecture;turing completeness"
  },
  {
    "id": "_softwareengineering.150293",
    "source": "Where could Distributed Version Control Systems currently be in Gartner's hype cycle? <eos> Edit: Given the recent downvoting (+8/-6 at this point) it was made clear to me that Gartner's lifecycle is a biased metric from a programmer's perspective. This is something that is part of a paper I'm going to present to management, and management types are part of Gartner's audience. Giving DVCS exposure & enthusiasm (that could be deemed as hype, or at least attacked as such), think about the following question when reading this one: how could I use Gartner's hype cycle to convince management that DVCSs are ready (or ready-enough) for us, and that it is not just hypeJust asking if DVCSs is hype wouldn't be constructive, Gartner's hype cycle is a more objective instrument than just asking that (even if this instrument is regarded as biased). If you know any other instrument please, by all means, mention it.Edit #2: I agree that Gartner's Life Cycle is not for every technology, but I consider it may have generated enough buzz to be considered hype by some, so it maybe deserves to be at least evaluated/pondered as such by using this instrument in order to prove/disprove it to whatever degree. I'm an advocate of DVCS, BTW.Edit #3: Thanks for your answers. Bounty goes to Caleb for answering my question with detail and practical advise. Accepted answer goes to philosodad for providing another useful instrument and answering beyond my question.I'm doing research for a whitepaper I'm writing in favor of DVCS adoption at company and I stumbled upon the concept of social proof. I want to prove that the social proof of DVCS adoption is not necessarily cargo cult and doing further research I now stumbled upon Gartner's hype cycle which describes technology maturity in 5 phases.My question is: what could be an indicator of the current location of Distributed Version Control Systems (I mean git, mercurial, bazaar, etc. in general) at a particular phase in the hype cycle?... in other (less convoluted) words, would you say that currently expectations of DVCSs are a) starting, b)inflated, c)decreasing (disillusionment), d)increasing (enlightenment) or e)stabilizing (mature) and (more importantly) why?I know it is a hard question and there is subjectivity involved, but I'll grant the answer (and the traditional cookie) to the clearest argument/evidence for a particular phase.",
    "target": "research;dvcs;cvcs"
  },
  {
    "id": "_reverseengineering.2887",
    "source": "Detailed description of malware content <eos> I have just started my journey into the vast and intersting field of malware analysis. I would like to know if there is any website/book or another resource that explains what a particular block of assembly code does. A detailed description of the code would be well appreciated. I know assembly language to some extent and is familiar with all the concepts,function call procedure etc. But i have very little knowledge on how all these applies when it come to windows. like what happens when a dll is used,etc... I would be very glad if someone could tell me where to find a resource that provides a step by step detailed analysis of any malware or any program for that matter.I have already a considerable experience in reverse engineering windows applications, most of the knowledge been taken from the 'legend of r4ndom' and woodman websites. I need something that clearly explains how a particular assembly code interacts with windows dlls, resources like menu bars text boxes, etc..",
    "target": "malware"
  },
  {
    "id": "_unix.47038",
    "source": "Kickstart: one network card with DHCP, one with static IP? <eos> I am using Kickstart to automate a CentOS install. I wanted one of the interfaces to have static IP so I wrote -network --onboot yes --bootproto static \\        -ip=intended IP -netmask=intended netmask \\        -gateway=intented gateway --device eth0*I also wanted the other ethernet to have dynamic ip so i also configured a DHCP server for my network and for the other interface card wrotenetwork --onboot yes --device eth1 --bootproto dhcpBut to my surprise the ethernet to be configured static was also provided with dynamic IP. What is wrong here?",
    "target": "networking;centos;ip;kickstart"
  },
  {
    "id": "_unix.139085",
    "source": "Extract line number of a file which is having a non zero value before a specified string <eos> I'm having a file which contains following data1. verification: 10 passed 0 failed2. verification: 10 passed 0 failed3. verification: 10 passed 1 failed4. verification: 10 passed 3 failed5. verification: 10 passed 0 failedI want to know the line numbers of 3 and 4.",
    "target": "grep;string;numbering"
  },
  {
    "id": "_cstheory.20241",
    "source": "Given a CSL formula, how can we generate an automaton that accepts the formula? <eos> The problem is same as the title, given a Continous Stochastic Logic(CSL) formula how can we create a machine which accepts the formula? Any intuitive ideas or references will be appreciated. ",
    "target": "lo.logic;model checking"
  },
  {
    "id": "_computergraphics.2410",
    "source": "Cohen-Sutherland Clipping <eos> Specify individually the translation and scaling matrices required to transform a 2Dwindow of [Xmin=-234, Ymin=156] and [Xmax=66, Ymax=456] to a display viewportof [Umin=45, Vmin=35] and [Umax=245, Vmax=185].Ignore the question above since I solved the matrix, the information is just relevant for the question I'm stuck onI was asked to compute the view-port positions (U1,V1) and (U2,V2) for two points A (-100,300)and B (30,-40) in a 2D window and determine if these two points are inside the view-port.Based on the transformation Matrix I found (U1,V1) to be (403/3, 407) and (U2,v2) to be (221, -103). It turns out that both these points are outside our view-port but part of the line between them is inside.Now I'm confused about this part below:Apply a 2D clipping method to the line segment between the two points A and B asgiven in above.My Attemptdelta x = 221-(403/3) = 260/3delta y = -103 - 406 = -510m = delta y / delta x = -5.88I started with U1,V1 since it is above our viewport:Y = 185X = 403/3 + (185-407)*(delta x/ delta y)X = 279.48Point 1 - (172, 185) Is this correct? Since the point is now within the view-port. Do I then do the same for the second point?",
    "target": "clipping"
  },
  {
    "id": "_webmaster.88351",
    "source": "Do search engines follow the additionalType url in microdata? <eos> For example <div itemscope itemtype=https://schema.org/ExerciseAction>        <meta itemprop=additionalType content=http://www.productontology.org/id/Long-distance_running>    </div>If so, which vocabulary(?) is more descriptive?productontology.orgdbpedia.orgwikipedia.org ?",
    "target": "seo;html5;microdata;schema.org"
  },
  {
    "id": "_unix.261123",
    "source": "Command to skip process if file exists <eos> I have been using a for loop to run a pipeline for multiple files but unfortunately the terminal froze halfway. I would like to run the pipeline again but because of time I would like to skip the directories that already has the output files created. Basically nest a if statement - if file output file exists, ignore if not run pipeline. Is this possible?for f in /Volumes/My\\ Passport/Documents/Projects/untitled\\ folder\\ 2/untitled\\ folder\\ 3/untitled\\ folder\\ 2/untitled\\ folder/*/*_1.fastq; dosubdir=${f%/*}pushd $subdir &>/dev/nullfile1=${f##*/}file2=${file1%_1.fastq}_2.fastqadapter=/Volumes/My\\ Passport/Documents/adapters.fareference=/Volumes/My\\ Passport/Documents/ucsc_hg19/ucsc.hg19.fastadbSNP=/Volumes/My\\ Passport/Documents/ucsc_hg19/dbsnp_138.hg19COSMIC=/Volumes/My\\ Passport/Documents/ucsc_hg19/CosmicCodingMuts.vcfinterval=/Volumes/My\\ Passport/Documents/plist.bedsjdb=/Volumes/My\\ Passport/Documents/ucsc_hg19/ucsc.hg19.gtffile3=${file1%_1.fastq}_1_trimmed.fastqfile4=${file2%_2.fastq}_2_trimmed.fastq#preQC (cutadapt -O subtracted, prinseq -min_qual_score 4 -ns_max_p 2 subtracted)~/Desktop/UTSW/Applications/bbmap/bbduk.sh -Xmx120g in1=${file1} in2=${file2} out1=${file1%_1.fastq}_1_trimmed.fastq out2=${file2%_2.fastq}_2_trimmed.fastq ref=${adapter} trimq=10paste - - - - < ${file3} | sort -k1,1 -t   | tr \\t \\n > ${file3%_1_trimmed.fastq}_trimmed_sorted_1.fastqpaste - - - - < ${file4} | sort -k1,1 -t   | tr \\t \\n > ${file4%_2_trimmed.fastq}_trimmed_sorted_2.fastqparallel -j $PARALLEL_TASKS perl ~/UTSW/Applications/prinseq-lite-0.20.4/prinseq-lite.pl -fastq ${file3%_1_trimmed.fastq}_trimmed_sorted_1.fastq -fastq2 ${file4%_2_trimmed.fastq}_trimmed_sorted_2.fastq -no_qual_header -trim_right 1 -custom_params A 75%;T 75%;G 75%;C 75% min_qual_mean 25 -min_len 40 -out_format 3 -out_good ${f%.*}_QC -out_bad null -logdone",
    "target": "bash;scripting;macintosh"
  },
  {
    "id": "_cs.71434",
    "source": "Numbering of computable functions <eos> Is there a numbering (not Gdel numbering) of all computable functions $U(p, x)$, such that the set of numbers of functions defined in zero is exactly the set of even numbers. More formally: $I = \\{p,\\ |\\ U(p, 0)\\  \\mathrm{defined}\\} = 2\\mathbb{N}$.My guess that it's true. But I'm not sure how to prove it.Ideas:We can construct a numbering of all computable functions, defined in zero using the function $F(p, x, t)$ which is equal to $0$ if $U(p, x)$ hasn't finished work in $t$ steps and $1$ in other case. We can do it because set of pairs $(p, t)$ is enumerable.Then, having this function $V(p, x)$ and some other numbering $U(p, x)$ we can construct numbering$$U'(p, x) = \\begin{cases}V(\\frac{p}{2}, x)\\ \\ if\\ p \\vdots 2\\\\U(\\frac{p + 1}{2}, x)\\ \\ if\\ p \\not\\vdots 2\\end{cases}$$",
    "target": "computability;discrete mathematics"
  },
  {
    "id": "_opensource.2456",
    "source": "What is copyleft? <eos> Straight up: I've never heard of the term 'copyleft' before. The fact that I get that little red squiggle under it tells me it's not really a word. Concisely, my question is, what does it mean to you? I saw it tagged on a few questions so I read the tag description:For questions about the copyleft concept (also known as Share-Alike), a concept that promotes or enforces the use of the same or compatible license for derived works.And I read the Wikipedia page on it. My understanding is that copyleft has attributes of Share-Alike but the author must disclose any other terms alongside it. To me, it seems like a bit of a useless term. Why describe it as copyleft if you need to add a licence to it anyway? Would you not be better off describing it as copyright with already-agreed-upon licenses? Otherwise it's only another word for Share-Alike. ",
    "target": "copyleft;terminology"
  },
  {
    "id": "_codereview.151188",
    "source": "Composed Architecture <eos> When refactoring and old class in PHP, I noticed that it contained a lot of business logic and thus was not allowing code reuse. So I thought about composition in order to achieve horizontal code reuse (since inheritance permits only vertical reuse) and the possibility to do Dependency Injection eventually. DI gives then the possibility to use Mock Services in order to test the classes.Basically, that class permits sending SMS using the API of a third-party and we have hundreds of APIs we need to deal with, so this is why the idea of horizontal code reuse would be useful.When we send an SMS, we need to:Send an HTTP request to some URL provided by the Carrier with the right body contents (phone number, SMS title, SMS content and other information, depending on the carrier) and in the right format (XML, JSON, SOAP, depending on the carrier)Log the sent SMS*in the database (phone number, title, contents, delivery_status). The table where it is logged is used for tracking all sent SMSses. Also, we attach a delivery_status code (1 for delivered, -1 for not delivered) because some carriers send us then a Delivery Report (by requesting a script on our end) if the phone acknowledges the delivery.Log the sent SMS specifically for that Carrier in another dedicated table that contains more fields than (phone_number, title, message, delivery_status). Those fields could be used in the future for special purposes.I decided to separate the logic in mainly three classes:LoggerService: Class that logs the sent sms informations in the database (also logs the carrier-specific sent sms informations)RequestMaker: Trait that simply makes HTTP requests and returns the result without any further processingSerializerService: Service that serializes the body of the request (converts from a dictionary of parameters to a specific format required  by the carrier like XML or JSON, etc.). XMLBodySerializer is one implementation of that service. JsonBodySerializer is another.SmsSender: The core class that is using the RequestMaker trait and the two other services in order to perform an API call to the specific carrier's API. If a carrier named MyCarrier exists, we would have a MyCarrierSender class inheriting SmsSender. The main task of that class would be to build the right request body and to pass it to the serializer, then to the request maker which will call the API. Finally, the class should fill the sent SMS DTO that will the be logged using the LoggerService currently in use.Do you think it is a good idea to adopt this design? In other words, does it meet the goals of:Decoupling business logicCode reusingPermitting testabilityHere is an implementation of the architecture:interface SmsSender {    public function initServices(        ILoggerService $resultLoggerService, // That Logs information about sent SMS in the databse        IBodySerializer $serializerService, // Request Body Serializer        );    public function sendText(        $msisdn,        $title=,        $text=,        $options=array());}trait RequestMaker {    public function makeGet($url, $params=array());    public function makePost($url, $params=array(), $body);    public function buildUrl($url, $params=array());    public function request($url, $method=null, $params=array(), $body=array());}interface IResultLoggerService {    // Logs the SMS sent to the database    public function logResult($sms2Dto);    // Logs sent SMS specific informations for that Carrier    public function logInMt($specificMtDto);}/*** Request Body Serializer (XMLBodySerializer, JSONBodySerializer implements it) that serializes the body of the request*/interface IBodySerializer {    public function serialize($data);    public function parse($response);}/** *  Example of an SMS Sender for a specific Carrier*/class MyCarrierSmsSender implements SmsSender {   use RequestMaker;   public function __construct() {        $this->initServices(            new MyCarrierLoggerService(),            new XMLBodySerializer() // Will use XML for communication with the carrier's API        );    }    protected function preSend($msisdn, $title, $text, $options) {        /**        * Performs some verifications, prepares some variables        * ....        */        // Example :        $sentSms = new Sms2Dto();        $sentSms->setMsisdn($msisdn);        // etc.        $this->setSms2(); // Set the Sent SMS DTO    }    public function sendText($msisdn, $title, $body, $options = array()) {        $this->preSend($msisdn, $title, $body, $options);        $data = {             // .... prepare request data        }        // Serialize data using the injected service        $raw_data = $this->getSerializerService()->serialize($data);        // Call request() from the RequestMaker trait        $raw_result = $this->request($url, array(), $raw_data, POST);        // Deserialize API's response         $result= $this->getSerializerService()->parse($raw_result);        // Interprets API's response and returns a SUCCESS or FAIL status code        $status = $this->interpretResult($result);        $this->postSend($status);        return $status;    }    protected function postSend($status) {        if($status == SUCCESS) {              // Log sent SMS              $this->getLoggerService()->logResult($this->getSms2Dto());              // Log specific sent SMS by this carrier (contains more useful and specific info to that carrier)              $this->getLoggerService()->logInMt($this->getMtDto());         }    }}There are also DTOs: Sms2Dto and {Carrier}MtDto for every Carrier.Before that design, everything here was done in one class. There was a class for each carrier so a lot of code was repeated.",
    "target": "php;design patterns"
  },
  {
    "id": "_unix.366506",
    "source": "Diff between a string and a file <eos> Basically I want to check the difference of the same file before and after a sedTried to run:diff /opt/postTrades.sh <<< $(sed 's/1\\ MIN/10\\ MIN/g' /opt/postTrades.sh)anddiff <<< $(sed 's/1\\ MIN/10\\ MIN/g' /opt/postTrades.sh) < /opt/postTrades.sh anddiff <<< (sed 's/1\\ MIN/10\\ MIN/g' /opt/postTrades.sh) < /opt/postTrades.shAlways getting:diff: missing operand after '/opt/postTrades.sh'diff: Try 'diff --help' for more information.What's the correct way to do it?Thanks.",
    "target": "diff;here document;here string"
  },
  {
    "id": "_softwareengineering.234532",
    "source": "Mobile IOS Application to Server interaction design? <eos> I've built a set of what will be server-side programs in python. Essentially they crawl the net and index news articles.The iOS mobile application will be what the user interacts with. So it needs to query the server somehow to get the results back. I.e. if the user types in 'Google' or 'GOOG' it will return news articles concerning Google.I'm assuming the server needs to be sent the query, the server produces the results by going over the hosted data and then sends it back, but how does it all work?I'm looking for a set of basic design principles for this sort of thing. Although if you would like to give a breakdown that would be even better.",
    "target": "server;mobile;search engine"
  },
  {
    "id": "_unix.267890",
    "source": "Can't get user $HOME over su on Solaris and AIX <eos> I'm trying to get user $HOME variable over su. Solaris# su oracle$ echo $HOME/rootAIX# su oracle$ echo $HOME/Linux# su oracle$ echo $HOME/home/oracleCan someone explain why on Solaris and AIX when I try to get $HOME variable it gets the root's $HOME directory?UPDATEUsing login with with - or -l works, but I can't use su - on my script. Any thoughts on how to overcome this?I was trying to not use a solution like the above but I'm getting out of optionscat /etc/passwd | grep oracle | cut -d: -f 6or as Thomas suggested:cat /etc/passwd | awk -F: '$1 ~ /^'oracle'$/ {print $6;}'",
    "target": "solaris;aix;su"
  },
  {
    "id": "_webmaster.63131",
    "source": "How can I see in Google Analytics where my users came from? <eos> I am using Google Analitics and struggling to find where my users came from. I can see demographics (country / city) information, but struggling to find what site have they came from.I found this answer:From your dashboard on the left side clickTraffic SourceSources All TrafficBut can not see this on my left side. It hasDashboardsShortcutsIntelligence EventsReal-TimeAudienceAcquisitionBehaviorConversionsCan someone help me?",
    "target": "google analytics;referrer"
  },
  {
    "id": "_unix.179590",
    "source": "Merge two csvfiles by column header <eos> I have two csv files:success.csvID,Legacy ID,Field1, Field21,1111,google,news2,2222,yahoo,newserror.csvLegacy ID,Field1,Field2,Message3333,aol,news,Failed to upload data    4444,cbs,news,Alredy existsHow can I merge these two files and create a new file as shown below? I cannot use indexes as the size and order of fields will keep changing.results.csvID,Legacy ID,Message1,1111,2,2222,,3333,Failed to upload data,4444,Alredy existsThe requirement is to create the results.csv file with only three columns from both success.csv and error.csv.If the row is successfully loaded then we get ID in the success file as the first column with no Message ColumnIf it's failed we get an error in the Message field which is always the last field in the file. In this case the ID will be empty.Read the values from success.csv as follows:awk '{print $1, $2;}' success.csvRead the values from error.csv as follows:awk '{print $1, NF;}' error.csvI am not able to figure out a way to combine both the statements and write the result to a file.",
    "target": "command line;text processing;scripting;awk;csv"
  },
  {
    "id": "_softwareengineering.159243",
    "source": "What is volume in terms of databases? <eos> I was reading a text. It said,Information presentation must be compatible with the response time needs of systems. The response time should be short enough that the information  does not lose its freshness and value but it should be long enough to reduce volume (and costs) and reveal important trends that signal the need for actionWhat does volume mean in it? Please help out. Thanks",
    "target": "database"
  },
  {
    "id": "_unix.46004",
    "source": "printing problems with DDST (aka PCL6) printer RICOH Aficio SP C240DN <eos> I'm having big problems printing on a RICOH Aficio SP C240DN (a color laser printer). CUPS/OpenPrinting doesn't have a driver for exactly this printer. There are similar numbers but not 240DN. It also seems there is no PPD file for this printer, as it doesn't accept PostScript at all. There are only so-called DDST and ICM drivers for Windows and Mac, but no PPD as opposed to slightly older models from RICOH (320DN for example). The technician at the company where I bought the printer said that DDST is a stripped-down version of PCL6.The connection to the printer works, I can access the web interface for management, I can print test pages via buttons on the printer or via the web interface. If I try any other driver (320DN for example), the printer shows that it is receiving data, the spool on the computer is processing, and then it just thinks the job is finished and done but the printer does nothing.I'm planning to return it, but was wondering if somebody could explain a bit about drivers (what is DDST?), and if somebody knows if there is any chance that such driver for Linux will be out in any time soon.I'm actually ready to donate a small amount to somebody who would hack an open-source driver (for CUPS).",
    "target": "printing;cups;postscript"
  },
  {
    "id": "_softwareengineering.301764",
    "source": "Is this code structure beneficial in any way? <eos> I was recently thrown into a Java web application project, and Ive come across a number of classes that follow this type of format:public class MyThingy {   private final int p1;   private final String p2;      public MyThingy (int p1, String p2, ) {      this.p1 = p1;      this.p2 = p2;         }   public static void doSomething(int p1, String p2, ) throws Throwable     {      final MyThingy myThingy = new MyThingy(p1, p2, );      myThingy.execute();   }   private void execute() throws Throwable {      //do stuff    }}It seems like this could be accomplished with the following code, which to me seems way easier to read.public class MyThingy {   public static void doSomething (int p1, String p2, ) throws Throwable {      //do stuff    }}The only possible benefit I can see from doing it the first way, is that if you had to break up execute() into smaller pieces, they could all share the initial parameters without having to explicitly pass them around.  But this maybe only benefits the lazy coder, as it becomes difficult for the reader to tell which methods need which parameters and when the values might be changed (akin to global variables.)Is there something I'm missing? Threading, performance?Edit:I should have mentioned, although the constructor is public, it is not called.  The only usage is like this:MyThingy.doSomething(p1, p2...);Aside from this in itself being problematic for testing, I can't see any reason not to put the logic of execute() directly into doSomething().  Even if we were to get rid of the static function, the constructor still doesn't make sense to me; I think the parameters should be passed directly to the method that will use them.",
    "target": "java;coding style"
  },
  {
    "id": "_unix.238741",
    "source": "Recommended method for shared data store writeable by all users <eos> I have a few users sharing a computer and accessing content (pictures, audio, video recordings etc) that other users save. I need a shared drive for this content. File permissions, access control or overwriting is not an issue - just need a simple method to share files, in fact, without worrying about ownership and read-write privileges.I used to have a hard-drive partition that was formatted NTFS which so far served this purpose, but I am getting tired to having to run chkdsk every now and then so am looking for a solution that is more native to Linux.Unlike this question, this is not about the path of the directory, but about the way to implement the store - e.g., Filesystem, share configuration etc.,.This setting is required only for this shared folder- otherwise, these users and their (other) data needs to be kept private like in any standard Linux installation.",
    "target": "linux;filesystems"
  },
  {
    "id": "_softwareengineering.223714",
    "source": "Is there any specific reason to use else if clause? <eos> We all use if ..else if.. else.But still I'm confused as to why we use else if. Where if does the same thing as else if.So why are we using else if?Any specific reasons behind this?Is there any algorithm where it's mandatory to use else if?",
    "target": "programming languages;algorithms"
  },
  {
    "id": "_codereview.148436",
    "source": "Validator Class in PHP <eos> I am trying to create a validation class that can be used to validate many forms of my webpage in general. It makes use of the database as well to verify records. The problem with it is that it looks bad and somewhat inefficient. I couldn't find any alternatives and I have used too many if-else if statements. And also dob makes use of an arbitrary variable. Overall the code seems bad, I know. But I couldn't find an alternative. Any help is extremely appreciated. I would also be happy if you could comment on the design and efficiency. I am willing to rewrite the whole code needed. This works, but it's all messed up. Thanks!    Class Validate {    //Take the user input into the data put it to a class.    protected $data; //Function argument    private $err; // boolean        protected $empty;     private $error;    private $clean;    private $query;    public function __construct() {         $this->query= new DBhandler();    }    private function basicSanitize($data) { //Basic level input santization to be used by other functions only.        $data=htmlspecialchars($data,  ENT_QUOTES);        $data=trim($data);            return $data;    }    public function sanitize($data) { // Sanitization at a massive level to sanitize a lot of inputs at one go.        foreach ($data as $k =>$v) {            $data[$k]= $this->basicSanitize($v);        }        return $this->clean=$data;    }    public function showError($type,$data) {        return $this->error[$type.$data];    }    private function basicEmptyCheck($data) {        if($data==|| empty($data) || !isset($data) || $data==-1) {            return true;        }    }    public function isEmpty($data) {        foreach ($data as $k =>$v) {            if($this->basicEmptyCheck($v)){                $this->error['empty']=There is an empty field;                return true;            }        }    }    private function checkLength($data,$min,$max) {        if(strlen($data)>=$min && strlen($data)<=$max) {            return true;        }    }    private function lengthErr($data,$min,$max) {        if(strlen($data)>$max) {            return too long;        }        else if (strlen($data)<$min) {            return too short;        }    }    public function name($data) {        if(!$this->checkLength($data,3,100)) {            $this->error['name'.$data]=Name .$this->lengthErr($data,3,100);        }        else  if(!preg_match(/^[a-zA-Z ]+$/,$data)) {            $this->error['name'.$data] = Please don't include special characters in names;        }        else return true;    }    private function isUniqueEmail($data) {        $sql= SELECT stuff1 FROM tablename WHERE stuff2=?;        if(!$this->query->checkIfExists($sql, s, 'jells')) {            return true; //the value set here jells is for testing purposes only. This will be replaced by $data        }    }    public function email($data) {        if (!$this->checkLength($data,8,254)) {            $this->error['email'.$data]= Enter a valid email;        }        else if (!filter_var($data, FILTER_VALIDATE_EMAIL)) {            $this->error['email'.$data] = Enter a valid email;         }        else if (!$this->isUniqueEmail($data)) {            $this->error['email'.$data]= This email already exists;        }        else return true;    }    public function password($data) {        if (!$this->checkLength($data,8,128)) {            $this->error['pass'.$data]='Password '.$this->lengthErr($data, 8, 128);        }        else if (count(array_keys($this->clean,$data))>1) {            $this->error['pass'.$data]='Password is too obvious';        }        else return true;            }    private function ageCheck($month,$day,$year,$limit) {        # object oriented        $date=$year.-.$month.-.$day;        $from = new DateTime($date);        $to   = new DateTime('today');        if($some=$from->diff($to)->y>=$limit) {            return 1;        }    }    public function age($data,$month, $day, $year,$limit) {        if(!is_numeric($day) || !is_numeric($month) || !is_numeric($year)) {            $this->error['age'.$data] = Please enter a valid date;        }        else if(!checkdate($month, $day, $year)){                    $this->error['age'.$data] = Please enter a valid date;        }        else if(!$this->ageCheck($month,$day, $year,$limit)) {            $this->error['age'.$data] = You must have a minimum of .$limit. of age to sign up;        }        else return true;    }    public function sex($data) {        if($data=='M' || $data=='F') {            return true;        }        else {            $this->error['sex'.$data]='Add a valid sex';        }    }    public function errorExists() {        if(isset($this->error)) {            return true;        }    }        }",
    "target": "php;validation"
  },
  {
    "id": "_scicomp.20624",
    "source": "Problems Implementing the Remez Algorithm <eos> So first off:*** This code is not being used in production software.It is a personal project of mine, trying to understand approximation theory and advanced curve fitting.  In other words, I'm trying to understand how it works, not trying to get a currently existing solution.So I have been trying to implement the Remez algorithm for polynomial approximation.I sort of/maybe/kind of have it working (not really).My current solution generate ok polynomials, but a)  the coefficients are not converging&b)  while monitoring the coefficients at each stage, I've noticed that the x-values seem to slip past each other.I'll give some examples to show what I mean.My base function I'm trying to model is the square root function with a 4 degree polynomial on the domain [0.25, 1]Round 1X[0] = 0.25X[1] = 0.4X[2] = 0.55X[3] = 0.7X[4] = 0.85X[5] = 1Round 2X[0] = 0.25X[1] = 0.595076928220583X[2] = 0.493988453622788X[3] = 0.714333640596557X[4] = 1.14135676154991X[5] = 1Round 3X[0] = 0.25X[1] = 0.638393337463021X[2] = 0.63752199068821X[3] = 0.538600997945798X[4] = 1.07101841739164X[5] = 1Round 4X[0] = 0.25X[1] = 0.559423143598625X[2] = 0.560673538304964X[3] = 0.580378820375143X[4] = 1.04454592077508X[5] = 1So here's a look at my actual code.template <typename func_t>type_t MiniMax(size_t Degree, const type_t& LowerLimit, const type_t& UpperLimit, unsigned char Iterations, func_t F0, func_t F1, func_t F2){    // (C) Jacob Wells 2015    // This code is licensed under the BSD 3-Clause License    // http://opensource.org/licenses/BSD-3-Clause    if((Degree < 1) || (Iterations < 1))    {        return (type_t)NAN;    }    const type_t ONE(1), NEG1(-1), ZERO(0);    matrix_t<type_t> M(Degree + 2, Degree + 3);    vector<type_t> XVal;    type_t Delta, Sign, Pow, Err;    type_t D1, D2;    size_t I, J;    Delta = (UpperLimit - LowerLimit) / (Degree + 1);    XVal.resize(Degree + 2);    Coef.resize(Degree + 1);    Sign = ONE;    for(I = 0; I < (Degree + 2); I++)               // Generate our initial x-values    {        XVal[I] = (I * Delta) + LowerLimit;    }    do    {        Sign = NEG1;        for(I = 0; I < (Degree + 2); I++)        {            Pow = ONE;            M[I][Degree + 1] = Sign;            // Enters the alternating error sign            M[I][Degree + 2] = F0(XVal[I]);     // Enters the f(x) value            Sign *= NEG1;                                   for(J = 0; J <= Degree; J++)        // Evaluates the polynomial for each power            {                M[I][J] = Pow;                Pow *= XVal[I];             }        }        rref(Degree + 2, M);                    // Use Row Reduction Echelon Form to find the polynomial coefficients        Err = M[Degree + 1][Degree + 2];        for(I = 0; I <= Degree; I++)            // Copy the coefficients into the polynomial class' array        {            Coef[I] = M[I][Degree + 2];        }        if(Iterations > 1)        {            for(I = 1; I <= Degree; I++)        // Use Newton's method to find our new x-values            {                D1 = nth_deriv(XVal[I], 1) - F1(XVal[I]);                D2 = nth_deriv(XVal[I], 2) - F2(XVal[I]);                if((D1 != ZERO) && (D2 != ZERO))                {                    XVal[I] -= (D1 / D2);                           }            }        }    }while(--Iterations != 0);    return Err;} A quick little guide to some of my code:  F0, F1, & F2 are, respectively, the square root functions, it's first derivative, and it's second derivative.nth_deriv calculate the Nth Derivative of the current polynomial.rref reduces the Matrix to Row Reduction Echelon Formmatrix_t is a bare bones matrix class I came up with.Now I have done a lot of testing on these functions, and I haven't found a single error with them, so I feel very confident that the problem is in the MiniMax Function.EDIT: My barebones matrix classtemplate <typename type_t>class matrix_t{    public:    ~matrix_t() {}    matrix_t(size_t ColL, size_t RowL)    {        Arr.resize(ColL * RowL);        RowLen = RowL;    }    type_t* operator [] (size_t I)    {        return &Arr[I * RowLen];    }    const type_t* operator [] (size_t I) const    {        return &Arr[I * RowLen];    }    type_t At(size_t I)    {        return Arr[I];    }    private:    size_t RowLen;    vector<type_t> Arr;    matrix_t();    matrix_t(const matrix_t& m);    void operator = (const matrix_t& m);};",
    "target": "regression;approximation algorithms;polynomials;curve fitting"
  },
  {
    "id": "_computergraphics.1438",
    "source": "What is the state of art in geometric LOD in games? <eos> How do modern games do geometry level-of-detail for object meshes like characters, terrain, and foliage? There are two parts to my question:What does the asset pipeline look like? Do artists make a high-poly model which is later decimated? If so, what decimation algorithms are most popular? Are LOD meshes sometimes done by hand?How do engines transition between different object LODs at run time? Are there any smooth or progressive transitions?The answer might be different studios use different techniques. If so, please identify some of the most common practices. It would also be great if you could point me to whitepapers/slides that cover specific examples.",
    "target": "geometry"
  },
  {
    "id": "_unix.229476",
    "source": "Getting RE error: repetition-operator operand invalid on osx sed <eos> I'm copy a sed script form Ubuntu debian to osx but gettingRE error: repetition-operator operand invalidWhat is wrong?$ . sed_shorter_version_user_extensions_to_ruby.shsed: 22: ### DELETE whole lines ...: RE error: repetition-operator operand invalidInspecting 1 file......The script is:(I left the line numbers in in case the 22 means line 22).  1 sed '  2 ### DELETE whole lines  3 /\\/\\//d  4 /^$/d  5 ### CHANGE large chunks  6 s/^storedVars\\[/  def /  7 s/SAD/sad/  8 s/HAPPY/happy/  9 s/\\][[:space:]]*=[[:space:]]*/\\ 10     / 11 s/;/\\ 12   end\\ 13 / 14 ### CHANGE small chunks 15 s/css=// 16 s/link=// 17 s/label=// 18 ### CHANGE specific lines 19 ### Scoped corrections for clarity 20 /def insurance_expiration/ { 21   /expiration_month/ { 22     s/value=.*\\+1)/(Date.new + 1.month).strftime(%B)/ 23   } 24   /expiration_year/ { 25     s/value=.*FullYear())/(Date.new + 1.month).strftime(%Y)/ 26   } 27 } 28 ### Unable to combine these for the %B and %Y despite several tries mdd 9/13/2015 29 /Date.*new.*month/ { 30   s///g 31   s/%B/%B/ 32   s/%Y/%Y/ 33 } 34 /choose_submodel_text/ { 35   s/ \\] =/\\n    / 36 } 37 /email.*albert.*random/ { 38   s/(albert.*gmail\\.com)/Faker::Internet.email/ 39 } 40 ' Variables/user-extensions.js | awk ' 41 ### ADD Header and footer 42 BEGIN { print # page object methods; print module PageObject # Variable values } 43       { print } 44 END { print end } '> rspec_conversions/new_page_object_methods.rb 45 rubocop -a rspec_conversions/new_page_object_methods.rb",
    "target": "shell;debian;sed;osx"
  },
  {
    "id": "_webmaster.96735",
    "source": "Is meta name=verify-v1 essentially google webmaters verification meta? <eos> If a website uses meta name=verify-v1 within the head, does this mean they are using Google Webmaster tools? and is it associated with any other services?",
    "target": "google search console;meta tags"
  },
  {
    "id": "_cs.14343",
    "source": "Asymptotic approximation of a recurrence relation (Akra-Bazzi doesn't seem to apply) <eos> Suppose an algorithm has a runtime recurrence relation:$   T(n) = \\left\\{     \\begin{array}{lr}       g(n)+T(n-1) + T(\\lfloor\\delta n\\rfloor ) & : n \\ge n_0\\\\       f(n) & : n < n_0     \\end{array}   \\right.$  for some constant $0 < \\delta < 1$. Assume that $g$ is polynomial in $n$, perhaps quadratic. Most likely, $f$ will be exponential in $n$.How would one go about analyzing the runtime ($\\Theta$ would be excellent)? The master theorem and the more general Akra-Bazzi method do not seem to apply.",
    "target": "asymptotics;recurrence relation"
  },
  {
    "id": "_webapps.58164",
    "source": "Does verification that owner of domain undergo on Google ever expire? <eos> Recently I've logged into my Webmaster Tools and noticed that I still got verifications on some of the sites that I do not own anymore, for like several years already. It suddenly brought multitude of questions to my mind, for example there were sites that I did together with some ex-partners, that I do not communicate with anymore, because of personal reasons. Does this mean that they still own some rights to my sites from Googles point of view? Shouldn't verification auto expire at some point in time?",
    "target": "google apps;domain"
  },
  {
    "id": "_webapps.75862",
    "source": "Can Cognito form work offline and be embedded in iPad app? <eos> Can Cognito form work offline? I need a form that works both online and offline. When offline, user can still fill in the form. Data is stored in the app and be sent to database once the iPad is connected to internet again.Can Cognito form be embedded in iPad app?",
    "target": "cognito forms"
  },
  {
    "id": "_unix.59531",
    "source": "How to edit rpm's HEADER and NAME-VERSION-RELEASE <eos> Is there's a way or a tool that can modify the HEADER and the NAME-VERSION-RELEASE for an existing rpm without installing/rebuilding it?",
    "target": "package management;rpm"
  },
  {
    "id": "_webmaster.29908",
    "source": "Why was my site not aproved for AdSense? <eos> Our new site http://www.sulabhloan.com has failed to get approval for AdSense.Even though site look reasonably better we cant figure out what is the real issue for disapproval can somebody help regarding this?EMAIL WE GOT : We did not approve your application for the reasons listed below.Issues:Site does not comply with Google policiesFurther detail:Site does not comply with Google policies: We're unable to approve your  AdSense application at this time because we feel that your site does not  comply with Google AdSense policies or webmaster quality guidelines. It's  our goal to provide our advertisers sites that offer rich and meaningful  content, receive organic traffic, and allow us to serve well-targeted ads  to users. We believe that currently your site does not fulfill this  criteria.Please help us find out the real factor which caused disapproval.",
    "target": "google search console;google adsense"
  },
  {
    "id": "_softwareengineering.340053",
    "source": "Which principle is it to fetch only needed data? <eos> It often makes sense to fetch only what you need for example if I should display only 10 rows of data then I should not fetch the entire data set because it would waste resources for a large data set. A practical example is the SQL Limit keyword. select * from users order by added limit 10I wonder if we can connect that to a software principle. There is the keep-it-simple principle but maybe it is a case of rule of the least power but for data instead of programs?",
    "target": "principles;workload estimation"
  },
  {
    "id": "_unix.372213",
    "source": "Remote text mode terminal shell screen <eos> I know it is possible to have remote VNC screen on server and connect to it and see, what is happening there.Is it possible to have the same in text-mode shell?I would connect to remote machine with ssh, then connect to such remote screen and see, what my program does there?The general task is following:I have python script, that is scrapping the web. This script just prints what it does to stdout. Currently I am running the script in ssh terminal. From time to time I am switching to ssh window and see, how my script feels: either it is still working, or it is crashed with error report.But in this situation, if I reboot my machine or network disconnect, my ssh session will quit and all containin programs will stop.How to avoid this? How to have something like text-mode VNC?",
    "target": "ssh;background process"
  },
  {
    "id": "_unix.293167",
    "source": "PCI passthrough device memory access incorrect <eos> I have a wrlinux yocto system running on an Intel Haswell processor. Here we pass through a PCIe device (broadcom switch) to the VM, launched using qemu/kvm. The Guest is able to detect the device via config space and is allocating memory space based on BAR, but the device memory access seems incorrect. Perhaps the Guest Physical address mapping went wrong? Access doesn't fail, it returns invalid data. How to debug whether the DMA remapping to guest is properly setup or not?",
    "target": "memory;virtual machine;kvm;pci passthrough"
  },
  {
    "id": "_unix.164831",
    "source": "Unable to use yum repos whether with baseurl or mirrorlist in CentOS 6.5 <eos> Since a couple of days, I'm unable to retrieve repositories data with Yum, in my CentOS 6.5 server.I did yum clean all a dozen of times, it emptied all but didn't solved the problem.I tried to retrieve things by restricting to the single base repo :[base]name=CentOS-$releasever - Basemirrorlist=http://mirrorlist.centos.org/?release=$releasever&arch=$basearch&repo=osgpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-6yum --verbose update results in :Loading fastestmirror pluginLoading priorities pluginConfig time: 0.010Yum Version: 3.2.29Setting up Package SacksDetermining fastest mirrorsCould not retrieve mirrorlist http://mirrorlist.centos.org/?release=6&arch=x86_64&repo=os error was14: PYCURL ERROR 22 - The requested URL returned error: 403 ForbiddenError: Cannot find a valid baseurl for repo: baseAnd when I configure a baseurl instead of a mirrorlist, I get this : Loading fastestmirror pluginLoading priorities pluginConfig time: 0.010Yum Version: 3.2.29Setting up Package SacksDetermining fastest mirrorshttp://mirror.centos.org/centos/6/os/x86_64/repodata/repomd.xml: [Errno 14] PYCURL ERROR 22 - The requested URL returned error: 404 Not FoundTrying other mirror.Error: Cannot retrieve repository metadata (repomd.xml) for repository: base. Please verify its path and try againThe server pings mirror.centos.org and I can reach without any problem the mirrorlist and the repomd.xml in a web browser. Disabling the plugins changed nothing.The mirrorlist gives a 403 error and a baseurl 404... rpm -q --verify -f /etc/yum.repos.d/* results in : S.5....T.  c /etc/issue.......T.  c /etc/yum.repos.d/CentOS-Base.repo.......T.  c /etc/yum.repos.d/CentOS-Debuginfo.repo.......T.  c /etc/yum.repos.d/CentOS-Media.repo.......T.  c /etc/yum.repos.d/CentOS-Vault.repoS.5....T.  c /etc/issue.......T.  c /etc/yum.repos.d/CentOS-Base.repo.......T.  c /etc/yum.repos.d/CentOS-Debuginfo.repo.......T.  c /etc/yum.repos.d/CentOS-Media.repo.......T.  c /etc/yum.repos.d/CentOS-Vault.repoS.5....T.  c /etc/issue.......T.  c /etc/yum.repos.d/CentOS-Base.repo.......T.  c /etc/yum.repos.d/CentOS-Debuginfo.repo.......T.  c /etc/yum.repos.d/CentOS-Media.repo.......T.  c /etc/yum.repos.d/CentOS-Vault.repoS.5....T.  c /etc/issue.......T.  c /etc/yum.repos.d/CentOS-Base.repo.......T.  c /etc/yum.repos.d/CentOS-Debuginfo.repo.......T.  c /etc/yum.repos.d/CentOS-Media.repo.......T.  c /etc/yum.repos.d/CentOS-Vault.repo.......T.  c /etc/yum.repos.d/epel-testing.repo.......T.  c /etc/yum.repos.d/epel.repo.......T.  c /etc/yum.repos.d/epel-testing.repo.......T.  c /etc/yum.repos.d/epel.repole fichier /etc/yum.repos.d/isv:ownCloud:community.repo n'appartient  aucun paquetage.......T.  c /etc/yum.repos.d/jpackage.repole fichier /etc/yum.repos.d/jpackage.repo.rpmsave n'appartient  aucun paquetagen'appartient  aucun paquetage means doesn't belong to any package, in french...Those problems occur with whatever repo I enable/disable.",
    "target": "linux;centos;yum;rpm"
  },
  {
    "id": "_unix.294089",
    "source": "When is {a,b,c} expanded in bash, when is it not? <eos> A bash script that containsfor i in {a,b}-{1,2}; do  echo $i;doneprintsa-1a-2b-1b-2when executed. This is what I expected - as the {a,b} construct is expanded.However, when (another) script containsv={a,b}-{1,2}echo $vit prints{a,b}-{1,2}which is not what I expected. I expected it to print a-1 a-2 b-1 b-2. Obviously, the {a,b} construct is not expanded.I can make it expand like sov=$(echo {a,b}-{1,2})Based on these observations I have two questions: 1) when is the {a,b} construct expanded? 2) is $(echo {a,b}-{1,2}) the preferred way to trigger an expansion when required?",
    "target": "bash;brace expansion"
  },
  {
    "id": "_unix.42349",
    "source": "How to make `xargs` ignore child's exit and keep processing further <eos> I sometimes run long xargs jobs overnight and it is really annoying to discover in the morning that xargs died somewhere in the middle, for example because of a segmentation fault in one single special case, as happened this night.If even one xargs child is killed, it does not process any more input:Console 1:[09:35:48] % seq 40 | xargs -i --max-procs=4 bash -c 'sleep 10; date +%H:%M:%S {};'xargs: bash: terminated by signal 1509:35:58 309:35:58 409:35:58 2<Exit with code 125>Console 2:[09:35:54] kill 5601Can I somehow prevent xargs from stopping to process any more input once a child process dies and instead continue processing?",
    "target": "kill;xargs;signals"
  },
  {
    "id": "_unix.62809",
    "source": "Change library location <eos> I've got different versions of the Libnet library installed in different locations on the same system:whereis libnetlibnet: /usr/lib/libnet.la /usr/lib/libnet.a /usr/lib/libnet.so /usr/local/lib/libnet.la /usr/local/lib/libnet.a /usr/local/lib/libnet.so /usr/include/libnet.h /usr/include/libnet /usr/man/man3/libnet.3I have some problems with compiling a program that depends on these libnet libraries so I want to remove the usr/local/....-ones. Can you tell me how to do that, i.e, when I whereis libnet on the command line I want to not see the /usr/local/... references ?!Thank you!",
    "target": "linux"
  },
  {
    "id": "_codereview.138351",
    "source": "Wikipath stack in Java - Part II/IV - The implicit Wikipedia article graph <eos> This question is the continuation of the Wikipath stack series: the two classes that - given a Wikipedia article \\$A\\$ - return the lists of neighbour articles. The forward node expander return the list of articles to which \\$A\\$ links, and the backward node expander return the list of articles that link to \\$A\\$. Since both are available, we can perform a bidirectional search for a shortest path. Also, note that whenever given two terminal nodes (the source article \\$s\\$ and the target article \\$t\\$), and both the expander classes, we can construct implicitly the Wikipedia article graph. By implicit we mean that only needed nodes (articles) are actually generated.As an overview of the entire software stack, I repost the diagram:The part in this question is the WikipediaGraphNodeExpanders.Below is my code:AbstractWikipediaGraphNodeExpander.java:package net.coderodde.wikipedia.graph.expansion;import com.google.gson.JsonArray;import com.google.gson.JsonObject;import com.google.gson.JsonParser;import java.io.IOException;import java.io.UnsupportedEncodingException;import java.net.URL;import java.net.URLEncoder;import java.nio.charset.Charset;import java.util.ArrayList;import java.util.HashMap;import java.util.List;import java.util.Map;import java.util.Objects;import java.util.regex.Pattern;import net.coderodde.graph.pathfinding.uniform.delayed.AbstractNodeExpander;import org.apache.commons.io.IOUtils;/** * This abstract class specifies the facilities shared by both forward and  * backward node expanders. *  * @author Rodion rodde Efremov * @version 1.6 (Aug 6, 2016) */public abstract class AbstractWikipediaGraphNodeExpanderextends AbstractNodeExpander<String> {    protected static final Map<Character, String> ENCODING_MAP =             new HashMap<>();    static {        ENCODING_MAP.put(' ', _);        ENCODING_MAP.put('', %22);        ENCODING_MAP.put(';', %3B);        ENCODING_MAP.put('<', %3C);        ENCODING_MAP.put('>', %3E);        ENCODING_MAP.put('?', %3F);        ENCODING_MAP.put('[', %5B);        ENCODING_MAP.put(']', %5D);        ENCODING_MAP.put('{', %7B);        ENCODING_MAP.put('|', %7C);        ENCODING_MAP.put('}', %7D);        ENCODING_MAP.put('?', %3F);    }    /**     * The script URL template for expanding forward.     */    private static final String FORWARD_REQUEST_API_URL_SUFFIX =             ?action=query +            &titles=%s +             &prop=links +             &pllimit=max +             &format=json;     /**     * The script URL template for expanding backwards.     */    private static final String BACKWARD_REQUEST_API_URL_SUFFIX =             ?action=query +            &list=backlinks +            &bltitle=%s +             &bllimit=max +             &format=json;    /**     * The pattern for Wikipedia URLs.     */    private static final Pattern WIKIPEDIA_URL_PATTERN =             Pattern.compile(^(https://|http://)?..+\\\\.wikipedia.org/wiki/.+$);    /**     * The HTTPS protocol prefix.     */    private static final String SECURE_HTTP_PROTOCOL_PREFIX = https://;    /**     * The HTTP protocol prefix.     */    private static final String HTTP_PROTOCOL_PREFIX = http://;    /**     * The <tt>wiki</tt> directory token.     */    private static final String WIKI_DIR_TOKEN = /wiki/;    /**     * The API script path.     */    private static final String API_SCRIPT_NAME = /w/api.php;    /**     * Caches the basic Wikipedia article URL. For example, the basic URL of      * <tt>https://en.wikipedia.org/wiki/Disc_jockey</tt> is     * <tt>en.wikipedia.org</tt>.     */    protected final String basicUrl;    /**     * Caches the textual representation of the URL pointing to the      * <a href=https://www.mediawiki.org/wiki/API:Main_page>Wikipedia API</a>.     */    private final String apiUrl;    /**     * Constructs a graph node expander for the language subgraph specified in     * the input URL.     *      * @param wikipediaUrl the entire Wikipedia article URL.     */    protected AbstractWikipediaGraphNodeExpander(String wikipediaUrl) {        final String originalWikipediaUrl = wikipediaUrl;        Objects.requireNonNull(wikipediaUrl,                               The input Wikipedia article is null.);        if (!WIKIPEDIA_URL_PATTERN.matcher(wikipediaUrl).matches()) {            throw new IllegalArgumentException(                    [INPUT ERROR] The input URL is not a valid Wikipedia  +                    article URL: \\ + originalWikipediaUrl + \\.);        }        wikipediaUrl = removeProtocolPrefix(wikipediaUrl);        if (wikipediaUrl.contains(://)) {            throw new IllegalArgumentException(                    [INPUT ERROR] The input URL specifies unknown protocol:  +                    \\ + originalWikipediaUrl + \\.);        }        this.apiUrl   = constructAPIURL(wikipediaUrl);        this.basicUrl = wikipediaUrl.                        substring(0, wikipediaUrl.indexOf(WIKI_DIR_TOKEN));    }    /**     * Returns the raw Wikipedia URL. For example, for      * <tt>https://en.wikipedia.org/wiki/Disc_jockey</tt>, this method will      * return <tt>en.wikipedia.org</tt>. This is used for making sure that a      * particular language (<tt>en</tt> in the example above) is selected.     *      * @return the basic Wikipedia URL.     */    public String getBasicUrl() {        return basicUrl;    }    /**     * {@inheritDoc }     */    @Override    public boolean isValidNode(final String node) {        return !expand(node).isEmpty();    }    /**     * Constructs a Wikipedia API URL from the raw {@code wikipediaUrl}. The     * input {@code wikipediaUrl} is of the form <tt>en.wikipedia.org</tt>. The     * idea here is that the search may be applied to article subgraphs with      * different languages.     *      * @param wikipediaUrl the Wikipedia URL.     * @return full URL to Wikipedia API.     */    private String constructAPIURL(final String wikipediaUrl) {        return SECURE_HTTP_PROTOCOL_PREFIX +               wikipediaUrl.substring(0, wikipediaUrl.indexOf(WIKI_DIR_TOKEN)) +               API_SCRIPT_NAME;    }    /**     * If the input string {@code url} has a prefix http:// or https://,      * removes it from the URL and returns the URL.     *      * @param url the URL to process.     * @return the URL without the protocol selector.     */    private String removeProtocolPrefix(final String url) {        if (url.startsWith(SECURE_HTTP_PROTOCOL_PREFIX)) {            return url.substring(SECURE_HTTP_PROTOCOL_PREFIX.length());        }        if (url.startsWith(HTTP_PROTOCOL_PREFIX)) {            return url.substring(HTTP_PROTOCOL_PREFIX.length());        }        return url;    }    /**     * The actual implementation of the method producing the neighbors of a      * graph node.     *      * @param node    the node to expand.     * @param forward specifies the direction of the node expansion operation.     *                if {@code forward} is {@code true}, generates the child     *                nodes of {@code node}. Otherwise, generates the parent      *                nodes of {@code node}.     * @return      */    protected List<String> baseGetNeighbors(final String node,                                            final boolean forward) {        String jsonDataUrl;        try {            jsonDataUrl =                     apiUrl + String.format(forward ?                                                FORWARD_REQUEST_API_URL_SUFFIX :                                                BACKWARD_REQUEST_API_URL_SUFFIX,                                           URLEncoder.encode(node,                                                             UTF-8));        } catch (final UnsupportedEncodingException ex) {            throw new IllegalStateException(ex.getMessage(), ex);        }        String jsonText;        try {            jsonText = IOUtils.toString(new URL(jsonDataUrl),                                        Charset.forName(UTF-8));        } catch (final IOException ex) {            throw new IllegalStateException(                    [I/O ERROR] Failed loading the JSON data from the  +                    Wikipedia API:  + ex.getMessage(), ex);        }        return forward ?                extractForwardLinkTitles(jsonText) :                extractBackwardLinkTitles(jsonText);    }    /**     * Returns all the Wikipedia article titles that the current article links      * to.     *      * @param jsonText the data in JSON format.     * @return a list of Wikipedia article titles parsed from {@code jsonText}.     */    private static List<String> extractForwardLinkTitles(String jsonText) {        List<String> linkNameList = new ArrayList<>();        JsonArray linkNameArray;        try {            JsonObject root = new JsonParser().parse(jsonText).getAsJsonObject();            JsonObject queryObject = root.get(query).getAsJsonObject();            JsonObject pagesObject = queryObject.get(pages).getAsJsonObject();            JsonObject mainObject  = pagesObject.entrySet()                                                .iterator()                                                .next()                                                .getValue()                                                .getAsJsonObject();            linkNameArray = mainObject.get(links).getAsJsonArray();        } catch (NullPointerException ex) {            return linkNameList;        }        linkNameArray.forEach((element) -> {            int namespace = element.getAsJsonObject().get(ns).getAsInt();            if (namespace == 0) {                String title = element.getAsJsonObject()                                      .get(title)                                      .getAsString();                linkNameList.add(encodeWikipediaStyle(title));            }        });        return linkNameList;    }    /**     * Returns all the Wikipedia article titles that link to the current     * article.     *      * @param jsonText the data in JSON format.     * @return a list of Wikipedia article titles parsed from {@code jsonText}.     */    private static List<String> extractBackwardLinkTitles(String jsonText) {        List<String> linkNameList = new ArrayList<>();        JsonArray backLinkArray;        try {            JsonObject root = new JsonParser().parse(jsonText).getAsJsonObject();            JsonObject queryObject = root.get(query).getAsJsonObject();            backLinkArray = queryObject.get(backlinks).getAsJsonArray();        } catch (NullPointerException ex) {            return linkNameList;        }        backLinkArray.forEach((element) -> {            int namespace = element.getAsJsonObject()                                   .get(ns)                                   .getAsInt();            if (namespace == 0) {                String title = element.getAsJsonObject()                                      .get(title)                                      .getAsString();                linkNameList.add(encodeWikipediaStyle(title));            }        });        return linkNameList;    }    /**     * Encodes some special characters using percent encoding.     *      * @param s the string to encode.     * @return the encoded version of {@code s}.     */    private static String encodeWikipediaStyle(final String s) {        final StringBuilder sb = new StringBuilder();        for (final char c : s.toCharArray()) {            String encoder = ENCODING_MAP.get(c);            if (encoder != null) {                sb.append(encoder);            } else {                sb.append(c);            }        }        return sb.toString();    }}ForwardWikipediaGraphNodeExpander.java:package net.coderodde.wikipedia.graph.expansion;import java.util.List;/** * This class implements a forward node expander in the Wikipedia article graph. * If article <tt>A</tt> has a link to <tt>B</tt>, this expander will generate * <tt>B</tt> whenever asked to process <tt>A</tt>. We can say that this  * expander traverses each directed arc from tail to head. *  * @author Rodion rodde Efremov * @version 1.6 (Aug 6, 2016) */public class ForwardWikipediaGraphNodeExpander extends AbstractWikipediaGraphNodeExpander {    public ForwardWikipediaGraphNodeExpander(final String wikipediaUrl) {        super(wikipediaUrl);    }    @Override    public List<String> expand(String node) {        return baseGetNeighbors(node, true);    }}BackwardWikipediaGraphNodeExpander.java:package net.coderodde.wikipedia.graph.expansion;import java.util.List;/** * This class implements a backward node expander in the Wikipedia article  * graph. If article <tt>A</tt> has a link to <tt>B</tt>, this expander will generate * <tt>A</tt> whenever asked to process <tt>B</tt>. We can say that this  * expander traverses each directed arc from head to tail. *  * @author Rodion rodde Efremov * @version 1.6 (Aug 6, 2016) */public class BackwardWikipediaGraphNodeExpander extends AbstractWikipediaGraphNodeExpander {    public BackwardWikipediaGraphNodeExpander(final String wikipediaUrl) {        super(wikipediaUrl);    }    @Override    public List<String> expand(final String node) {        return baseGetNeighbors(node, false);    }}DemonstrationYou can see the expanders in action at https://wikipath.herokuapp.com/Critique requestI want to improve anything there is to improve, yet I don't see myself any opportunity for that, so tell my anything that comes to mind.Component list so farWikipediaGraphNodeExpandersDelayedGraphSearchLibrary",
    "target": "java;json;graph;web scraping;pathfinding"
  },
  {
    "id": "_codereview.172029",
    "source": "Find all combinations of a number sequence which is first increasing then decreasing <eos> Given an integer N(Natural Number), A program/Algorithm to find the  remainder of arrangements that can be obtained by rearranging the  numbers 1, 2, ...., N. Input Format: One line containing the integer N Output Format: An integer m, giving the remainder of the number of  arrangements that could be obtained from 1, 2, ...., N is divide  by Mod Constraints:Mod = 10^9+7N  10^9 Example 1 Input3 Output2 Explanation: Consider the first three natural numbers 1, 2, 3. These can be arranged in the following ways: 2, 3, 1 and 1,  3, 2. In both of these arrangements, the numbers increase to a certain  point and then decrease. There are two such arrangements: 2, 3, 1 and  1, 3, 2. Example 2Input4 Output6 Explanation: The six arrangements are (1, 2, 4, 3), (1,3,4,2), (1,4,3,2), (2,3,4,1), (2,4,3,1), (3,4,2,1).#include<stdio.h>#include<stdlib.h>#define m 1000000007unsigned long long int power(unsigned long long int x, unsigned long long int n){    unsigned long long int res = 1;    while(n > 0){        if(n & 1){            res = res * x;            res = res%m;        }        x = x * x;        x= x%m;        n >>= 1;    }    return res;}int main(){    unsigned long long int n,res=0,temp=1,i;    scanf(%llu, &n);    if(n==1 || n==0){        printf(0\\n);        return 0;    }    temp = power(2, n-1);    temp--;    temp--;    printf(%llu\\n, temp);    return 0;}Can Anyone Solve This with Better Time Complexity?",
    "target": "performance;algorithm;c;combinatorics"
  },
  {
    "id": "_softwareengineering.246167",
    "source": "Why would a C executable be smaller when compared to C++ executable <eos> I'm trying to understand why the output file sizes are significantly different when using a C and a C++ compiler.I was writing a small hello world program in C and C++, I noticed that in C version, the size of the executable was 93.7KB and in C++, the size of the same hello world program was 1.33MB. I am not sure why that is. I think it may be because C++ has more libraries and namespaces to use so I removed the using namespace std line and simply used std::cout and still the result was the same. C#include <stdio.h>int main(){    printf(hello world);    return 0;}// size 93.7KBC++#include <iostream>int main(){    std::cout<<Hello world;    return 0;}// size 1.33MBThere doesn't seem to be much difference in the code above.  Is there some sort of compiler difference that creates the differing file sizes?",
    "target": "c++;c"
  },
  {
    "id": "_cstheory.17151",
    "source": "What is the relationship between the number of states in Quantum Finite Automata and the number of non-regular languages they can recognize? <eos> It is has been shown that Quantum Finite Automata can recognize at least some non-regular languages. What is the relationship between the number of states in a qfa and the number of non-regular languages it can recognize? Is there a relationship at all or has it not yet been established?I have been unable to find a paper that addresses this in an overtly and understandable way. More specifically, for any one specific type (ex/ 1-way MM-QFA), has any such relationship been established for the class it recognizes? I know different types of QFAs have different closure properties and other characteristics that can make them vastly different and bounds have been established for some, but I'm wondering if anyone knows of, has seen, or knows who to contact regarding the relationship between teh number of states in a qfa and its recognition properties? Or, if this question is totally mute and I'm looking at it wrong, tell me why. I have read into some of Freivalds' research where he touches on this, but can't find any theorems, proofs, lemmas, ect. that hammer it out, if anyone has done so at all. There is a possibility that this question is open and that's why I havent found an answer. Any help you can give would be appreciated.",
    "target": "fl.formal languages;automata theory;probabilistic automata"
  },
  {
    "id": "_unix.807",
    "source": "Updating FreeBSD 8.0 to 8.1 (methods and policy) <eos> I have 8.0-RELEASE-p4 + few ports installed. I wonder wheather I should update to 8.1.How long is 8.0 supported?How to update the system? I couldn't find anything about it in handbook.SOLUTION (based on gvkv answer): I take the liberty of describing all steps I've done at the end: # STEP 1: Revert to GENERIC kernelcd /tmp wget -r ftp://ftp.freebsd.org/pub/FreeBSD/releases/i386/8.0-RELEASE/kernels/cd pub/FreeBSD/releases/i386/8.0-RELEASE/kernels/sha256 generic.* install.sh | diff - CHECKSUM.SHA256./install.sh GENERICnextboot -k GENERIC# STEP 2: Upgrade - part 1freebsd-update upgrade -r 8.1-RELEASE # Ignore kernel warning. Fix configurationfreebsd-update installshutdown -r now# STEP 3: Upgrade - part 2nextboot -k GENERICfreebsd-update installshutdown -r now# STEP 4: Upgrade - part 3rm -rfv /usr/objportmaster -Raf # Rebuilds all packages. If you don't use portmaster use other tool or do it manuallycd /usr/srcmake buildkernel KERNCONF=CUSTOM # Rebuild kernelmake installkernel KERNCONF=CUSTOM # Install kernelshutdown -r now",
    "target": "freebsd;upgrade"
  },
  {
    "id": "_softwareengineering.283222",
    "source": "Is Collection.stream().filter().forEach() inefficient compared to a standard for each loop? <eos> IntelliJ IDEA recommended to me just now to replace the following for-each loop with a Java 8 forEach call:    for (Object o : objects) {        if (o instanceof SomeObject) {            doSomething();        }    }The recommended call would like like this:objects.stream().filter(o -> o instanceof SomeObject).forEach(o -> doSomething());Unless I'm misunderstanding how the underlying functionality of Stream works, it seems to me like using stream is an O(2n) operation as opposed to an O(n) operation for the standard for-each loop.",
    "target": "java;performance;java8"
  },
  {
    "id": "_codereview.124072",
    "source": "Computing the circumference of two circles <eos> This is a program which computes the circumference of two circles and gives some information such as the difference between circumferences.  I want to know whether the method declarations and method calling in my code is correct.  I didn't face any errors.import java.text.*;import javax.swing.*;class Q5Main{    public static void main(String args[]){        double smallCircum;        double largeCircum;        InputHandler input = new InputHandler();        Question5 myq = new Question5();        double a = input.getDouble(Radius for the smaller circle:);        smallCircum = (myq.start(a));//calculate the small circle circumference        a = input.getDouble(Radius for the larger circle: );        largeCircum = (myq.start(a));//calculate the large circle circumference        myq.showDetails(smallCircum, largeCircum);    }}class Question5{    DecimalFormat df = new DecimalFormat(0.000);    private double circumference;//to store circumference    //carry out the full process    public double start(double value){        return circum(value);    }    //compute the circumference    private double circum(double radius){        circumference = 2 * Math.PI * radius;        return circumference;    }    public void showDetails(double smallCircum, double largeCircum){        System.out.println(Circumference of smaller circle: +df.format(smallCircum));        System.out.println(\\n);        System.out.println(Circumference of larger circle: +df.format(largeCircum));        System.out.println(\\n);        System.out.println(Difference: +df.format((largeCircum-smallCircum)));    }}class InputHandler{    private static final String DOUBLE_DEFAULT_PROMPT = Enter integer: ;    public double getDouble(){        return getDouble(DOUBLE_DEFAULT_PROMPT);    }    public static double getDouble(String prompt){        String inStr;        inStr = JOptionPane.showInputDialog(null,prompt);        return Double.parseDouble(inStr);    }}",
    "target": "java"
  },
  {
    "id": "_cogsci.10544",
    "source": "What other personality traits are proved to correlate with Self-discipline? <eos> Are there any studies that prove other personality traits being correlated with the Big5 facet C5 - Self-discipline? (I'm looking for links to scientific reports)",
    "target": "personality"
  },
  {
    "id": "_unix.310843",
    "source": "moving tcp flows between interfaces and recovering traffic <eos> Lets say, I have two machines A and B.Both have a 2 port 10G NIC. Let their interfaces names be eth0 and eth1 respectively.Let eth0 of machine A be connected to eth0 of machine B.And eth1 of machine A be connnected to eth1 of machine B.I have the following questions.I have a TCP application (some web application) that starts sending some data using eth0 port (Machine A), so it will be received at eth0 port (Machine).After a few seconds, I want to move the TCP application from eth0 port to eth1 port (in Machine A). How can I do this?As soon as I move the data to eth1 port (in Machine A), I want to capture the data in eth1 port (in Machine B). Same mechanism as above.Now, part of the data (packets) was passed through eth0 port and part of the data would have passed through eth1 port. I presume this will break the tcp connection. How can I recover the data at machine B (ie, unify and recover packets that were obtained in eth0 and eth1 interfaces).Any pointers or help is greately appreciated. ",
    "target": "linux;networking;tcp"
  },
  {
    "id": "_softwareengineering.329577",
    "source": "SVN best practices - different code logic in branches <eos> While working with one project I was assigned to, I noticed a small problem with our SVN strategy. A few months ago, someone created a new feature branch from our trunk. In this branch he implemented a second implementation of an already implemented feature (but in a  more efficient way). He changed actually only one class.After this action some of the classes methods are common for both places - trunk and feature branch - but some methods are specific for each implementation. It was decided that we have to support both version so sometimes we create a deploy from branch, sometimes from trunk (some business assumptions). Now I have some problems with merging - normally I want to merge only these code parts which are common for trunk and branch. It makes each merge more complicated because each time I have conflicts to solve (and I have many of them) I have to pay extra attention to what action should I take for each conflicted line. My question is: am I right in claiming that the decision of creating a new version which should be supported as a feature branch was a bad idea? What are the best practices in such case?",
    "target": "svn;branching"
  },
  {
    "id": "_hardwarecs.1050",
    "source": "Are there any known Android phones planned which will work on Project Fi besides Nexus 5x and Nexus 6p? <eos> I know Project Fi recently rolled out and currently requires a Nexus 5x or Nexus 6p. At the time I'm writing this, no other phones currently support Project Fi, but are there any others in the pipeline that will work, which will be released (or have been released later)?",
    "target": "smartphones;android;project fi"
  },
  {
    "id": "_softwareengineering.153309",
    "source": "When writing tests for a Wordpress plugin, should i run them inside wordpress or in a normal browser? <eos> I have started using BDD for a wordpress plugin i'm working on and i'm rewriting the js codebase to do tests. I've encountered a few problems but i'm going steady now, i was wondering if i had the right approach, because i'm writing test that should pass in a normal browser environment and not inside wordpress.I choose to do this because i want my plugin to be totally indipendent from the wordpress environment, i'm using requirejs in a way that i don't expose any globals and i'm loading my version of jQuery that doesn't override the one that ships with Wordpress. In this way my plugin would work the same on every wordpress version and my code would not break if they cheange the jQuery version or someone use my plugin on an old wordpress version.I wonder if this is the right approach or if i should always test inside the environment i'm working in. Since wordpress implies some globals i had to write some function purely for testing purpose, likeget_ajax_url: function() {    if( typeof window.ajaxurl === undefined ) {        return http://localhost/wordpress/wp-admin/admin-ajax.php;    } else {        return window.ajaxurl;    }}, but apart from that i got everything working right. What do you think?",
    "target": "javascript;unit testing;plugins;bdd;wordpress"
  },
  {
    "id": "_vi.10184",
    "source": "vim c++ clang_complete doesn't work for std::cin.get() <eos> I'm using vim to do c++ projects on Mac OS X.To auto complete, I use this plugin: clang_completeFor most of cases, such as members of user-defined classes, members of namespaces, it works very well.For example, when I type std::, many things such as cout, cin will popup.However, when I type std::cin., or std::string str; str. nothing popups and I got an error:Pattern not foundIt seems that user-defined classes' members can popup automatically whereas C++ Library stuff's members can't. I don't know why.Here is my .vimrc file:",
    "target": "vimrc;autocompletion;filetype c++;plugin clang complete"
  },
  {
    "id": "_unix.340169",
    "source": "What's the difference between `mkdir -p` and `install -d`? <eos> What, precisely, is the difference in what is being performed by mkdir -p and install -d, in terms of what changes the two commands are doing to the system?",
    "target": "c;coreutils"
  },
  {
    "id": "_codereview.149559",
    "source": "Wild and changing business rules implemented with functional programming <eos> I attempted the Business Rules Kata. Here's a video overview.However, I am not confident that going functional is a good strategy for the following objective:How can you tame these wild business rules? How can you build a system  that will be flexible enough to handle both the complexity and the  need for change? And how can you do it without condemning yourself to  years and years of mindless support?Is there an alternative FP approach that satisfies the objective stated above?module PaymentSystem(*Types*)type ProductId =          ProductId of stringtype MemberId =           MemberId  of stringtype Email =              Email     of stringtype Agent =              Agenttype RoyaltyDepartment =  RoyaltyDepartmenttype PackingSlip = {    MemberId:MemberId    ProductId:ProductId}type PhysicalProducts =    | Book    | Video    | Othertype MembershipType =    | Membership of MemberId    | Upgrade    of MemberIdtype PaymentFor =    | PhysicalProduct of PhysicalProducts * PackingSlip    | Membership      of MembershipTypetype PackingSlipOptions =    | PackingSlip       of PackingSlip    | DuplicateSlips    of PackingSlip    | WithFirstAidVideo of PackingSliptype PaymentResponse =    | PackingSlip        of PackingSlipOptions    | ActivateMembership of MemberId    | UpgradeMembership  of MemberId    | EmailOwner         of MembershipType    | CommissionPayment  of Agent(*Functions*)let publish payload = ()       // Stublet getAgent productId = Agent // Stublet respondTo (payment:PaymentFor) =    match payment with    | PhysicalProduct     (kind , packingSlip) ->         publish (CommissionPayment (getAgent packingSlip.ProductId))        match kind with        | Book  -> publish (DuplicateSlips    packingSlip)        | Video -> publish (WithFirstAidVideo packingSlip)        | Other -> publish packingSlip    | Membership kind ->        publish(EmailOwner kind)        match kind with        | MembershipType.Membership memberId -> publish(ActivateMembership memberId)        | MembershipType.Upgrade    memberId -> publish(UpgradeMembership  memberId)    ",
    "target": "f#"
  },
  {
    "id": "_webapps.98018",
    "source": "If I like a post that is shared with friends but the original post was public, who can see that I liked the shared post? <eos> If I like a post that is shared by a friend with their friends but the original post was public, who can see that I liked the shared post?In other words, if friend A (let's call her Anna) shares a post from a general page B (let's call this FB page Bananas) - and the original Bananas post was public but Anna is only sharing that bananas post with her friends, who can see my 'like' to this shared post? ",
    "target": "facebook like;facebook privacy"
  },
  {
    "id": "_cstheory.37848",
    "source": "Implications of faster randomized $CIRCUIT SAT$ algorithm <eos> In here on page $13$ proposition $1$ it says 'If $CIRCUIT$ $SAT$ on $n$ inputs and $m$ gates is in $2^{n^{o(1)}}poly(m)$ time, then $EXP\\not\\subseteq P/poly$'.Can we have randomized $2^{n^{o(1)}}poly(m)$ time in above statement?Is there a similar result that would give $E\\not\\subseteq SIZE(2^{\\delta n})$ (this would give $P=BPP$)?How large can $o(1)$ be in the statement above and in 1. if applicable (can it be as large as $1/\\log\\log n$)?",
    "target": "big picture;derandomization"
  },
  {
    "id": "_unix.190547",
    "source": "find files with path of a directory exclude subdirectories <eos> How can I use find to traverse a directory, but not recurse into its subdirectories?I tried -prune and it does not work. And there is no -maxdepth option.find /opt/projectname/bin -type f /opt/projectname/bin -prune -o -printfind: missing conjunction/opt/projectname/bin/file_1_is_printed/opt/projectname/bin/file_2_is_printed/opt/projectname/bin/directory_within_bin/some_file_should_not_be_printed/opt/projectname/bin/directory_2_within_bin/some_file_2_should_not_be_printed/usr/bin/find:         find.c $Date: 2011/08/12 15:04:36 $Revision: r11.31/4 PATCH_11.31 (PHCO_42158)         libcpio.c $Date: 2008/05/27 16:08:10 $Revision: r11.31/2 PATCH_11.31 (PHCO_36666)         $Revision: @(#) find R11.31_BL2011_0923_2 PATCH_11.31 PHCO_42158This question is not a repeat question. There is no GNU here. Although the question may be a repeat question, the answers posted on those questions ask installations of GNU tools. Hence if the answers here help solve, this is a unique thread.",
    "target": "find"
  },
  {
    "id": "_unix.310222",
    "source": "How to tell apt to use the latest package by default? <eos> I put jessie-backports in my /etc/apt/sources.list, but it seems that apt will not automatically use the packages from backports but older packages.However, if I use apt-cache show to check the version it shows the latest, and I am able to use apt install xxx=<latest-version> to install it.How to tell apt always use the latest package by default?",
    "target": "debian;apt"
  },
  {
    "id": "_webapps.71320",
    "source": "Spotify is not working at all after cancelling premium <eos> Everytime I double-click a song in my library (saved, not local) I get an error that the current song cannot be played. I cancelled premium and I've played a few songs in my app, but the desktop software and web player will not play anything. Help appreciated!",
    "target": "spotify"
  },
  {
    "id": "_cs.45222",
    "source": "Collisions in independent hashing <eos> Let $H$ be a $s$-wise independent family of hash functions from $\\{1,\\ldots,M\\}$ to $\\{1,\\ldots,N\\}$. It is easy to bound one collision, but are there good bounds for muliple collision ?",
    "target": "computability;data structures;probability theory;hash;hash tables"
  },
  {
    "id": "_datascience.15439",
    "source": "Check Accuracy of Model Provided by Consultant <eos> My company has recently engaged a consultant firm to develop a predictive model to detect defective works.I understand that there are many ways to validate the model, for example, using k-fold cross-validation and I believe that the consultant firm will carry out the validation before submitting the model to us.However, at the employer's side, how can I check the accuracy of the model developed by the consultant firm ?? Someone suggested that I can give 2000-2015 data to the consultant firm and keep 2016 data for our own checking. However, a model with good accuracy on 2016 data does not imply that it will have good predictive power in the future. In my view, keeping 2016 data for checking seems like adding one more test set for validation, which in my view, is unnecessary since I already hv k-fold cross validation.Could someone advise what the employer can do to check the consultant's model? ",
    "target": "machine learning;predictive modeling;cross validation;accuracy"
  },
  {
    "id": "_unix.126270",
    "source": "Update .profile in /etc in UNIX <eos> How can i append the following text in .profile in folder /etc/security of UNIX OS?PS1='hostname -s':$LOGNAME'[$PWD]'i tried:print 'export PS1='hostname -s':$LOGNAME'[$PWD]'  '  >> profilemy output gives:export PS1='hostname -s':$LOGNAME[/etc]with [/etc].",
    "target": "shell;quoting;prompt"
  },
  {
    "id": "_codereview.27255",
    "source": "Proper use or convenience, or both? <eos> In my current project, I am working with a lot of JSON objects that contain arrays, er.. lists so I setup a decorator for convienece when the list is one item or multiple. Even though this is convienent in the current project, is it reusable code?def collapse(function):    @functools.wraps(function)    def func(*args, **kwargs):        call = function(*args, **kwargs)        if isinstance(call, (list, tuple)) and (len(call) == 1):            return call[0]        return call    return func@collapsedef get_results(query, wrapper=None):    # get json object.    result = result.json() # using the requests library.    if wrapper:        return result[wrapper]    return resultSo, get_results() has the potential of returning either a list or a dict. In most cases, the code knows when what type is returned, so using the @collapse decorator changes [result_dict] to just result_dictIs this a good practice, or should I write a decorator that takes a limit parameter@limit(1) # def limit(items=None): ... return data[0:items] if items else datadef get_results(query, wrapper=None):Just wrote out the limit decorator...def limit(items=None, start=0, collapse=False):    if items and (start > 0):        items += start    def wrapper(function):        @functools.wraps(function)        def func(*args, **kwargs):            call = function(*args, **kwargs)            if isinstance(call, (list, tuple)):                results = call[start:items] if items else call                if collapse and (len(results) == 1):                    return results[0]                else:                    return results            return call        return func    return wrapper",
    "target": "python"
  },
  {
    "id": "_webapps.49830",
    "source": "Count occurrence of a word in Google Spreadsheet <eos> I've got a ton of cells (say 6x20) that have various names in them. I'd like to total the number of times a name in another field matches any of the other cells.Alice  Bob    ClaireDoug   Alice  ChrisBob    Claire BobIt seems like there should be a way to look at the example 3x3 above (or my actually much larger group of names) and extract how many Bobs or Alices or whatever occur. My Spreadsheet-Fu is weak and I haven't been able to find an answer via Google (probably because I just don't know the right term for what I want to do).Here's a sample of what I'm trying for: Count OccurenceIt uses IF statements, but since EACH cell needs it's own IF statement this is not really a viable way to make the spreadsheet, especially as more people can be added in at later points.",
    "target": "google spreadsheets"
  },
  {
    "id": "_unix.97559",
    "source": "git and sshfs: status is inaccurate <eos> I am mounting a git repository on a virtual machine over sshfs onto my host machine. So far so good. However, git claims that there are many uncommitted changes when viewing the repository over sshfs. Why is that?The relevant bit from /etc/fstab, if that helps:sshfs#usr@virtual:/home/user/repos /home/user/repos/ fuse noauto,user,uid=1000,gid=1000,umask=0,workaround=rename 0 0Note: Cloning, push, and pull operations could done instead but the code needs to compile on the virtual machine OS and not on the host machine -- long story, it has to be this way.  I do not fancy doing a commit per compile, that's just silly.",
    "target": "git;sshfs"
  },
  {
    "id": "_unix.325907",
    "source": "Disable search option for resolv.conf <eos> We are running a script that tries to resolve thousands of domains for a research project. The issue we are having is that a lot of domains are not resolvable for example foo.com. If we ping foo.com the system will do a lookup for foo.com. If that does not resolve, it will do a lookup for foo.com.ourdomain.com. It /etc/resolv.conf we had:# Generated by NetworkManagersearch ourdomain.comnameserver 8.8.8.8nameserver 4.2.2.2The above result is expected since we had the search setting set. If we changed it to say:# Generated by NetworkManagersearch ourdomain.netnameserver 8.8.8.8nameserver 4.2.2.2then as expected any non-resolvable query will be queried again with ourdomain.net at the end.The issue that we have is if we remove the search line completely from resolv.conf then system goes back to using ourdomain.com as the search. What we want is if a DNS lookup does not resolve to NOT then look it up with the domain that WAS set in resolv.conf (which is also the domain of the box).",
    "target": "centos;resolv.conf"
  },
  {
    "id": "_unix.316163",
    "source": "Crontab order run with differents schedule <eos> I have a crontab with different time to execute some task, for example every minute, every 10 min, 1 hour, daily... And i have a question, when some of this cron coincide in the same time for example, when 10 minutes execute, also execute 1 min cron and this cron execute in parallel... but I want to execute in sequence, for example all jobs in 1 minute, and the all jobs in 10 min... how can I do this??",
    "target": "cron;executable"
  },
  {
    "id": "_unix.353757",
    "source": "How to convert a colored file to mail readable in bash? <eos> I have a file which was created by a script which will be colored when I open using cat. But when I tried to send that file as attachment, it is not showing properly. Like below it is showing.^[[33m================================================================================^[[m                            ^[[34m172.29.0.110^[[m^[[33m================================================================================^[[mFilesystem              Size    Used    Avail   Use%    Mounted on/dev/mapper/centos  109G   13G   91G  13% //dev/mapper/mpatha       1.6T  1.3T  277G  83% /var/lib/SQL^[[33m================================================================================^[[m                            ^[[34m172.29.8.110^[[m^[[33m================================================================================^[[mFilesystem              Size    Used    Avail   Use%    Mounted on/dev/mapper/centos  117G  9.1G  102G   9% //dev/mapper/mpatha       1.6T  1.4T  109G  93% /var/lib/SQL^[[33m================================================================================^[[m                            ^[[34m172.29.16.110^[[m^[[33m================================================================================^[[mFilesystem              Size    Used    Avail   Use%    Mounted on/dev/mapper/centos      117G   18G   94G  17% //dev/mapper/VG01-LV 1.5T  812G  590G  58% /var/lib/SQL^[[33m================================================================================^[[m                            ^[[34m172.29.26.110^[[m^[[33m================================================================================^[[mFilesystem              Size    Used    Avail   Use%    Mounted on/dev/mapper/LogVol02  117G   22G   90G  20% //dev/mapper/mpathm    1.6T  1.1T  435G  71% /var/lib/SQLThe script(part of the script) that creates the file is ::for IP in $(cat file.txt); do    (echo -e  \\e[33m$LINE\\e[m    echo -e                             \\e[34m$IP\\e[m                                     echo -e \\e[33m$LINE\\e[m    echo -e Filesystem\\t\\tSize\\tUsed\\tAvail\\tUse%\\tMounted\\ton    ssh $SSH_ARG -q user@${IP} df -Ph | egrep -iv 'filesystem|boot|tmpfs') >> /disk_${DATE}_log    echo -e \\e[33m$LINE\\e[m    echo Successful for $IPdonecat disk_${DATE}_log | mail -s Disk space mail@mail.comI can remove those echo's that creating colors, but I want to know is there any way I can send this file properly by mail or can I do something in mail command to solve this?",
    "target": "linux;bash;files;sendmail"
  },
  {
    "id": "_webapps.57623",
    "source": "Any way to download from Scribd? <eos> Is there any way I can download from Scribd? I need to download a few documents for my research.",
    "target": "scribd"
  },
  {
    "id": "_unix.47578",
    "source": "Is it possible to select tabs as tabs with mouse in urxvt? <eos> I am running urxvt on Arch Linux. I can select the output with mouse for copy / paste. The problem occurs when output contains tabulators. All tabulators are selected and copied as spaces. That makes it really difficult to preserve the structure of some outputs when copying them.Is there any way to fix this behaviour?EDIT: I am using zsh if that has any effect on the issue.",
    "target": "terminal;mouse;clipboard;rxvt"
  },
  {
    "id": "_cs.32903",
    "source": "Theta estimation of two functions <eos> I'm in a data structures class, and am working on an assignment right now that asks me to find the theta complexity of certain loops. I missed class the day we were introduced to the topic, and everything I can find online expects more prior knowledge than I feel I have. Can someone just explain this in beginners terms for me? I don't know what Big-O or theta even refer to in this notation. I think I have a loose idea of what complexity refers to (a measure of how efficient code is, depending on how long a function will take in different circumstances?)The problem in question:Demonstrate the $\\Theta$-complexity of the functions below. In order to demonstrate that $f(n) = \\Theta(g(n))$ you must find two constants $C_1$ and $C_2$ such that$$ C_1g(n)  f(n)  C_2g(n). $$a.) $f(n) = n^3 - 3n^2 + 5$.b.) $f(n) = 2\\log_2 n - 4$.",
    "target": "asymptotics;landau notation"
  },
  {
    "id": "_webapps.54643",
    "source": "How to check the file usage summary in Google Drive <eos> After sharing the folder/file in Google Drive to some other mail address, how can I monitor the log activity, like when the respective user has accessed the file, what are the modifications done etc.?Is this possible in Google Drive?",
    "target": "google drive"
  },
  {
    "id": "_reverseengineering.13253",
    "source": "Reverse engineering a whole website <eos> How do i reverse engineer every single aspect and functionality of a website so that i get an exact fully working copy of it?. All interactions including JavaScript, cascade style sheets, PHP to make a perfect clone of it?",
    "target": "websites"
  },
  {
    "id": "_unix.328000",
    "source": "BASH Operations on a for loop object <eos> I'm attempting to run a bash command on a forloop object but it's trying to look for a file instead of use the forloop object.Example:The input file contains lines in the format of user:passwordfor item in $(cat myItems);do        USER = cat $item | cut -d : -f1        PASS = cat $item | cut -d : -f2doneThe result of this is that it says File $item isn't foundI also triedfor item in $(cat myItems);do        USER = $(cat $item | cut -d : -f1)        PASS = $(cat $item | cut -d : -f2)done",
    "target": "shell script"
  },
  {
    "id": "_unix.313043",
    "source": "Can't install libcairo / x11-common <eos> I was trying to install libcairo which required x11-common. However, upon installation it saysSetting up x11-common (1:7.7+7) ...update-rc.d: warning: start and stop actions are no longer supported; falling back to defaultsinsserv: warning: script 'node-influenza.sh' missing LSB tags and overridesinsserv: There is a loop between service monit and node-influenza.sh if stoppedinsserv:  loop involving service node-influenza.sh at depth 2insserv:  loop involving service monit at depth 1insserv: Stopping node-influenza.sh depends on monit and therefore on system facility `$all' which can not be true!insserv: exiting now without changing boot order!update-rc.d: error: insserv rejected the script headerdpkg: error processing package x11-common (--configure): subprocess installed post-installation script returned error exit status 1Processing triggers for systemd (215-17+deb8u5) ...Errors were encountered while processing: x11-commonE: Sub-process /usr/bin/dpkg returned an error code (1)I suspect it's a problem with the post install - however I have no idea on how to fix it. I tried pretty much installing and uninstalling everything by hand, to no avail. Strangely, on my Debian 8 VM it works fine.I uploaded the x11-common.postinst if it is needed.",
    "target": "debian;software installation;dpkg"
  },
  {
    "id": "_datascience.8024",
    "source": "Does reinforcement learning require the help of other learning algorithms? <eos> Can't reinforcement learning be used without the help of other learning algorithms like SVM and MLP back propagation? I consulted two papers:Paper 1Paper 2both have used other machine learning methods in the inner loop.",
    "target": "machine learning;reinforcement learning"
  },
  {
    "id": "_cstheory.10627",
    "source": "How big is the variance of the treewidth of a random graph in G(n,p)? <eos> I am trying to find how close $tw(G)$ and $E[tw(G)]$ really are, when $G \\in G(n,p=c/n)$and $c>1$ is a constant not depending on n (so $E[tw(G)] = \\Theta(n)$). My estimate is that $tw(G) \\leq E[tw(G)] + o(n)$ w.h.p, but i haven't been able to prove it.",
    "target": "graph theory;co.combinatorics;treewidth;random graphs"
  },
  {
    "id": "_cs.24334",
    "source": "Is traversing an unconnected graph possible? <eos> I have been assigned a fun project: design and implement a program that maintains the data of a simple social network. Each person in the network should have a profile that contains his name, current status, and a friends list.I think it is clear that the project calls for the use of the ADT graph. Each vertex represents a person in the network and an edge between vertices a friendship. Now, the graph may not be connected because some members do not have any friends in the network. With that in mind, consider this feature that must be implemented:The network must have a feature that computes the emergency phone chain, make sure that each member in the network is contacted, and only by one person. Any of the people in the network may initiate the first call. Utilize a depth-first graph traversal algorithm.Now, what I think my professor is suggesting is merely a full traversal of the graph. How is that possible for an unconnected graph? Any suggestions?(btw, the wording above is somewhat unclear - does the professor mean that everyone in the network is contact by the same one person? Thoughts? I would ask her, but she is unavailable until next week.)",
    "target": "graphs;weighted graphs"
  },
  {
    "id": "_unix.360261",
    "source": "Fetch elapsed time value from a file <eos> I need to fetch elapsed time output from file. I need the value just before elapsed that is 2:10:42.File content :312.90user 15.57system 2:10:42elapsed 4%CPU (0avgtext+0avgdata 0maxresident)k0inputs+0outputs (1major+152440minor)pagefaults 0swaps",
    "target": "shell script;text processing"
  },
  {
    "id": "_unix.334324",
    "source": "How to compare files from Solaris and Linux <eos> I want to compare the contents of same file present there in both Solaris and Linux for our testing purpose.I there is any tool available for that.If I want to develop new tool, haw can I achieve that?We are migrating project from Solaris to Linux.We want to verify the final output with is there in binary format by comparing them.Both the files are there in different systems.Please suggest me how we will do that comparison.",
    "target": "linux;solaris"
  },
  {
    "id": "_cs.6116",
    "source": "Given a truth table, force a contradiction <eos> Suppose I have a formula, and a lying witness is attempting to make it evaluate to False.Given a truth table $c(F_1,, F_n)$, how could you force a lying   witness to contradict herself?A contradiction is simply when the witness's statements are logically impossible; i.e. that $x_1,x_2$ are each True, but $x_1 \\space AND\\space x_2$ is False.How can I characterize the set of all formula for which I force the witness to contradict herself?What complexity class does this problem fall in?",
    "target": "complexity theory;computability;np complete;closure properties;decision problem"
  },
  {
    "id": "_unix.182527",
    "source": "Epiphany shuts down as it is loading <eos> On my Raspberry Pi, Epiphany starts up and then after loading 'Most Visited'... it closes. I reinstalled Epiphany after doing a full update, and the same thing still is happening. Other programs are running OK, including the Dillo browser.",
    "target": "debian"
  },
  {
    "id": "_webmaster.60055",
    "source": "Can pre-populating HTML and AJAX replacing it when scrolled be a good lazy loading strategy for SEO? <eos> So I've read several posts here regarding SEO and lazy loading as well as the Google page for lazy loading your site's content. Since setting up HTML snapshots for an AJAX website is a large amount of work after the learning curve, I propose the following alternative to serving static content to a crawler.I have prepopulated my content divs with SEO optimized, bare HTML content. My asynchronous content is loaded in replacing the original static    content (per scrolling trigger of course).I cannot think of a reason why this isn't a smooth way to serve up the static HTML for crawlers. I mean if they really can't index asynchronous content then they shouldn't even recognize that the above process is happening after seeing the original content.Am I missing something here?",
    "target": "seo;ajax"
  },
  {
    "id": "_unix.271619",
    "source": "Wifi stopped working, Unknown symbol wireless_nlevent_flush <eos> As of this afternoon the wifi on my Dell XPS 13 stopped working (running Debian sid with kernel 4.4.0-1-amd64). lspci detects my wifi card, but ifconfig -a shows only the loopback interface.I tried plugging in a USB wifi dongle which I have used recently with this laptop, and this also does not get recognized as a network interface. Both during startup and immediately after plugging in a USB wifi dongle, the following message appears in dmesg:cfg80211: Unknown symbol wireless_nlevent_flush (err 0)cfg80211 sounds like it would be used for configuring 802.11 (i.e. wifi) so I suspect this kernel module isn't getting loaded correctly. Indeed, if I try to modprobe cfg80211 I receive the following error:modprobe: ERROR: could not insert 'cfg80211':? Unknown symbol in module, or unknown parameter (see dmesg)and checking dmesg I see the same message as above.Googling for unknown symbol wireless_nlevent_flush yields zero results, although googling for just wireless_nlevent_flush seems to imply that it relates to wext somehow. One page suggested that rfkill must be loaded before cfg80211, but rfkill is already loaded. I would be very grateful for any advice.",
    "target": "wifi;kernel modules;dmesg"
  },
  {
    "id": "_cs.24470",
    "source": "Is polynomial time reducibility reversible? <eos> If a language $A$ is reducible to some language $B$, does it follow that $B$ is reducible to $A$?My guess is no, it having something to do with the function $f$ in the definition of $A$ reducing to $B$ needing to be invertible.",
    "target": "complexity theory;reductions;polynomial time"
  },
  {
    "id": "_cs.52756",
    "source": "How to build the Reduction from Hamiltonian Cycle problem to Subgraph isomorphism? <eos> I'm trying to prove that the Subgraph isomorphism problem is NPC using the Hamiltonian Cycle problem.Unfortunately I feel (or don't understand) that the solution is empty and doesn't explain the Hamiltonian Cycle - Subgraph Isomorphic connection, @Luke Mathieson says that Hamiltonian Cycle to Subgraph Isomorphism is really just rephrasing what it means for a graph to have a Hamiltonian cycle - but I don't get it.How does one transforms from Hamiltonian Cycle to Subgraph Isomorphism?I read Reducing from Hamiltonian Cycle to Subgraph Isomorphism and https://en.wikipedia.org/wiki/Subgraph_isomorphism_problem and couldn't understand how should a proper reduction look like, how to build one that proves the subgraph problem?Your help in simplifying the problem(s) will be very appreciated.",
    "target": "complexity theory;np complete;reductions;hamiltonian path;graph isomorphism"
  },
  {
    "id": "_cs.27760",
    "source": "Completeness and first order logic with Least fixed point operator (LFP) <eos> Is there any result about the extension of first order logic with least fixed point operator, being complete (as logic in general on infinite structures too) or not? In other words does the Goedel completeness theorem of first order logic extent to such FO-LFP logic ? ",
    "target": "first order logic;descriptive complexity"
  },
  {
    "id": "_unix.209333",
    "source": "Install app on tiny core <eos> How do you install mysql on tiny core? Also how do you install clamav? Can you install apt-get or yum on tiny core?All should be done in command line / terminal",
    "target": "mysql;tinycore"
  },
  {
    "id": "_unix.383908",
    "source": "Sharing zsh and vim configuration with root user <eos> I have modified my .zshrc and .vimrc to my likings. Both files source other files containing more configuration and plugins (vundle, antibody). Now I would like to use these configurations when I change to the root user as well.Currently my .zshrc looks like this# .zshrc# Sources the files in .shell directoryexport SHELL_CONF_DIR='/home/myUser/.shell'source $SHELL_CONF_DIR/initShell.shinitShell.sh does the following# initShell.sh# Sources further scripts. $SHELL_CONF_DIR/antibody.sh. $SHELL_CONF_DIR/compinstall.sh. $SHELL_CONF_DIR/configuration.sh. $SHELL_CONF_DIR/options.sh. $SHELL_CONF_DIR/aliases.sh. $SHELL_CONF_DIR/variables.sh. $SHELL_CONF_DIR/virtualenv.sh. $SHELL_CONF_DIR/functions.sh. $SHELL_CONF_DIR/keybindings.sh. $SHELL_CONF_DIR/xorg.shI want to manage my .vimrc in a similar fashion.Now the root users .zshrc is just a symlink to my normal users .zshrc. This works pretty well but I think, concerning security, this might not be an ideal solution. So where should I actually put all this configuration and how should I handle it so the root user can use it, too? Or is this actually the wrong approach? I know that I can preserve environment variables with sudo -E but that doesn't work when doing sudo -i.",
    "target": "sudo;environment variables;root;bashrc;vimrc"
  },
  {
    "id": "_softwareengineering.210240",
    "source": "Is it safe to just use MySQLi? <eos> I have developed an open source PHP application and currently it uses both the MySQLi or MySQL extension for backwards compatibility. I'm wondering about switching it over to only be compatible with MySQLi since PHP now no longer supports the MySQL. Another reason I'd like to get away from supporting both MySQL and MySQLi is that I'm basically using MySQLi the same way I do as with the old MySQL extension. Can anyone explain to me if this is a good or bad idea?",
    "target": "php;mysql;backward compatibility;compatibility"
  },
  {
    "id": "_softwareengineering.270311",
    "source": "How can I decouple query and context in a query object scenario? <eos> I'm using a query object pattern (similar to this) to manage disparate queries while avoiding bloaded facades/repositories.A query object takes a number of constructor parameters, representing query arguments. The query is then passed to an IQueryHandler by the caller, into which is injected the IDataContext. The IDataContext is then passed into an Execute method of the IQuery.The thing I don't like is this:public interface IQuery<TResult>{    public TResult Execute(IDataContext context);}Because the IDataContext is passed into the method and thus explicitly declared in the interface, there is no option to have a query that fetches things via a different mechanism - IQuery is coupled to whatever defines the IDataContext interface. Suppose, for example, I want to switch from an SQL DB store to a document DB.I've tried a couple of alternatives, but neither quite gets me where I want to be.The first is to inject the data context into the query's constructor and use a factory to generate the query objects. This successfully decouples the interfaces, but now working with the queries is more cumbersome. Instead of using the constructor/object initializer to set up the query, callers have to do something like this:var query = _queryFactory.Create<PersonQuery, Person>(); // Second type argument can't be inferred from first due to limitations in generic type inference.query.Name = Bob;query.Age = 32;var result = query.Execute();The second is to abstract the execution of the query - and thus the dependency on IDataContext - to a handler class, then have another class that resolves a handler for each query, which again abstracts the dependency away from any interfaces:public class ISomeQueryHandler : IQueryHandler<SomeQuery, SomeQueryResult>{    private readonly IDataContext _context = ...;    public SomeQueryResult Execute(SomeQuery query) { ... }}I don't like this option because it means every new query involves writing two classes, which, again, is cumbersome and increases the potential for a query to exist with no way of handling it (it also involves an empty marker interface for queries since the Execute method is moved to the handler, which always feels off). It also involves some rather funky convention-based dependency resolution to get the right handler for each query.Creating an abstraction over IDataContext is not really feasible due to its complexity.Is there a happy medium I haven't seen?",
    "target": "c#;design patterns"
  },
  {
    "id": "_cstheory.3716",
    "source": "Is there any research on the notion of weak isolation? <eos> (First of all, sorry for the long article which makes you want to skip through, but since the background and motivations are important to this question or it would be nonsense to the main problem, forgive me if this makes you sleep. I owe you a cup of coffee.)BackgroundIsolation lemma, one of the best tool in complexity theory invented by K. Mulmuley, U. Vazirani and V. Vazirani in Matching is as easy as matrix inversion, have been used to prove many amazing results like an RNC-algorithm for matching in the above paper; ValiantVazirani theorem which is a randomized reduction from NP problems to USAT; NL/poly=UL/poly; and many others. Surveys and introduction in blogs are also all over the web. In the center of the isolation lemma, we use randomization to assign weights on the base set $U$, such that for a family $\\mathcal{F}$ of subsets of $U$, there is a unique minimum weighted subset in $F$ with high probability. Formally,Lemma. Let $U$ be a set of size $n$, and $\\mathcal{F}$ be a non-empty family containing elements which are the subsets of $U$. Uniform-randomly assign integral weights in $[2n]$ on the set $U$, then there exist a unique minimum weighted subset in $\\mathcal{F}$ with probability at least $1/2$.A stronger form which covers a collection of $\\mathcal{F_1}, \\ldots, \\mathcal{F_m}$ that is used in practical situations can be found in the survey. There are also some variants that may reduced the use of random bits, or derandomized the lemma to get a deterministic weight assigning algorithm when the size of $\\mathcal{F}$ is not too large.ProblemAfter a search of literature, it seems that all the research on this topic were all focus on isolating a unique subset of $U$. I want to know whether there is any obvious reason that we don't have a weak isolation lemma, in the sense that the number of minimum weighted subsets is bounded by a particular bound, and the requirement for the weak lemma is less than the original one. For example, do we have a lemma that only isolates $O(\\log n)$ minimum weighted subsets? How about linear or polynomial? Since the size of $\\mathcal{F}$ is at most $2^n$, when the bound is set to $2^n$, the result becomes trivial since no isolation is needed.Problem. Is there any research on the notion of weak isolation, that only limits the number of minimum weighted subsets instead of a unique one? If so, is there any references? If not, what is the most obvious obstacle toward such a result?I've been trying to prove such a lemma with some approaches, but despite of using the exactly same techniques (thus the same requirements) which is clearly no better than the original one (since with the same requirements you can indeed isolate a unique subset), there is no success to reduce any conditions we need, even in the case that we only need a loose bound on the number of minimum subsets, say polynomial. (please read on if you need motivations to the problem! The part below contains some technical details to the usage of the lemma, and some applications to log-space computations.)MotivationI am working on the problems in log-space computations, precisely the relation between classes $\\mathsf{NL}$, $\\mathsf{UL}$, and many other classes below and in between.Consider the above lemma, which requires $O(n \\log n)$ random bits if we assign weights to $U$ accordingly. A random-bit-saving version of the lemma is presented in this paper by Chari et al., which states:Lemma. Let $U$ be a set of size $n$, and $\\mathcal{F}$ be a non-empty family containing elements which are the subsets of $U$. There is a way of assigning weights in $[n^7]$ on $U$ with $O(\\log|F|+\\log n)$ random bits, such that there exist a unique minimum weighted subset in $\\mathcal{F}$ with probability at least $1/4$.That gives us an $\\mathsf{USPACE}[O(\\log|F|+\\log n)]$ algorithm for reachability. Of course this is a pity bound, since by Savitch's theorem we have $\\mathsf{NL} \\subseteq \\mathsf{L}^2 \\subseteq \\mathsf{UL}^2$.But what if we consider the reachability problem with a restriction that there are at most $f(n)$ paths from the source to any node in the graph? This defines the problem $\\mathtt{Reach}[f(n)]$, and we have $\\mathtt{Reach}[2^n]$ to be the normal reachability problem. By setting $f(n)$ a polynomial, applying the above lemma together with an $\\mathsf{UL}$-algorithm for reachability in graphs with a minimum unique path (see the paper for more details), we can solve $\\mathtt{Reach}[n^{O(1)}]$ in $\\mathsf{UL}$. (The result occurs in this recent paper. In fact they use a stronger version of the lemma, which isolates every paths in the graph by a constructive way.)If a weaker isolation lemma is known to have less restrictions on either the size of $\\mathcal{F}$, or the number of random bits being used, we can provide better bounds on the problem $\\mathtt{Reach}[f(n)]$, with the help of some modifications to solve reachability in graphs with few minimum paths. Hopefully if the lemma is weak enough to set $f(n) = 2^n$, and we can obtain some better bounds about the important class $\\mathsf{NL}$.Any comments on the proof techniques or obstacles will give insight to the question, and I would like to know that whether this idea has a tiny little chance of success, or it is just a completely impossible concept.",
    "target": "cc.complexity theory;randomness"
  },
  {
    "id": "_unix.255970",
    "source": "Gnome Boxes: proper network configuration? <eos> I've got a problem with Gnome Boxes:I've 2 machines, cloned 1 from other, with CentOS. Both machines get same IP addr on Gnome Boxes, so when I boot 2nd, 1st gets disconnected from network, and vice-versa. This is not acceptable behaviour,and I've been struggling to find out why does this happen for quite some time. ",
    "target": "networking;gnome;virtual machine"
  },
  {
    "id": "_webmaster.47559",
    "source": "Wordpress redirects to IP instead of domain <eos> Following this blog post I set up Wordpress on an EC2 instance. I've pointed A records to my Amazon EC Elastic IP Address. After propagation, when I open my website with the domain name, it works. But whenI click on other page, it just redirects me to my IP address instead.",
    "target": "domains;amazon ec2;wordpress"
  },
  {
    "id": "_unix.45793",
    "source": "How to view Flash and other videos on Linux systems? <eos> I'm running Fedora 17 and Firefox 12. When I navigate to some sites I'm unable to view videos because I'm missing some plugin. When I click 'installl missing plugin' I'm still not able to view the video.Any idea I can view them without installing Flash Player (not Open Source I believe)? What directory are these web plugins stored?",
    "target": "fedora;firefox;adobe flash"
  },
  {
    "id": "_unix.314157",
    "source": "Delete string between two regex patterns <eos> I have a file with following contents..\\..\\src\\modules\\core\\abc\\abc.cpp..\\..\\src\\modules\\core\\something\\xyz\\xyz.cpp..\\..\\src\\other_modules\\new_core\\something\\pqr\\pqr.cpp..\\..\\src\\other_modules\\new_core\\something\\pqr\\abc.cppThe result I am expecting is ..\\..\\src\\abc\\abc.cpp..\\..\\src\\xyz\\xyz.cpp..\\..\\src\\pqr\\pqr.cpp..\\..\\src\\pqr\\abc.cppHow can I achieve this using sed?I am unable to write an regular expression to capture two groups at the same time.initial group (....\\src) - this will be same in all the linesvariable group (abc\\abc.cpp) or (xyz\\xyz.cpp) or (pqr\\pqr.cpp) or (pqr\\abc.cpp) ",
    "target": "text processing;sed"
  },
  {
    "id": "_unix.338100",
    "source": "How to add a CAA Record on Debian <eos> I currently have a Let's Encrypt SSL certificate for my Debian server, and would like to implement CAA (Certification Authority Authorization, RFC 6844) on it.I'm a bit confused as to how to implement it however, as I don't seem to be able to add it to my zone file on my registrar's site. (gandi.net)Is it a file I add to the root of the web server, or do I have to wait until my registrar supports it?",
    "target": "dns;openssl;ssl"
  },
  {
    "id": "_cstheory.21331",
    "source": "Largest embeddable hypersphere given membership oracle <eos> I have a membership oracle to tell me whether a point is inside of some set, S. I would like to find the radius of the largest (origin-centered) hypersphere that is contained in S.Do you know any good references for this problem? (I'm looking for an algorithm along with a confidence that the hypersphere is fully contained in S).",
    "target": "cg.comp geom"
  },
  {
    "id": "_webapps.51639",
    "source": "Possible to open Office documents in Office Web Apps by default? <eos> Is it possible to set Office Web Apps as the default application for Office documents on Windows? I figure this can't be done at the system level, so I'd be happy with a Firefox extension or IE add-on that could accomplish this.I found a Chrome extension that does what I'm looking for  is there any equivalent in Firefox or IE?",
    "target": "office online"
  },
  {
    "id": "_softwareengineering.64593",
    "source": "Is it good idea to write variable names that match application specific terms? <eos> Let us say I am writing a Facebook like application.I write code like below$this->get_user_friends(); then next morning the boss says that we don't want to call Friends friends anymore, we will call them Pal. Then all the templates are changed but what about the code above? After 2 years when some programmer will have to look into it he is likely to get confused isnt it ?What do you guys really do ? ",
    "target": "variables;naming;coding standards"
  },
  {
    "id": "_datascience.22406",
    "source": "New values for categorical variable in Prediction dataset <eos> I am performing regression task using *random forest**.In my prediction set I am having *new levels for categorical variable** which are not present in training data .Currently I am performing one hot encoding to handle this.At present I am not getting considerable results. This article is saying that it is not good to perform one hot encoding.How to handle this case?",
    "target": "machine learning;statistics;regression;random forest;categorical data"
  },
  {
    "id": "_unix.136884",
    "source": "How to use a shell command to only show the first column and last column in a text file? <eos> I need some help to figure out how to use the sed command to only show the first column and last column in a text file. Here is what I have so far for column 1:cat logfile | sed 's/\\|/ /'|awk '{print $1}'My feeble attempt at getting the last column to show as well was:cat logfile | sed 's/\\|/ /'|awk '{print $1}{print $8}'However this takes the first column and last column and merges them together in one list.Is there a way to print the first column and last columns clearly with sed and awk commands?Sample input:foo|dog|cat|mouse|lion|ox|tiger|bar",
    "target": "shell;sed;awk"
  },
  {
    "id": "_webmaster.14251",
    "source": "Setting up a personal domain name <eos> Possible Duplicate:How to find web hosting that meets my requirements? I'm looking to set up a personal website, but I know very little about web hosting. Could somebody recommend a (not very expensive) host? What should I look for when choosing a host? Also, I'm rather icky about atriyasen.com because people can't make out if I'm Atriya Sen (which I am) or Atri Yasen! Would you recommend atriya-sen.com? atriya_sen.com? Finally, what about other TLDs like .name? ",
    "target": "domains;looking for hosting"
  },
  {
    "id": "_unix.57982",
    "source": "Creating Emacs TAGS file <eos> I am working through the Emacs Lisp Intro book within Emacs 23.4.1 on Debian Wheezy (CrunchBang Waldorf).Section 4.1 discusses the find-tags command and the TAGS file. Instructions are included to build/install the TAGS file if necessary.How do I do this in Debian? The folders mentioned are not present on my system and I cannot locate a TAGS file.I'm not sure that I have the source of Emacs installed? I installed it using apt-get. My sources.list file does not include any deb-src lines, if that is relevant.",
    "target": "debian;emacs"
  },
  {
    "id": "_webmaster.36316",
    "source": "Will uploading our .docx files on scribd and embedding the files on our website affect search engine rankings? <eos> We have prepared notes for university students which are on .docx format. And we want it to put on our website for viewing. We tried one option. Uploading the files on scribd and embedding it on our website for viewing on scribd viewer. Will making documents available on srcibd viewer on our website affect search engine rankings ? Will search engines treat it as duplicate content as those are already uploaded on scribd and we are embedding it on our website ?On scribd we have set the uploaded documents as 'private' though.And if it affects, can you suggest any suitable way to make .docx files to be viewed on our website that doesn't affect search engine rankings ?",
    "target": "seo;embed"
  },
  {
    "id": "_webmaster.107379",
    "source": "Protocol Agnostic Robots Sitemap <eos> Recently, I have enabled all my servers to serve everything over HTTP and HTTPS. Users can access any site via http://www.example.com or https://www.example.com. All pages are identical between the versions, so http://www.example.com/about.php is the same as https://www.example.com/about.php and so on.URLs are relative, so they do not mention the protocol with one exception. In other words, if the page is loaded with HTTP, it will link to other pages, images, CSS, Javascript over HTTP and the same with HTTPS, as to avoid mixed content warnings.Now about that exception. It is in robots.txt:Sitemap: http://www.example.com/sitemap.phpApparently this URL must be absolute.Now the problem I see if that when Google reads https://www.example.com/robots.txt it gets an HTTP sitemap! The documentation on robots.org says that one can specify multiple sitemaps but if I am not sure that putting both the HTTP and HTTPS sitemap is a good idea since they will contain each a list of identical pages (one with HTTP and one with HTTPS).How should Sitemap in robots.txt be handled for websites that accept  HTTP and HTTPS?Some ideas that came to mind:Specify both sitemaps (as mentioned above). Afraid this would cause duplicate content issues.Only specify the HTTPS Sitemap. That gives access to all unique pages anyway.Find a magical (Apache) way to sent a different robots.txt via HTTP and HTTPS. Is that even possible? Could it cause issues?",
    "target": "sitemap;robots.txt"
  },
  {
    "id": "_unix.91057",
    "source": "Configuring Org-mode to open PDFs with evince <eos> I'm starting to use org-mode to export text to LaTeX.My problem is that it opens the generated PDF with ebook-viewer (it is a EPUB, CHM reader) instead of using evince.QuestionDoes anyone know how to change this behaviour and configure evince to be the default viewer?",
    "target": "emacs;pdf;file opening;org mode"
  },
  {
    "id": "_codereview.47851",
    "source": "Multi-threaded socket server high load <eos> I'm trying to make a backend for QuizUp like application: user connects to a server, sends credentials and gets paired up with another user. After that server handles each pair, periodicaly sending server messages to each user in a pair and also redirecting user's mesages between them.Server class:private static class Server{    private static final int NUM_THREADS = 2400;    private ExecutorService executorService;    private ServerSocket serverSocket;     private int listeningPort;    public volatile boolean isRunning;      private Thread mainThread;    private volatile Map<String, Conn> playRequests;    public Server(int port){        try {            executorService = Executors.newFixedThreadPool(NUM_THREADS);            listeningPort = port;            serverSocket = new ServerSocket(listeningPort);            isRunning = true;            playRequests = new ConcurrentHashMap<String, Conn>();            mainThread = new Thread(new Runnable(){                @Override                public void run() {                    handleIncomingConnections();                }            });        } catch (IOException e) {            System.out.println(e.toString());        }    }    public void run(){        mainThread.start();    }    private void handleIncomingConnections(){        while(isRunning){                           try {                final Socket client = serverSocket.accept();                Runnable gameRunnable = new Runnable(){                    @Override                    public void run() {                        try{                            BufferedReader reader = new BufferedReader(new InputStreamReader(client.getInputStream()));                            PrintWriter writer = new PrintWriter(new BufferedWriter(new OutputStreamWriter(client.getOutputStream())), true);                              String read = null;                            String id = null;                            boolean isRequesting = false;                            String rid = null;                            while(!(read = reader.readLine()).equals(FIN_1)){                                String[] str = read.split(#);                                if(str[0].equals(id)){                                    id = str[1];                                }else if(str[0].equals(isRequesting)){                                    isRequesting = (str[1].equals(1));                                }else if(str[0].equals(rid)){                                    rid = str[1];                                }                            }                            Conn connection = new Conn(client, isRequesting, id, writer, reader);                            if(isRequesting){                                playRequests.put(rid, connection);                            }else{                                if(playRequests.containsKey(id)){                                    Conn conn = playRequests.get(id);                                    playRequests.remove(id);                                    handleGame(conn, connection);                                }                            }                                                       }catch(Exception e){                            System.out.println(e.toString());                        }                    }                                       };                executorService.execute(gameRunnable);            } catch (IOException e) {                // TODO Auto-generated catch block                e.printStackTrace();            }                   }    }    private void handleGame(Conn a, Conn b){        new GameHandler(a, b).execute();    }}GameHandler class:private class GameHandler{        private volatile Conn a;        private volatile Conn b;            private Thread aReadThread;        private Thread bReadThread;        private Thread messageThread;        private Runnable aReadRunnable;        private Runnable bReadRunnable;        private Runnable messageRunnable;        private volatile PrintWriter aWriter;        private volatile PrintWriter bWriter;        private volatile BufferedReader aReader;        private volatile BufferedReader bReader;        private volatile boolean aIsReady;        private volatile boolean bIsReady;        private volatile boolean isGameRunning;        public GameHandler(final Conn s1, final Conn s2){            this.a = s1;                        this.b = s2;            isGameRunning = true;            try {                aWriter = a.writer;                bWriter = b.writer;                aReader = a.reader;                bReader = b.reader;            } catch (Exception e) {                try {                    isGameRunning = false;                    a.close();                    b.close();                } catch (IOException e1) {                    // TODO Auto-generated catch block                    e1.printStackTrace();                }                System.out.println(e.toString());            }            messageRunnable = new Runnable(){                @Override                public void run() {                    System.out.println(a.id +   + b.id);                    messageThread = Thread.currentThread();                    for(int i = 0; i < 6; i++){                        if(isGameRunning){                            try{                                Thread.sleep(4000);                            }catch(InterruptedException e){                            }                        }                    }                    //end game                    isGameRunning = false;                    try {                        a.close();                        b.close();                    } catch (IOException e) {                        // TODO Auto-generated catch block                        e.printStackTrace();                    }                }            };            aReadRunnable = new Runnable(){                @Override                public void run() {                         aReadThread = Thread.currentThread();                    String line = null;                    try {                        while (isGameRunning && (line = aReader.readLine()) != null &&  !(line = aReader.readLine()).equals(FIN)){                            bWriter.println(line);                        }                        a.close();                        System.out.println(a.id +  done);                    } catch (Exception e) {                        try {                            isGameRunning = false;                            a.close();                            b.close();                        } catch (IOException e1) {                            // TODO Auto-generated catch block                            e1.printStackTrace();                        }                        System.out.println(e.toString());                    }                }            };            bReadRunnable = new Runnable(){                @Override                public void run() {                    bReadThread = Thread.currentThread();                    String line = null;                    try {                        while (isGameRunning && (line = bReader.readLine()) != null &&  !(line = bReader.readLine()).equals(FIN)){                            aWriter.println(line);                        }                        b.close();                        System.out.println(b.id +  done);                    } catch (Exception e) {                        try {                            isGameRunning = false;                            a.close();                            b.close();                        } catch (IOException e1) {                            // TODO Auto-generated catch block                            e1.printStackTrace();                        }                        System.out.println(e.toString());                    }                }                               };        }                   public void execute() {            executorService.execute(messageRunnable);            executorService.execute(aReadRunnable);            executorService.execute(bReadRunnable);                 }               } And a container class for each users to hold open socket, in/out streams, credentials, etc:private class Conn{        public Socket s;        public boolean isRequesting;        public PrintWriter writer;        public String id;        public BufferedReader reader;        Conn(Socket s, boolean isRequesting, String id, PrintWriter writer, BufferedReader reader){            this.s = s;            this.isRequesting = isRequesting;            this.id = id;               this.writer = writer;            this.reader = reader;        }        public void close() throws IOException{            s.close();        }    }The logic is following:Server has a mainThread, where it accepts incoming connections and creates client sockets. For each new socket it creates a gameRunnable, where it listens for client's credentials (whether this client is the one requesting connection, id of the user it wants to connect to, id of itself). After receiving credentials, server creates a new Conn object, storing all the info(id, and also socket and in/out streams, so it doesn't have to open it again after) there, and than places it in the Map (playRequests) with requested user id as a key. If there is a matching pair in a map, server creates a new GameHandler for these two Conn objects (all this still goes inside the gameRunnable). Each GameHandler contains three Runnables: messageRunnable to send messages from server to both users, and two Runnables (aReadRunnable and bReadRunnable) to read incoming data from both sockets. So basically, each communication session (game) requires 4 threads (1 to get credentials and start a game, and three to maintain the game before the end). Here are the questions I have:Are there any design/implementation issues you see here? Please be as picky as possible because I'd really not want it to crash under high load. If you see smth, you are more than welcome to give your solutionsI know that having large and uncontrolled number of threads is a bad practice, so I'm using an executer with fixed thread pool to execute all the Runnables. However, due to the game features, I can't make users who are requesting connections wait for empty threads in a pool, what is obviously going to happen if I have a lot of incoming connections. So is usage of thread pool reasonable here? If yes, what number of threads should I use, given that I need 4 threads per game, and each game lasts approximately 2 minutes.Am I closing all the sockets correctly? Are there any memory leaks?Other questions regard server deploying:I'm planning to run it on Amazon EC2. Should I use Tomcat server for this, or can I just run it as a plain java program on JVM?I tested it on my laptop, and having many simultaneous connections, heap size is not enough to handle all of them. Should I increase heap size before lunch as much as possible, or it may affect performance?",
    "target": "java;multithreading;socket;server"
  },
  {
    "id": "_unix.50329",
    "source": "Two exact copies of folder using FTP and command-line only <eos> I'm looking for any solution that will allow me to emulate functionallity similar to Dropbox/rsync using only FTP protocol and command-line.The general problem is, that I have to run it on a very limited Linux (actually NAS), so I can't install / use to complex solutions (not enough resources to run) and/or GUI utils, as I have no GUI there. SSH also works weak on that NAS and is not present at all on one of destinations.What I need, is to have a command-line (bash) script or program that I will be able to run periodically (via CRON) that will assure that source and destination are identical:all files on both sides copied to both sides,if two files of the same name exists, copy newest version of a file to both sides,delete on one side all files that are missing on another one.Of course, this solution must support iteration on all subfolders of both source and destination, for this to work succesfully -- there will be a large directory structure on both sides.I've tried many backups solutions, but most of them failed for one of these reasons:unable to create exact duplicate copy of both sides and offering incremental backup instead,not able to be run directly from command-line, on very limited Linux distro.I was advised to use Unison and give it a good try. This really looks good, but it uses SSH, and I'm unable to establish SSH connection to one of my destinations (not supported) -- i.e. FTP access is the only available way.The perfect solution for me would be anything that I can run (command-line or  configuration) like this:something.sh path/to/local/folder ftp://user:pass@111.11.11.1/path/to/folderIf it does exists at all...",
    "target": "backup;ftp"
  },
  {
    "id": "_unix.226420",
    "source": "How to get disk name that contains a specific partition <eos> If I know that a partition is for example /dev/sda1 how can I get the disk name (/dev/sda in this case) that contains the partition ?  The output should be only a path to disk (like /dev/sda).  It shouldn't require string manipulation, because I need it to work for different disk types.",
    "target": "linux;partition;disk;block device"
  },
  {
    "id": "_unix.154039",
    "source": "Create a file that's really a network port <eos> I have a program running on a cluster, and the output of the program is written to a log file which I specify.  However, instead of writing it to a file, I want to write it to a network port, so that it can be read with e.g. Node.js.For example, I want to be able to specify a file along the lines of /dev/127.0.0.1:3000Currently, I'm using Node.js to watch the log file, re-read all the data when it changes, compare the new data with the old data to see what was added, and then process that.  But that's quite inefficient.",
    "target": "files;filesystems;serial port"
  },
  {
    "id": "_unix.283409",
    "source": "rename the 10 most-recently modified files on AIX <eos> I have some .xls files in a defined directory (say in /A/B). I want to rename top 10 latest files and append -bkp in their names.I tried, not workingls -lt *.xls | head -1 | awk '{print mv  $9  $9-bkp}' | shI tried find and -exec but how do we get top l0 latest modified files",
    "target": "files;rename;aix"
  },
  {
    "id": "_unix.91286",
    "source": "wpa supplicant: No network configuration found for current AP - carl9170-driven wifi adapter glitching on Debian 7 <eos> I've got a Debian 7 machine with Linux3.2 kernel and a USB wifi adapter with Atheros chipset (D-Link DWA-16 Xtreme N Dual Band), which in theory should work. Indeed, I managed to establish a wifi communication with NetworkManager and it worked more or less fine for ~30 minutes, but then disconnected and failed to reestablish the connection.I failed to reestablish the connection with NetworkManager, it successfully associates and authenticates, starts 4-way handshake, but then deauthenticates due to reason 15 (4-way handshake timeout).Then I tried to do the same via the good old ifupdown by creating an entry in /etc/network/interfaces:allow-hotplug wlan1iface wlan1 inet static       wpa-ssid MyNet       wpa-psk <My key hash generated by `wpa_passphrase MyNet key`>       address 192.168.1.2       netmask 255.255.255.0       broadcast 192.168.1.255       gateway 192.168.1.1       dns-nameservers a.b.c.dWhen I sudo ifup wlan1, it behaves reasonably,  until:wpa_supplicant[8258]: wlan1: Associated with <router's MAC>wpa_supplicant[3402]: wlan1: No network configuration found for the current AP(from  /var/log/syslog). Wireshark sees ARP packages going from my wifi adapter to the router, but the router doesn't reply.Do you have any ideas about what could that mean and how to troubleshoot this?SOLUTION:Thanks to suggestion by peterph, I tried to create wpa_supplicant.conf and run wpa_supplicant as a standalone program both in foreground and background and then used wpa-conf wpa_supplicant.conf in /etc/network/interfaces.sudo wpa_supplicant -iwlan1 -c/etc/wpa_supplicant/wpa_supplicant.conf -dsudo wpa_supplicant -iwlan1 -c/etc/wpa_supplicant/wpa_supplicant.conf -BI had the first part of troubles (with spontaneous disconnect after status: associated) disappear, when I killed a running instance of NetworkManager. It seems to have interfered.Second part of trouble was with the 4-way handshake failing. It passed ok, when I disabled MAC address filtration on the Access Point. My wifi interface's MAC was in the list of available MACs, but for some reason it still was failing to connect with MAC filtering on the router.UPDATE 2: The problems are back. 4-way handshake is failing again. Reload of the driver won't help.",
    "target": "debian;networking;wifi;wpa supplicant"
  },
  {
    "id": "_webmaster.4069",
    "source": "How do I differentiate 404 messaging with no dynamic language ability on the web server? <eos> Depending on the type of page visited (for example, static content vs. product page), we have a requirement to show different error messaging when the page requested is not found.  Given that we are on a two tier architecture and have no dynamic language ability on the web servers, we are using HTTP status codes in the 400 range to display this messaging using the ErrorDocument setting in Apache configuration.These status codes, of course, show up in Google Webmaster tools as HTTP errors rather than not found errors and there is concern that these 400 range errors will not cause search engines to remove these pages from their indexes.Is there anyone else who has had this type of requirement with the limitation of no dynamic languages on the web server - and if so - have you solved this problem differently?Thanks",
    "target": "seo;search engines;apache"
  },
  {
    "id": "_computerscience.5377",
    "source": "How can I perform a triangle inside test in polygon meshes? <eos> I have 3 vertices (V1, V2, V3) randomly selected on a regular triangle mesh. For these 3 vertices, I have computed the geodesic distance and the path (by using Dijkstra) among them and formed a triangle-like surface as in the above figure. Now, I have the vertices that lie in each path and can compute geodesic distances from a given vertex.What I want to do is to get the vertices or triangles that lies in triangle-like area. How can I do this?",
    "target": "mesh;triangulation"
  },
  {
    "id": "_unix.232562",
    "source": "Mounting a shared drive from windows with CIFS <eos> What I'm trying to achieve is mounting some drives shared on my network (one a Time Capsule, 3 shared drives from a Windows 10 machine) on a Raspberry Pi 2 running Ubuntu 14.04 with read and write permissions.  I have been able to get the drives to mount by using this://10.0.1.2/Movies /home/kev/NetworkDrives/Movies cifs username=user,password=password 0 0Obviously using the correct info for username and password.Using this line in the /etc/fstab file achieves mounting the drives.I am able to read the files and copy them to my local storage but I can not write to the mounted drives and I can not find out what is wrong.This is new territory for me so your help is appreciated.",
    "target": "mount;ubuntu"
  },
  {
    "id": "_unix.145476",
    "source": "How to install D-Link DWA-510 for Debian 7? <eos> I just bought a D-Link DWA-510. But I can't install it on my Debian 7 32 bits. And I want to use in a runlevel 3. How can I use this D-link? Thanks! ",
    "target": "debian;wifi;drivers"
  },
  {
    "id": "_unix.340010",
    "source": "How do I create sequentially numbered file names in bash? <eos> I need a script that will create a file with the next file in a sequence. Each execution of the script should only create one file and the script could be run zero or more times on any given day. The files should be named after the current date in format %y%m%d with the second file having -01 appended, the third file to be created on a given date would have -02 etc. For example:20170125.txt  // first file create on the day.20170125-01.txt // 2nd file20170125-02.txt // 3rd fileSo far I've got this super basic script that creates my first daily file but I'm stumped as to how to do the incremental numbering after that.#! /bin/bashDATE=`date +%Y%m%d`touch $DATE.txt",
    "target": "bash;shell script;scripting"
  },
  {
    "id": "_unix.320274",
    "source": "Not getting libglib2.0-dev (updated libraries) even after upgrading from Ubuntu 14.04 to 16.06 <eos> I wanted to compile and install something-for-reddit from git.As I went with ./configure.ac it showed below error../configure: line 5088: GLIB_GSETTINGS: command not found./configure: line 5089: syntax error near unexpected token `1.42.0'./configure: line 5089: `GOBJECT_INTROSPECTION_CHECK(1.42.0)'As I searched here in stackoverflow, it showed me that the GLIB_GSETTINGS are found in libglib2.0-dev but as I tried to install it through sudo apt-get install libglib2.0Again it threw below error    Reading package lists... DoneBuilding dependency tree       Reading state information... DoneNote, selecting 'libglib2.0-0-refdbg' for regex 'libglib2.0'Note, selecting 'libglib2.0-cil-dev' for regex 'libglib2.0'Note, selecting 'libglib2.0-tests' for regex 'libglib2.0'Note, selecting 'libglib2.0-0-dbg' for regex 'libglib2.0'Note, selecting 'libglib2.0-bin' for regex 'libglib2.0'Note, selecting 'libglib2.0-cil' for regex 'libglib2.0'Note, selecting 'libglib2.0-dbg' for regex 'libglib2.0'Note, selecting 'libglib2.0-dev' for regex 'libglib2.0'Note, selecting 'libglib2.0-doc' for regex 'libglib2.0'Note, selecting 'libglib2.0-data' for regex 'libglib2.0'Note, selecting 'libglib2.0-0' for regex 'libglib2.0'libglib2.0-0 is already the newest version (2.48.1-1~ubuntu16.04.1).libglib2.0-data is already the newest version (2.48.1-1~ubuntu16.04.1).libglib2.0-bin is already the newest version (2.48.1-1~ubuntu16.04.1).Some packages could not be installed. This may mean that you haverequested an impossible situation or if you are using the unstabledistribution that some required packages have not yet been createdor been moved out of Incoming.The following information may help to resolve the situation:The following packages have unmet dependencies: libglib2.0-0-dbg : Depends: libglib2.0-0 (= 2.48.0-1ubuntu4) but 2.48.1-1~ubuntu16.04.1 is to be installed libglib2.0-0-refdbg : Depends: libglib2.0-0 (= 2.48.0-1ubuntu4) but 2.48.1-1~ubuntu16.04.1 is to be installed libglib2.0-dev : Depends: libglib2.0-0 (= 2.48.0-1ubuntu4) but 2.48.1-1~ubuntu16.04.1 is to be installed                  Depends: libglib2.0-bin (= 2.48.0-1ubuntu4)I have upgraded the system from 14.04 to 16.04 one month back, did I miss something or am I doing something wrong now .The something for reddit git source is here. https://github.com/samdroid-apps/something-for-reddit You can check all the dependencies here too, Package Details: something-for-reddit-git 0.1-1",
    "target": "ubuntu;libraries;github"
  },
  {
    "id": "_unix.384378",
    "source": "What should be in the /etc/shadow file if I want my root account to be disabled? <eos> On one of my machines it's root::somenumber[...]::: with somenumber[...] being the same as for my actual account (after what appears to be the encrypted passphrase) and the logcheck account (after :*:). On another machine it's root :!:somenumber[...]::: with somenumber[...] being the same for all accounts until the most recently added ones starting with postfix:*:.I didn't enter a root password during installation for both of these machines. However I accidentally set it for one of them and had to remove it again using the passwd -d root command. I'm running Debian 9.1 with KDE.What exactly should be in there if I wish for my root account to be locked (I use the sudo command)? Are those file contents fine?And related to this would also be this question: how can I view a history of changes to the shadow file including info on which user changed what and when.",
    "target": "debian;root;shadow"
  },
  {
    "id": "_unix.369827",
    "source": "ssh-agent terminating on network change <eos> My work computer is a painfully out of date Ubuntu 16.04 machine. I have it configured such that that lightdm invokes ssh-agent (not gnome-keyring-daemon) and ssh-agent invokes my session. This is not too dissimilar to how I have my personal laptop configured, except there I use Arch and use login on a tty instead of lightdm. My .xinitrc invokes ssh-agent which invokes my window manager. In the end, in both cases, X has been started in an environment that is a child process of ssh-agent, so every shell gets the SSH_AUTH_SOCK environment variable.The odd thing about my work computer is that when I switch networks (either one WiFi network to another or wired <-> WiFi) there is a high probability that ssh-agent will terminate and my session's process will get reparented. This is super frustrating because I can't easily start a new ssh-agent and reparent my session under it - I have to log out and back in again.I have not found any log messages containing ssh-agent or even agent in the systemd journal nor dmesg. The only debugging options ssh-agent seems to have is the -d option to run it in the foreground, I have not tried that yet because it is invoked by lightdm and I don't know if I would even be able to see the output.Are there any debugging steps or known issues I should be aware of with the ssh-agent from openssh-client 1:7.2p2-4ubuntu2.2 ?",
    "target": "ssh agent"
  },
  {
    "id": "_codereview.126441",
    "source": "Diamondize a matrix <eos> The task is to output a representation of the matrix where the top left element is on top, the anti-diagonal is the central row and the bottom right element is at the bottom.For example, consider the following matrix:1 23 45 6The diamond version of this matrix is:  1 3 25 4 6which would correspond to a nested array of [[1],[3,2],[5,4],[6]].This is my program:FNUlQ=Y+Y=QXQN+Y@QN;=Q.TQ;FNUlQ=Hx@QNInH_1=QXQN<@QNH;FNUlQ=QXQN_@QN;=Q>Q1;pQ;How it works:(Q is implicitly assigned to the evaluation of input)FNUlQ=Y+Y=QXQN+Y@QN;FNUlQ                ;         for N in range(len(Q)):     =Y+Y                        Y = Y+           =QXQN+Y@QN              Q[N] = Y+Q[N]=Q.TQ;                         assign('Q',transpose(Q))FNUlQ=Hx@QNInH_1=QXQN<@QNH;FNUlQ                          for N in range(len(Q)):     =Hx@QN                      H = Q[N].index_of()             InH_1                 if H != -1:                  =QXQN<@QNH           Q[N] = Q[N][:H]FNUlQ=QXQN_@QN;FNUlQ         ;                for N in range(len(Q)):     =QXQN_@QN                     Q[N] = reverse(Q[N])=Q>Q1;                         Q = Q[1:]pq;                            print(Q)I am especially interested in advice on the readability of my code.Link to my first attempt.",
    "target": "pyth"
  },
  {
    "id": "_softwareengineering.163427",
    "source": "How to Convert HTML to PDF Using PHP? <eos> PDF or Portable Document Format is a popular file type that is often used for online documents. It's great for distributing downloadable written content, and is frequently used by governments and businesses alike. Because it's a format that's familiar to all, many applications allow the user to convert other document types to the PDF format. PHP is one programming language that has a built-in ability to convert to PDF. PHP scripts can be used to transform file types such as HTML into PDF files.",
    "target": "software"
  },
  {
    "id": "_unix.238612",
    "source": "Fast field extraction with grep <eos> The problemI have a 32M lines file with the following formattoken^Iname^Iurl$where ^I is the tab escape sequence, and $ is the end-of-line.I need to get the url corresponding to not more than 10k matches with the field name.What I've done is# Get second columncut -f2 <myFile> |# Find the word and line numbergrep -nwi <matchWord> |# Get just the numbercut -f1 -d ':' |# Not more than 10khead -n10000And then, for each entry of the previous output# Print line number sed -n '<number>{p;q}' <myFile># Get 3rd fieldcut -f3Now, this last operation with sed is ridiculously slow.I am wondering how to get the all of this by using grep only, or any other way that doesn't slow down after the first 1k matches.IdeaIt would be just perfect to be able to operate grep on the whole line (without cut -f2), targeting only the second column, and then cut -f3, but I don't have a clue of how to do it.ExampleLine xyzqwertyuiop^Ibananas are yellow^Ihttp://mignons.cool$Match word yellow in field name -> give me http://mignons.cool.cut is needed, because I don't want to match stuff in the field token and url.If I send to grep a cut of myFile, then I no longer have access to the url field, which I am interested in.Input and expected outputInput file:mxp4EdOy-IXkuwsuOfs0EQ^Ilegal yellow pad paper^I0/3/3031.jpg$AeS7tgmlVffBhousr9YY5Q^Ihelicopter parking only sign^I0/3/3032.jpg$8dl-VixSjG4Y0FpX9f5KHA^Iwritten list ^I0/3/3033.jpg$XYvKZC3D_JSwlY8SPl-zLQ^Ihelicopter parking only road sign^I0/3/3034.jpg$xF6zpvpHcmfpHP2MmT2FVg^Irun menu windows programming^I0/3/3035.jpg$mCJvV2rXOmItLBkMZlyIwQ^Icoffee mug^I0/3/3040.jpg$ZiobHk_dLsN-Q921KPJUTA^Icarpet^I0/3/3197.jpg$xFrbGOMfVMl0WeqVAcT27A^Iwater jugs^I0/3/3199.jpg$where ^I is the tab escape sequence, and $ is the end-of-line.Match word helicopter.Expected output (not more than 10k lines):0/3/3032.jpg0/3/3034.jpgPotential solutionSince the url field contains only numbers, I couldcut -f 2,3 <myFile> | grep <matchWord> | cut -f2 | head -n10000But it would be nicer to grep the second field only...",
    "target": "shell script;grep;regular expression"
  },
  {
    "id": "_unix.283228",
    "source": "BASH: count # of words in each line of a document <eos> I need to identify patterns in a text file for further analysis. So the input files may contain semi-structured text as follows;file1905:john: abc123: john@doe.com: US  920:eric: ericaA: eric007@gmail.com: US  1000: rio: ri0ri0: rio@yahoo.com: IN  file2 nathen <tab> nathen@yman.com <tab> 764323545 <tab> UKthomas <tab> thom@gmail.com <tab> 563363421 <tab> UKian <tab> rt@gmail.com <tab> 3453245472 <tab> SPnumber of words in a line may vary for each document. delimiter also vary but unique for each document. what I want is to count number of words per each line in each document.output would be:for file1 5  5 5 5   for file2 4  4 4 4I want generalize this for any file with any delimiter.  It could be - | : \\space+ \\tab+. Some files are as follows:| hetro@gmail.com | er34532 |  | rt@gmail.com | 764474 |",
    "target": "bash;patterns"
  },
  {
    "id": "_webapps.5552",
    "source": "How to edit a person's name in the new Gmail chat? <eos> Previously in Gmail chat, I was just able to click on the name of a person to edit his name. Now, the name acts as a link which opens Contacts, where the editing can happen. the old way was faster. Can I edit the names the old way somehow?For example, here Aardvark is a link, and is not directly editable.",
    "target": "gmail;chat;gmail contacts"
  },
  {
    "id": "_webapps.73545",
    "source": "Auto-Populate Google Apps Hangouts Roster? <eos> I want every user in my organization to have every other user in their Hangouts roster. Is there a way to do this, or even a way to manually populate those rosters for them to give them a starting point?",
    "target": "google apps"
  },
  {
    "id": "_unix.300125",
    "source": "lualatex not available in Debian Wheezy <eos> I want to use lualatexfor compiling Latex document based on Luatex. I have installed those packages: luatex, texlive-binaries, texlive-luatex but no lualatexbinary can be found. What did I miss?",
    "target": "debian;latex"
  },
  {
    "id": "_webapps.88435",
    "source": "Even after I press Publish release, Github release stays as Draft <eos> Creating a Github release usually works well, but for one particular project I can't seem to be able to publish: The Draft stays a Draft and never gets published.It happens both for forks and for projects I created from scratch.Happens with both Firefox and Chrome.",
    "target": "github"
  },
  {
    "id": "_unix.182925",
    "source": "dconf-WARNING **: failed to commit changes to dconf: The connection is closed <eos> Whenever I open any software through Terminal I get following errors and eventually the software opensdconf-WARNING **: failed to commit changes to dconf: The connection is closed(gedit:3609): dconf-WARNING **: failed to commit changes to dconf: The connection is closed(gedit:3609): dconf-WARNING **: failed to commit changes to dconf: The connection is closedError creating proxy: The connection is closed (g-io-error-quark, 18)Error creating proxy: The connection is closed (g-io-error-quark, 18)Error creating proxy: The connection is closed (g-io-error-quark, 18)Error creating proxy: The connection is closed (g-io-error-quark, 18)Error creating proxy: The connection is closed (g-io-error-quark, 18)What can be the possible issue?",
    "target": "dconf"
  },
  {
    "id": "_webmaster.87018",
    "source": "Banning unresolved IP addresses <eos> My server has run out of memory a few times in the past two days, because of which the site crashed. I checked AWstats and found that hundreds of unresolved IP addresss have been logged, and the number of hits from them seems unreasonable:I'm going to ban the top 10 IP addresses as they all seem spammy to me. But there are other hundreds of IP addresses that seems to be causing thousands of hits, and I really don't know if they are legitimate request from users using browsers. I could ban all of them using htaccess, but that doesn't seem very practical nor is a long term solution. (The site gets around 3 million pageviews/month.)My questions are:How do I filter out legitimate users from unwanted bots or IP addresses that are scraping content?Should I go ahead and ban all unresolved IP addresses?Is there an automated way of banning spammy IP addresses?",
    "target": "ip address"
  },
  {
    "id": "_cs.11648",
    "source": "Show that TQBF $\\notin$ SPACE$((\\log{n})^4)$? <eos> How do I show that TQBF $\\notin$ SPACE$((\\log{n})^4)$?  I know that TQBF is PSPACE complete, but is this the right approach?",
    "target": "complexity theory"
  },
  {
    "id": "_webmaster.12962",
    "source": "New site not showing in Google for unique name <eos> I have launched a site for myself and now I'm doing some simple SEO for it.The site uses my name and it's unique and has no competition on search engines, but I don't know why Google crawlers haven't done anything on my site.I have added my site's URL to Google (via addurl) and I have also signed in to Google Webmaster Tools.The title and the url of my site is also related to my name, but even when I Google my name Google returns nothing about my site, and Google Webmaster Tools also shows no keywords for my site. Do you have any idea why this happens?[update] OK, I won't link my site here, I launched it about 5 days ago, and it's on my name (completely unique). I just want it to be shown everytime some one Googles my name - just that simple, but it seems Google hasn't done anything with my site yet, is this normal?",
    "target": "google;seo;google search console"
  },
  {
    "id": "_unix.152114",
    "source": "Automatically starting smuxi-server <eos> Smuxi (isn't that a weird name?) is an IRC client, which has a decoupled server and client setup. The server sits in some always-on machine in the cloud and the client connects to it from a local machine. This is particularly useful if the client machine does not have good or reliable connectivity.If the client loses the connection, it can reconnect to the server, and not lose any of the ongoing chat.So, that brings me to my question. the Smuxi server documentation is a little sparse, It saysIf you want the smuxi-server to automatically start in the background  when your system boots, continue reading the following sections. This  is highly dependent of your operating system as each system provides  its own way to auto start services.There are then some highly instructive blank spaces starting with words like Debian, Ubuntu, and Other Linux.The section then hasTo always start the smuxi-server automatically when the Linux server  boots, add this to your /etc/rc.local file:sudo -u your_linux_user bash -c 'nohup smuxi-server > $HOME/smuxi-server.log &'I'm not sure whether I should be taking this advice.I use Debian, and this script has the wordsThis script is executed at the end of each multiuser runlevel.I'm not sure what that means. Does that mean it executes multiple times? Isn't that a bad thing?Anyway, I'm looking for advice (or possibly scripts) for a way to start the server automatically on boot, and also a way to run it manually and have it background automatically. I could run it inside screen, but that feels a little... hacky.Since I'm using Debian wheezy, I'd like a method that would work with that systems default setup.",
    "target": "debian;init script"
  },
  {
    "id": "_unix.71190",
    "source": "md5 String and File different <eos> Why do I become a different hash when I try:md5 <<< Hellomd5 -s HelloIs it because of a possible line break in the first example?",
    "target": "shell;hashsum"
  },
  {
    "id": "_codereview.31027",
    "source": "Guessing Game (Heads or Tails) <eos> You guess heads or tails by clicking one of the buttons on easyGUI.  If it's right, you will get a good job message.  If it's wrong, you will get a wrong message! After that, there is an option to play again.Please give me some feedback on how I can make my code better, if there is room for improvement.import randomimport timeimport easyguiimport syswhile True:    rand = random.choice([Heads, Tails])    firstguess = easygui.buttonbox(Pick one, choices= [Heads, Tails])    if firstguess == rand:        easygui.msgbox(Wow you win!)    else:    easygui.msgbox(Sorry you guessed wrong!)    time.sleep(2)    answer = easygui.buttonbox(Play again?, choices=[Yes,No])    if answer == Yes:        pass    else:        breakeasygui.msgbox(Ok, see you later!)sys.exit(0)",
    "target": "python;beginner;game"
  },
  {
    "id": "_unix.102205",
    "source": "Doubt when compiling USB/IP drivers <eos> I need to install a USB 3G modem to a Windows virtual machine (running on OVM).The modem will be plugged on a Linux host. (Would Windows be easier?)I don't understand what the following README file says. For newer kernels ( >=2.6.28 ), try linux-staging code!This directory contains the source code of usbip drivers for mainline kernel.[How to make USB/IP drivers]    1. cd $(top)/drivers/{version}/    2. make KSOURCE=/usr/src/kernel-source-2.6.20            KSOURCE is the directory that your kernel was built.    3. If succeed, usbip_common_mod.ko, vhci-hcd.ko and usbip.ko are built.    4. Copy these kernel modules to client and server hosts.    5. Don't forget to make USB/IP tools. See $(top)/src/README.The result of my cat /proc/version is:Linux version 2.6.39-400.209.1.el6uek.x86_64 (mockbuild@ca-build44.us.oracle.com) (gcc version 4.4.6 20110731 (Red Hat 4.4.6-3) (GCC) )What is this linux-staging code? It says I'll need it.Another thing is that the MAKE call requires the KSOURCE location, but I've checked it and it's empty. I should download and extract the 2.6.39 kernel source there, right?Where should I put the generated .ko files as instructed by item 4? ",
    "target": "kernel;compiling;drivers"
  },
  {
    "id": "_webmaster.14229",
    "source": "Updating a News pages written in html <eos> I was wondering how to update a page with new stuff like a new news article or something. (The Website is html based). The only thing I could think of is by uploading and replacing the whole .html page with the new article etc. But isn't there an easier way? Like in wordpress where you just sign in and write the article and post it.",
    "target": "html"
  },
  {
    "id": "_cogsci.12603",
    "source": "Can speech dysarthria occur in schizophrenia without other neurological or medication-induced disruptions? <eos> As I understand it, acquired dysarthria of speech is caused due to problems with motor neurons or other neurological, cerebral and peripheral, conditions in the CNS affecting those. And schizophrenia is primarily a problem in mesolimbic and mesocortical dopaminergic pathways, amongst possibly other problems. Can a purely schizophrenic or psychiatric condition without neurological diagnoses cause dysarthria as a symptom by itself? Or is acquired dysarthria always a sign of a comorbid neurological diagnosis?",
    "target": "schizophrenia;speech"
  },
  {
    "id": "_unix.266075",
    "source": "How to login by ssh when default shell is wrong <eos> I have change default root shell to wrong path. Now the first line of /etc/passwd is look like the following string:root:x:0:0:root:/root:/usr/bin/bashThen I logout from server and now cannot log in by root.There is no other user on server.I know, here is much stupid mistakes, but how I can fix it?Access to server is available only by ssh.UPDATEThe mission is impossible.I found a way to execute any command as www-data user.How can I change /etc/passwd as non-sudo user? ",
    "target": "ssh"
  },
  {
    "id": "_codereview.70620",
    "source": "Small command-line helper tool <eos> I've coded a small command line helper tool for this library I'm working on. The library provides tools for the use of Virtual Texturing on iOS devices (mainly games).This little command line helper is still pretty much a prototype that I coded as quick as I could, for testing a new file format. Some feedback would be appreciated before I expand it further:// Virtual Texturing Library:#include vt_tool_image.hpp#include vt_tool_pagefile_builder.hpp#include vt_tool_platform_utils.hpp// Standard library:#include <cstdarg>#include <cstdio>#include <cstdlib>#include <cstring>#include <string>namespace {// ======================================================// Local data:// ======================================================vt::tool::PageFileBuilderOptions cmdLineOpts;std::string inputFile, outputFile;// ======================================================// printHelpAndExit()// ======================================================void printHelpAndExit(){    std::printf(\\n    Usage:\\n    $ vtmake <input_file> <output_file> [--flags=]\\n    \\n    Flags accepted:\\n    --help           : prints help text with list of commands.\\n    --filter         : (str)  type of mipmapping filter: box, tri, quad, cubic, bspline, mitchell, lanczos, sinc, kaiser.\\n    --page_size      : (int)  total page size in pixels, including border.\\n    --content_size   : (int)  size in pixels of page content, not including border.\\n    --border_size    : (int)  size in pixels of the page border.\\n    --max_levels     : (int)  max mipmap levels to generate.\\n    --flip_v_src     : (bool) flip the source image vertically.\\n    --flip_v_tiles   : (bool) flip each individual tile/page vertically.\\n    --stop_on_1_mip  : (bool) stop subdividing when mip 0 is reached.\\n    --add_debug_info : (bool) print debug text to each page.\\n    --dump_images    : (bool) dump each page as an image file (TGA format).\\n    --verbose        : (bool) print stuff to STDOUT while running.\\n    \\n);    std::exit(0);}// ======================================================// error():// ======================================================void error(const char * format, ...){    va_list vaList;    char buffer[1024];    va_start(vaList, format);    std::vsnprintf(buffer, sizeof(buffer), format, vaList);    va_end(vaList);    buffer[sizeof(buffer) - 1] = '\\0'; // Ensure a null at the end    throw vt::tool::PageFileBuilderError(buffer);}// ======================================================// parseFilterName():// ======================================================vt::tool::FilterType parseFilterName(const char * str){    // Find the value after the '=' sign, if any:    while ((*str != '=') && (*str != '\\0'))    {        ++str;    }    if (*str == '=') { ++str; }    if (std::strcmp(str, box     ) == 0) { return vt::tool::FilterType::Box;       }    if (std::strcmp(str, tri     ) == 0) { return vt::tool::FilterType::Triangle;  }    if (std::strcmp(str, quad    ) == 0) { return vt::tool::FilterType::Quadratic; }    if (std::strcmp(str, cubic   ) == 0) { return vt::tool::FilterType::Cubic;     }    if (std::strcmp(str, bspline ) == 0) { return vt::tool::FilterType::BSpline;   }    if (std::strcmp(str, mitchell) == 0) { return vt::tool::FilterType::Mitchell;  }    if (std::strcmp(str, lanczos ) == 0) { return vt::tool::FilterType::Lanczos;   }    if (std::strcmp(str, sinc    ) == 0) { return vt::tool::FilterType::Sinc;      }    if (std::strcmp(str, kaiser  ) == 0) { return vt::tool::FilterType::Kaiser;    }    std::printf(WARNING: Unknown filter '%s'! Defaulting to box filter.\\n, str);    return vt::tool::FilterType::Box;}// ======================================================// parseInt():// ======================================================int parseInt(const char * str){    // Find the value after the '=' sign, if any:    while ((*str != '=') && (*str != '\\0'))    {        ++str;    }    if (*str == '=') { ++str; }    return std::stoi(str);}// ======================================================// parseBool():// ======================================================bool parseBool(const char * str){    // Find the value after the '=' sign, if any:    while ((*str != '=') && (*str != '\\0'))    {        ++str;    }    if (*str == '=') { ++str; }    if ((std::strcmp(str, false) == 0) ||        (std::strcmp(str, no)    == 0) ||        (std::strcmp(str, 0)     == 0))    {        return false;    }    // Assume true for anything else, including an invalid value or an empty string.    // (results in true for --flag with no =value part)    return true;}// ======================================================// startsWith():// ======================================================bool startsWith(const char * str, const char * prefix){    const size_t prefixLen = std::strlen(prefix);    if (prefixLen == 0)    {        return false;    }    return std::strncmp(str, prefix, prefixLen) == 0;}// ======================================================// parseCmdLine():// ======================================================void parseCmdLine(const int argc, const char * argv[]){    // Possible --help call    if ((argc == 2) && startsWith(argv[1], --help))    {        printHelpAndExit();    }    // Must have at least argv[0], in_file and out_file    if (argc < 3)    {        error(Not enough arguments!);    }    /* argc[0] == vtmake (prog name) */    inputFile  = argv[1];    outputFile = argv[2];    for (int i = 3; i < argc; ++i)    {        if (startsWith(argv[i], --help))        {            printHelpAndExit();        }        else if (startsWith(argv[i], --filter))        {            cmdLineOpts.textureFilter = parseFilterName(argv[i]);        }        else if (startsWith(argv[i], --page_size))        {            cmdLineOpts.pageSizePixels = parseInt(argv[i]);        }        else if (startsWith(argv[i], --content_size))        {            cmdLineOpts.pageContentSizePixels = parseInt(argv[i]);        }        else if (startsWith(argv[i], --border_size))        {            cmdLineOpts.pageBorderSizePixels = parseInt(argv[i]);        }        else if (startsWith(argv[i], --max_levels))        {            cmdLineOpts.maxMipLevels = parseInt(argv[i]);        }        else if (startsWith(argv[i], --flip_v_src))        {            cmdLineOpts.flipSourceVertically = parseBool(argv[i]);        }        else if (startsWith(argv[i], --flip_v_tiles))        {            cmdLineOpts.flipTilesVertically = parseBool(argv[i]);        }        else if (startsWith(argv[i], --stop_on_1_mip))        {            cmdLineOpts.stopOn1PageMip = parseBool(argv[i]);        }        else if (startsWith(argv[i], --add_debug_info))        {            cmdLineOpts.addDebugInfoToPages = parseBool(argv[i]);        }        else if (startsWith(argv[i], --dump_images))        {            cmdLineOpts.dumpPageImages = parseBool(argv[i]);        }        else if (startsWith(argv[i], --verbose))        {            cmdLineOpts.stdoutVerbose = parseBool(argv[i]);        }        else        {            std::printf(WARNING: Unknown command line argument: '%s'\\n, argv[i]);        }    }    if (cmdLineOpts.stdoutVerbose)    {        std::printf(Input  file: \\%s\\\\n, inputFile.c_str());        std::printf(Output file: \\%s\\\\n, outputFile.c_str());        cmdLineOpts.printSelf();    }}// ======================================================// runPageFileBuilder():// ======================================================void runPageFileBuilder(){    if (inputFile.empty())    {        error(No input filename!);    }    if (outputFile.empty())    {        error(No output filename!);    }    vt::tool::PageFileBuilder pageFileBuilder(inputFile, outputFile, cmdLineOpts);    pageFileBuilder.generatePageFile();    std::printf(Done!\\n);}} // namespace {}// ======================================================// main():// ======================================================int main(int argc, const char * argv[]){    try    {        parseCmdLine(argc, argv);        runPageFileBuilder();        return 0;    }    catch (std::exception & e)    {        std::printf(ERROR: %s\\n, e.what());        return -1;    }}The main purpose of this code, as you can see, is to parse and validate command line args. The heavy work is then done by the library. It looks very C-ish, I'll admit. Since I wrote it quickly for testing, I didn't bother much. Also, command args validation is still pretty weak. I might consider refactoring it into a class and using less char* and more std::string.",
    "target": "c++;c++11;console"
  },
  {
    "id": "_softwareengineering.177308",
    "source": "Can I use a project code which has New BSD license but uses a GPL license library? <eos> I want to use the ICSOpenVpn project source code in my commercial application.If we see the ICSOpenVpn project, it states that its license is New BSD but the libopenvpn.so library it uses is under GNU GPLv2 license.As per FAQ for version 2 of GNU GPL If a library is released under the GPL (not the LGPL), does that mean that any program which uses it has to be under the GPL? The answer says: Yes, because the program as it is actually run includes the library.Also, how could ICSOpenVpn change the license to New BSD?",
    "target": "android;gpl;bsd license"
  },
  {
    "id": "_unix.78611",
    "source": "My reverse-ssh tunnel is using keepalives but they're not helping <eos> I have an ssh client machine picard behind multiple unreliable internet connections - all with NAT.I have my server time, reliable with a static IP.I want to be able to access picard thorugh time. I've done this before:ssh -N -R 19999:localhost:22 user@my.domainThis works, but if there is a problem it exits and does not restart, and it doesn't start on boot, so now I add a sydtemd service to run:/bin/bash -c while true; do /usr/bin/ssh -i <unencrypted key> -o ServerAliveInterval=10 -v -o ServerAliveCountMax=6 -N -R 19999:localhost:22 user@my.domain; sleep 5; donewhile true ... sleep 5 re-runs ssh if it exits-o ServerAliveInterval=10 sends a keep-alive every 10 secnods-o ServerAliveCountMax=6 exits if 6 keep-alives go out with no response-v keeps debug info in /var/log/messages through systemdOn the server side I added a couple of lines to sshd_config:KeepAlive yesClientAliveInterval 10ClientAliveCountMax 6Same idea as the client -  break the connection after 60s of inactivity.Unfortunately it seems to take a lot longer than a minute to restart:< tunnel is up and keepalives are coming in >Jun  7 17:31:02 picard bash[135]: debug1: client_input_global_request: rtype keepalive@openssh.com want_reply 1Jun  7 17:31:12 picard bash[135]: debug1: client_input_global_request: rtype keepalive@openssh.com want_reply 1Jun  7 17:31:15 picard bash[135]: debug1: client_input_channel_open: ctype forwarded-tcpip rchan 2 win 2097152 max 32768Jun  7 17:31:15 picard bash[135]: debug1: client_request_forwarded_tcpip: listen localhost port 19998, originator 127.0.0.1 port 38267Jun  7 17:31:15 picard bash[135]: debug1: connect_next: host localhost ([127.0.0.1]:22) in progress, fd=4Jun  7 17:31:15 picard bash[135]: debug1: channel 0: new [127.0.0.1]Jun  7 17:31:15 picard bash[135]: debug1: confirm forwarded-tcpipJun  7 17:31:15 picard bash[135]: debug1: channel 0: connected to localhost port 22Jun  7 17:31:20 picard systemd-logind[137]: New session 1 of user main_username.< I break eth0 and plug it back in after NM sees it's down >< eth0 is back up within a few seconds >< nothing happens with my ssh connection for a LONG time >Jun  7 17:54:16 picard bash[135]: Write failed: Broken pipeJun  7 17:54:22 picard bash[135]: OpenSSH_6.1p1, OpenSSL 1.0.1c-fips 10 May 2012Jun  7 17:54:22 picard bash[135]: debug1: Reading configuration data /etc/ssh/ssh_configJun  7 17:54:22 picard bash[135]: debug1: /etc/ssh/ssh_config line 50: Applying options for *Jun  7 17:54:22 picard bash[135]: debug1: Connecting to my.domain [123.234.123.234] port 22.Jun  7 17:54:22 picard bash[135]: debug1: Connection established.Jun  7 17:54:23 picard bash[135]: debug1: identity file /home/test/.ssh/id_rsa type 1Jun  7 17:54:23 picard bash[135]: debug1: identity file /home/test/.ssh/id_rsa-cert type -1Jun  7 17:54:23 picard bash[135]: debug1: Remote protocol version 2.0, remote software version OpenSSH_5.8p1 Debian-1ubuntu3Jun  7 17:54:23 picard bash[135]: debug1: match: OpenSSH_5.8p1 Debian-1ubuntu3 pat OpenSSH_5*Jun  7 17:54:23 picard bash[135]: debug1: Enabling compatibility mode for protocol 2.0Jun  7 17:54:23 picard bash[135]: debug1: Local version string SSH-2.0-OpenSSH_6.1Jun  7 17:54:23 picard bash[135]: debug1: SSH2_MSG_KEXINIT sentJun  7 17:54:23 picard bash[135]: debug1: SSH2_MSG_KEXINIT receivedJun  7 17:54:23 picard bash[135]: debug1: kex: server->client aes128-ctr hmac-md5 noneJun  7 17:54:23 picard bash[135]: debug1: kex: client->server aes128-ctr hmac-md5 noneJun  7 17:54:23 picard bash[135]: debug1: SSH2_MSG_KEX_DH_GEX_REQUEST(1024<1024<8192) sentJun  7 17:54:23 picard bash[135]: debug1: expecting SSH2_MSG_KEX_DH_GEX_GROUPJun  7 17:54:23 picard bash[135]: debug1: SSH2_MSG_KEX_DH_GEX_INIT sentJun  7 17:54:23 picard bash[135]: debug1: expecting SSH2_MSG_KEX_DH_GEX_REPLYJun  7 17:54:23 picard bash[135]: debug1: Server host key: RSA 7a:19:72:9d:f5:39:f5:03:cf:16:b2:ee:fc:a4:e6:baJun  7 17:54:23 picard bash[135]: debug1: Host 'my.domain' is known and matches the RSA host key.Jun  7 17:54:23 picard bash[135]: debug1: Found key in /home/test/.ssh/known_hosts:1Jun  7 17:54:23 picard bash[135]: debug1: ssh_rsa_verify: signature correctJun  7 17:54:23 picard bash[135]: debug1: SSH2_MSG_NEWKEYS sentJun  7 17:54:23 picard bash[135]: debug1: expecting SSH2_MSG_NEWKEYSJun  7 17:54:23 picard bash[135]: debug1: SSH2_MSG_NEWKEYS receivedJun  7 17:54:23 picard bash[135]: debug1: Roaming not allowed by serverJun  7 17:54:23 picard bash[135]: debug1: SSH2_MSG_SERVICE_REQUEST sentJun  7 17:54:23 picard bash[135]: debug1: SSH2_MSG_SERVICE_ACCEPT receivedJun  7 17:54:23 picard bash[135]: debug1: Authentications that can continue: publickey,passwordJun  7 17:54:23 picard bash[135]: debug1: Next authentication method: publickeyJun  7 17:54:23 picard bash[135]: debug1: Offering RSA public key: /home/test/.ssh/id_rsaJun  7 17:54:23 picard bash[135]: debug1: Server accepts key: pkalg ssh-rsa blen 279Jun  7 17:54:23 picard bash[135]: debug1: read PEM private key done: type RSAJun  7 17:54:24 picard bash[135]: debug1: Authentication succeeded (publickey).Jun  7 17:54:24 picard bash[135]: Authenticated to my.domain ([123.234.123.234]:22).Jun  7 17:54:24 picard bash[135]: debug1: Remote connections from LOCALHOST:19999 forwarded to local address localhost:22Jun  7 17:54:24 picard bash[135]: debug1: Requesting no-more-sessions@openssh.comJun  7 17:54:24 picard bash[135]: debug1: Entering interactive session.Jun  7 17:54:24 picard bash[135]: debug1: remote forward success for: listen 19999, connect localhost:22Jun  7 17:54:24 picard bash[135]: debug1: All remote forwarding requests processedJun  7 17:54:44 picard bash[135]: debug1: client_input_global_request: rtype keepalive@openssh.com want_reply 1Jun  7 17:54:45 picard bash[135]: debug1: client_input_channel_open: ctype forwarded-tcpip rchan 2 win 2097152 max 32768Jun  7 17:54:45 picard bash[135]: debug1: client_request_forwarded_tcpip: listen localhost port 19999, originator 127.0.0.1 port 60222Jun  7 17:54:45 picard bash[135]: debug1: connect_next: host localhost ([127.0.0.1]:22) in progress, fd=4Jun  7 17:54:45 picard bash[135]: debug1: channel 0: new [127.0.0.1]Jun  7 17:54:45 picard bash[135]: debug1: confirm forwarded-tcpipJun  7 17:54:45 picard bash[135]: debug1: channel 0: connected to localhost port 22Jun  7 17:54:50 picard systemd-logind[137]: New session 3 of user main_username.< whenever I connect the keepalive debug messages stop coming, not sure if this is normal >I'm sure I've overlooked something. I've seen some projects like autossh that do pretty much the same thing I'm doing now, but I'd like to be able to fix this if possible. How do I get the delay down to 2-3 minutes instead of 23 minutes?",
    "target": "ssh;ssh tunneling;sshd"
  },
  {
    "id": "_unix.264055",
    "source": "How do I find out the license for each of my installed applications/packages? <eos> I am using Ubuntu-15.10.I have installed many applications apart from vanilla installations.Now, I would like to find out how many installed packages are licensed under the GPL or third-party licenses (e.g. Fluendo).Is there any way to find this out? Or do I need to check manually each and every license of each installed application?EDIT:Following snippet I used to list out the name of various installed License files.find /usr/share/doc -type f -name copyright -exec grep License\\: {} + | cut -f3 -d: | sort -u",
    "target": "ubuntu;licenses"
  },
  {
    "id": "_unix.76827",
    "source": "Zsh: quickly bookmark commands <eos> I just had an idea, I'm sure it must exist though I could not find anything on the web.This topic gets close to my idea but not enough:How to quickly store and access often used commands?I'd like to have a .bookmark.zsh file in which I store commands, not often used (I could create an alias for these), but more those which were a pain in the ass to write down, and that I could use some other times.Like I just typed: rake db:drop --trace && echo 'dropped' && \\  rake db:create --trace && echo 'created' && \\  rake db:migrate --trace && echo 'migrated' && \\  rake db:seed --trace && echo 'seed'And I want to save it, so I type bm -save 'description' and it adds rake db:drop --trace && echo 'dropped' && \\  rake db:create --trace && echo 'created' && \\  rake db:migrate --trace && echo 'migrated' && \\  rake db:seed --trace && echo 'seed' # description`in my .bookmark.zsh file.And then I can do bm -find 'description' (or ideally 'descr' 'desc' etc.) and I find the command back. Like bookmarks work!I'm pretty bad at shell so any tip would be super nicely welcomed!",
    "target": "zsh;command history"
  },
  {
    "id": "_unix.197332",
    "source": "Modeline for Dell U2415 1920x1200 resolution <eos> I'm trying here to run my secondary display (U2415) on the native resolution 1920x1200. Xrandr unfortunately reports only 1920x1080, which is not satisfactory.$ xrandr Screen 0: minimum 8 x 8, current 3286 x 1080, maximum 32767 x 32767LVDS1 connected 1366x768+1920+312 (normal left inverted right x axis y axis) 344mm x 194mm   1366x768      59.97*+   1024x768      60.00     800x600       60.32    56.25     640x480       59.94  DP1 disconnected (normal left inverted right x axis y axis)HDMI1 disconnected (normal left inverted right x axis y axis)VGA1 connected 1920x1080+0+0 (normal left inverted right x axis y axis) 509mm x 286mm   1920x1080     60.00*+   1680x1050     59.95     1280x1024     75.02    60.02     1440x900      74.98    59.89     1280x960      60.00     1280x800      59.81     1152x864      75.00     1024x768      75.08    70.07    60.00     800x600       75.00    60.32     640x480       75.00    60.00  OS:Linux arch 3.19.3-3-ARCH #1 SMP PREEMPT Wed Apr 8 14:10:00 CEST 2015 x86_64 GNU/LinuxHW:$ lspci -nnks 00:02.000:02.0 VGA compatible controller [0300]: Intel Corporation Core Processor Integrated Graphics Controller [8086:0046] (rev 02)    Subsystem: Lenovo Device [17aa:3920]    Kernel driver in use: i915    Kernel modules: i915I've googled it and it seems that Intel GMA has no problem whatsoever to run 1920x1200 via VGA.The following command gives me my modeline which I've tried and which works, but not quite really - it produces worse quality image than on the 1920x1080 and entire desktop is shifted to the left. Furthermore, when I go the OSD menus on the display I see that I'm getting 1600x1200 60Hz :($ gtf 1920 1200 60 -x  # 1920x1200 @ 60.00 Hz (GTF) hsync: 74.52 kHz; pclk: 193.16 MHz  Modeline 1920x1200_60.00  193.16  1920 2048 2256 2592  1200 1201 1204 1242  -HSync +VsyncI've also tried something called 915Resolution, well it's patched version from this location. But it didn't work very well either. By following examples in their README I've tried:# ./915resolution 30 1920 1200Intel 800/900 Series VBIOS Hack : version 0.5.3Chipset: HDGraphicsBIOS: TYPE 1Mode Table Offset: $C0000 + $268Mode Table Entries: 36Patch mode 30 to resolution 1920x1200 complete# ./915resolution -lIntel 800/900 Series VBIOS Hack : version 0.5.3Chipset: HDGraphicsBIOS: TYPE 1Mode Table Offset: $C0000 + $268Mode Table Entries: 36Mode 30 : 640x480, 8 bits/pixelMode 32 : 800x600, 8 bits/pixelMode 34 : 1024x768, 8 bits/pixelMode 38 : 1280x1024, 8 bits/pixelMode 3a : 1600x1200, 8 bits/pixelMode 3c : 1920x1440, 8 bits/pixelMode 41 : 640x480, 16 bits/pixelMode 43 : 800x600, 16 bits/pixelMode 45 : 1024x768, 16 bits/pixelMode 49 : 1280x1024, 16 bits/pixelMode 4b : 1600x1200, 16 bits/pixelMode 4d : 1920x1440, 16 bits/pixelMode 50 : 640x480, 32 bits/pixelMode 52 : 800x600, 32 bits/pixelMode 54 : 1024x768, 32 bits/pixelMode 58 : 1280x1024, 32 bits/pixelMode 5a : 1600x1200, 32 bits/pixelMode 5c : 1920x1440, 32 bits/pixelYou can see, that Mode 30 remains on 640x480...And finally last but not least important, I'm running all this via QUMOX VGA to HDMI Converter. Their specs clearly state, that they support 1920x1200 resolutions, but I've started to doubt it.So dear sirs, what else I may try, to make my ultra cool display operate on the correct resolution??Thanks",
    "target": "x11;kernel modules;xrandr;pci"
  },
  {
    "id": "_codereview.1462",
    "source": "Coffeescript beautification and refactoring <eos> As much as I try, I cannot seem to get this Coffeescript code to look beautiful (I'd like to think it is possible). I have tried both Javascript and Coffeescript. Just to be clear, this code works fine, but it is hard to read, for reasons that I am unable to pinpoint.How can it be refactored, reorganized, and what changes to coding style can be made to make it more appealing to read?define [  plugins/ui/ui,  ./js/highlight], (ui, highlight) ->  editor = {}  jQuery ($) ->    # A widget to view source code.    $.widget 'core.editor',      _create: ->        $editor = $(this.element)        $editor          .addClass('editor')          .append($('<ul spellcheck=false contenteditable> <li></li> </ul>'))        # Move the gutter along with the editable area.        this.lines().bind 'scroll', (event) ->          $this = $(this)          $this.siblings(.gutter).css(top: $this.scrollTop() * -1)      # Highlight the sourceview using the given language.      # The language's JSON rule file is loaded.      highlight: (language) ->        this.language = language        require [text!plugins/editor/js/#{ language }.json], (json) =>          this._rules = JSON.parse(json)          return      # Update the `left` of the `<ul>` based on the gutter width.      # Each time the number of digits in the gutter changes, it becomes wider or      # narrower, and the editor needs the shift accordingly.      updateGutterWidth: () ->        # The `8` is the gutter's left padding.        this.lines().css(left: this.gutter().width() + 8)      # Add or remove line numbers if the number of lines has changed.      # `change` is a modification the the line count (In case the character was not yet      # typed).      updateLineNumbers: (change = 0) ->        $gutter = this.gutter()        count =   this.lines().children(li).length        current = $gutter.children(span).length        count += change        # Add lines        if (count > current)          for i in [current..(count - 1)]            ele = document.createElement(span)            ele.innerText = #{ i + 1 }            $gutter[0].appendChild(ele)        # Remove lines        else if (current > count)          for j in [count..(current - 1)]            $gutter.children(span:last-child).remove()        this.updateGutterWidth() if current != count        return      # Set whether or not the gutter should be visible.      lineNumbers: (bool) ->        if bool == true and !this.number          $(this.element)            .prepend('<div class=gutter></div>')          this.lines()            .css(left: 20)          this.updateLineNumbers()        else if bool == false and this.number          this.gutter().remove()          $(this.element)            .css(left: 1)        this.number = bool      # Return the gutter (a jQuery object).      gutter: () ->        this._gutter ?= $(this.element).children(div.gutter)        return this._gutter      # Return a jQuery `<ul>`. Each `<li>` is a line of the source viewer.      lines: ->        return $(this.element).children('ul')      # A hash of syntax highlighting rules.      rules: ->        return this._rules    # Re-highlight the text.    $(.editor > ul).live 'keyup', (event) ->      # 13:              Enter      # 37, 38, 39, 40:  Arrow Keys      # 33, 34:          Page up / down      # 16, 17, 18, 91:  Shift, Ctrl, Alt, Meta      # 35, 36:          Home / end      if !(event.which in [13, 37, 38, 39, 40, 33, 34, 16, 17, 18, 91, 35, 36]) and !event.altKey and !event.ctrlKey        # Prevent an annoying error when backspacing to the beginning of a line.        selection = window.getSelection()        # Store the cursor position before highlighting.        cursorPos = selection.getRangeAt(0)        if cursorPos.getClientRects()[0]          clickx = cursorPos.getClientRects()[0].left          clicky = cursorPos.getClientRects()[0].top          # Highlight          $li = $(selection.focusNode).closest(li)          rules = $li.closest(.editor).editor('rules')          highlight.highlight($li, rules)          # Restore cursor position.          cursorPos = document.caretRangeFromPoint(clickx, clicky)          window.getSelection().addRange(cursorPos)    # Line numbering update.    $(.editor > ul).live 'keydown', (event) ->      # Redo line numbering for Enter, Backspace, Delete.      if (event.which in [13, 8, 46])        $this = $(this)        newline = switch event.which          when 13 then 1          when 8  then -1          else 0        $this.parent().editor('updateLineNumbers', newline)        # Correction        setTimeout(() ->          $this.parent().editor('updateLineNumbers', 0)        , 300)    # ##################### MAIN ##########################    $(.frame).frame('tabs').last().tab(content)      .append(<div id='sourceview'></div>)    $(#sourceview)      .css        position: 'absolute'        left:   1        right:  1        top:    1        bottom: 1      .editor()      .editor('theme', 'plugins/editor/themes/idlefingers.css')      .editor(highlight, javascript)      .editor(lineNumbers, true)  return editor",
    "target": "javascript;jquery;jquery ui;coffeescript"
  },
  {
    "id": "_codereview.86593",
    "source": "Doubly linked list: iterator/pointer arithmetic <eos> I'm using a doubly linked list container I've written as the working example.  The textbook I'm using is from 2001, so feel free to point out where later versions of the C++ standard should be used instead.Notes:List::iterator functionality mimics pointer arithmetic.Unlike most containers, list beginning is marked by a specific element which holds no data, to make reverse iteration easier:  [begins][data][data][data][data][data][ends]De-referencing begin/end will deference the closest data element, so *begin = data@0 & *end = data@end-1.The List container plays more elegantly with basic loops (see main).list.h:#ifndef GUARD_List_h#define GUARD_List_htemplate <class T>struct element {    element<T> *prev = NULL;    element<T> *next = NULL;    T data = NULL;    int elem_ID = NULL;    char t_flag = NULL;};template <class T>struct elem_iter {    elem_iter() { target = NULL; }    elem_iter(element<T>* e) { target = e; }    element<T>* target;    element<T>* elem_iter::operator++(void) {        if (target->next->t_flag == 'e'){            return NULL;        }        target = target->next;        return target;    }    element<T>* elem_iter::operator--(void){        if (target->prev->t_flag == 'b'){            return NULL;        }        target = target->prev;        return target;    }    T elem_iter::operator*(void){        if (target->t_flag == 'e'){            target = target->prev;            return target->data;        }        else if (target->t_flag == 'b'){            target = target->next;            return target->data;        }        return target->data;    }    bool elem_iter::operator!=(elem_iter& rhs){        return (rhs.target != this->target);    }    bool elem_iter::operator>=(elem_iter& rhs){        return (this->target->elem_ID >= rhs.target->elem_ID);    }    bool elem_iter::operator<=(elem_iter& rhs){        return (this->target->elem_ID <= rhs.target->elem_ID);    }    bool elem_iter::operator>(elem_iter& rhs){        return (this->target->elem_ID > rhs.target->elem_ID);    }    bool elem_iter::operator<(elem_iter& rhs){        return (this->target->elem_ID < rhs.target->elem_ID);    }    elem_iter elem_iter::operator+(int val){        for (int i = 0; i < val; i++){            this->target = this->target->next;        }        return *this;    }    elem_iter elem_iter::operator-(int val){        for (int i = 0; i < val; i++){            this->target = this->target->prev;        }        return *this;    }};template <typename T>class List {public:    List::List(void) {        element_count = 0;        // create begin        element<T>* b = new element <T>;        b->t_flag = 'b';        begins = b;        // create end        element<T>* e = new element <T>;        e->t_flag = 'e';        ends = e;        // double link: begins & ends         begins->next = ends;        ends->prev = begins;        element_count = 0;    }    typedef elem_iter<T> iterator;    iterator begin(void) {        iterator it(begins);        return it;    }    iterator end(void) {        iterator it(ends);        return it;    }    void push_back(T val) {        element<T>* elem = new element<T>;      // create: new-elem                 elem->data = val;                       // set data        elem->elem_ID = element_count++;        // set ID                       elem->prev = ends->prev;                // link: new-elem to last-data-elem        ends->prev->next = elem;                // link: last-data-elem to new-element                                      elem->next = ends;                      // link: new-elem to List-end                       ends->prev = elem;                      // link: List-end to new-elem                       ends->elem_ID = element_count;          // update: ends-ID when List grows    }    T at(size_t pos) {        return get_element(pos)->data;    }    void del(size_t pos) {        element<T>* elem = get_element(pos);            // get: element for deletion                elem->prev->next = elem->next;                  // rejoin: double link        elem->next->prev = elem->prev;                  // rejoin: double link        delete elem;        ends->elem_ID = (element_count--);              // update: when List shrinks    }    void clear(void) {        element<T>* ep = begins->next;        element<T>* ep_next = ep->next;        while (ep->t_flag != 'e'){            delete ep;            ep = ep_next;            ep_next = ep->next;        }        begins->next = ends;        ends->prev = begins;        begins->data = NULL;        ends->elem_ID = NULL;        element_count = 0;    }    size_t size(void) const {        return element_count;    }    bool empty(void) const {        if (element_count == 0){ return true; }        else { return false; }    }private:    element<T>* begins;                           // List begins    element<T>* ends;                             // List ends    size_t element_count;                         // List size    element<T>* get_element(size_t pos) {        if (empty())                        {            std::cerr << No Element - Empty List;            throw;        }        if (pos < 0 || pos >= element_count){            std::cerr << No Element - Out of Range;            throw;        }        iterator it;        // Determine the more efficent iteration direction(forward or reverse) ?         if ((element_count / 2) > pos) {            it = begin();            for (size_t i = 0; i <= pos; i++){                it++;            }        }        else {            it = end();            for (size_t i = size() - pos; i > 0; i--){                it--;            }        }        return it.target;    }};#endiftypedef List<int> container;main.cpp:#include <iostream>#include <vector>#include <list>#include list.hint main() {        container ls;    container::iterator begin = ls.begin();    container::iterator end = ls.end();    container::iterator iter = begin;    std::cout << Attempt to retrieve data from empty list: ls.at(3) << std::endl;    std::cout << -------------------------------------------------- << std::endl;    //std::cout << ls.at(3) << std::endl << std::endl;    std::cout << Test: growing list does not invalidate iter << std::endl;    std::cout << ------------------------------------------- << std::endl;    std::cout << Empty list << std::endl << std::endl;    std::cout << begin addr:  << &begin <<   << std::endl;    std::cout << begin t_flag:  << begin.target->t_flag <<   << std::endl;    std::cout << end addr:  << &end <<   << std::endl;    std::cout << end t_flag:  << end.target->t_flag <<   << std::endl;    std::cout << std::endl << Add data to list: 33  << std::endl << std::endl;    ls.push_back(33);    std::cout << begin addr:  << &begin <<   << std::endl;    std::cout << begin t_flag:  << begin.target->t_flag <<   << std::endl;    std::cout << end addr:  << &end <<   << std::endl;    std::cout << end t_flag:  << end.target->t_flag <<   << std::endl;    std::cout << std::endl << Add data to list: 33  << std::endl << std::endl;    ls.push_back(856);    std::cout << begin addr:  << &begin <<   << std::endl;    std::cout << begin t_flag:  << begin.target->t_flag <<   << std::endl;    std::cout << end addr:  << &end <<   << std::endl;    std::cout << end t_flag:  << end.target->t_flag <<   << std::endl << std::endl;    std::cout << clear()  << std::endl << std::endl;    ls.clear();    std::cout << std::endl << std::endl;    std::cout << Add data to list: 0 1 2 3 4 5 6 7 8 9 << std::endl;    std::cout << ------------------------------------------------- << std::endl;    for (int i = 0; i != 10; i++){        ls.push_back(i);    }    std::cout << std::endl << std::endl;    std::cout << data@ begin+4 << std::endl;    std::cout << ------------- << std::endl;    std::cout << *(iter + 4) << std::endl;    std::cout << std::endl << std::endl;    std::cout << data@ begin->end << std::endl;    std::cout << ---------------- << std::endl;    iter = begin;    while (iter++){        std::cout << *iter <<  ;    }    std::cout << std::endl << std::endl << std::endl;    std::cout << data@ end->begin << std::endl;    std::cout << ---------------- << std::endl;    iter = end;    while (iter--){        std::cout << *iter <<  ;    }    std::cout << std::endl << std::endl << std::endl;    std::cout << for/iter: begin->end << std::endl;    std::cout << ---------------- << std::endl;    for (iter = begin; iter++;){        std::cout << *iter <<  ;    }    std::cout << std::endl << std::endl << std::endl;    std::cout << iter arith: +4 +1 -1 << std::endl;    std::cout << -------------------- << std::endl;    iter = ls.begin();    iter = iter + 4;    std::cout << *iter <<  ;    std::cout << *(iter + 1) <<  ;    std::cout << *(iter - 1) <<  ;    std::cout << std::endl << std::endl << std::endl;    std::cout << data@: (0)(1)(2)(3)(4)(5)(6)(7)(8)(9) << std::endl;    std::cout << ------------------------------------- << std::endl;    for (int i = 0; i != 10; i++){        std::cout << ls.at(i) <<  ;    }    ls.clear();    return 0;}",
    "target": "c++;linked list;iterator"
  },
  {
    "id": "_unix.183488",
    "source": "NGINX Reverse Proxy - no user/password was provided for basic authentication <eos> I've got Nginx set up on a RPi (raspbian)as a reverse proxy using SSL between the remote user and the Nginx instance. All seems to work well for two services mounted on the RPi (Shellinabox and RPi Monitor). However I can't get Nginx to work with a Couch Potato instance that is held on another server on the same home network.When on the home network, I can access Couch Potato from any device on the network without authentication, but when trying to access it externally through the Nginx reverse proxy, the Nginx error log shows:2015/02/05 10:43:46 [error] 30557#0: *1 no user/password was provided for basic authentication, client: XXX.XXX.XXX.XXX, server: , request: GET /couchpotato/ HTTP/1.1, host: XXX.XXX.XXX.XXXand the Nginx generated access log for Couchpotato shows:XXX.XXX.XXX.XXX - - [05/Feb/2015:10:43:46 +0000] GET /couchpotato/ HTTP/1.1 401 590 - Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; Trident/6.0)       The Nginx configuration file in sites-available is here: http://paste.debian.net/144279/Having read many of the other questions about this I'm guessing that Nginx is trying to pass it's own authentication to couchpotato when I think I don't want anything passed, but I don't know.Grateful for any help",
    "target": "nginx;ssl"
  },
  {
    "id": "_codereview.20955",
    "source": "Kata: Natural Sort <eos> I am choosing to learn F# for my own enjoyment. I am getting to the point where concepts of F# seem to be pretty easy, but understanding some of the whys and whens is a bit harder.Before I get into the code and the explanation, let me put my question up front. I am asking where can I find better advice on formatting F# code for readability? Or can someone give me a few guiding tips based off of the example given below?So what are the best practices for code format and file layout?Now to the explanation of the code.I have started practicing coding Kata's in F# just to allow me to flex the language a little.  The following program is an implementation of a natural sort. This was my first attempt to solving the problem in a TDD fashion in F#, as such I chose to forgo any framework as I did not want to deal with figuring out how to use any of them and not break the functional paradigm.So the code below carries a light weight unit test framework.Here is the code for the natural sort:namespace Katas    open System.Linq    module NaturalSortKata =        exception InvalidException of string        type Comparison =        | Equal        | Lesser        | Greater            static member Compare x y =                if x = y then                    Equal                elif x > y then                    Greater                else                    Lesser        type ChunckType =        | NumberType        | StringType        | Unknown            static member GetType (c : char) =                if System.Char.IsDigit(c) then                    NumberType                else                    StringType            member this.Compare other =                 match other with                | ty when ty = this -> Equal                | Unknown -> Lesser                | NumberType when this = Unknown -> Greater                | NumberType -> Lesser                | StringType -> Greater        let natualCompare (left : string) (right : string) =             if left = right then                Equal            else                let fix str =                    new System.String( str |> List.rev |> List.toArray )                let gatherChunck str =                     let rec gather str acc =                        match str with                        | [] ->                            let (ty, l) = acc                            (ty, fix(l))                        | fistLetter::rest ->                            match acc with                            | (ty, _) when ty = Unknown ->                                let t = ChunckType.GetType(fistLetter)                                gather rest (t, fistLetter :: [])                            | (ty, l) when ty = ChunckType.GetType(fistLetter) ->                                gather rest (ty, fistLetter::l)                            | (ty, l) -> (ty, fix(l))                    gather str (Unknown, [])                let rec compare (left : string) (right : string) =                    if (not (left.Any())) || (not (right.Any())) then                        match left.Length, right.Length with                        | llen, rlen when llen = rlen -> Equal                        | llen, rlen when llen > rlen -> Greater                        | llen, rlen when llen < rlen -> Lesser                        | _ -> raise (InvalidException Bad Data)                    else                        let lt, lChunk = left |> Seq.toList |> gatherChunck                         let rt, rChunk = right |> Seq.toList |> gatherChunck                        match lt.Compare rt with                        | Equal ->                            if lChunk = rChunk then                                let lVal = left.Replace(lChunk, )                                let rVal = right.Replace(rChunk, )                                compare lVal rVal                            else                                match lt with                                | NumberType ->                                    Comparison.Compare (System.Int64.Parse(lChunk)) (System.Int64.Parse(rChunk))                                | _ ->                                    Comparison.Compare lChunk rChunk                        | _ ->                            lt.Compare(rt)                compare left rightHere is the code for the tests:namespace Katas.Testing    open Katas.NaturalSortKata    module Tests =        let test left right expected title=            let testRun x =                  let result = right |> natualCompare left                if result = expected then                    x |> printfn %d good                    true                else                    title +  fails |> printfn %d %s x                    result                     |> sprintf %d            Actual: %A x                     |> sprintf %d            Expected: %A\\r\\n%s x expected                    |> printfn %s                    false            testRun        let testRunner tests=            let rec runner x result tests =                match tests with                | [] -> result                | head::tests ->                     let current = (head x) && result                    tests |> runner (x + 1) current            tests |> runner 1 true        let test01 = Simple Equality                           |> test one               one               Equal        let test02 = left < right                              |> test left              right             Lesser        let test03 = beta > alpha                              |> test beta              alpha             Greater        let test04 = \\9\\ < \\10\\                            |> test 9                 10                Lesser        let test05 = \\alpha9\\ < \\alpha10\\                  |> test alpha9            alpha10           Lesser        let test06 = \\alpha9Centary9\\ < \\alpha9Centary10\\  |> test alpha9Centary9    alpha9Centary10   Lesser        let test07 = \\10\\ > \\9\\                            |> test 10                 9                Greater        let test08 = \\alpha10\\ > \\alpha9\\                  |> test alpha10            alpha9           Greater        let test09 = \\alpha9Centary9\\ < \\alpha9Centary10\\  |> test alpha9Centary10    alpha9Centary9   Greater        let tests = test01 :: test02 :: test03 :: test04 :: test05 :: test06 :: test07 :: test08 :: test09 ::[]        let runTests =                    tests |> testRunner |> printfn %bHere is the code that runs it all:open Katas.NaturalSortKataopen Katas.Testing.Tests[<EntryPoint>]let main argv =     //Katas.Lockers.showLockerResults 300    runTests    let _ = System.Console.ReadKey(true)    1",
    "target": "unit testing;f#"
  },
  {
    "id": "_cs.71326",
    "source": "Regular expression for a language which doesn't look regular <eos> I'm trying to find a regular expression for the following language:$$L=\\{x0y : \\text{$x$ contains same number of 0's as $y$ contains 1's}\\}. $$",
    "target": "regular languages;regular expressions"
  },
  {
    "id": "_softwareengineering.287827",
    "source": "What's wrong about extending a class with prototype methods? <eos> I was at a bar last night with a few of my colleagues. They said that it's a bad idea to extend the functionality of basic JavaScript Objects with a prototype method.For example, let's say you created a method for finding the factorialNumber.prototype.factorial = function(n) {  return n == 0 ? 1 : factorial(n - 1)}They said there was some danger to creating prototypes. Why would this be a bad practice?",
    "target": "javascript;functions;prototyping"
  },
  {
    "id": "_cs.41465",
    "source": "PAC learning model definition <eos> The probably approximately correct (PAC) learning model is defined as:A concept class $C$ is said to be PAC-learnable if there exists an algorithm $A$ and a polynomial function $poly(,,,)$ such that for any $>0$ and $>0$, for all distributions $D$ on $X$ and for any target concept $cC$, the following holds for any sample size $mpoly(1/,1/,n,size(c))$:$Pr[R(hs)]1-$where $R(hs)$ is the generalization error over a sample $S$ of size $m$ containing instances of variable $X$ following distribution $D$ and $size(c)$ is the maximal cost of the computational representation of $cC$.I know $poly(1/,1/,n,size(c))$ is a polynomial. But what is the explicit form of $poly(1/,1/,n,size(c))$? What are the variables? What is its degree?",
    "target": "machine learning"
  },
  {
    "id": "_webmaster.30231",
    "source": "Safari HTML for Planck Constant/Reduced Planck Constant <eos> I want to display the symbols commonly known as h and h-bar.  This is for Safari and iOS.  What do I enter into my html?If there is a table of such things somewhere, a reference to it would be great.  Thanks!",
    "target": "html;safari"
  },
  {
    "id": "_webapps.25637",
    "source": "disable moving cards between lists <eos> I like the way Trello on Trello lists are locked to the degree where users cannot move cards between lists (only for board owner/admin).  Is there a setting that controls this feature?  ",
    "target": "trello"
  },
  {
    "id": "_webapps.61363",
    "source": "Is there a way to put TODO marker in Confluence pages, then find all pages with this marker? <eos> I'm looking for a way to put TODO markers on Confluence pages. SO I could then see TODO items in all documents. Just the way it's done in Visual Studio and other IDEs.",
    "target": "confluence"
  },
  {
    "id": "_codereview.85926",
    "source": "Java program to encrypt files using Shamir Secret Sharing <eos> Shamir's Secret Sharing scheme essentially splits a secret into n parts, at least k of which are needed to recover it. I'm using that to encrypt/decrypt arbitrary files (it's part of a college project).Here's a rough idea of what I'm doing:Take a file, and read N bytes. Treat those bytes as an integer, and encrypt it using this implementation of the Shamir algorithm. I get n integers, and I write one each to a file. Read N more bytes, and so on until I am done.Similarly, when decrypting, take n files, read an integer from each (I write a byte to denote the length of an integer before each, so I know how many bytes to read), decrypt the n integers to get the original one, and convert it to bytes to get N bytes, and write them to a file, and then read more integers.This is working, but is rather slow - with encrypting to 3 files a 170 MB file, it takes me 5 minutes to encrypt, 4 minutes to decrypt. How can I speed it up? Of course, any other suggestions are also welcome.package crypto;import com.tiemens.secretshare.main.cli.MainCombine;import com.tiemens.secretshare.main.cli.MainSplit;import java.io.*;import java.math.BigInteger;import java.nio.file.Files;import java.nio.file.Paths;import java.util.ArrayList;import java.util.regex.Matcher;import java.util.regex.Pattern;import static java.lang.Integer.min;import static java.util.Arrays.copyOfRange;/** * Created by hooda on 2/3/2015. */public class Shamir {    //The encoding that will be used when splitting and combining files.    static String encoding = ISO-8859-1;    //The number of bytes per piece (except maybe the last one)!    static int pieceSize = 128;    //Mode 0 for strings, 1 for ints.    public static ArrayList<String> shamirSplit(String inputString, int numPieces, int minPieces, int mode) {        String type = -sS;        if (mode == 1) {            type = -sN;        }        ArrayList<String> parts = new ArrayList<>();        String[] splitArgs = {-n, Integer.toString(numPieces), -k, Integer.toString(minPieces), type, inputString, -primeNone};        MainSplit.SplitInput splitInput = MainSplit.SplitInput.parse(splitArgs);        MainSplit.SplitOutput splitOutput = splitInput.output();        ByteArrayOutputStream baos = new ByteArrayOutputStream();        PrintStream ps = new PrintStream(baos);        splitOutput.print(ps);        String content = baos.toString(); // e.g. ISO-8859-1        BufferedReader reader = new BufferedReader(new StringReader(content));        String line;        int i = 0;        try {            while ((line = reader.readLine()) != null && i < numPieces) {                if (line.startsWith(Share (x)) {                    i++;                    parts.add(line.trim());                }            }        } catch (Exception e) {            //TODO Catch        }        return parts;    }    //Returns the Integer that the decryption represents, but in string format.    public static String shamirCombineInt(ArrayList<String> parts, ArrayList<Integer> partNums, ArrayList<String> flags, int k) {        ArrayList<String> args = new ArrayList<>();        args.add(-primeNone);        args.add(-k);        args.add(Integer.toString(k));        for (int i = 0; i < k; i++) {            String partSecret = parts.get(i);            String partNum = partNums.get(i).toString();            args.add(-s.concat(partNum));            args.add(partSecret);        }        ByteArrayOutputStream baos = new ByteArrayOutputStream();        PrintStream ps = new PrintStream(baos);        String[] combineArgs = args.toArray(new String[args.size()]);        MainCombine.CombineInput combineInput = MainCombine.CombineInput.parse(combineArgs, null, ps);        MainCombine.CombineOutput combineOutput = combineInput.output();        combineOutput.print(ps);        String content = baos.toString(); // e.g. ISO-8859-1        Pattern pattern = Pattern.compile(secret.number = ');        Matcher matcher = pattern.matcher(content);        if (matcher.find()) {            int i = matcher.end();            char c = content.charAt(matcher.end());            while (c != '\\'') {                i++;                c = content.charAt(i);            }            return (content.substring(matcher.end(), i));        } else {            return ;        }    }    /**     * Splits the given file into numPieces, of which at least minPieces are needed to recover the original.     *     * @param filePath  Path to the file to be encrypted.     * @param numPieces Number of files to split into.     * @param minPieces Minimum splitted files needed to recover original.     * @return     * @throws IOException     */    public static ArrayList<FileOutputStream> fileSplit(String filePath, int numPieces, int minPieces) throws IOException {        long startTime = System.currentTimeMillis();        //Create files to which encrypted pieces will b written.        ArrayList<FileOutputStream> splitFiles = new ArrayList<>(numPieces);        for (int i = 0; i < numPieces; i++) {            //TODO            splitFiles.add(i, new FileOutputStream(E://.concat(dummy.txt..concat(Integer.toString(i + 1)))));        }        //Get the file as a byte array.        byte[] fileAsBytes = Files.readAllBytes(Paths.get(filePath));        System.out.println(File had .concat(Integer.toString(fileAsBytes.length)));        //Do the encryption.        for (int i = 0; i < fileAsBytes.length; ) {            //We want to partition the byte array into pieces of length 4/8/16 whatever, but if length is not multiple (eg there are 15 bytes)            //then the last piece should be shorter. j takes care of that.            int j = min(fileAsBytes.length - i, Shamir.pieceSize);            byte[] piece = copyOfRange(fileAsBytes, i, i + j);            i = i + j;            Shamir.encryptAndWrite(piece, numPieces, minPieces, splitFiles);        }        for (FileOutputStream f : splitFiles) {            f.close();        }        long endTime = System.currentTimeMillis();        System.out.println(Encryption took  + (endTime - startTime) / 1000.0 +  seconds);        //TESTING CODE. TODO remove        startTime = System.currentTimeMillis();        System.out.println(\\n\\ntesting the decryption\\n\\n);        ArrayList<String> files = new ArrayList<>();        files.add(E://dummy.txt.1);        files.add(E://dummy.txt.2);        files.add(E://dummy.txt.3);        Shamir.fileCombine(files, minPieces);        endTime = System.currentTimeMillis();        System.out.println(Decryption took  + (endTime - startTime) / 1000.0 +  seconds);        return splitFiles;    }    /**     * Okay, this is a bit hacky. We want to take a piece of a file, encrypt/split it, and write the splits     * to the given FileOutPutStreams array. We want to treat the piece as an integer (treating it as string => large space overhead).     * This is tricky because of two reasons:     * 1. If all the bytes are zero, out piece will be zero, and we get an exception! It cannot be encrypted.     * 2. If the piece has any zero bytes at start, they get lost in the encrypt/decrypt process.     * 3. We cannot predict the length of the encrypted result. A 128 byte piece, when encrypted, can be 128, or 129 or whatever bytes.     *     * To fix this, we use prefixing and size byte.     * We prefix each piece with a one byte - 00000001. This means our piece will never have zero bytes at start. Takes care of 1 and 2.     * And, when writing the encrypted data to files, we prefix each with one byte containing its size.     *     * Then, when reading, here's what we do - we have N files. From each, we read the first byte. That will give us sizes n1,n2..nN.     * From each file, we then read the corresponding number of bytes n1 bytes from 1.. nN bytes from N, and feed them to shamir decryptor.     * Finally, we convert the recovered number to byte array, and discard the first one - we inserted it ourselves.     *     * @param piece     * @param numPieces     * @param minPieces     * @param files     * @throws IOException     */    public static void encryptAndWrite(byte[] piece, int numPieces, int minPieces, ArrayList<FileOutputStream> files) throws IOException {//        printByteArray(piece);        //Prefixing a new 1 at the start of piece == Add to 2^(no. of bytes*8).        BigInteger pieceAsInt = new BigInteger(1, piece);        BigInteger toAdd = (new BigInteger(2)).pow(piece.length * 8);        pieceAsInt = pieceAsInt.add(toAdd);        assert (pieceAsInt.toByteArray().length == piece.length + 1);        ArrayList<String> pieceSplit = Shamir.shamirSplit(pieceAsInt.toString(), numPieces, minPieces, 1);        //Write to file.        for (int i = 0; i < pieceSplit.size(); i++) {            String secret = pieceSplit.get(i).split(=)[1].trim();            byte[] toWrite = (new BigInteger(secret)).toByteArray();            files.get(i).write((byte) toWrite.length);//                files.get(i).write(flag);            files.get(i).write(toWrite);        }    }    public static void writeBytesToFiles(ArrayList<String> shamirOutput, ArrayList<FileOutputStream> files) throws IOException {        for (int i = 0; i < shamirOutput.size(); i++) {            String partSecret = shamirOutput.get(i).split(=)[1].trim();//            System.out.println(shamirOutput.get(i));            byte[] toWrite = (new BigInteger(partSecret)).toByteArray();            assert (toWrite.length <= 255);//            System.out.println(toWrite.length);            System.out.println(toWrite.length);            files.get(i).write((byte) (toWrite.length));            files.get(i).write(toWrite);        }    }    public static void fileCombine(ArrayList<String> files, int k) throws IOException {        //Create input streams, and part numbers (needed when decrypting)        ArrayList<FileInputStream> fileStreams = new ArrayList<>(files.size());        ArrayList<Integer> partNums = new ArrayList<>(files.size());        for (int i = 0; i < files.size(); i++) {            fileStreams.add(i, new FileInputStream(files.get(i)));            partNums.add(i, Integer.parseInt(files.get(i).substring(files.get(i).lastIndexOf(.) + 1, files.get(i).length())));        }        ArrayList<ArrayList<BigInteger>> filesAsInts = new ArrayList<>();        for (int i = 0; i < fileStreams.size(); i++) {            ArrayList<BigInteger> temp = new ArrayList<>();            long size = fileStreams.get(i).getChannel().size();            for (int j = 0; j < size; ) {                //Need to bitmask because java stores integers as two's complement.                //If we convert i>128 to a byte and back, we'll end up with negative value without this.                int bytesToRead = (int) (fileStreams.get(i).read() & 0xFF);                j ++;                byte[] intBytes = new byte[bytesToRead];                fileStreams.get(i).read(intBytes);                BigInteger bigInteger = new BigInteger(1, intBytes);                j += bytesToRead;                temp.add(bigInteger);            }            filesAsInts.add(i, temp);        }        ArrayList<BigInteger> decryptedInts = new ArrayList<>(filesAsInts.get(0).size());        for (int i = 0; i < filesAsInts.get(0).size(); i++) {            ArrayList<String> intsAsStrings = new ArrayList<>();            for (int j = 0; j < filesAsInts.size(); j++) {                intsAsStrings.add(filesAsInts.get(j).get(i).toString());            }            String decrypted = Shamir.shamirCombineInt(intsAsStrings, partNums, null, k);            decryptedInts.add(i,new BigInteger(decrypted));        }        FileOutputStream fileOutputStream = new FileOutputStream(files.get(0).substring(0, files.get(0).length() - 2));        for (int i = 0; i < decryptedInts.size(); i++) {            byte[] intBytes = decryptedInts.get(i).toByteArray();            byte[] toWrite = copyOfRange(intBytes, 1, intBytes.length);            fileOutputStream.write(toWrite);        }        fileOutputStream.close();        System.out.println(File decrypted!);        for(FileInputStream f : fileStreams){            f.close();        }    }    }",
    "target": "java;performance;io;cryptography"
  },
  {
    "id": "_softwareengineering.95362",
    "source": "Can I use publicly mentioned algorithms for writing programs? <eos> I want to write a program that solves sudoku.  So, I found some sudoku algorithms on Wikipedia. Can I use them or do I need to develop my own algorithm? Also, do I need to ask the specific license holder's permission?.. If so, how would I go about obtaining that permission? ",
    "target": "open source;licensing;algorithms"
  },
  {
    "id": "_unix.204383",
    "source": "Fail2ban is not blocking IPs trying to access my server via ssh <eos> I installed fail2ban with the default settings because there's a bunch of bots trying to log in as root to my server. I installed it but nothing has changed, I checked fail2ban jail IP list and there's nothing there.This is how my secure log looks like: May 19 09:11:25 localhost sshd[6080]: Failed password for root from 43.255.188.160 port 52111 ssh2May 19 09:11:25 localhost unix_chkpwd[6083]: password check failed for user (root)May 19 09:11:25 localhost sshd[6080]: pam_succeed_if(sshd:auth): requirement uid >= 1000 not met by user rootMay 19 09:11:28 localhost sshd[6080]: Failed password for root from 43.255.188.160 port 52111 ssh2May 19 09:11:28 localhost unix_chkpwd[6084]: password check failed for user (root)May 19 09:11:28 localhost sshd[6080]: pam_succeed_if(sshd:auth): requirement uid >= 1000 not met by user rootMay 19 09:11:29 localhost sshd[6080]: Failed password for root from 43.255.188.160 port 52111 ssh2May 19 09:11:29 localhost sshd[6080]: Received disconnect from 43.255.188.160: 11:  [preauth]May 19 09:11:29 localhost sshd[6080]: PAM 2 more authentication failures; logname= uid=0 euid=0 tty=ssh ruser= rhost=43.255.188.160  user=rootMay 19 09:11:30 localhost unix_chkpwd[6087]: password check failed for user (root)May 19 09:11:30 localhost sshd[6085]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=43.255.188.160  user=rootMay 19 09:11:30 localhost sshd[6085]: pam_succeed_if(sshd:auth): requirement uid >= 1000 not met by user rootMay 19 09:11:31 localhost sshd[6085]: Failed password for root from 43.255.188.160 port 39053 ssh2May 19 09:11:31 localhost unix_chkpwd[6088]: password check failed for user (root)May 19 09:11:31 localhost sshd[6085]: pam_succeed_if(sshd:auth): requirement uid >= 1000 not met by user rootMay 19 09:11:33 localhost sshd[6085]: Failed password for root from 43.255.188.160 port 39053 ssh2May 19 09:11:33 localhost unix_chkpwd[6089]: password check failed for user (root)May 19 09:11:33 localhost sshd[6085]: pam_succeed_if(sshd:auth): requirement uid >= 1000 not met by user rootMay 19 09:11:36 localhost sshd[6085]: Failed password for root from 43.255.188.160 port 39053 ssh2May 19 09:11:36 localhost sshd[6085]: Received disconnect from 43.255.188.160: 11:  [preauth]May 19 09:11:36 localhost sshd[6085]: PAM 2 more authentication failures; logname= uid=0 euid=0 tty=ssh ruser= rhost=43.255.188.160  user=rootMay 19 09:11:36 localhost unix_chkpwd[6093]: password check failed for user (root)May 19 09:11:36 localhost sshd[6091]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=43.255.188.160  user=rootMay 19 09:11:36 localhost sshd[6091]: pam_succeed_if(sshd:auth): requirement uid >= 1000 not met by user rootMay 19 09:11:38 localhost sshd[6091]: Failed password for root from 43.255.188.160 port 53516 ssh2May 19 09:11:38 localhost unix_chkpwd[6094]: password check failed for user (root)May 19 09:11:38 localhost sshd[6091]: pam_succeed_if(sshd:auth): requirement uid >= 1000 not met by user rootMay 19 09:11:40 localhost sshd[6091]: Failed password for root from 43.255.188.160 port 53516 ssh2May 19 09:11:40 localhost unix_chkpwd[6095]: password check failed for user (root)May 19 09:11:40 localhost sshd[6091]: pam_succeed_if(sshd:auth): requirement uid >= 1000 not met by user rootMay 19 09:11:42 localhost sshd[6091]: Failed password for root from 43.255.188.160 port 53516 ssh2May 19 09:11:42 localhost sshd[6091]: Received disconnect from 43.255.188.160: 11:  [preauth]May 19 09:11:42 localhost sshd[6091]: PAM 2 more authentication failures; logname= uid=0 euid=0 tty=ssh ruser= rhost=43.255.188.160  user=rootMay 19 09:11:43 localhost unix_chkpwd[6098]: password check failed for user (root)May 19 09:11:43 localhost sshd[6096]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=43.255.188.160  user=rootMay 19 09:11:43 localhost sshd[6096]: pam_succeed_if(sshd:auth): requirement uid >= 1000 not met by user rootMay 19 09:11:44 localhost sshd[6096]: Failed password for root from 43.255.188.160 port 40323 ssh2May 19 09:11:44 localhost unix_chkpwd[6099]: password check failed for user (root)May 19 09:11:44 localhost sshd[6096]: pam_succeed_if(sshd:auth): requirement uid >= 1000 not met by user rootMay 19 09:11:46 localhost sshd[6096]: Failed password for root from 43.255.188.160 port 40323 ssh2May 19 09:11:46 localhost unix_chkpwd[6100]: password check failed for user (root)May 19 09:11:46 localhost sshd[6096]: pam_succeed_if(sshd:auth): requirement uid >= 1000 not met by user rootI enabled fail2ban, (here says that is already running) fail2ban-client startERROR  Server already runningand the status since yesterday: fail2ban-client statusStatus|- Number of jail:  0`- Jail list:Is there something that I'm not doing which is not enabling fail2ban?",
    "target": "ssh;fail2ban"
  },
  {
    "id": "_vi.8109",
    "source": "How do I search only the displayed part of concealed text? <eos> If I have syntax highlighting rules setup using conceal to hide or change certain characters in a file, how do I search what is displayed, as opposed to what the buffer actually contains?The concealed part may contain formatting markup, for example, which I wish to ignore.I'd like a method that:doesn't rely on the specific rules used to create the concealed text.provides some level of compatibility with the traditional search operators like n, *, etc.Can this be done without re-implementing n, * and the like?Related:How can I copy the displayed text, instead of the actual text?",
    "target": "search;conceal"
  },
  {
    "id": "_unix.374201",
    "source": "Read-only file system error on Samba share, alternative share with identical options working (Linux client) <eos> I'm experiencing a very strange problem which I've been trying to solve in the past few days and I already tried various methods of resolution to which I will get to in a moment.My home network consists of a micro server (Ubuntu Linux Server 17.04, kernel 4.10.0-26-generic on x86_64, CLI only) and several Windows and Linux clients. My goal is to set up a Samba share with read-only guest access and read-write access for myself (Linux Mint 18.1, kernel 4.4.0-81-generic).In my smb.conf, there are two identical shares, media and temp (the later is for bug fixing purposes):[media]comment = smb sharepath = /mediabrowsable = yesguest ok = yeswritable = nowrite list = ap[temp]comment = smb sharepath = /tempbrowsable = yesguest ok = yeswritable = nowrite list = ap/media and /temp both are set to chmod -R 775 and chown -R ap:ap.Now the strange thing is that I can access both shares from my Linux client as ap but I only have write access on [temp]. When I try to create a folder or delete a file on [media], I get a Read-only file system error. I also don't have any problems writing when I log onto my server (as root user ap) using SSL.It might also be of interest that I'm mounting three different internal hard drives to /media/*. Their fstab entries look like this:UUID=954d122e-ef13-4248-acb3-5c95fb44d2ad /media/misc ext4 defaults 0 0UUID=d213c725-a715-40f3-8278-de890fad1168 /media/cinema ext4 defaults 0 0UUID=6469b3d0-bdb5-4b0c-8559-b9d26f69b332 /media/series ext4 defaults 0 0The following possible solutions didn't work:Setting chmod to 777, setting chown back to root:rootfscking all partitions, including the system partitionPlaying around with my smb.conf (trying out options like valid users, read list, create mask)Adding ap as a Samba userTrying to mount the share with mount -t cifs -o username=ap //server /mntpoint (and trying out options like rw,uid,gid,domain,forceuid,forcegid)remounting my internal hard disks with the rw optionI guess that I could switch to NFS but I'm still wondering if I missed something very obvious or what further steps I could take to solve this problem.",
    "target": "ubuntu;networking;samba;readonly"
  },
  {
    "id": "_unix.353198",
    "source": "Script for getting CPU utilization of particular cores <eos> I am looking for a script for checking CPU utilization of particular CPU Cores. We have 80 cores, We need get CPU utilization percentage for particular 4 cores.Can you help us on this.Thanks.",
    "target": "linux;shell script;shell;cpu"
  },
  {
    "id": "_webmaster.96721",
    "source": "What can be the consequences of using google webmaster tools for my youtube video downloader website? <eos> Will it be blocked/spam-listed if google detects that it provides youtube-video downloading ?",
    "target": "google search console;youtube"
  },
  {
    "id": "_unix.300013",
    "source": "php not working (source file) <eos> I do not know why php is not working.I install Nginx  and php  server {  listen       80;  server_name  t.com t.com;  location ~ \\.php$  {   fastcgi_split_path_info ^(.+\\.php)(/.+)$;    root   /var/www/t.com/public_html/;    index  index.html index.htm;    try_files $uri $uri/ =404;    }    error_page   500 502 503 504  /50x.html;  location = /50x.html {    root   html;  }}and php.conf#s# PHP is an HTML-embedded scripting language which attempts to make it# easy for developers to write dynamically generated webpages.#<IfModule prefork.c>LoadModule php5_module /usr/lib64/httpd/modules/libphp5.so</IfModule><IfModule worker.c>  LoadModule php5_module modules/libphp5-zts.so</IfModule>## Cause the PHP interpreter to handle files with a .php extension.#AddHandler php5-script .phpAddType text/html .phpAddType application/x-httpd-php  .php## Add index.php to the list of files that will be served as directory# indexes.#DirectoryIndex index.php## Uncomment the following line to allow PHP to pretty-print .phps# files as PHP source code:##AddType application/x-httpd-php-source .phps<FilesMatch \\.php$>    SetHandler application/x-httpd-php</FilesMatch>and when browser  file  , show  download file",
    "target": "php"
  },
  {
    "id": "_cstheory.37995",
    "source": "Paper regarding the complexity of the longest path problem on weighted directed graphs of bounded treewidth <eos> I would like to cite a paper/report/etc that solves the following problem polynomially in $n$:Given a weighted directed graph $G=(V,E)$, $|V|=n$, of bounded treewidth $k \\in \\mathbb{N}$ and a source-destination pair $s,t\\in V$, find a longest path (not walk) from $s$ to $t$.The corresponding Wikipedia article (https://en.wikipedia.org/wiki/Longest_path_problem#Parameterized_complexity)  implies that it is possible: the longest path problem is [...] fixed-parameter tractable when parameterized by the treewidth of the graphSadly, my knowledge of treewidth-techniques is rather small.I found the following paper, but it is on undirected (?unweighted?) graphs: Confronting Hardness Using a Hybrid Approach: Cites a paper of Bodlaender (in Section 2.2.1), where Theorem 2.2 states that the longest path problem is solvable in $O(2^k k! n)$ (assuming a treewidth decomposition is given)Is it easy to see that this technique also extends to directed weighted graphs? What happens when the weights are encoded in binary, i.e., they can be exponential in $n$?There is also a nice discussion here, but it also seems to rely on undirected (?unweighted?) graphs.Thank you!",
    "target": "cc.complexity theory;graph algorithms;treewidth;fixed parameter tractable;dynamic programming"
  },
  {
    "id": "_computerscience.4630",
    "source": "What graphic languages are simpler than SVG for database diagrams? <eos> This is PNG was exported from Inkscape.  I created it manually and used theconnector tool to link tables.I find the plain SVG for this diagram more complicated than I was expecting so would like to know if there are simpler graphic languages or specifications for this task?I would like to write something using Python.Here's the pastebin: SVG for database diagram",
    "target": "2d;vector graphics;diagram"
  },
  {
    "id": "_webapps.70812",
    "source": "Adding a script to Google Forms to identify incorrect phone numbers <eos> I currently use Google Forms as a way for applicants to submit their forms. One of the fields that is required is for their contact information. In my country phone numbers have 11 digits.Is there a script that I can use that will not accept a number if it does not contain 11 digits and display an error message, like Incorrect number, please check and try again?The number format should be 09xxxxxxxxx.",
    "target": "google apps script;google forms;phone number"
  },
  {
    "id": "_webapps.69993",
    "source": "Why does Google Docs still ask me for permission when people try to view my doc? <eos> I created a doc that I want anyone with a link to see. Here are the settings I used:I gave that link to people on my site.For some reason, every week, I get emails from Google Docs saying that people want to access my document and need my permission.This is what those emails look like.What can I do to keep people who I gave the link to from needing my permission?",
    "target": "google drive;google documents;permissions"
  },
  {
    "id": "_unix.374145",
    "source": "Live USB version of Kali Linux GRUB issues <eos> I have installed kali linux on a 32GB USB drive, and i have a 9GB partition for persistence. Also, the Macbook Pro i am running Kali on requires the AMD GPU to be disabled, so i am using this guide  to disable the AMD GPU (Step 3). I want to disable it permanently, but the /etc/default/grub file is missing. I reinstalled GRUB 2.0 and the grub config file was there although there was an error:    error: failed to get canonical path of 'overlay'After editing it , i couldn't get the grub-update command to run. It says that there is no such command. And after rebooting, the file disappeared again.Please help me with this issue. I appreciate your assistance greatly.",
    "target": "kali linux;grub2;live usb"
  },
  {
    "id": "_webapps.26879",
    "source": "GitHub pages do not appear <eos> I have added a gh-pages branch to a project on GitHub, but the GitHub pages are not appearing.What could be going wrong?",
    "target": "github"
  },
  {
    "id": "_codereview.165936",
    "source": "Using a destructuring assignment on a style object to extract two members <eos> Recently, one of my colleague decided to destructure the React-Native styles object this way:const { header, headerHint, bodyContainer, body, normalText, buttonWrapper, button, footer, footerLinks } = styles;And then used the variables in the React code:<View style={header}>  <Text style={headerHint}hint</Text> ...</View>This felt quite wrong to me as it doesn't provide much value to the code, destructuring an object to grab more than 5-6 variables makes the code more difficult to read in my opinion. Also, keeping the styles in the styles object let you know your styles comes from the StyleSheet. In some cases we might want to create variables to merge several styles, they become much easier to spot.He argues destructuring reduces areas that you need to change - if you need to change them like if the styles object changes to something else, you don't have to remove all the references to styles.I'm wondering what is your opinion on this point and if you follow any style guide about destructuring object like this one?",
    "target": "javascript;react.js;react native"
  },
  {
    "id": "_codereview.57834",
    "source": "Working with Classes (inheriting), @ properties and Initialization <eos> I'm working on this Objective C programming assignment I found online.  I'm not sure if I have met all the requirements, especially part C. Any help or suggestion will be appreciated.Part 6a) Implement class A with properties a1, a2, and a3 (int,  string, int).b) New objects are automatically initialized to 1, hello, 1.c) Also provide initializer to any data and constructor (called  without alloc) to do the same.d) Make sure %@ ob object of A will print all data.e) Then implement B inheriting from A. B adds property b (string). f) Make sure B works as A, that is new object is initialized to 1, hello, 1, and 3 (the new data). The rest also must work on B.   //classA.h file#import <Foundation/Foundation.h>@interface ClassA : NSObject// Part 6a@property int a1;@property NSString *a2;@property int a3;-(NSString *) description;-(id) initWithA1: (int) x andA2: (NSString *) s andA3: (int) y;-(id) init;@end//classA.m file#import ClassA.h@implementation ClassA-(id) initWithA1:(int)x andA2:(NSString *)s andA3:(int)y {    self = [super init];    if (self) {        self.a1 = x;        self.a2 = s;        self.a3 = y;    }    return self;}// part 6b- (id) init {    return [self initWithA1:1 andA2:@hello andA3:1];}// part 6d-(NSString *) description {    return [NSString stringWithFormat:@ClassA a1 = %d , a2 = %@ , a3 = %d, self.a1, self.a2, self.a3];}@end//classB.h file#import ClassA.h@interface ClassB : ClassA@property int a1;@property NSString *a2;@property int a3;@property NSString * b;-(NSString *) description;-(id) initWithA1:(int)x andA2:(NSString *)s andA3:(int)y andB: (NSString *) z;-(id) init;@end//classB.m file#import ClassB.h@implementation ClassB-(id) initWithA1:(int)x andA2:(NSString *)s andA3:(int)y andB:(NSString *)z {    self = [super init];    if (self) {        self.a1 = x;        self.a2 = s;        self.a3 = y;        self.b = z;    }    return self;}-(id) init {    return [self initWithA1:1 andA2:@hello andA3:1 andB:@3];}-(NSString *) description {    return [NSString stringWithFormat:@ClassB a1 = %d , a2 = %@ , a3 = %d , b = %@ , self.a1, self.a2, self.a3, self.b];}@end//viewController.m file#import ViewController.h#import ClassA.h#import ClassB.h@interface ViewController ()@end@implementation ViewController- (void)viewDidLoad{    [super viewDidLoad];    ClassA * a = [ClassA new];    NSLog(@%@, a);    ClassB * j = [ClassB new];    NSLog (@%@, j);}- (void)didReceiveMemoryWarning{    [super didReceiveMemoryWarning];    // Dispose of any resources that can be recreated.}@end",
    "target": "classes;objective c;inheritance"
  },
  {
    "id": "_unix.246715",
    "source": "How can I make a perl script parse blocks more intelligently? <eos> I have a file ~/bigfile.txt that consists of thousands of blocks of text of the formBLOCK NUMBER : <block>SIZE : <size1> <size2>EXTRA : <extraNumber><block of text>For this example say$ cat ~/bigfile.txtBLOCK NUMBER : 1SIZE : 7 6EXTRA : 0john paulgeorge ringoBLOCK NUMBER : 2SIZE : 7 3EXTRA : -10i amthewalrusBLOCK NUMBER : 3SIZE : 4 3EXTRA : -1024hello worldI am trying to write a script that separates each block into a separate file named <block>-block.txt, nested into subdirectories of ~/data/ indexed by <size1> and <size2>. For instance, running the script should result in $ tree ~/data/~/data/|- 4-size1   |- 3-size2      |- 3-block.txt|- 7-size1   |- 3-size2      |- 2-block.txt   |- 6-size2      |- 1-block.txtCurrently I have a script that simply dumps each block to a separate file in ~/data/ but I can't figure out how to alter it. I can post my current script if that would help but I suspect that it's quite inefficient and not suited to tackle this sort of organizational task.I would appreciate any pointers on how to accomplish this task with perl.",
    "target": "perl"
  },
  {
    "id": "_cs.72116",
    "source": "Can the following Huffman tree be extended to include more letters? <eos> The following table shows a possible set of Huffman codes to be used for lossless compression of a text consisting only of the eight letters shown:e        t        o        h        l         p         w         z10       01       111      110      0001      0000      0011      0010The codes will have been chosen by using an algorithm that has as input the frequencies of occurrence of each of the letters in the particular text. The choice of codes can be presented as a Huffman tree. The tree is shown below:                 ()               /    \\            ()        ()          /   \\      /   \\       ()       t  e       ()        /    \\              /     \\   ()       ()        h          o  / \\      /  \\p    l    z    wa) Could this tree be extended to include more letters? If not, why not?b) Can you suggest a modification of the tree to include two more letters? ",
    "target": "huffman coding"
  },
  {
    "id": "_codereview.61195",
    "source": "Unit Testing of Curl based Rest Client Library <eos> I ran into some issues with unit testing in that getting the response body etc from the curl handle was tricky. I didn't want to necessarily use a mock or abstract the curl functionality.A colleague of mine suggested that I just use the localhost as an endpoint and reflect back the request for unit testing. I thought this was a novel approach.The directories in question are /test/echo/ and /test/unit/I'm also interested in seeing if anyone had any opinions on the assertions.GitHubThe echo endpoint:    <?phpheader('Content-Type: application/json');$data = array('headers' => getallheaders(),// 'server' => $_SERVER,'request_method' => $_SERVER['REQUEST_METHOD'],'get' => $_GET,'post' => $_POST,'put' => $_POST,);//If the request is a put then get the file contents and try to parse the string into an arrayif($data['request_method'] == 'PUT'){parse_str(file_get_contents(php://input), $put_data);$data['put'] = $put_data;}echo json_encode($data);An example of one of the unit tests:<?phpclass TransactionTest extends PHPUnit_Framework_TestCase{static $endpoint = 'http://localhost/payjunctionphp/test/echo';public function setUp(){$options = array('username' => 'pj-ql-01','password' => 'pj-ql-01p','appkey' => '2489d40d-a74f-474f-9e8e-7b39507f3101');parent::setUp();$this->client = new TransactionClient($options);$this->client->setEndpoint(self::$endpoint);}private function getRequestPath($client = null){if(!isset($client)) $client = $this->client;return str_replace($client->baseUrl,'',curl_getinfo($client->curl)['url']);}/*** Ensure that the correct verb and path are used for the create method*/public function testCreate(){$data = array('achRoutingNumber' => '987654321','achAccountNumber' => '123456789','achAccountType' => 'CHECKING','foo' => 'bar');$transaction = $this->client->create($data);$this->assertEquals($data, get_object_vars($transaction->post),'Passed variables are not correct');$this->assertEquals('POST', $transaction->request_method,'The PHP Verb Is Incorrect');$this->assertEquals('/transactions', $this->getRequestPath(), 'The path is incorrect');}/*** Ensure that the correct verb and path are used for the read method*/public function testRead(){$transaction = $this->client->read(543);$this->assertEquals('GET', $transaction->request_method,'The PHP Verb Is Incorrect');$this->assertEquals('/transactions/543', $this->getRequestPath(), 'The path is incorrect');}/*** Ensure that the correct verb and path are used for the read method*/public function testUpdate(){$data = array('foo' => 'baz');$transaction = $this->client->Update(654,$data);$this->assertEquals($data, get_object_vars($transaction->put),'Passed variables are not correct');$this->assertEquals('PUT', $transaction->request_method,'The PHP Verb Is Incorrect');$this->assertEquals('/transactions/654', $this->getRequestPath(), 'The path is incorrect');}/*** Ensure that the correct verb and path are used for the read method*/public function testAddSignature(){$data = array('foo' => 'baa');$transaction = $this->client->addSignature(655,$data);$this->assertEquals($data, get_object_vars($transaction->post),'Passed variables are not correct');$this->assertEquals('POST', $transaction->request_method,'The PHP Verb Is Incorrect');$this->assertEquals('/transactions/655/signature/capture', $this->getRequestPath(), 'The path is incorrect');}}The base model from which the various clients extend from:    <?phpclass PayjunctionClient{public $liveEndpoint = 'https://api.payjunction.com';public $testEndpoint = 'https://api.payjunctionlabs.com';public $packageVersion = '0.0.1';public $userAgent;public function __construct(){$this->userAgent = 'PayJunctionPHPClient/' . $this->packageVersion . '(BrandedCreate; PHP/)'; //@todo add process.version$this->baseUrl = $this->testEndpoint;}public function setEndpoint($endpoint){$this->baseUrl = $endpoint;}/*** @description initializes the curl handle with default configuration and settings* @param null $handle* @return $this*/public function initCurl($handle = null){$this->curl = curl_init();curl_setopt($this->curl, CURLOPT_SSL_VERIFYPEER, false); //Don't worry about validating ssl @todo talk about security concernscurl_setopt($this->curl, CURLOPT_RETURNTRANSFER, true);//if we have a password and username then set it by default to be passed for authenticationif (isset($this->defaults['password']) && isset($this->defaults['username'])) {curl_setopt($this->curl, CURLOPT_HTTPAUTH, CURLAUTH_ANY);curl_setopt($this->curl, CURLOPT_USERPWD, $this->defaults['username'] . : . $this->defaults['password']);}//if we have default headers to pass then pass themif (isset($this->defaults['headers']) && is_array($this->defaults['headers'])) {$headers = array();foreach ($this->defaults['headers'] as $key => $value) {array_push($headers, $key . ': ' . $value);}curl_setopt($this->curl, CURLOPT_HTTPHEADER, $headers);}return $this;}/*** @description generates a new client* @param null $options* @return $this*/public function generateClient($options = null){$this->baseUrl = isset($options['endpoint']) ? $options['endpoint'] : $this->baseUrl;$this->defaults['username'] = isset($options['username']) ? $options['username'] : '';$this->defaults['password'] = isset($options['password']) ? $options['password'] : '';$this->defaults['headers']['X-PJ-Application-Key'] = isset($options['appkey']) ? $options['appkey'] : '';$this->defaults['headers']['User-Agent'] = $this->userAgent;$this->initCurl();return $this;}/*** @description takes the response from our curl request and turns it into an object if necessary* @param $response* @param null $contentType* @return array|mixed*/public function processResponse($response){$contentType = curl_getinfo($this->curl, CURLINFO_CONTENT_TYPE);if ($contentType == 'text/html' || is_null($contentType) || !isset($contentType) || $contentType = '' || $contentType == FALSE) {return $response;}try {$object = json_decode($response);return $object;} catch (Exception $e) {return array('errors' => array(0 => 'Invalid Response Type, Error In Processing Response From Payjunction'));}}/*** @description processes a curl post request* @param $path* @param null $params* @return array|mixed*/public function post($path, $params = null){curl_setopt($this->curl, CURLOPT_POST, TRUE);curl_setopt($this->curl, CURLOPT_URL, $this->baseUrl . $path);if (is_object($params) || is_array($params)) {curl_setopt($this->curl, CURLOPT_POSTFIELDS, http_build_query($params));}return $this->processResponse(curl_exec($this->curl));}/*** @description processes a curl get request* @param $path* @param null $params* @return array|mixed*/public function get($path, $params = null){//create the query string if there are any parameters that need to be passed$query_string = ;if (!is_null($params)) {$query_string = ? . http_build_query($params,'','&');}curl_setopt($this->curl, CURLOPT_HTTPGET, TRUE);curl_setopt($this->curl, CURLOPT_URL, $this->baseUrl . $path . $query_string);return $this->processResponse(curl_exec($this->curl));}/*** @description processes a curl put request* @param $path* @param null $params* @return array|mixed*/public function put($path, $params = null){curl_setopt($this->curl, CURLOPT_CUSTOMREQUEST, PUT);if (is_object($params) || is_array($params)) {curl_setopt($this->curl, CURLOPT_POSTFIELDS, http_build_query($params));}curl_setopt($this->curl, CURLOPT_URL, $this->baseUrl . $path);return $this->processResponse(curl_exec($this->curl));}/*** @description processes a curl delete request* @param $path* @param null $params* @return array|mixed*/public function del($path, $params = null){curl_setopt($this->curl, CURLOPT_CUSTOMREQUEST, DELETE);if (is_object($params) || is_array($params)) {curl_setopt($this->curl, CURLOPT_POSTFIELDS, http_build_query($params));}curl_setopt($this->curl, CURLOPT_URL, $this->baseUrl . $path);return $this->processResponse(curl_exec($this->curl));}}The TransactionClient related specifically to this unit test:<?phpclass TransactionClient extends PayjunctionClient{public function __construct($options){parent::__construct();$this->generateClient($options);}/*** @description create a new transaction* @param $params* @return array|mixed*/public function create($params){return $this->post('/transactions',$params);}/*** @description read from an existing transaction* @param $id* @return array|mixed*/public function read($id){return $this->get('/transactions/'.$id);}/*** @description update an existing transaction* @param $id* @param null $params* @return array|mixed*/public function update($id, $params = null){return $this->put('/transactions/'.$id, $params);}/*** @todo this does not appear to be working 405 Method Not Allowed* @description add a signature to an existing transaction* @param $id* @param $params* @return array|mixed*/public function addSignature($id, $params){return $this->post('/transactions/'.$id.'/signature/capture',$params);}}",
    "target": "php;unit testing;phpunit"
  },
  {
    "id": "_unix.23453",
    "source": "Burning a directory structure from a stdin pipe <eos> I'm trying to do something tricky, I want to burn a directory structure onto a CD from a pipe stream. The reason is that it is coming from the network and I don't want it written on the hard drive of the cd-burning machine. I am unsure of how (or if possible) to pipe the output of tar (for example) into genisoimage or mkisofs. I noticed a stream option in genisoimage, but when I tried doing tar -cvf - /home/myuser | genisoimage --stream-media-size 200 -o test.isoI only got a test.iso which contained a stream.img (as specified in genisoimage(1)) which itself was the original tar-archive. This will not do, it needs to be a directory structure on the CD. I know that cdrskin (cli tool for burning) can take data from stdin and burn it. So how can I pipe data into genisoimage, have it create a directory structure of that data for the ISO and then have it pipe that data back out to cdrskin to burn? I know also that genisoimage pipes the iso data to stdout by default so my only issue appears to be getting a stream of a directory structure piped into genisoimage and having that directory structure maintained in the ISO data. The tags on this post are terrible because I couldn't find genisoimage, cdrskin, not even stdin. Edit: This is not about data security, it's about lack of disk space. I don't care if the data is buffered on the HDD but I can't write the full ISO. And of course genisoimage is just a suggestion, I'm open to any other method of creating the ISO data. For your information it's intended for blu ray discs. ",
    "target": "debian;pipe"
  },
  {
    "id": "_softwareengineering.156300",
    "source": "Should we use an outside CMS? <eos> I work at a web design/development shop.  Everything we do is centered around the Joomla! CMS.  I'm a bit worried-if anything goes wrong with Joomla (major security flaw revealed, Joomla folds and ceases development) we're sunk.  I'm meeting with the CEO to plan the next few steps for our company.  Should I recommend that we create our own in-house CMS or am I just being paranoid about a single point of failure?",
    "target": "cms;joomla"
  },
  {
    "id": "_scicomp.10712",
    "source": "Auto labeling algorithm <eos> I have a set of points (2D space), and for every point there's a label (like city names on a map).I want to find a real-time algorithm that allows labels to avoid overlapping, moving them from their original position if necessary.I've heard about simulated annealing algorithm, but I can't find a good source to learn how to do this. Do you have some idea where I can find bibliography and practical examples?Thanks in advance for your replies.",
    "target": "computational geometry"
  },
  {
    "id": "_cstheory.29215",
    "source": "On the notion of positive rank of a matrix <eos> The positive rank of a square matrix is defined in Theorem $3$ of Expressing Combinatorial Optimization Problems by Linear Programs by Mihalis Yannakakis as follows: given a $n\\times n$ matrix $A$, the positive rank $rank_{\\Bbb R}^+(A)$ is the smallest $m$ such that $A=LR$ for a non-negative $n\\times m$ matrix $L$, and non-negative $m\\times n$ matrix $R$.This concept is valuable in communication complexity, since it was shown that if $rank_{\\Bbb R}^+(A)$ and $rank_{\\Bbb R}(A)$ could be subexponentially related for a $0/1$ matrix $A$, then the log-rank conjecture holds.Is there an exponential separation between $rank_{\\Bbb R}^+(A)$ and $rank_{\\Bbb R}(A)$ for a general non-negative real matrix $A$ (as opposed to just $0/1$) or is this problem also open?I checked the references in Jukna's book, but I am still unable to clarify the above question.",
    "target": "communication complexity;definitions"
  },
  {
    "id": "_unix.329161",
    "source": "How to delete the filesytem on a RAID device? <eos> How do I delete the filesystem on a RAID device?sudo blkid /dev/md1/dev/md1: UUID=9a27b794-12d7-4794-9764-dda623f12e58 TYPE=ext4",
    "target": "filesystems;software raid"
  },
  {
    "id": "_codereview.97726",
    "source": "Powershell to quickly ping a number of machines <eos> I came up with the below code to improve the peformance of pinging a large number of machines.At present it's fairly basic, but thought I should see what people thought before proceeding further.NB: This is my first time playing with workflows, so I've probably committed a few faux-pas there.clsworkflow Test-ConnectionQuickly {    [cmdletbinding()]    param(        [Parameter(Mandatory = $true)]        [string[]]$computers    )    $computerGroups = InlineScript {        #group computers to throttle the number of threads        [psobject]$itemCounter = [pscustomobject]@{itemNo=0;groupSize=10} #alter groupSize per your preference        $itemCounter | Add-Member -MemberType ScriptMethod -Name 'groupNo' -Value {            [math]::Floor($this.itemNo++ / $this.groupSize)        }        write-output $using:computers | Group-Object -Property {$itemCounter.groupNo()}    }    ForEach -parallel ($computerGroup in $computerGroups) {        $computerGroup | select -ExpandProperty group | %{            $pingable = (Test-Connection $_ -Count 2 -Quiet -ErrorAction SilentlyContinue)            write-output (new-object -type psobject -property @{Name=$_;Online=$pingable})        }    } }[string[]]$computers = (1..100 | %{(Server{0:000} -f $_)}) #here's where we'd read in the computere from fileTest-ConnectionQuickly $computers | select Name, Online #here's where we'd pipe the output to fileDesign Notes:The InlineScript is used to group servers into small sets (of 10; an arbitrary size) in the hope of balancing serial's performance for small sets against parallel's performance for large sets of computers.The $itemCounter variable's an attempt at making grouping into defined set sizes simpler to read-count 2 is specified on the test-connection so that we have some tolerence for network glitches without too much affect on performance.-Quiet is specified because we don't need output / and not having output will help performance.",
    "target": "networking;powershell;status monitoring"
  },
  {
    "id": "_unix.104205",
    "source": "How to compile with third party libs properly? <eos> This is a follow up question to Confusion about linking boost library while compilation:What is to do, when I generate a Makefile by qmake and I have only a third party boost lib installed (I uninstalled all boost libs from dependency management, because it always links to the boost lib from dependency management what I don't want) and I want it to compile only against this manually installed library as well as run against it.These are the important parts of a Makefile generated by qmake:CC            = gccCXX           = g++DEFINES       = -DQT_GUI -DBOOST_THREAD_USE_LIB -DBOOST_SPIRIT_THREADSAFE -DBOOST_THREAD_PROVIDES_GENERIC_SHARED_MUTEX_ON_WIN -D__NO_SYSTEM_INCLUDES -DUSE_UPNP=1 -DSTATICLIB -DUSE_QRCODE -DUSE_DBUS -DHAVE_BUILD_INFO -DLINUX -DQT_NO_DEBUG -DQT_DBUS_LIB -DQT_GUI_LIB -DQT_CORE_LIB -DQT_SHAREDCFLAGS        = -m64 -pipe -O2 -Wall -W -D_REENTRANT $(DEFINES)CXXFLAGS      = -m64 -pipe -fstack-protector -O2 -fdiagnostics-show-option -Wall -Wextra -Wformat -Wformat-security -Wno-unused-parameter -D_REENTRANT $(DEFINES)INCPATH       = -I/usr/share/qt4/mkspecs/linux-g++-64 -I/usr/include/qt4/QtCore -I/usr/include/qt4/QtGui -I/usr/include/qt4/QtDBus -I/usr/include/qt4 -Isrc -Isrc/json -Isrc/qt -IC:/deps/ -IC:/deps/boost -Ic:/deps/db/build_unix -Ic:/deps/ssl/include -IC:/deps/libqrencode/ -Ibuild -IbuildLINK          = g++LFLAGS        = -m64 -fstack-protector -Wl,-O1LIBS          = $(SUBLIBS)  -L/usr/lib/x86_64-linux-gnu -LC:/deps/miniupnpc -lminiupnpc -lqrencode -lrt -LC:/deps/boost/stage/lib -Lc:/deps/db/build_unix -Lc:/deps/ssl -LC:/deps/libqrencode/.libs -lssl -lcrypto -ldb_cxx -lboost_system-mgw46-mt-sd-1_54 -lboost_filesystem-mgw46-mt-sd-1_54 -lboost_program_options-mgw46-mt-sd-1_54 -lboost_thread-mgw46-mt-sd-1_54 -lQtDBus -lQtGui -lQtCore -lpthread This is the path to boost:/usr/local/lib/boost1.55/lib# ls -1libboost_atomic.alibboost_atomic.solibboost_atomic.so.1.55.0libboost_chrono.alibboost_chrono.solibboost_chrono.so.1.55.0libboost_context.alibboost_context.solibboost_context.so.1.55.0libboost_coroutine.alibboost_coroutine.solibboost_coroutine.so.1.55.0libboost_date_time.alibboost_date_time.solibboost_date_time.so.1.55.0libboost_exception.alibboost_filesystem.alibboost_filesystem.solibboost_filesystem.so.1.55.0libboost_graph.alibboost_graph.solibboost_graph.so.1.55.0libboost_locale.alibboost_locale.solibboost_locale.so.1.55.0libboost_log.alibboost_log_setup.alibboost_log_setup.solibboost_log_setup.so.1.55.0libboost_log.solibboost_log.so.1.55.0libboost_math_c99.alibboost_math_c99f.alibboost_math_c99f.solibboost_math_c99f.so.1.55.0libboost_math_c99l.alibboost_math_c99l.solibboost_math_c99l.so.1.55.0libboost_math_c99.solibboost_math_c99.so.1.55.0libboost_math_tr1.alibboost_math_tr1f.alibboost_math_tr1f.solibboost_math_tr1f.so.1.55.0libboost_math_tr1l.alibboost_math_tr1l.solibboost_math_tr1l.so.1.55.0libboost_math_tr1.solibboost_math_tr1.so.1.55.0libboost_prg_exec_monitor.alibboost_prg_exec_monitor.solibboost_prg_exec_monitor.so.1.55.0libboost_program_options.alibboost_program_options.solibboost_program_options.so.1.55.0libboost_random.alibboost_random.solibboost_random.so.1.55.0libboost_regex.alibboost_regex.solibboost_regex.so.1.55.0libboost_serialization.alibboost_serialization.solibboost_serialization.so.1.55.0libboost_signals.alibboost_signals.solibboost_signals.so.1.55.0libboost_system.alibboost_system.solibboost_system.so.1.55.0libboost_test_exec_monitor.alibboost_thread.alibboost_thread.solibboost_thread.so.1.55.0libboost_timer.alibboost_timer.solibboost_timer.so.1.55.0libboost_unit_test_framework.alibboost_unit_test_framework.solibboost_unit_test_framework.so.1.55.0libboost_wave.alibboost_wave.solibboost_wave.so.1.55.0libboost_wserialization.alibboost_wserialization.solibboost_wserialization.so.1.55.0This is the output of ldconfig -v concerning boost:# ldconfig -v/sbin/ldconfig.real: Path `/lib/x86_64-linux-gnu' given more than once/sbin/ldconfig.real: Path `/usr/lib/x86_64-linux-gnu' given more than once/usr/local/lib/boost1.55/lib:    libboost_wave.so.1.55.0 -> libboost_wave.so.1.55.0    libboost_thread.so.1.55.0 -> libboost_thread.so.1.55.0    libboost_system.so.1.55.0 -> libboost_system.so.1.55.0    libboost_prg_exec_monitor.so.1.55.0 -> libboost_prg_exec_monitor.so.1.55.0    libboost_context.so.1.55.0 -> libboost_context.so.1.55.0    libboost_atomic.so.1.55.0 -> libboost_atomic.so.1.55.0    libboost_filesystem.so.1.55.0 -> libboost_filesystem.so.1.55.0    libboost_math_c99l.so.1.55.0 -> libboost_math_c99l.so.1.55.0    libboost_math_c99.so.1.55.0 -> libboost_math_c99.so.1.55.0    libboost_timer.so.1.55.0 -> libboost_timer.so.1.55.0    libboost_wserialization.so.1.55.0 -> libboost_wserialization.so.1.55.0    libboost_math_c99f.so.1.55.0 -> libboost_math_c99f.so.1.55.0    libboost_coroutine.so.1.55.0 -> libboost_coroutine.so.1.55.0    libboost_signals.so.1.55.0 -> libboost_signals.so.1.55.0    libboost_random.so.1.55.0 -> libboost_random.so.1.55.0    libboost_chrono.so.1.55.0 -> libboost_chrono.so.1.55.0    libboost_program_options.so.1.55.0 -> libboost_program_options.so.1.55.0    libboost_date_time.so.1.55.0 -> libboost_date_time.so.1.55.0    libboost_locale.so.1.55.0 -> libboost_locale.so.1.55.0    libboost_log.so.1.55.0 -> libboost_log.so.1.55.0    libboost_log_setup.so.1.55.0 -> libboost_log_setup.so.1.55.0    libboost_serialization.so.1.55.0 -> libboost_serialization.so.1.55.0    libboost_math_tr1f.so.1.55.0 -> libboost_math_tr1f.so.1.55.0    libboost_unit_test_framework.so.1.55.0 -> libboost_unit_test_framework.so.1.55.0    libboost_math_tr1l.so.1.55.0 -> libboost_math_tr1l.so.1.55.0    libboost_graph.so.1.55.0 -> libboost_graph.so.1.55.0    libboost_math_tr1.so.1.55.0 -> libboost_math_tr1.so.1.55.0    libboost_regex.so.1.55.0 -> libboost_regex.so.1.55.0What do I have exactly to do to compile and run the code properly? I tried combinations of:-L/usr/local/lib/boost1.55/lib/boost_thread-mgw46-mt-sd-1_54-L/usr/local/lib/boost1.55/lib/boost_thread-I/usr/local/lib/boost1.55/-I/usr/local/lib/boost1.55/lib/-lboost_system-mgw46-mt-sd-1_54-lboost_system-mgw46-mt-sd-1_55-lboost_systemAll this NEVER works when there is no boost installed by package manager, but I don't want it to use it from package manager. That means it doesn't compile. Sometimes I get something like:/usr/bin/ld: cannot find -lboost_system-mgw46-mt-sd-1_54or /usr/bin/ld: cannot find -lboost_systemor addrman.cpp:(.text.startup+0x23): undefined reference to `boost::system::generic_category()'...and so on.I don't get it. What's wrong here?[UPDATE]It turns out that there seems to be something wrong with boost lib itself.After modifying the important parts of the makefile to:LIBS          = $(SUBLIBS)  -L/usr/lib/x86_64-linux-gnu -lminiupnpc -lqrencode -lrt -lssl -lcrypto -ldb_cxx -L/usr/local/lib/boost1.55/ -L/usr/local/lib/boost1.55/include/ -L/usr/local/lib/boost1.55/lib/ -lboost_system -lboost_filesystem -lboost_program_options -lpthread -lboost_thread -lQtDBus -lQtGui -lQtCoremake produced another error:build/json_spirit_reader.o: In function `void boost::call_once<void (*)()>(boost::once_flag&, void (*)())':json_spirit_reader.cpp:(.text._ZN5boost9call_onceIPFvvEEEvRNS_9once_flagET_[_ZN5boost9call_onceIPFvvEEEvRNS_9once_flagET_]+0x14): undefined reference to `boost::detail::get_once_per_thread_epoch()'json_spirit_reader.cpp:(.text._ZN5boost9call_onceIPFvvEEEvRNS_9once_flagET_[_ZN5boost9call_onceIPFvvEEEvRNS_9once_flagET_]+0x2c): undefined reference to `boost::detail::once_epoch_mutex'json_spirit_reader.cpp:(.text._ZN5boost9call_onceIPFvvEEEvRNS_9once_flagET_[_ZN5boost9call_onceIPFvvEEEvRNS_9once_flagET_]+0x35): undefined reference to `boost::detail::once_epoch_mutex'json_spirit_reader.cpp:(.text._ZN5boost9call_onceIPFvvEEEvRNS_9once_flagET_[_ZN5boost9call_onceIPFvvEEEvRNS_9once_flagET_]+0x72): undefined reference to `boost::detail::once_epoch_mutex'json_spirit_reader.cpp:(.text._ZN5boost9call_onceIPFvvEEEvRNS_9once_flagET_[_ZN5boost9call_onceIPFvvEEEvRNS_9once_flagET_]+0x77): undefined reference to `boost::detail::once_epoch_cv'json_spirit_reader.cpp:(.text._ZN5boost9call_onceIPFvvEEEvRNS_9once_flagET_[_ZN5boost9call_onceIPFvvEEEvRNS_9once_flagET_]+0xa8): undefined reference to `boost::detail::once_epoch_mutex'json_spirit_reader.cpp:(.text._ZN5boost9call_onceIPFvvEEEvRNS_9once_flagET_[_ZN5boost9call_onceIPFvvEEEvRNS_9once_flagET_]+0xb0): undefined reference to `boost::detail::once_epoch_mutex'json_spirit_reader.cpp:(.text._ZN5boost9call_onceIPFvvEEEvRNS_9once_flagET_[_ZN5boost9call_onceIPFvvEEEvRNS_9once_flagET_]+0xd9): undefined reference to `boost::detail::once_global_epoch'json_spirit_reader.cpp:(.text._ZN5boost9call_onceIPFvvEEEvRNS_9once_flagET_[_ZN5boost9call_onceIPFvvEEEvRNS_9once_flagET_]+0xde): undefined reference to `boost::detail::once_epoch_cv'json_spirit_reader.cpp:(.text._ZN5boost9call_onceIPFvvEEEvRNS_9once_flagET_[_ZN5boost9call_onceIPFvvEEEvRNS_9once_flagET_]+0xe9): undefined reference to `boost::detail::once_global_epoch'json_spirit_reader.cpp:(.text._ZN5boost9call_onceIPFvvEEEvRNS_9once_flagET_[_ZN5boost9call_onceIPFvvEEEvRNS_9once_flagET_]+0x128): undefined reference to `boost::detail::once_global_epoch'json_spirit_reader.cpp:(.text._ZN5boost9call_onceIPFvvEEEvRNS_9once_flagET_[_ZN5boost9call_onceIPFvvEEEvRNS_9once_flagET_]+0x19b): undefined reference to `boost::detail::once_epoch_cv'collect2: error: ld returned 1 exit statusIt seems that there is no such function (in this boost version?):$ objdump -T /usr/local/lib/boost1.55/lib/libboost_thread.so|c++filt|grep once_epochprints nothing as well as $ for i in /usr/local/lib/boost1.55/lib/libboost_*.so ; do if grep once_epoch_mutex <(objdump -T $i|c++filt) ; then echo $i ; fi ; donedoes not.[UPDATE 2]After adding -I/usr/local/lib/boost1.55/include/ -I/usr/local/lib/boost1.55/include/boost/to INCPATH and recompile the whole application within a fresh workspace, the error is different but now, I don't see any error message:/usr/local/lib/boost1.55/include/boost/bind/arg.hpp: In constructor boost::arg<I>::arg(const T&):/usr/local/lib/boost1.55/include/boost/bind/arg.hpp:37:22: warning: typedef T_must_be_placeholder locally defined but not used [-Wunused-local-typedefs]         typedef char T_must_be_placeholder[ I == is_placeholder<T>::value? 1: -1 ];                      ^In file included from /usr/local/lib/boost1.55/include/boost/tuple/tuple.hpp:33:0,                 from /usr/local/lib/boost1.55/include/boost/thread/detail/async_func.hpp:37,                 from /usr/local/lib/boost1.55/include/boost/thread/future.hpp:22,                 from /usr/local/lib/boost1.55/include/boost/thread.hpp:24,                 from src/util.h:22,                 from src/bignum.h:13,                 from src/main.h:9,                 from src/wallet.h:9,                 from src/wallet.cpp:7:/usr/local/lib/boost1.55/include/boost/tuple/detail/tuple_basic.hpp: In function typename boost::tuples::access_traits<typename boost::tuples::element<N, boost::tuples::cons<HT, TT> >::type>::const_type boost::tuples::get(const boost::tuples::cons<HT, TT>&):/usr/local/lib/boost1.55/include/boost/tuple/detail/tuple_basic.hpp:228:45: warning: typedef cons_element locally defined but not used [-Wunused-local-typedefs]   typedef BOOST_DEDUCED_TYPENAME impl::type cons_element;                                             ^src/wallet.cpp: In member function bool CWallet::AddToWallet(const CWalletTx&):src/wallet.cpp:402:13: error: replace_all is not a member of boost             boost::replace_all(strCmd, %s, wtxIn.GetHash().GetHex());             ^In file included from /usr/local/lib/boost1.55/include/boost/system/system_error.hpp:14:0,                 from /usr/local/lib/boost1.55/include/boost/thread/exceptions.hpp:22,                 from /usr/local/lib/boost1.55/include/boost/thread/pthread/thread_data.hpp:10,                 from /usr/local/lib/boost1.55/include/boost/thread/thread_only.hpp:17,                 from /usr/local/lib/boost1.55/include/boost/thread/thread.hpp:12,                 from /usr/local/lib/boost1.55/include/boost/thread.hpp:13,                 from src/util.h:22,                 from src/bignum.h:13,                 from src/main.h:9,                 from src/wallet.h:9,                 from src/wallet.cpp:7:/usr/local/lib/boost1.55/include/boost/system/error_code.hpp: At global scope:/usr/local/lib/boost1.55/include/boost/system/error_code.hpp:222:36: warning: boost::system::posix_category defined but not used [-Wunused-variable]     static const error_category &  posix_category = generic_category();                                    ^/usr/local/lib/boost1.55/include/boost/system/error_code.hpp:223:36: warning: boost::system::errno_ecat defined but not used [-Wunused-variable]     static const error_category &  errno_ecat     = generic_category();                                    ^/usr/local/lib/boost1.55/include/boost/system/error_code.hpp:224:36: warning: boost::system::native_ecat defined but not used [-Wunused-variable]     static const error_category &  native_ecat    = system_category();                                    ^make: *** [build/wallet.o] Error 1",
    "target": "compiling;libraries;boost"
  },
  {
    "id": "_codereview.139973",
    "source": "Locate a number in an array with ascending even and descending odd entries <eos> Below are two examples of arrays I have, with some given length:For some value z, I want to find the column the value is in. MATLAB code I wrote:if z == 1   column = ceil(length/2);   elseif logical(mod(z,2))   column = length - (z-3)/2;else   column = z/2;endIt is correct I think. But ugly and possibly slow. Is there a one-liner in MATLAB that can do this?",
    "target": "matlab"
  },
  {
    "id": "_softwareengineering.151919",
    "source": "Plan variable and call dependencies <eos> I'd like to write down the design of my program to understand the dependencies and calls better. I know there are class diagrams which show inheritance and attribute variables. However I'd also like to document the input parameters to method functions and in particular which calls the methods function executes inside (e.g. on the input parameters).Also sometimes it might be useful to show how actual objects are connected (if there is a standard structure).This way I can have a better understanding of the modules and design before starting to program. Can you suggest a method to do this software design? It should be one-to-one to programming code structure so that I really notice all quirks beforehand (instead of high-level design where thing are hard to implement without further work).Maybe some special diagram or tool or a combination?It is static dependency and call design rather than time dependent execution monitoring.(I use Python if you have any specialized recommendations).",
    "target": "design;uml"
  },
  {
    "id": "_scicomp.23303",
    "source": "Numerical Euler Rotation Equation <eos> The problem I have may be really simple, but still getting a hard time solving it. So I have the Euler rotation equations:$$I_{1}\\dot{\\omega}_{1}+\\left(I_{3}-I_{2}\\right)\\omega_{2}\\omega_{3}=\\lambda_{1}$$$$I_{2}\\dot{\\omega}_{2}+\\left(I_{1}-I_{3}\\right)\\omega_{3}\\omega_{1}=\\lambda_{2}$$$$I_{3}\\dot{\\omega}_{3}+\\left(I_{2}-I_{1}\\right)\\omega_{1}\\omega_{2}=\\lambda_{3}$$where the $I_{i}$ are the moments of inertia about the principal axes of rotation and $\\omega_{i}$ the time dependent angular velocities about each axis. In general $I_{i}\\neq I_{j}, i\\neq j$, or don't satisfy any situations in which they can be reduced to easier relations. $\\lambda_{i}$ is a normal distributed random number.I know that these equations are non-linear and, in general, have no analytic solution. The question is:$\\qquad$ Is there a good numerical integrator for these equations?I'm using C++ and have looked into the LAPACK package, but I'm kind of confused on how to use it.I know the reference from Skowron and Gould (arXiv:1203.1034 [astro-ph.EP]); however I really don't know how to implement this algorithm.If somebody could help me in finding an open source integrator or a reference where they talk about the implementation of this code, it would be great.",
    "target": "computational physics;software"
  },
  {
    "id": "_cstheory.5920",
    "source": "LU factorization of a 0-1 matrix <eos> I have a rather naive question on LU factorization which probably should be easy to answer. Say I have a matrix with entries only from $\\{0,1\\}$. When can we expect to get an LU factorization of such a matrix(whenever it exists) with entries $(a)$ from integers? $(b)$ from $\\{-1,0,+1\\}$?",
    "target": "linear algebra;matrices;na.numerical analysis"
  },
  {
    "id": "_cogsci.9734",
    "source": "Why can't subjective utilities take probabilities into account? <eos> If my understanding of expected utility theory is correct, it is rational for a decision maker to have subjective utilities for objective consequences.  For example, it can be rational for a decision maker to value 5 dollars twice as much as 4 dollarshowever, it is not rational for a decision maker to value a 100% chance of 5 dollars twice as much as an 80% chance of 5 dollarsThat is, probabilities must be outside of- not taken into account by- subjective utilities.  Is this understanding correct, and if so, why is the theory structured this way?  Note: My understanding is based on Hastie & Dawes (2010), Rational Choice in an Uncertain World.",
    "target": "decision making;economics;rationality;behavioral economics"
  },
  {
    "id": "_unix.63985",
    "source": "sed into csv format <eos> I have a file of the formVL-8299673,30.000,49.000,1.000,21.901,2630.000,428861.000VL-8299673,1071.000,570.000,35.000,3963.608,632.000,366563.000VL-8299673,36.000,867.000,24.000,6523.005,3544.000,176054.000VL-8299673,5:281185.000VL-8299673,44.000,372.000,67.000,7029.358,293.000,446448.000VL-8299673,5:48479.000VL-8299673,0:2.000,2:7.000,3:80.222,4:1153.000it is supposed to be of the formVL-8299673,1190.000,609.000,28.000,12676.158,1819.000,452813.000but when there are zeros in the file it only shows the column numbers that are nonzero such asVL-8299673,0:2.000,2:7.000,3:80.222,4:1153.000I would like to write a sed command that makes a 7 length row with zeros included such as VL-8299673,2.000,0,7.000,80.222,1153.000,0Any ideas?",
    "target": "sed"
  },
  {
    "id": "_softwareengineering.309322",
    "source": "Open / Closed Principle <eos> I found this code example explaining Open / Closed principle.Code before application of principle:public class Logger{    public void Log(string message, LogType logType)    {        switch (logType)        {            case LogType.Console:                Console.WriteLine(message);                break;            case LogType.File:                // Code to send message to printer                break;        }    }}public enum LogType{    Console,    File}And refactored code:public class Logger{    IMessageLogger _messageLogger;    public Logger(IMessageLogger messageLogger)    {        _messageLogger = messageLogger;    }    public void Log(string message)    {        _messageLogger.Log(message);    }}public interface IMessageLogger{    void Log(string message);}    public class ConsoleLogger : IMessageLogger{    public void Log(string message)    {        Console.WriteLine(message);    }}public class PrinterLogger : IMessageLogger{    public void Log(string message)    {        // Code to send message to printer    }}Can you explain me the reason to still keep Logger class with private IMessageLogger instance? I would simply avoid it by:public interface ILogger{    public void Log(string message);}public class ConsoleLogger : ILogger{    public void Log(string message)    {        Console.WriteLine(message);    }}    public class PrinterLogger : ILogger{    public void Log(string message)    {        // Code to send message to printer    }}The only reason I can think about is, that in suggested solution with Logger class, we could still refer to this class in client code, but we still need to modify all Log(msg) calls to remove LogType arguments. ",
    "target": "c#;interfaces;solid;open close"
  },
  {
    "id": "_codereview.64626",
    "source": "Project Euler #48 in C++ <eos> This question is similar to Project Euler #48 but constraints are different:$$N < 2000000$$Just in case the link is unavailable, here is the problem statement:We've to print $$\\left( \\sum_{i=1}^N i^i \\right) \\mod 10^{10}$$I've tried the following, but I need something faster than that, because the execution time limit is 2s, and this program can only compute values until \\$ N=30000\\$ (approx) in the given time limit.#include <iostream>using namespace std;#define Mod 10000000000int main() {    int N;    cin>>N;    long long Temp,Sum=0;    for( int ii=1 ; ii<=N ; ii++ )    {        if(ii%10==0)        {            continue;        }                Temp=1;        for( int jj=1 ; jj<=ii ; jj++ )        {               Temp*=ii;            Temp=Temp%Mod;        }        Sum+=Temp;        Sum=Sum%Mod;    }    cout<<Sum;    return 0;}I've added if(N%10==0){    continue;}because numbers of form $$ (k*10)^{k*10}=k^{k*10}*10^{k*10}=k^{k*10}*10^{k}*10^{10} $$ are not at all going to contribute to the answer.Note: code is compiled using g++ 4.8.2, C++11 mode  ",
    "target": "c++;optimization;c++11;programming challenge;time limit exceeded"
  },
  {
    "id": "_unix.231664",
    "source": "List all files that end in ball using ls command <eos> I am trying to use ls command to find specific files thatHave 4 letters in front of the word ballMust have the ending word ballI have been trying to use ls *ball but this shows words with 4 or more words in front of the word ball. Is there a specific command that ignores the word that has 4 or more letters before ball? ",
    "target": "linux;ls"
  },
  {
    "id": "_unix.362469",
    "source": "What does Chromium NET::ERR_CERT_COMMON_NAME_INVALID mean? <eos> I'm trying to figure out why Chromium is not happy with a TLS certificate, and how to fix it:After upgrading & restarting Chromium (now 58.0.3029.81, running on Debian testing), I can no longer access our internal GitLab server (installed on Debian Jessie, via the omnibus package). I get:Your connection is not privateAttackers might be trying to steal your information from git.ourdomain.net (for example, passwords, messages, or credit cards). NET::ERR_CERT_COMMON_NAME_INVALIDThe certificate is signed with our internal CA, which is installed in the system store (by putting it in /usr/local/share/ca-certificates). I checked the site with both Firefox 52 and openssl s_client -verify 5 -verify_return_error -connect git.ourdomain.net:443; both are happy. OpenSSL shows the chain as:Certificate chain 0 s:/C=US/ST=Virginia/L=Sterling/O=us/OU=Servers/CN=git.ourdomain.net   i:/C=US/ST=Virginia/L=Sterling/O=us/CN=us Certification Authority/emailAddress=ca@ticket.ourdomain.netBoth OpenSSL and Firefox show strong signing (SHA-512) and ciphers (AES-GCM). The certificate (according to openssl x509 -text) is sha512WithRSAEncryption, with a 4096-bit RSA key. It has a Netscape Cert Type of SSL Client, SSL Server.Note: us and ourdomain.net are redactions; the actual output has our company name for us and our actual domain for ourdomain.net. I carefully checked that all the ourdomain.net actually match.As far as I can tell, there is nothing wrong with the certificate, and the common name (git.ourdomain.net) is perfectly valid and matches the URLso what is Chromium complaining about? And, presuming it's not a real issue, is there some way to override it?",
    "target": "chrome;ssl;https"
  },
  {
    "id": "_cs.79314",
    "source": "Algorithm to project onto line segments <eos> I have the following problem: A large number $N$ of (finite length) line segments in the plane (if it helps, we can assume non-intersecting except at end points, and forming a graph with a small number of components); and a smaller number $n$ of points.  For each point, I wish to find the closest line segment.Given one line segment, this is easy: orthogonally project onto the line, and if this doesn't fall on the line segment, choose the appropriate end point.  This gives a naive $O(Nn)$ algorithm.I am wondering if there is a clever data structure which, with some pre-processing on the lines, would give a faster algorithm?",
    "target": "computational geometry"
  },
  {
    "id": "_computergraphics.4991",
    "source": "Invoking shader in DX <eos> So I am new to the DX12 world. I am currently trying to tweek the nbody_gravity DX12 sample, but appending or calling another Compute Shader which is to add 2 buffers to produce an output in a different buffer.I have written this code in ComputeShader.hlsl however when i tried to invoke it using the following, i get an error sayin file not foundWhen i printed the debug error it says the following: D3D12GetDebugInterface: This method requires the D3D12 SDK Layers for Windows 10, but they are not present on the system.I am invoking my shader after the default invocation to the nBodyGravity.hlsl is done:ComPtr<ID3DBlob> computeShader;ComPtr<ID3DBlob> computeShader_m;#if defined(_DEBUG)        // Enable better shader debugging with the graphics debugging tools.        UINT compileFlags = D3DCOMPILE_DEBUG | D3DCOMPILE_SKIP_OPTIMIZATION;#else        UINT compileFlags = 0;#endif        ThrowIfFailed(D3DCompileFromFile(GetAssetFullPath(LNBodyGravityCS.hlsl).c_str(), nullptr, nullptr, CSMain, cs_5_0, compileFlags, 0, &computeShader, nullptr));//extra call for my shaderComPtr<ID3DBlob> error_ptr;        ThrowIfFailed(D3DCompileFromFile(GetAssetFullPath(LComputeShader.hlsl).c_str(), nullptr, nullptr, main, cs_5_0, compileFlags, 0, &computeShader_m, &error_ptr));if (error_ptr){    OutputDebugStringA((char *)error_ptr->GetBufferPointer());}Is there somthing amiss?",
    "target": "directx"
  },
  {
    "id": "_unix.338234",
    "source": "How to find release date of any .rpm before installing it <eos> Is there any way to get the release date (via command line) of an RPM without downloading or installing it?I can get detailed information via the command below but can't find the release date of that particular RPM:[root@connect ~]# yum info kernel-2.6.32-642.6.2.el6.x86_64Loaded plugins: fastestmirrorLoading mirror speeds from cached hostfile * base: centos.excellmedia.net * epel: ftp.jaist.ac.jp * extras: centos.excellmedia.net * updates: centos.excellmedia.netAvailable PackagesName        : kernelArch        : x86_64Version     : 2.6.32Release     : 642.6.2.el6Size        : 32 MRepo        : updatesSummary     : The Linux kernelURL         : http://www.kernel.org/License     : GPLv2Description : The kernel package contains the Linux kernel (vmlinuz), the core of any            : Linux operating system.  The kernel handles the basic functions            : of the operating system: memory allocation, process allocation, device            : input and output, etc.",
    "target": "linux;rpm"
  },
  {
    "id": "_webapps.86268",
    "source": "Can I Disable the Download All feature on a shared Google Photos album? <eos> If I share a Google Photos album, other people who view it see a Download All button at the top of the page, as shown in the screenshot below. You should be able to see it yourself if you visit this album.Is there any way to prevent that button from being shown? I've looked in my Google+ settings under Photos and Videos, and the option Allow viewers to download my photos and video is already unchecked. ",
    "target": "google photos"
  },
  {
    "id": "_reverseengineering.4682",
    "source": "kernel32.BaseThreadInitThunk without IAT <eos> On starting notepad.exe with Ollydbg, I see that eax has a value that points at kernel32.BaseThreadInitThunk.notepad.exe does not seem to import kernel32.dll::BaseThreadInitThunk.I cannot find that function, by running dependency walker on notepad.exe.How can kernel32.dll::BaseThreadInitThunk function be executed without importing it ?",
    "target": "windows;dll;iat"
  },
  {
    "id": "_unix.162079",
    "source": "SSH over multiple server and save output of multiple commands in file on local server <eos> I want to SSH over multiple server (host 1, host2 and host 3) and save output of multiple commands (cmd1, cmd2 etc) in file (output.properties) on local server. I know there are a few posts similar to this, but I a not sure where I am going wrong. Below is the code snippet.folderPath=cd /usr/local/apps/tempdir;echo $folderPath;eval $folderPath;# host 1echo RepCard1=$(expr $(grep -r sample text * | wc -l) / 2) >> /usr/local/host1/tempdir/output.properties;# Server 2ssh -T user@host2 <<EOF >>/usr/local/host1/tempdir/output.properties;#alias GetDuplicateCardStats=cd /usr/local/apps/tempdirfolderPath=cd /usr/local/apps/tempdir;echo $folderPath;eval $folderPath;echo RepCard2=$(expr $(grep -r sample text * | wc -l) / 2);exitEOF. /usr/local/host1/tempdir/output.properties;echo host 1echo $RepCard1echo host 2echo $RepCard2# RepCard2 is always executed on Host 1 and print value from host 1What is the mistake in the above script?",
    "target": "shell script;ssh"
  },
  {
    "id": "_codereview.145471",
    "source": "Time-dependent state machine <eos> I keep having to write state machines that depend on time for various experiments I run and I'd like to know how to write them better. This state machine is for training a neural network by feeding in keys and expected values.import numpy as npdt = 0.001period = 0.1class SimpleEnv(object):    def __init__(self, keys, values, env_period=0.1):        self.keys = keys        self.values = values        self.env_idx = np.arange(len(keys))        self.idx = 0        self.shuffled = False        self.i_every = int(round(env_period/dt))        if self.i_every != env_period/dt:            raise ValueError(dt (%s) does not divide period (%s) % (dt, period))    def get_key(self):        return self.keys[self.idx]    def get_val(self):        return self.values[self.idx]    def step(self, t):        i = int(round((t - dt)/dt))  # t starts at dt        ix = (i/self.i_every) % len(self.keys)        if ix == 0 and not self.shuffled:            print(shuffling)            np.random.shuffle(self.env_idx)            self.shuffled = True        elif ix == 1:            self.shuffled = False        self.idx = self.env_idx[ix]        return ix# note the toy keys and values for testing purposess_env = SimpleEnv(np.arange(4), np.arange(1, 5), env_period=period)key = -1val = -1ix = -1# iterate through keys and values twicerun_time = 4 * period * 2# the event loop# starts at dt because of reasonsfor t in np.arange(dt, run_time, dt):    last_ix = ix    ix = s_env.step(t)    key = s_env.get_key()    val = s_env.get_val()    assert key + 1 == val    if last_ix != ix:        print(Key: %s, Value: %s %(key, val))The results should look something like:shufflingKey: 2, Value: 3Key: 0, Value: 1Key: 3, Value: 4Key: 1, Value: 2shufflingKey: 2, Value: 3Key: 1, Value: 2Key: 3, Value: 4Key: 0, Value: 1How can I write this better or more efficiently? Is there a state machine library in Python that would stop me from having to rewrite variations of this class all the time?",
    "target": "python;state machine"
  },
  {
    "id": "_codereview.52249",
    "source": "Find the subarray with the max sum <eos> In an interview I was asked to solve the following problem:find a subarray with max sumI have written a piece of code for the same.  I need your help in reviewing this code.package com.ankit.rnd;public class MaxSubArrSum {    int largestSum=0;    int previousLargestSum=0;    public static void main(String[] args) {        // int [] array = {-2,1,-3,4,-1,2,1,-5,4};        int [] array = {-5,1,-3,7,-1,2,1,-4,6};        // int [] array = {-2,-3,-4,2};        MaxSubArrSum obj = new MaxSubArrSum();        for(int varindex=0;varindex<array.length;varindex++){            // int sumis =new MaxSubArrSum().findSum(varindex,array);            // System.out.println(sumis:: +sumis);            obj.splitCurrentArray(varindex,array);        }    }    private void splitCurrentArray(int in, int[] arr) {        int [] tempArr = new int[arr.length-in];        for(int i=in;i<arr.length;i++){            if(in ==0){                tempArr[i] = arr[i];            }            else{                tempArr[i-in] = arr[i];            }        }        int sum =findSum(in, tempArr);        System.out.println(Previous Largest Sum:: + previousLargestSum);        System.out.println(Largest Sum found: + sum);     }      @SuppressWarnings(unused)    private int findSum(int start,int [] array) {        int[] currentArray ={};        int [] largestArray = new int[array.length];        int sum=0;        /*for(int i=start;i<array.length;i++){*/            for(int i=0;i<array.length;i++){            //a little inefficient here as it always create an array with size more than total number of elements that should be there in the temp array.            int psuedoIndex=i;            if(start==0){                currentArray = new int[i + 1];                for (int j = 0; j <= i; j++) {                    currentArray[j] = array[j];                    psuedoIndex=psuedoIndex+1;                }            }            else {                currentArray = new int[i+1];                for (int j = 0; j <= i; j++) {                    currentArray[j] = array[j];                    /*                     * if(psuedoIndex == array.length){ //needs a fix. as we                     * have reached the end of the array. //currentArray[j] =                     * array[psuedoIndex-1]; currentArray[j] = 0; break; } else{                     *                      * currentArray[j] = array[psuedoIndex]; is commented out                     * because it missed the element in the previous array.                     *                      *                      * //currentArray[j] = array[psuedoIndex]; currentArray[j] =                     * array[j]; }                     */                    psuedoIndex=psuedoIndex+1;                }            }            if((sum = calculate(currentArray))>largestSum){                previousLargestSum=largestSum;                largestSum=sum;                for(int k=0;k<currentArray.length;k++){                    System.out.print(currentArray[k] + |);                }                System.out.println();            }        }        return largestSum;    }    private int calculate(int [] currentArr){        int sumOfElements =0;        for(int index=0;index<currentArr.length;index++){            sumOfElements +=currentArr[index];        }        //System.out.println(sum is: + sumOfElements);        return sumOfElements;    }    }",
    "target": "java;array;interview questions"
  },
  {
    "id": "_codereview.83934",
    "source": "Complex search program <eos> I am working on a fairly complex (at least it feels complex to me at the moment) search program and am looking to possibly increase the performance. Everything works exactly how I want it to, but I'm just wondering if there are any slight performance increases I could benefit from. In this code, even minor performance increases are essential.  This is due to the extensive amount of operations being performed.// Split search into multiple terms and check the {x} longest terms against the cache.string[] word = searchTerm.Split(' ');Array.Sort(word, (x, y) => y.Length.CompareTo(x.Length));for (int i = 0; i < word.Length; i++){    string searchValue = word[i];    if (i <= MAX_WORD_ITERATIONS && (xmlsearchResults == BLANK_SEARCH_XML_SCHEMA || xmlsearchResults == string.Empty))    {        xmlsearchResults = GetCachedRecord(thisSearch, searchValue);    }    if (xmlsearchResults != BLANK_SEARCH_XML_SCHEMA && xmlsearchResults != string.Empty)    {        thisSearch.Value = searchValue;        ignoreCache = true;        break;    }}xmlString.Append(string.Format(@<{0}>, xmlHeader));int objcount = 0;string prevResultName = string.Empty;try{    if (searchResults.hitCount > 0)    {        List<SearchItem> SearchResults = new List<SearchItem>();        foreach (Node ResultNode in Results.Nodes)        {            string code = ResultNode.code.ToString();            string result = ResultNode.id.ToString();            string name = ResultNode.name_l.ToString();            string image = string.Empty;            if (!code.ToLower().Contains(ccb) && code.Length <= MAX_CODE_LENGTH &&                name != prevResultName && objcount < maxResults)            {                Boolean addResult = true;                if (thisSearch.FilterDescription)                {                    if (!name.ToLower().Contains(thisSearch.Value.ToLower()))                    {                        addResult = false;                    }                }                if (addResult)                {                    SearchItem oSearch = new SearchItem(name, code);                    SearchResults.Add(oSearch);                    prevResultName = name;                }            }        }        var SortedSearchResults = SearchResults.OrderByDescending(s => s.Downloads).ToList();        for (int i = 0; i < SortedSearchResults.Count(); i++)        {            if ((objcount < maxResults))            {                string te = string.Format(<ResultName>{0}</ResultName>, SortedSearchResults[i].Description);                if (!xmlString.ToString().Contains(te))                {                    xmlString.Append(SortedSearchResults[i].GetXMLString());                    objcount += 1;                }            }        }    }}xmlString.Append(string.Format(@</{0}>, xmlHeader));return objcount;",
    "target": "c#;performance;xml;search"
  },
  {
    "id": "_webmaster.11423",
    "source": "Software which will fetch all relevant included files for a web app? <eos> Hopefully this is the correct Stack Exchange site to be asking this question.I've inherited a fairly large web app from the previous IT guy at my organisation. It's written in PHP and there's no documentation. My PHP is very rusty at best but I've been given the task of looking at the code for the web app, working out what it does, and preparing it so it can definitely be moved to another host with no problems. The directories in which the relevant PHP, js and css files sit have a whole load of other PHP, js and css files in them - things like early revisions of files, backups, slight changes etc. All very messy.I'd like to be able to just download locally all the files that are relevant to the app and not all the extra ones so that when I come to look at the code it'll be much easier to untangle. Is there such a piece of software which, when given relevant permissions on the server, goes off and fetches an initial PHP file, looks for any code from includes and downloads them, does the same for css and js files. Is there an IDE which does something similar for when people need to debug and untangle others' web apps?",
    "target": "php"
  },
  {
    "id": "_unix.76380",
    "source": "The fastest desktop environment for Mint 14 <eos> I'm using Mint 14 with the Cinnamon desktop environments, but some times it get's extremely slow.So I googled about other desktop environments and I found this great article:https://askubuntu.com/questions/65083/what-different-desktop-environments-and-shells-are-availableBut I don't know which one is faster, I want to install the fastest desktop environment among them, because I have a low performances in my computer.",
    "target": "linux mint;desktop environment"
  },
  {
    "id": "_webapps.92608",
    "source": "Google apps script to check availability <eos> I'm using google form+calendar to create a reservation system for my makers lab. The user fills out the form and an event is created on the calendar so the TA knows when to goto the lab to help the user.Currently I'm using this script(which i found online and modified it a bit to fit my usage)+trigger to create events based on the form submissions    var calendarId = -hidden-@group.calendar.google.com;    //below are the column ids of that represents the values used in the spreadsheet (these are non zero indexed)    //Column containing the Start Date+Time for the event    var startDtId = 6;    //Column containg the End Date+Time for the event    var endDtId = 7;    //Column containing the First Part of the Title for the event (In this case, user ID)    var titleId = 4;    //Column containing the Second part of the Title for the event (In this case, user Name)    var titleId2 = 3;    //Column containing the user's mobile number    var descId = 5;    //Column containing the Time Stamp for the event (This will always be 1)    var formTimeStampId = 1;    //Column containing the machine Selected    var mId = 8;    function EnSubmitToCalendar() {    //Allow access to the Spreadsheet    var sheet = SpreadsheetApp.getActiveSheet();    var rows = sheet.getDataRange();    var numRows = rows.getNumRows();    var values = rows.getValues();    var lr = rows.getLastRow();    var startDt = sheet.getRange(lr,startDtId,1,1).getValue();    var endDt = sheet.getRange(lr,endDtId,1,1).getValue();    //Create an addition to the Description to included when    var subOn = TimeStamp :+sheet.getRange(lr,formTimeStampId,1,1).getValue();    //Setting the Comments as the description, and adding in the Time stamp    var desc = subOn;    //Create the Title    var title = sheet.getRange(lr,mId,1,1).getValue()+-+sheet.getRange(lr,titleId,1,1).getValue()+ +sheet.getRange(lr,titleId2,1,1).getValue()+ +sheet.getRange(lr,descId,1,1).getValue();    //Run the Crete event Function    createEventEN(calendarId,title,startDt,endDt,desc);    };    function createEventEN(calendarId,title,startDt,endDt,desc) {    var cal = CalendarApp.getCalendarById(calendarId);    var start = new Date(startDt);    var end = new Date(endDt);    //Set the Options, in this case we are only using Description and Location, as we do not need Guests or sendInvites    var event = cal.createEvent(title, start, end, {    description : desc,    });    };it works well, and there's really no major problems to it, except when the user doesn't check availabilitysince we only have so many machines(3),if more than 3 users fill in the same time, the calendar will show more than 3 events, and it gets complicated.is there a way to script it so the script checks to see if there's 3 events during that time, and if so, it doesn't create a event?example:event A: 13:30-15:30event B: 13:30-14:30event C: 14:00-15:30User D submits a form that'll create event D: 14:00-15:30but because 14:00-14:30 there's already 3 events, event D isn't created (or is adjusted by the script to start at 14:30 instead)I'm thinking of using getEvents(startTime, endTime, options)    var checkAvail = CalendarApp.getDefaultCalendar().getEvents(startDtId, endDtId);but I got no idea how to integrate this into my current scriptcan someone give me some pointers/comments? am I even on the right track?(sorry, I'm not at a level where I know how to write scripts, I only know how to modify existing scripts)",
    "target": "google spreadsheets;google calendar;google apps script"
  },
  {
    "id": "_unix.223300",
    "source": "Single line command to cat last file in ls -lrt output? <eos> System log files are serialized and I use ls -lrt to show me the most recent file. I then cat that file. This requires typing a long serial number each time. How can I cat the last file appearing in my ls -lrt output in one command?I'm using cygwin and the the output from ls -lrt foobar_job* look like this:--rw-r--r-- 1 zundarz Domain Users   1133 Jul 31 16:54 foobar_job4855125.log-rw-r--r-- 1 zundarz Domain Users   1256 Jul 31 17:10 foobar_job4855127.log-rw-r--r-- 1 zundarz Domain Users   1389 Aug 11 10:20 foobar_job4887829.log-rw-r--r-- 1 zundarz Domain Users   1228 Aug 11 10:39 foobar_job4887834.log",
    "target": "ls;cat"
  },
  {
    "id": "_scicomp.21675",
    "source": "Detecting and joining series of line segments that run along each other <eos> Given: Several circular series of map GPS coordinates for several bus routes. The GPS coordinates are not all equal when they run along the same road. The number of GPS coordinates for a single bus route runs from 140-600.Problem: When the points are downloaded drawn, the raw routes don't follow each other perfectly and especially when zoomed-out you can't see some of the routes. I want to somehow show the multiple routes that run along a road, mostly likely dashed with multiple colors. But in order to do that, I need to detect the segments of the route that run really close to each other.What would be perfect is finding the segments of the routes and mutating their GPS coords to be shared among them. Once that's done I can easily render it.So my question is: are there any good algorithms for this purpose, or some combination/tweaks of other algorithms I can use? It all has to be done autonomously in an app, not hand-done/hand-checked.If you need any other information please ask.",
    "target": "computational geometry;geometry"
  },
  {
    "id": "_webmaster.89206",
    "source": "How to use Google business without showing address <eos> I'm working on a website and my understanding is, by having the place of business listed with Google Business, it will help with local searches.The problem we have is, this person is a self employed lady and her business is also her home address, and she doesn't want to provide this location to the world. Her website shows the town where she lives which appears to be enough for visitors looking for her location, and only after an enquiry is made does she provide her location. The point is, the website does not expose this.Is it possible to utilise the localisation for searches (Google Business) without it exposing the full address?",
    "target": "google;local seo"
  },
  {
    "id": "_softwareengineering.65184",
    "source": "Is it fair to charge again for checking why my code not working on client's server? <eos> So, I was tasked by client to help him convert his wp menu to javascript dropdown. I did on my development server. He did see the change and I was paid. I deliver the code he deploy it. But, no change on his server. So, I have to spent hours debugging it on his server. It turns out, his other plugin is not compatible with my change. That plugin is really custom. I have to change my code to make sure it's compatible with that plugin.My question is, is it fair for me to charge him for the hours I spent on debugging it AND actually fixing it? or is it still my responsibility, to make sure my code deployed properly?",
    "target": "project management"
  },
  {
    "id": "_unix.248461",
    "source": "Booting EFI on KVM <eos> I'm on Ubuntu 14.04 running kernel 3.19. I'm trying to use virt-manager to start a virtual machine. I have installed ovmf for EFI firmware and booted the machine with a Gentoo ISO in the CD slot.I see the OVMF firmware logo, then some log messages like this:Boot failed. EFI DVD/CDROMBoot failed. EFI Floppy.Boot failed. EFI Floppy 1.It then initializes the network card, presumably for network boot, and then drops to an EFI shell:How do I get EFI booting working in KVM/libvirt? ",
    "target": "virtual machine;kvm;uefi"
  },
  {
    "id": "_unix.168527",
    "source": "OS X SSH keeps asking for password <eos> I connect from a Linux machine to several Macs over ssh using public/private keys.The setup is the identical on every ac, different OSs from 10.5 to 10.9 and publickey working. Only one of them, running OS X 10.9.5, keeps asking for user's password instead of using publickey.Actually there's no access using publickey from any machinessh -vvv is:...debug1: Authentications that can continue: publickey,keyboard-interactivedebug3: start over, passed a different list publickey,keyboard-interactivedebug3: preferred publickey,keyboard-interactive,passworddebug3: authmethod_lookup publickeydebug3: remaining preferred: keyboard-interactive,passworddebug3: authmethod_is_enabled publickeydebug1: Next authentication method: publickeydebug1: Offering DSA public key: /Users/akeeem/.ssh/id_dsadebug3: send_pubkey_testdebug2: we sent a publickey packet, wait for replydebug1: Authentications that can continue: publickey,keyboard-interactivedebug1: Trying private key: /Users/akeeem/.ssh/id_rsadebug3: no such identity: /Users/akeeem/.ssh/id_rsa: No such file or directorydebug2: we did not send a packet, disable methoddebug3: authmethod_lookup keyboard-interactivedebug3: remaining preferred: passworddebug3: authmethod_is_enabled keyboard-interactivedebug1: Next authentication method: keyboard-interactivedebug2: userauth_kbdintdebug2: we sent a keyboard-interactive packet, wait for replydebug2: input_userauth_info_reqdebug2: input_userauth_info_req: num_prompts 1Password:What should i check to make sure publickey is operational?",
    "target": "ssh;osx;macintosh;public key authentication"
  },
  {
    "id": "_codereview.83346",
    "source": "Update URL with new parameter value <eos> I needed a way to update a parameter in the URL, or add it if it doesn't exist, but keep any other variables the same value.  I built this function to do the task, and while it works, I feel like it's taking longer than it should.  Does anyone have any suggestion on what I could change or a faster method?function changeURLParameter(sVariable, sNewValue){    var aURLParams = [];    var aParts;    var aParams = (window.location.search).substring(1, (window.location.search).length).split('&');    for (var i = 0; i < aParams.length; i++)    {        aParts = aParams[i].split('=');        aURLParams[aParts[0]] = aParts[1];    }    if (aURLParams[sVariable] != sNewValue)    {        if (sNewValue.toUpperCase() == ALL)            aURLParams[sVariable] = null;        else            aURLParams[sVariable] = sNewValue;        var sNewURL = window.location.origin + window.location.pathname;        var bFirst = true;        for (var sKey in aURLParams)        {            if (aURLParams[sKey])            {                if (bFirst)                {                    sNewURL += ? + sKey + = + aURLParams[sKey];                    bFirst = false;                }                else                    sNewURL += & + sKey + = + aURLParams[sKey];            }        }        return sNewURL;    }}",
    "target": "javascript;url"
  },
  {
    "id": "_codereview.52490",
    "source": "Is there a simple way to use Underscorejs to achieve this? <eos> I have an object, having key and values.  I'd like to pick the object and call the appropriate function from the key:var requireViews = {            breadCrumbView: true,            headerView: false,            footerView: false        };var that = this;    _.each(requireViews, function(value, key){                    if(value){ //if true?                        if(_.functions(that, key)) that[key](); //checking is that function, and calling the function                    }                })Is it ok or can we minimize it further?",
    "target": "javascript;underscore.js"
  },
  {
    "id": "_cs.11590",
    "source": "Algorithm of Communication with Failures <eos> I am interested in Distributed Algorithms especially in communication in network with failures.I look for the proof of the following randomized algorithm of communication in network with failures. For me it seems like very general result in the communication, nevertheless I havent found the proof yet. Algorithm: Initially only vertex $v_0$ has the message, at the end of the algorithm every vertex of the network should have the message. On every round every vertex that has the message choice the neighbour randomly and sends it the message.Assumptions: only $f$ failures might happen on the edges between the vertices.$T = O(\\log n)$ - time complexity and the entire network will know the message with high probability, when $f<n/3$, where n - number of vertices.I will appreciate for link or reference to the paper.",
    "target": "algorithms;distributed systems"
  },
  {
    "id": "_unix.85275",
    "source": "iptables: what the difference between filter and mangle <eos> I am using iptables to to mark the package and want to route based on the marks. First I added the ip rule:sudo ip rule add fwmark 1 prohibit(The prohibit is just for test, I will change it to some route table later.)Then I began to mark the packages:sudo iptables -A OUTPUT -d 192.168.1.0/24 -j MARK --set-mark 1But the computer can still access the 192.168.1.0/24 networks. After a long time's googling and struggling, I tried:sudo iptables -t mangle -A OUTPUT -d 192.168.1.0/24 -j MARK --set-mark 1It works and the connection was blocked.In the first case, the default table of filter is used. So my question is what is the difference between mangle table and filter table? Which one should be used in what cases? As my understanding, all these tables will be consulted before the routing policy, then why the filter table doesn't work properly?",
    "target": "linux;iptables;routing;iproute"
  },
  {
    "id": "_unix.314603",
    "source": "Debian and Centos, why ipv6 prevail over ipv4 <eos> Every time I am configuring a Debian or Centos machine with a static IP address, I forget about that behavior of not taking in account my IPV4 configuration. Then, I search for the 1000nd time the parameter to put in sysctl.conf to disable IPV6, and finally I reboot the beast.An example to illustrate :Linux deb-router 3.2.0-4-amd64 #1 SMP Debian 3.2.81-2 x86_64 GNU/LinuxIt has 2 interfaces, eth0 is configured in IPV4 since some time (1 year maybe).ETH1 is bridged on my physical network and was addressed by the DHCP, in IPV4. I talk to the VM through this interface.Tonight, I lost my Internet gateway, this device is also my DHCP server.I realized I cannot reach my VM anymore, so I checked ifconfig result and saw a nice IPV6 instead of the old IPV4 bound to ETH1.So, action ! $ sudo vim /etc/network/interfacesallow-hotplug eth1# was dhcp beforeiface eth1 inet static    address 192.168.0.15    netmask 255.255.255.0$ sudo ifdown eth1 && ifup eth1Deception :(ifconfig output only an ipv6, I cannot reach my VM. I must disable IPV6 (net.ipv6.conf.eth1.disable_ipv6 = 1) and reboot to get the connection back.I don't understand this choice to favor IPV6 over IPV4, most of people are working with IPV4 from what I know.Is it technical, or political to influence people to adopt IPV6 ?",
    "target": "debian;centos;ipv6;ipv4"
  },
  {
    "id": "_webmaster.23568",
    "source": "Trouble with pleskrestore The file you are trying to upload is not a valid backup file <eos> I am having trouble with pleskrestore on Plesk 10.4.1, CentOS 5. I have 6 files I created (also in Plesk 10.4.1) with pleskbackup, split into 4GB:Here is what I used ...$ /usr/local/psa/bin/pleskbackup --server --output file=ftp://user:pass@domain.com/colossus729_split_0 --split=4G... to make these files:colossus729_split   colossus729_split.001   colossus729_split.002   colossus729_split.003   colossus729_split.004  colossus729_split.005 But plesk restore wouldnt work with those files (contrary to the documentation)# /usr/local/psa/bin/pleskrestore --restore colossus729_split -level server -licenseand get this error:The file you are trying to upload is not a valid backup file",
    "target": "linux;plesk"
  },
  {
    "id": "_unix.202143",
    "source": "Pass SNMP trap packet to a php daemon on Ubuntu <eos> I have a Ubuntu server which is collecting incoming SNMP traps. Currently these traps are handled and logged using a PHP script.file /etc/snmp/snmptrapd.conftraphandle default /home/svr/00-VHOSTS/nagios/scripts/snmpTrap.phpThis script is quite long and it contains many database operations. Usually the server receives thousands of traps per day and therefore this script is taking too much CPU time. My understand is this is due to high start-up cost of the php script every-time when a trap received.I got a request to re-write this and I was thinking of running this script as a daemon. I can create an Ubuntu daemon. My question is how can I pass  trap-handler to this daemon using snmptrapd.conf file?Thank you in advance.",
    "target": "ubuntu;php;daemon;snmp"
  },
  {
    "id": "_softwareengineering.141899",
    "source": "When is a requirement considered complete? <eos> Which elements must a requirement contain that it can be considered complete? Or if this works better - which questions should I ask about a requirement to find out if it is complete. I am not talking about the implementation of the requirement but the requirement itself.I am asking this from the perspective of an analyst who wants to make sure that his requirements are complete before passing them on to the design team.",
    "target": "requirements"
  },
  {
    "id": "_cs.14591",
    "source": "Problem with storing an existing triangulation in a DCEL <eos> I am new to StackExchange, and I already made the mistake of posting a new question as a response to a previous question. Here, I rewrote my question more clearly and separately.I am trying to store an existing 2D triangulation in a DCEL data structure, and I have all of the vertices and edges.I was able to store all of the information correctly except the half_edge representative for each triangle. Here is the algorithm I used:(taken from Constructing of Double Connected Edge List (DCEL))Algorithm:For each endpoint, create a vertex. For each input segment, create two  half-edges and assign their tail vertices and twins. For each  endpoint, sort the half-edges whose tail vertex is that endpoint in  clockwise order. For every pair of half-edges e1, e2 in clockwise  order, assign e1->twin->next = e2 and e2->prev = e1->twin. Pick one of  the half-edges and assign it as the representative for the endpoint.  (Degenerate case: if there's only one half-edge e in the sorted list,  set e->twin->next = e and e->prev = e->twin.) The next pointers are a  permutation on half-edges. For every cycle, allocate and assign a face  structure.The last sentence seems to be easier said than done. How can I ensure that every triangle will have a representative, and that a representative will be assigned only once for each triangle? Furthermore, which cycle is it referring to? If you have any other ideas, please share.Thank you very much for your help. I've been struggling with this for a while.PS- I am working in C++. Also, I am using the same structure as provided in the link above.",
    "target": "algorithms;data structures;computational geometry"
  },
  {
    "id": "_webmaster.16345",
    "source": "find adsense earning from different websites <eos> I am going to add my Adsense code to one new website I've created recently.The problem is how to find out which site earned what in final earning. I need to share the earning of second site with my partner. I can setup different channel to see what each site earned but the final earning may not be the same.So how can I find out which site earned what in final earning page.Thanks in advance.",
    "target": "google adsense"
  },
  {
    "id": "_codereview.129026",
    "source": "Custom user input function <eos> The program consists of 3 files: demo.c, mylib.c and mylib.h. The code is heavily commented.demo.c:/*********************************************************************** * * This is a program that prompts the user for an input string using a * custom input function. * ***********************************************************************/#include <stdio.h>  /* printf */#include <stdlib.h> /* exit */#include mylib.h/* For testing purposes, let's make the length of the string 4 */#define STRING_LENGTH 4int main(int argc, char* argv[]) {    char* s = udf_get_input(Prompt: , STRING_LENGTH);    printf(You entered: \\%s\\\\n, s);    /* I put quotes around the string to better see       what has actually been entered */    free(s);    s = NULL; /* This is not really necessary */    exit(EXIT_SUCCESS);}mylib.h:#ifndef MYLIB_H_#define MYLIB_H_size_t udf_strlen(const char* s);char*  udf_get_input(const char* const prmpt, int str_len);#endif /* MYLIB_H_ */mylib.c:#include <stdio.h>  /* printf, getchar */#include <stdlib.h> /* malloc, realloc, free, exit */#define ERROR_MSG error: could not allocate enough memory/*********************************************************************** * * This is just my own implementation of the C Standard Library's * strlen function. We're going to need it later. * ***********************************************************************/size_t udf_strlen(const char* s) {    size_t i = 0;    while (*s++) {        i++;    }    return i;}/*********************************************************************** * * This is a function that takes in as arguments a pointer to a string * that represents the prompt the user sees when typing things at the * keyboard and the length of the string. The function returns a pointer * to the string that has been entered. * * How it works: * We are going to allocate a certain number of bytes on the heap. This * is going to be our buffer. Then we will read whatever the user types * in into that buffer. After that, we will check if we need to tweak * the amount of memory that the string takes up so that no memory is * wasted unnecessarily. If the number of characters entered by the user * exceeds the buffer size, the rest of the string is discarded. * ***********************************************************************/char* udf_get_input(const char* const prmpt, int str_len) {    int   buffer_size = str_len + 1; /* Number of characters allowed to be                                        entered plus one to accommodate                                        the null character */    char* buffer;            /* Temporary storage for the user's string  */    if (!(buffer = malloc(buffer_size * sizeof(char)))) {        printf(%s\\n, ERROR_MSG);        exit(EXIT_FAILURE);    }    printf(%s, prmpt);     /* Display the prompt                       */    int ch;                  /* Stores characters retrieved from stdin   */    char* p = buffer;        /* Temporary pointer to traverse the buffer */    while ((ch = getc(stdin)) != EOF) {        /* If the character read is a newline character or buffer_size - 1           characters have been already entered, terminate the string with a           null character and bail out of the loop */        if (ch == '\\n' || !--buffer_size) {            *p = '\\0';            break;        }        *p++ = ch;    }    /* If buffer_size is more than zero, that means there are unused bytes in       the buffer. So, we will reallocate memory to shirk it so that the string       occupies as much memory as exactly necessary. Otherwise no memory       reallocation is needed and we can skip this step. */    if (buffer_size) {        buffer = realloc(buffer, (udf_strlen(buffer) + 1) * sizeof(char));        if (!buffer) {            printf(%s\\n, ERROR_MSG);            exit(EXIT_FAILURE);        }    }    return buffer; /* Return the pointer to the string stored on the heap */}To test the program, make a separate directory and create these three files in it:touch demo.c mylib.c mylib.hTo run the program, execute this command:gcc -c demo.c mylib.c && \\gcc demo.o mylib.o -o a.out && \\./a.out",
    "target": "c;strings;io"
  },
  {
    "id": "_webapps.30108",
    "source": "How to make multipage book in Calameo? <eos> If I upload a PDF binder I get the correct amount of pages but with the content of the first page on each. If I upload a number of PDFs separately its just creates a new publication for each PDF.Would anyone know how to correctly publish a multi page book with Calameo from PDFs?",
    "target": "pdf;books"
  },
  {
    "id": "_opensource.1700",
    "source": "Are derivative works a subset of combined works? <eos> This question stems from discussion of a question on programmers.stackexchange.com.In the LGPL 3.0 section 4 Combined Works it states:You may convey a Combined Work under terms of your choice that,  taken together, effectively do not restrict modification of the  portions of the Library contained in the Combined Work and reverse  engineering for debugging such modifications, if you also do each of  the following:Generally, it seems the LGPL license is concerned with open source libraries and software that uses these libraries where a combined work would be a piece of software that includes a library.If one were to open source a standalone single file program and someone modified that and redistributed it, it would technically be a derivative work. Would the statements regarding combined works map to derivative works?Or more simply: Are derivative works a subset of combined works?",
    "target": "derivative works;lgpl"
  },
  {
    "id": "_scicomp.7846",
    "source": "Need an example of convection-dominated problem to test on FreeFEM++ <eos> Can you all give me (at least) one example about convection-dominated problem in order that I can test it (them) on FreeFEM++. If possible, please give me specific examples (it/they contain(s) full equations, boundary condition, initial condition, value of parameters, code in FreeFEM++,...)",
    "target": "finite element;numerical analysis"
  },
  {
    "id": "_codereview.23341",
    "source": "Self Join Exercise. Have I over-complicated it? <eos> This my 3rd question on the same exercise, but by no means a duplicate.  The two previous questions were posted on StackOverflow here and here.Now I'm posting my Oracle solution (below) that works. I wonder if the same could've been simpler and/or much more efficient. Not in terms of CTE or analytic expressions but with basic simple logic.Data:CREATE TABLE Readings (  user_id varchar(10),  reading_time int ,  x decimal(10,2),  y decimal(10,2));INSERT ALL    INTO Readings (user_id, reading_time, x, y) VALUES ('u1', 60, 345, 400)    INTO Readings (user_id, reading_time, x, y) VALUES ('u1', 100, 560, 300)    INTO Readings (user_id, reading_time, x, y) VALUES ('u2', 35, 1024, 250)    INTO Readings (user_id, reading_time, x, y) VALUES ('u1', 90, 450, 450)    INTO Readings (user_id, reading_time, x, y) VALUES ('u3', 150, 600, 100)    INTO Readings (user_id, reading_time, x, y) VALUES ('u3', 100, 500, 125)SELECT * FROM dual;Intermediate script:SELECT r.user_id, rm.reading_time start_time, r.reading_time end_time,        (r.reading_time-rm.reading_time) time_spent,       (TO_CHAR(rm.x)||' ; '||TO_CHAR(rm.y)) start_point,        (TO_CHAR(r.x)||' ; '||TO_CHAR(r.y)) end_point,       SQRT(POWER(r.x-rm.x, 2)+POWER(r.x-rm.y, 2)) distance            FROM Readings r JOIN Readings rm ON (r.user_id = rm.user_id and                      rm.reading_time = (SELECT MAX(r2.reading_time) FROM Readings r2 WHERE r2.reading_time < r.reading_time))ORDER BY 1,2; Final script:SELECT rr.user_id, SUM(rr.distance) Total Distance,        SUM(rr.time_spent) Total Time, SUM(rr.distance)/SUM(rr.time_spent) Average Speed FROM (SELECT r.user_id, (r.reading_time-rm.reading_time) time_spent,        SQRT(POWER(r.x-rm.x, 2)+POWER(r.x-rm.y, 2)) distance            FROM Readings r JOIN Readings rm ON (r.user_id = rm.user_id and                      rm.reading_time = (SELECT MAX(r2.reading_time) FROM Readings r2 WHERE r2.reading_time < r.reading_time))) rrGROUP BY rr.user_idORDER BY 1;Exercise Description Multiple users roam a plain and at irregular time intervals report their coordinates (x, y).  This information (user id, time-stamp and the coordinates) populate table Readings. For each user that reported more than one set of coordinates we need to find total distance traveled, total time spent, and their average speed.For the sake of simplicity coordinates are Cartesian and time-stamps are integers. ",
    "target": "sql;oracle"
  },
  {
    "id": "_computerscience.3660",
    "source": "Converting cartesian pixels to polar pixels <eos> (I've largely revamped this entire question, though the motivation remains the same.)revised questionI want to convert a raster of cartesian pixels into polar pixels.  Is there a sensible algorithm for doing this?  For example, how do I compute the value of the shaded (polar) pixel in the image below, given the value of the three (cartesian) pixels that it overlaps? original questionIs there a reasonable way to compute the area of the intersection of a square and an annular section, as shown in the orange section below?The motivation: I have a raster of square pixels, and I'm converting it to polar pixels -- I want to find out the contribution of each cartesian pixel to each polar pixel.",
    "target": "polygon;2d graphics"
  },
  {
    "id": "_codereview.154433",
    "source": "Function to log arguments and return value of any function in Clojure <eos> I have implemented a function, which logs the inputs and outputs of any function, indenting the log based on the depth of the call stack:(def depth (atom 0))(defn logfun [fun]       (fn [& args]           (do               (swap! depth inc)               (println (str (apply str (repeat @depth  )) >>> ( fun   args )))               (let [result (apply fun args)]                    (do                          (swap! depth dec)                         (println (str (apply str (repeat @depth  ))  <<<  result))                         result)))))Usage example:(defn fact [n] (if (> n 1) (* n (fact (dec n))) n))(def fact (logfun fact))(fact 5)Output: >>> (lang.core$fact@5eb14bce (5))  >>> (lang.core$fact@5eb14bce (4))   >>> (lang.core$fact@5eb14bce (3))    >>> (lang.core$fact@5eb14bce (2))     >>> (lang.core$fact@5eb14bce (1))     <<< 1    <<< 2   <<< 6  <<< 24 <<< 120Main questions:Is there a way to improve this function so that it is not dependent on global variables? (I have already attempted a solution based on with-local-vars / var-set -- see below, but it seems to me that they do not work as I wish they did).Are there any edge cases, for which the above function does not work?Are there any modifications by which this function can be made better adhering to Clojure best practices (besides somehow getting rid of the global state)?Is there a way to improve the output of the function names (e.g., instead of lang.core$fact@5eb14bce I would like to get lang) in a way that satisfies both conditions below:It must be available in the Clojure core language (no third-party libs, no usage of repl utilities)It must not use string manipulation (e.g. find the @ and $ characters via regexp and then strip away the parts before/after them).In other words, I'm looking for something like: (get-pretty-printed-function-name fun). (I already did some research, and found only solutions which do not satisfy the criteria above. Still asking, just in case ;) )The attempted, NOT WORKING solution using var-set/with-local-vars:(defn logfun [fun]   (with-local-vars [depth 0]       (fn [& args]           (do               (var-set [depth (inc @depth)])               (println (str (apply str (repeat @depth  )) >>> ( fun   args )))               (let [result (apply fun args)]                    (do                          (println (str (apply str (repeat @depth  ))  <<<  result))                         (var-set [depth (dec @depth)])                         result))))))EDIT: using bound-fn, I get one step further, but unluckily it still does not do what is expected, as it seems that the variable depth in the closure is reset to zero upon every invocation of the returned function:(defn logfun [fun]   (with-local-vars [depth 0]       (bound-fn [& args]           (do               (var-set depth (inc @depth))               (println (str (apply str (repeat @depth  )) >>> ( fun   args )))               (let [result (apply fun args)]                    (do                          (var-set depth (dec @depth))                         (println (str (apply str (repeat @depth  ))  <<<  result))                         result))))))Result: >>> (lang.core$fact@510da75f (5)) >>> (lang.core$fact@510da75f (4)) >>> (lang.core$fact@510da75f (3)) >>> (lang.core$fact@510da75f (2)) >>> (lang.core$fact@510da75f (1)) <<< 1 <<< 2 <<< 6 <<< 24 <<< 120",
    "target": "clojure;logging"
  },
  {
    "id": "_softwareengineering.344204",
    "source": "Is it required to disclose source code for custom Qt software? <eos> I was hired to develop a custom Qt application for a customer, but I'm concerned about the licensing.My software will not be publicly distributed and it is going to be used exclusively by this customer.Do I need to disclose my source code for this customer, if I link my application with Qt libraries, such as QtCore and QWebKit that can be installed from a Linux distribution repository?",
    "target": "licensing;open source;qt;closed source"
  },
  {
    "id": "_unix.379972",
    "source": "Can a long option be shortened arbitrarily? <eos> Is that a long option can be shortened arbitrarily part of GNU conventions for options, or some other conventions/standards, or just provided by some special C function? For example, why do python and awk behave differently?$ python --versionPython 2.7.12$ python --versioUnknown option: --usage: python [option] ... [-c cmd | -m mod | file | -] [arg] ...Try `python -h' for more information.$ awk --versionGNU Awk 4.1.3, API: 1.1 (GNU MPFR 3.1.4, GNU MP 6.1.0)$ awk --versiGNU Awk 4.1.3, API: 1.1 (GNU MPFR 3.1.4, GNU MP 6.1.0)Thanks.",
    "target": "command line;options"
  },
  {
    "id": "_webmaster.104877",
    "source": "Google Analytics not recording 99%+ of traffic <eos> I have Google Analytics on a Rails web app.Lately traffic has picked up, and I get about 1000 page views per hour as seen from Rails. But GA only picks up 25-100 per day, and I need help understanding this.I know GA doesn't pick up some kinds of traffic, like web crawlers, and my own traffic. What else does it deliberately ignore?Is there a way I can recognize these categories in my Rails code?",
    "target": "google analytics"
  },
  {
    "id": "_softwareengineering.212769",
    "source": "Discovering functionality from parallel class hierarchy <eos> I have an abstract syntax tree which I want to compile down to different representations. I am now struggling to arrange the classes in a way that new representations can be added easily.The easiest way to achieve this is to add a method for each representation, e.g. compile_to_foo, compile_to_bar. Additional representations can be added by monkey patching. The problem with this is that the compilation implementations are spread all over the place, and that it violates the single responsibility principle. The advantage is that compilation can be inherited.Now, I could also define a compilation function containing a giant switch which dispatches on argument type. But this looses advantages of polymorphism, and makes inheriting behavior of the compilation more difficult. This is not a viable option.An interesting solution would use an abstract factory:This design looks fairly promising, but has some disadvantages:The AST Node hierarchy cannot be extended without also extending the AbstractCompiler, and in turn all concrete compilers and their parallel hierarchies of concrete nodes.The subtyping information of the AST nodes is spead across the whole system. it has to be specified between the AbstractNodes in order to share behaviour (I will be using roles), between the ConcreteNodes in order to share compile implementations, and in at least in the AbstractCompiler to provide default implementations (e.g. method NodeA() { return Node() }). This could be partially solved via metaprogramming.When an AST is built, this can only compile down to one representation. If I want to have multiple outputs, I need to rebuild the AST with a different ConcreteCompiler.Ideally, I would just pass a concrete compiler instance as a parameter to the compile method: but I have no idea how the compile method could obtain the actual implementation from a parallel class hierarchy (without again using a giant switch on the node type).I also investigated the Bridge pattern, but the solution does not seem applicable to my problem without creating a thousand little bridges.I carefully read through this previous question: Designing a robust architecture for multiple export types?. The key difference is that the input data (there: equivalent, standalone data represenations) are now hierarchical AST nodes, so that inheritance between the compilation implementations is crucial.The system will be implemented in Perl, so I'm not restricted to classic OOP, but can also use Metaprogramming, Roles (aka. traits), and Functional Programming.What am I missing? Is there an architecture I could use to elegantly structure this system? How can I make the corresponding class from the parallel class hierarchy discoverable to the node classes, without sacrificing polymorphism?",
    "target": "design patterns;architecture;perl;single responsibility"
  },
  {
    "id": "_softwareengineering.355035",
    "source": "Using Qt in Open Source App that Communicates with Closed Source Hardware <eos> PrefaceI'm having trouble determining if I can use the Qt framework for developing a cross platform desktop app.SituationThe app is open source, and the libraries it uses are also open source.So I can provide the source code for the whole app without issue.However, the app will be communicating with hardware that has closed source firmware. The app will read and write data from the device. Read data will be used to visualize what the hardware is doing. It will also update the hardware by feeding the device an encrypted firmware file, which its boot-loader (also closed source) will encrypt and commit to flash. LGPL and GPL licensed code will in no way be used in the firmware or boot-loader. QuestionsDoes the free LGPL version of the Qt framework allow me to keep my firmware as closed source? If so, does the GPL license allow for this use-case as well? EditI read something interesting on a similar question involving the LGPL and GPL licenses: As a rule of thumb, the GPL reaches as far as the address space of the licensed code.If I am reading this correctly, my Qt app should have no licensing issues.",
    "target": "licensing;gpl;lgpl;qt"
  },
  {
    "id": "_webmaster.7372",
    "source": "Best free blogging site that allows AdSense and other advertising? <eos> I'm looking to start my own blog. Under the incredibly vain assumption that anyone cares what I think, I'd like to put up some ads to fund my, um, habits, yeah. I don't want to have to pay anything, nor do I want to host it myself (if possible).What blogging platform fits this bill?",
    "target": "advertising;blog;free;google adwords"
  },
  {
    "id": "_codereview.55108",
    "source": "Parsing ODataQueryOptions to Expression> <eos> I am following up on this answer for a scenario that I am currently working on. Like the OP, I am too concerned about the longevity of the code.public IQueryable<TEntity> EmptyEnumerable(){    return Enumerable.Empty<TEntity>().AsQueryable();}private Expression<Func<TEntity, bool>> GetFilterExpression(FilterQueryOption filter){    var enumerable = this.EmptyEnumerable();    var param = Expression.Parameter(typeof(TEntity));    if(filter != null)    {        enumerable = (IQueryable<TEntity>)filter.ApplyTo(enumerable, new ODataQuerySettings());        var mce = enumerable.Expression as MethodCallExpression;        if(mce != null)        {            var quote = mce.Arguments[1] as UnaryExpression;            if(quote != null)            {                return quote.Operand as Expression<Func<TEntity, bool>>;            }        }    }    return Expression.Lambda<Func<TEntity, bool>>(Expression.Constant(true), param);}My questions are:Is there anything that I should be checking, which I am not already checking?Is returning a truth expression a sensible default?Any refactorings/improvements are welcome.",
    "target": "c#;api"
  },
  {
    "id": "_cs.53636",
    "source": "What is the state-of-the-art in machine translation on Chinese/CJK? <eos> Sorry for my unfamiliarity with the field. Hopefully this question is on-topic here.Currently the machine translation from western European languages to English is arguably quite robust, with Google Translate able to quite accurately translate articles on Wikipedia or news site. However, it seems to me that the translation between Chinese/Japanese and English is still quite off: Google Translate is frequently unable to produce a reasonably coherent/meaningful translation for even just one Chinese/Japanese sentence.It gets me wondering, is the state-of-the-art in CJK machine translation still much off the pace compared with European languages? Or is it just that some research advances haven't been applied to the industry yet? What is the current status of the cutting-edge researches on this field, e.g. novel translation models/improvements on precision rate. Where should I go to look for more information?",
    "target": "reference request;natural language processing"
  },
  {
    "id": "_codereview.61366",
    "source": "Setting .conf files for Nginx <eos> I use Nginx as a server, and I currently use this for configuration of each my sites. Basically, I have multiple files like this located in /etc/nginx/conf.d/.#example.confserver {  listen             80;  server_name        www.my-site.com  my-site.com;  root               /var/www/html/my-site.com;  location / {         rewrite ^/category/(.*)$ /category.php?id=$1 last;         rewrite ^/profile/(.*)$ /profile.php?id=$1 last;         try_files $uri $uri/ /index.php?$query_string;  }  index  index.html index.htm index.php;  error_page  404              /404.html;        location = /var/www/html/nginx/error/404.html {        root       /var/www/html/nginx/error/;  }  error_page   500 502 503 504  /50x.html;       location = /var/www/html/nginx/error/50x.html {       root        /var/www/html/nginx/error/error/;  }  location ~ \\.php$ {       fastcgi_pass   127.0.0.1:9000;       fastcgi_index  index.php;       fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;       include        fastcgi_params;  }}So, I have 6 sites with their own file like this, and since I am about to do a complete re-install of my server, I would like to know how I can improve this configuration, both security and optimization wise.",
    "target": "server;nginx"
  },
  {
    "id": "_unix.191534",
    "source": "top for web browsers <eos> This is a bit off the Unix road, but I believe most people interested in the answer are linux or unix users so here goes.For a long time it seems that the number one process chewing up CPU time and memory is my web browser ( mainly firefox, but others too ). It is true that I have a lot of pages open at once, so I generally don't mind, but recently it's gotten to the point where the browser just bogs down the system, and when I close some pages some sanity is restored.What would be nice is if there were some tool or plugin that would tell me exactly what web pages/sites are using the most resources.",
    "target": "browser"
  },
  {
    "id": "_unix.349161",
    "source": "OpenVPN: Routing by Destination Name OR Port, Not IP <eos> On a DD-WRT router, OpenVPN uses policy based routing for 192.168.1.128/25. If the VPN goes down, the firewall denies access to clients in the range.I would like to add exceptions to the VPN routing.Is it possible to specify that connection to certain FQDNs will be sourced from the WAN address not the VPN address (and of course be unencrypted)? If not possible as above, at least have connections to a certain port (587) be routed off VPN, across the board?",
    "target": "routing;openvpn;router;route;dd wrt"
  },
  {
    "id": "_cstheory.31194",
    "source": "Complexity of Knapsack-type problem with applications to computational workflows <eos> Consider the following problem:Let there be a set A of $n$ items $A=\\{z_1, ..., z_n\\}$, and let $W$ be a strictly positive integer.  Each item $z_i$ has a value $v_i$ and a weight $w_i$. Finding a subset $AS$ of $A$ so that the weight of $AS$ is less than $W$ and the value of $AS$ (the sum of the value of its items) is maximized is the 0/1 Knapsack ProblemNow, consider a deviation from it where the items in $A$ have certain dependency relationships between each other, and these dependencies can be captured by a directed acyclic graph $G(A, E)$.  The value of the set $AS$ is no longer the sum of the value of the items in $AS$. For each item in $AS$,  its value depends on which other items are also in $AS$.  More formally, this is how we calculate the value of an item $v$ in $AS$.  Let $a$ be the a closest ancestor of $v$ in $G$ that is also in $AS$.  Then the contribution of $v$ to the value of $AS$ would be its own value, plus the value of all the ancestors in the path between $v$ and $a$. (Since this is a DAG, there could be many of these ancestors. See formalization below).This problem has important applications in computational workflow systems where you have limited storage, and you want to optimize the computational time of running a workflow (represented by a DAG) by storing some of the intermediate datasets for future use.My questionsThe problem is obviously NP-Hard because the Knapsack problem can be reduced to it. I have a feeling that it is likely that no pseudo-polynomial algorithm exists for it. Do you know of a problem that I could use to reduce to my problem to confirm those feelings? Or do you think that it is possible to produce a pseudo-polynomial algorithm for this?EDIT: FORMALIZATION ON HOW TO COMPUTE VALUE OF $AS$To succinctly define the value of $AS$ I will add to the notation from above a little bit. Let $v(z_i)$ be equivalent to $v_i$ from above. Then $v(z_i|AS)$ reads: value of node $z_i$ given answer set $AS$.If $z_i \\in AS$, then $v(z_i|AS)=0$. Otherwise, if $z_i \\not\\in AS$, $v(z_i|AS) = v(z_i) + \\sum_{z_j \\in parents(z_i)}{v(z_j|AS)}$Those two definitions are enough to then say that:$value(AS) = \\sum_{z_i \\in AS}{v(z_i|AS-\\{z_i\\})}$END OF EDIT",
    "target": "np hardness;time complexity;reductions"
  },
  {
    "id": "_webapps.1229",
    "source": "Sending files over Twitter <eos> I want to be able to send a file to my followers. How do I do this?",
    "target": "twitter;file send"
  },
  {
    "id": "_cogsci.10571",
    "source": "Does sitting idle for one month without work leads to depression? <eos> Does sitting idle for one month without work leads to depression?Following case is an example:If a human do 8 hours job before Computer. Because of no work or a few work; generally sitting idle for one month. and when work came after a month; then that human do not want to do it because:Symptoms which generally such human is facing:1) that humans head remain heavy; always feel like outing. Even if that human go to outing and come back to office feel like go out again.2) It is like nothing is in that human head. Just sounds shaaan shaaaan.3) Sometimes it is like that human need to get my ear clean from ENT; may be due to that head is heavy. but nothing is there in that human's ear , because that human use to clean my ears during bathing.4) Life becoming dull. Now work came after 1 month; that human being lazy not to attempt that work. that human do not want work now.5) Not agreeing to any external Motivation and self motivation is becoming zero.6) Just looking at Facebook, Amazon and doing nothing. Not a like on facebook; but looking just. It is like NOTHING NEW.7) if reading news forget the story after 15 minutes. Forget the work that human's family member says.8) that human feel like that human is blunder; that human do mistakes; you all leave that human; throw that human out of computer company.Could anyone please figure out situation of that human's mind!!! is that human getting mad or depressed?",
    "target": "depression"
  },
  {
    "id": "_cs.19505",
    "source": "Importance of the empty string <eos> In the sense of a string distinct from a null reference string, what is the importance of an empty string in CS (and specially in formal languages)? Why do you need a separate concept, that of 'empty string', which even has it's own Greek letter ()?Couldn't just an EOL character replace it?",
    "target": "formal languages;terminology"
  },
  {
    "id": "_cstheory.1418",
    "source": "Best sources on data stream algorithms <eos> I recently got interested in data stream algorithms to the point that I'd like to study the topic and then teach it to someone.I'd be thus grateful for pointers to really good sources on the topic, t.i. papers presenting major ideas in a particularly articulate way, papers with clever proofs of clever theorems, just good overviews of the state of the art, whatever.My two cents:Lecture notes from the Dartmouth University, 2009. This is the best source I've found so far.Distributing Frequency-Dependent Data Stream Computations, described in my answer to a different (also mine) question.The book Data streams: algorithms and applications (I haven't read it yet)",
    "target": "reference request;big list;data streams"
  },
  {
    "id": "_unix.288129",
    "source": "Autostart bash script, debian 8 <eos> Bash script#!/bin/shxflux -l 55 -g 37How autoboot it precisely in debian 8? I.e via Startap Application commandgnome-terminal -e /path_to_script/script.shDoesn't work",
    "target": "debian"
  },
  {
    "id": "_scicomp.3296",
    "source": "Numerical solution of fractional integro-diffrential equ. using collocation method? <eos> problem comes from Numerical solution of fractional integro-differential , equations by collocation method , E.A. Rawashdeh, Department of Mathematics, Yarmouk University, Irbid 21110, Jordan$D^qy(t)=p(t)y(t)+f(t)+\\int_{0}^{1}{K(t,s)y(s)\\,ds} , t\\in I=[0,1]$I want to create a maple code to check if the results in given article is valid or not but I do not have any idea about collocation method!any reference to collocation method solution are welcome!",
    "target": "finite difference;matlab;mathematica;integral equations;collocation"
  },
  {
    "id": "_webmaster.59433",
    "source": "How to install OSQA using Xampp on Windows 7 32bit? <eos> I want to install OSQA using Xampp on Windows 7 32bit. I've followed the instructions on this tutorial until the Install the database server section. In this section, to create a database, I've used phpMyAdmin and created a database (name: osqa; password: 1234). Now my problem is the next step, Edit settings. In this step I don't know how to fill in the settings_local.py's fields.  I know that Apache needs mod_wsgi.so so, I've placed mod_wsgi.so into my apache modules directory and then added LoadModule wsgi_module modules/mod_wsgi.so to the file httpd.conf. Then I restarted the apache with no errors. Then I followed the next steps, but after entering http://127.0.0.1:8000/ in my browser, I just see a blank page! Can someone please provide me with an instruction in full details? Please note that I don't like to use Bitnami osqa for some reasons.Unfortunately, the official support for OSQA is not very active in these days.  P.s.: I'm using Python 2.7.5 and Django 1.6.2. Also my OSQA source files are in C:\\xampp\\htdocs\\osqa.",
    "target": "xampp;django;python"
  },
  {
    "id": "_unix.59300",
    "source": "How to place / store a file in memory on linux? <eos> I have read somewhere that one can put a file on a linux system into memory, and loading it will be superfast.How do I do this? How do I verify the file is loaded from memory?",
    "target": "linux;files;memory"
  },
  {
    "id": "_cs.10911",
    "source": "Undecidability of the language with its elements(TM) having empty language <eos> We can write a decider for the language:$E=\\{A\\; |\\; A \\mbox{ is a DFA and } L(A)=\\emptyset\\}$by marking method. Why we cannot use the same method to write a decider for the language with TM as follows?$A = \\{ M \\;|\\; M \\mbox{ is a TM and } L(M)=\\emptyset\\}$",
    "target": "turing machines"
  },
  {
    "id": "_unix.294650",
    "source": "Table - Replace values of a column <eos> I have several tables (tab separated) in which the first column is as follow:MONTH0.000.000.000.000.000.000.000.000.000.000.000.00I would like to replace those values by the actual month value, as follow:MONTH123456789101112",
    "target": "table"
  },
  {
    "id": "_codereview.126652",
    "source": "Using a singleton for a collection of discounts to calculate? <eos> I'm wondering if using a Singleton for a storage of discounts is the right way to go. This is because I will be looping over all added discounts in another class.client code// Dynamically add new Discounts$collection = DiscountCollection::getInstance();$collection->add(new TenPercentDiscount());$collection->add(new TwentyPercentDiscount());DiscountCollection<?php namespace Notflip\\Discount;use Notflip\\Discount\\Discounts\\Discount;class DiscountCollection {    private static $instance;    private static $discounts;    final static function getInstance()    {        if(static::$instance === null)        {            static::$instance = new static();        }        return static::$instance;    }    public function add(Discount $discount)    {        static::$discounts[] = $discount;    }    public function count()    {        return count(static::$discounts);    }    public function show()    {        return static::$discounts;    }}",
    "target": "php;object oriented;singleton"
  },
  {
    "id": "_codereview.51354",
    "source": "Given a string, return a string where every character in the original is doubled <eos> For example, given the string xyz, return the string xxyyzz.I was given this as a part of a test. I would really appreciate if you can help me to find a better way of doing it.I came up with two methods to do the same thing but one was an extension method.I have a couple more questions which I will post in separate posts.public class RepeatCharactersInString{                   public string RepeatAString(string sInputString, int repeatCount)    {        StringBuilder sOutputString = new StringBuilder();        if (string.IsNullOrEmpty(sInputString))        {            Console.WriteLine(Empty string !);        }        else        {            foreach (char c in sInputString)            {                sOutputString.Append(new String(c, repeatCount));            }        }        return sOutputString.ToString();    }}// Method 2 Using extension methodspublic static class RepeatCharactersInStingExtensions{    public static string RepeatAllCharactersInThisString(this string sInputString, int repeatCount)    {        StringBuilder sOutputString = new StringBuilder();        if (string.IsNullOrEmpty(sInputString))        {            Console.WriteLine(Empty string !);        }        else        {            foreach (char c in sInputString)            {                sOutputString.Append(new String(c, repeatCount));            }        }        return sOutputString.ToString();    }}",
    "target": "c#;strings"
  },
  {
    "id": "_unix.299956",
    "source": "Linux software center cannot run anymore <eos> I am using Linux Mint 18 Cinnamon.Linux Mint has Software Center, just like Ubuntu Software Center in Ubuntu. After LinuxMint installation, I could run the software center in my system. But someday, may be after some operation like remove OpenJDK, install Oracle JDK,...the Software Center doesn't run anymore. When I click the Software Center icon or run from Terminal, the OS ask for super user password too, after entered the password, the round-spin (waiting) cursor appear for some seconds. After all, nothing happen. The Software Center doesn't run. Something I tried:Reinstall default JRE (OpenJRE)remove software-manager and reinstall software-managerThis is the output when I try to run sudo mintinstall$ sudo mintinstallVector smash protection is enabled.add_categories took 13.497 msbuild_matched_packages took 0.298 msadd_packages took 3828.769 msFirst run detected, initial set of reviews usedadd_reviews took 1022.018 msTraceback (most recent call last):  File /usr/lib/linuxmint/mintinstall/mintinstall.py, line 1920, in <module>    Application()  File /usr/lib/linuxmint/mintinstall/mintinstall.py, line 59, in wrapper    res = func(*arg)  File /usr/lib/linuxmint/mintinstall/mintinstall.py, line 617, in __init__    sans26 = ImageFont.truetype(self.FONT, 26)  File /usr/local/lib/python2.7/dist-packages/PIL/ImageFont.py, line 239, in truetype    return FreeTypeFont(font, size, index, encoding)  File /usr/local/lib/python2.7/dist-packages/PIL/ImageFont.py, line 128, in __init__    self.font = core.getfont(font, size, index, encoding)  File /usr/local/lib/python2.7/dist-packages/PIL/ImageFont.py, line 37, in __getattr__    raise ImportError(The _imagingft C module is not installed)ImportError: The _imagingft C module is not installed",
    "target": "linux mint;software installation"
  },
  {
    "id": "_unix.355113",
    "source": "colordiff - how to retain color while saving to file <eos> Is it possible to retain the color while storing the diff output in a file?This is working and showing the colors in terminalcolordiff -yW 1000 --suppress-common-lines file1 file2 > tempfileBut when I redirect the output to a file its not showing the colors. colordiff -yW 1000 --suppress-common-lines file1 file2 > tempfile",
    "target": "diff;colordiff"
  },
  {
    "id": "_softwareengineering.234459",
    "source": "Backing up messages in S3 within a Storm topology <eos> In my project we are trying to build up a KIND-of-a-lambda storm based architecture. The component would be responsible for indexing the site usage events so we expect a quite massive random load. The solution for real-time processing of the messages seems fine, but in parallel to the speed layer we want to back up the messages in a raw form (just as they are coming down from the queue) in Amazon S3. Since writing a file per message is obviously out of the question, we need to somehow buffer/aggregate the messages before posting to S3 - and here is where the problems begin. We have two concurrent approaches and none seems perfect:We used Redis as a buffer. Basically messages coming down from a queue (RabbitMQ) are buffered in Redis and once some preconfigured batch size (say 1000) is reached the buffer is flushed and stored to S3. The whole message proccesing cycle is not transactional. Once message is stored to Redis it is acknowledged in the queue. This means that if Redis dies the whole batch gets lost and this is not acceptable. We can think of Redis cluster to make the thing more bullet proof but... doesn't it seem like going in a wrong direction?The second approach would be to use Trident Topology. Changing the input queue to Kafka makes things looking more or less straightforward. The message processing cycle can be transactional. HOWEVER, there is this one annoying keyword that keeps beeing repeated in the Trident documentation - small batches - that Trident assumes small batches. For example the TransactionalTridentKafkaSpout batches the messages into 2 seconds chunks. This is much too little for us. I'm not sure why the batches should be small, but if it's really required maybe the first approach is better?Which one from above is better? Maybe somoeone would come up with a third idea?",
    "target": "architecture;real time;redis;aws;apache kafka"
  },
  {
    "id": "_unix.348056",
    "source": "How to remap keys using xkb/symbols/us file in Ubuntu? <eos> I have dropped some water on my keyboard and only one key is not working which is the DOWN key. I want now to use some other keys such as right Alt or menu key between right-Alt and right-Ctrl keys as I do not use them very often. I have open the us file in ...xkb/sybmols/us file, however, I am very confused and could not find the Up, Down, Left and Right keys. Can anyone help me to remap the Down key to the menu key on the keyboard? Thanks",
    "target": "ubuntu;keyboard shortcuts;keyboard layout;xkb"
  },
  {
    "id": "_webmaster.35497",
    "source": "Why is MediaWiki auto-linking the word files <eos> Our MediaWiki installation is auto-linking the word files.  SoHere are some files: a, b, cwould result in the word files being linked to http://ourhost/mediawiki/files.Why is that happening and how do I make it stop? I can use the nowiki tag, but perhaps it does not surprise you that the word files appears often, and it is aggravating to use that tag all the time.Here is some info on our MediaWiki installation from Special:Version.  Yes, it's old.Installed softwareProduct   VersionMediaWiki 1.16.5PHP   5.2.14-pl0-gentoo  (apache2handler)MySQL 5.0.84Installed extensionsParser hooks GoogleDocs4MW (Version 1.1)  Adds  tag  for Google Docs' spreadsheets display Jack Phoenix SyntaxHighlight  (Version 1.0.8.6) Provides syntax highlighting  using GeSHi  Highlighter   Brion Vibber, Tim Starling, Rob Church and Niklas LaxstrmWebServiceSequenceDiagram(Version 1.0)    Render inline sequence diagrams  using websequencediagrams.com Eddie Olsson Other MWSearch MWSearch  plugin    Kate Turner and Brion VibberExtension functions  efLucenePrefixSetupParser extension tags gallery,  googlespreadsheet, html, nowiki, pre, sequencediagram,  source and syntaxhighlightParser function hooks  anchorencode,  basepagename, basepagenamee, defaultsort, displaytitle, filepath,  formatdate, formatnum, fullpagename, fullpagenamee, fullurl, fullurle,  gender, grammar, int, language, lc, lcfirst, localurl, localurle,  namespace, namespacee, ns, nse, numberingroup, numberofactiveusers,  numberofadmins, numberofarticles, numberofedits, numberoffiles,  numberofpages, numberofusers, numberofviews, padleft, padright,  pagename, pagenamee, pagesincategory, pagesize, plural,  protectionlevel, special, subjectpagename, subjectpagenamee,  subjectspace, subjectspacee, subpagename, subpagenamee, tag,  talkpagename, talkpagenamee, talkspace, talkspacee, uc, ucfirst and  urlencode",
    "target": "mediawiki"
  },
  {
    "id": "_datascience.12874",
    "source": "Tensorflow RNN not learning when output included in training variables <eos> I have been attempting to train a RNN on a set of time series data. The goal is to predict one of six categorical outputs. The input is given as 5 time steps of 14 inputs, six of which at one-hot attributes for the output. There is an output at each time step, but the goal is to use previous recorded time spots and their human-assigned outputs to assign an output to the most recent event. Confusingly the RNN is unable to learn that one of the inputs is in fact the output of the classification. This is simply a sanity check for me, but it seems that it may indicate a larger underlying problem.The data is heavily imbalanced, 91%, 4%, 2%, 1%,<1%,<1%, but a cost function is being use to weight mis-classification inversely to it's make-up in the data set. Could the imbalance cause this issue? I'm using 60,000 training examples right now, is this not enough?I'm working off of this dynamic RNN model: https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/dynamic_rnn.py.Note the additional matrix multiplication for a hidden layer. Is this done correctly?def dynamicRNN(x, seqlen, weights, biases):# Prepare data shape to match `rnn` function requirements# Current data input shape: (batch_size, n_steps, n_input)# Required shape: 'n_steps' tensors list of shape (batch_size, n_input)# Permuting batch_size and n_stepsx = tf.transpose(x, [1, 0, 2])# Reshaping to (n_steps*batch_size, n_input)x = tf.reshape(x, [-1,n_input])x  = tf.matmul(x, weights['hidden'])+ biases['hidden']# Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)x = tf.split(0, n_steps, x)# Define a lstm cell with tensorflowlstm_cell = rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0)# Get lstm cell output, providing 'sequence_length' will perform dynamic# calculation.outputs, states = tf.nn.rnn(lstm_cell, x, dtype=tf.float32,                            sequence_length=seqlen)# When performing dynamic calculation, we must retrieve the last# dynamically computed output, i.e, if a sequence length is 10, we need# to retrieve the 10th output.# However TensorFlow doesn't support advanced indexing yet, so we build# a custom op that for each sample in batch size, get its length and# get the corresponding relevant output.# 'outputs' is a list of output at every timestep, we pack them in a Tensor# and change back dimension to [batch_size, n_step, n_input]outputs = tf.pack(outputs)outputs = tf.transpose(outputs, [1, 0, 2])# Hack to build the indexing and retrieve the right output.batch_size = tf.shape(outputs)[0]# Start indices for each sampleindex = tf.range(0, batch_size) * n_steps + (seqlen - 1)# Indexingoutputs = tf.gather(tf.reshape(outputs, [-1, n_hidden]), index)# Linear activation, using outputs computed abovereturn tf.matmul(outputs, weights['out']) + biases['out']",
    "target": "tensorflow"
  },
  {
    "id": "_webapps.50262",
    "source": "Making a header row in a Google spreadsheet <eos> Is there a way to put text in a row at the top of a spreadsheet, like a header?  So it is separate and fixed from the columns below it?  In other words, I want a header row at the top and the columns below it in different widths from the columns in the Header row.",
    "target": "google spreadsheets"
  },
  {
    "id": "_cstheory.34389",
    "source": "Variant of Subset Sum Problem with Changing Bound <eos> Given a sequence of decreasing integers, i.e., $a_1 \\geq a_2 \\geq \\cdots \\geq a_T $ and a positive real $k\\geq 1$, find a subset $S$ such that$$\\max_{S\\subseteq \\{1,\\ldots,T\\}} \\sum_{i\\in S} a_i$$$$s.t., \\sum_{i\\in S/\\{t\\}} a_i \\leq k \\cdot a_t,$$where $a_t$ represents the smallest one of subset $S$. Note that $a_t$ is the smallest of set $S$ and may be different for different set $S$. I am wondering whether this problem is still NP-complete. Any comments or suggestions will be very appreciated.",
    "target": "np hardness;partition problem;subset sum"
  },
  {
    "id": "_webmaster.45513",
    "source": "Port numbers for SSL <eos> We have an existing web site with HTTP on port 80 and HTTPS on port 443. I'm adding a second site to that now, and from what I understand, I cannot host two sites on the same SSL port. So my question is: which port number range is appropriate for me to use as my SSL port on the second site?",
    "target": "https;server;iis7;iis;configuration"
  },
  {
    "id": "_softwareengineering.325674",
    "source": "Best practice for ensuring name uniqueness/correctness in message queues in a microservice architecture/distributed system <eos> I was wondering what a good solution would be for ensuring that queue-names are entered correctly and are only used by the correct applications in a large system which uses message queues to exchange messages.We have a large system written in Java and Apache Camel. It is split into several microservices where they use message queues to communicate with each other. The queue names are as of now strings, which tend to get pretty simple, like incupdate or inccreate. When the system continues to grow and we continue to add more services I am worried that someone is going to reuse a queue-name that already exists, which would create bugs that would not show up in local testing and would be hard to debug. An easy solution to this is to simply add the service name as a prefix to the queue-name, this would ensure uniqueness between the services.But I was thinking, Why not take it a little further?What if I created a reference, that all services had access to, for example an enum, where each service would only use entries in the reference as the queue-names? This way it would not only ensure uniqueness, but it would also ensure correctness (for example typos in queue-names). And it would also provide code-highlighting for wherever each queue-name is used.Do you have any solutions or suggestions for a problem like this? Is the reference-solution viable at all? I can see one problem with it, and it's that each service actually has to have access to the enum, which means injecting it from somewhere. I think we could use maven or spring for this, but I am not sure.",
    "target": "java;spring;message queue;microservices"
  },
  {
    "id": "_cs.44453",
    "source": "Saving a pointer to the n/4 node in AVL tree <eos> I have an AVL Tree which every node has a filed with a key which is an integer. I need to save a pointer to the Minimum , Maximum and the $\\left \\lfloor \\frac{n}{4} \\right  \\rfloor $ nodes. the first and the second were pretty easy i just saved a pointer between each node and its follow and back nodes. But i couldn't find a way to save the $\\left \\lfloor \\frac{n}{4} \\right  \\rfloor$  one. Any ideas? thank you.",
    "target": "data structures;trees;search trees;balanced search trees"
  },
  {
    "id": "_unix.299335",
    "source": "kvm - how to use a usb as storage <eos> I'm on Debian testing.I'm trying to install a vm on a storage which is located on a ext4 formated usb stick. However I'm getting a permission error before the OS can be installed. I'm using Virtual Machine Manager:Unable to complete install: 'Cannot access storage file '/media/user/mnt/generic.qcow2' (as uid:121, gid:131): Permission denied'Traceback (most recent call last):  File /usr/share/virt-manager/virtManager/asyncjob.py, line 88, in cb_wrapper    callback(asyncjob, *args, **kwargs)  File /usr/share/virt-manager/virtManager/create.py, line 2288, in _do_async_install    guest.start_install(meter=meter)  File /usr/share/virt-manager/virtinst/guest.py, line 461, in start_install    doboot, transient)  File /usr/share/virt-manager/virtinst/guest.py, line 396, in _create_guest    self.domain = self.conn.createXML(install_xml or final_xml, 0)  File /usr/lib/python2.7/dist-packages/libvirt.py, line 3777, in createXML    if ret is None:raise libvirtError('virDomainCreateXML() failed', conn=self)libvirtError: Cannot access storage file '/media/user/mnt/generic.qcow2' (as uid:121, gid:131): Permission deniedI mounted the usb using the following command:sudo mount -t ext4 /dev/sdb1 /media/user/mnt  -o rwI have also tried to chmod 777 on the mount point while the usb was mounted as well as on the storage file itself (generic.qcow2).Further I changed the owner of the mount point to libvirt-qemu (uid=121) however the error still persists.How can I provide the appropriate permissions to be able to install the OS?",
    "target": "permissions;virtual machine;kvm"
  },
  {
    "id": "_unix.123153",
    "source": "Limiting number of processes by name <eos> is it possible to limit number of processes for a given group or user using the process name? Eg. I'd like to groups remotes have only 5 simultaneous ssh processes that are run on my server.I don't see any options in pam_limit (I can only limit number of process per user or group, regardless of process name) and I don't see ability in cgroups.Do you have any ideas how to accomplish this? (script in cron is not an answer for me :))",
    "target": "process;limit"
  },
  {
    "id": "_unix.166815",
    "source": "iptables NAT on Debian openvz <eos> So i want to create a nat rule for an openVPN server.After getting trouble with the TAP/TUN Devices, it's finally working i think.Now i have to make a nat rule like so : >iptables -t nat -A POSTROUTING -s 172.16.0.0/24 -o venet0:1 -j MASQUERADE   iptables v1.4.14: can't initialize iptables table `nat': Table does not exist (do you need to insmod?)Perhaps iptables or your kernel needs to be upgraded.But it doesn't work. I searched a lot and found another commandiptables -t nat -A PREROUTING -i tun0 -j DNAT  --to-destination 5.135.###.###This command does the same result as the previous one.Don't know what to do.I ask the host to enable nat but he tell me that i have to do it on my own.",
    "target": "debian;iptables;nat;openvz"
  },
  {
    "id": "_unix.282436",
    "source": "Switching to a virtual terminal is slow <eos> When switching to a virtual terminal using e.g. Ctrl+Alt+F2, it takes about a second to switch. Not too horrible for something that's typically rarely used, but I would like to use it more and it's substantially slower than, say, Alt+Tab. It's particularly weird since switching back to the desktop environment (Alt+F7 for me) is instant.I've noticed it before, but currently I'm running Debian testing (Stretch) with Cinnamon 2.8.7 on X 1.18.3. The resolution of the virtual terminal is the same as X's resolution.What is this delay caused by and how can I improve it?",
    "target": "console"
  },
  {
    "id": "_cstheory.20453",
    "source": "Reference for Dudley's chaining integral <eos> Dudley's chaining integral is commonly used to bound Rademacher complexities. I recall seeing several papers give this as the reference@ARTICLE{MR512411,  author = {Dudley, R. M.},  title = {Central limit theorems for empirical measures},  journal = {Ann. Probab.},  year = {1978},  volume = {6},  pages = {899--929 (1979)},  number = {6},  coden = {APBYAE},  fjournal = {The Annals of Probability},  issn = {0091-1798},  mrclass = {60F05 (28C20 60B10 60F17)},  mrnumber = {MR512411 (81k:60029a)},  mrreviewer = {P. R{\\'e}v{\\'e}sz}}but I don't think the result in question actually appears in that paper. Could anyone point me to the definitive reference?",
    "target": "reference request;machine learning;lg.learning"
  },
  {
    "id": "_unix.50634",
    "source": "Requesting user input while reading file line by line <eos> For class I need to write a Bash script that will take the output from ispell and when I try and request user input inside the while loop it just saves the next line of the file as the user input.How could I go about requesting user input in the while loop?#!/bin/bash#Returns the misspelled words#ispell -l < file#define varsISPELL_OUTPUT_FILE=output.tmp;INPUT_FILE=$1ispell -l < $INPUT_FILE > $ISPELL_OUTPUT_FILE;#echo a new line for give space between command#and the output generatedecho ;while read line;do   echo '$line' is misspelled. Press Enter to keep;   read -p this spelling, or type a correction here:  USER_INPUT;   if [ $USER_INPUT !=  ]   then      echo INPUT: $USER_INPUT;   fi   echo ; #echo a new linedone < $ISPELL_OUTPUT_FILE;rm $ISPELL_OUTPUT_FILE;",
    "target": "bash;shell script;control flow;user input"
  },
  {
    "id": "_softwareengineering.338481",
    "source": "Is there any good/fundamental reason that Python classvars, and JavaScript prototype inheritance, don't mutate the parent on assignment? <eos> In Python, if you have a classvar, it's accessible from an instance, but if you set the variable on the instance it doesn't actually change the classvar, rather it assigns a new name which shadows the parent value:>>> class Foo:...     classvar = 10...>>> f = Foo()>>> (Foo.classvar, f.classvar)(10, 10)>>> f.classvar = 30>>> (Foo.classvar, f.classvar)(10, 30)>>> Foo.classvar = 9>>> (Foo.classvar, f.classvar, Foo().classvar)(9, 30, 9)This is exactly akin to prototype inheritance in JavaScript:> var proto = {x: 10};> function Bar() { }> Bar.prototype = proto;> var b = new Bar(); > [proto.x, b.x][10, 10]> b.x = 30> [proto.x, b.x][10, 30]> proto.x = 9> [proto.x, b.x, (new Bar()).x][9, 30, 9]Of course, if the child mutates the value, then it is seen in the parent, because the variable was not re-assigned and so no shadowing occurred:>>> class Foo:...     classvar = [10]...>>> f = Foo(); f.classvar[10]>>> f.classvar[0] = 30>>> (Foo.classvar, f.classvar)([30], [30])My question is: Is there any good reason for this? It seems like it would be less of a gotcha if the assign semantics were assign on any parent if the value exists there, otherwise create the new value.I ask because I'm designing my own language and, as I get to choose what the semantics are, I'm wondering if I should break from the herd and do what seems like less of a gotcha.",
    "target": "design;javascript;programming languages;python;semantics"
  },
  {
    "id": "_vi.10481",
    "source": "Easier way to dig into docs <eos> I would to know a way to dig into vim and plugin doc easily. I saw mentions about doc ctrlp documentation or commandt.I would like easier documentation discovery for functions, motions, commands I don't know.Thanks",
    "target": "help system;plugin ctrlp"
  },
  {
    "id": "_unix.204639",
    "source": "hg:command not found <eos> I am trying to clone a repository from bitbucket, and I installed mercurial, and copied the HTTPS command. When I run this command I still get hg: command not found, why is this?",
    "target": "mercurial"
  },
  {
    "id": "_webapps.93252",
    "source": "Can't log out of Facebook <eos> For two days, we have not been able to log out of our Facebook account. If we cannot log out the normal way, how can we do this?",
    "target": "facebook;security"
  },
  {
    "id": "_softwareengineering.159804",
    "source": "How do you encode Algebraic Data Types in a C#- or Java-like language? <eos> There are some problems which are easily solved by Algebraic Data Types, for example a List type can be very succinctly expressed as:data ConsList a = Empty | ConsCell a (ConsList a)consmap f Empty          = Emptyconsmap f (ConsCell a b) = ConsCell (f a) (consmap f b)l = ConsCell 1 (ConsCell 2 (ConsCell 3 Empty))consmap (+1) lThis particular example is in Haskell, but it would be similar in other languages with native support for Algebraic Data Types.It turns out that there is an obvious mapping to OO-style subtyping: the datatype becomes an abstract base class and every data constructor becomes a concrete subclass. Here's an example in Scala:sealed abstract class ConsList[+T] {  def map[U](f: T => U): ConsList[U]}object Empty extends ConsList[Nothing] {  override def map[U](f: Nothing => U) = this}final class ConsCell[T](first: T, rest: ConsList[T]) extends ConsList[T] {  override def map[U](f: T => U) = new ConsCell(f(first), rest.map(f))}val l = (new ConsCell(1, new ConsCell(2, new ConsCell(3, Empty)))l.map(1+)The only thing needed beyond naive subclassing is a way to seal classes, i.e. a way to make it impossible to add subclasses to a hierarchy.How would you approach this problem in a language like C# or Java? The two stumbling blocks I found when trying to use Algebraic Data Types in C# were:I couldn't figure out what the bottom type is called in C# (i.e. I couldn't figure out what to put into class Empty : ConsList< ??? >)I couldn't figure out a way to seal ConsList so that no subclasses can be added to the hierarchyWhat would be the most idiomatic way to implement Algebraic Data Types in C# and/or Java? Or, if it isn't possible, what would be the idiomatic replacement?",
    "target": "java;c#;scala;haskell;algebraic data type"
  },
  {
    "id": "_cs.11658",
    "source": "How to represent OOP concepts in algorithms in a standard way? <eos> I have usually been using the Cormen algorithm format to teach some introductory courses in Programming. I mean something like this:TreeSearch(k,n)1. if x==NIL or k==x.key2.     return x3. if k<x.key4.     return TreeSearch(k.left,n)5. else return TreeSearch(k.right,n)Actually I have not agree with a couple of lecturers in my institution that they insist to put the type of the variable that they are using in the algorithm. I mean, to do that, will it not be to make a bias toward the programming language and not to focus on the algorithm? For example what would happen if the student grab other programming language, like R or Python, that really do not care about the type of variable.The other issue that I have is how to represent OOP algorithms in a nice algorithmic way. For example when I make a constructor should I put something like:Class: carAttributes: wheelsConstructor car()or something likeClass: carFunction car()also when I come to the part of inheritance, one of my colleages put the word super() to define inheritance in an algorithmic way, but again I think that is too Java-way to do this part. Usually they teach in that way because the practical part is made in Java, but again I think that the algorithm should be more freely, directly towards the logic, and not to an specific programming language.Does anybody knows some standard to represent algorithms for OOP?",
    "target": "algorithms;terminology;education;object oriented;didactics"
  },
  {
    "id": "_unix.134763",
    "source": "Filter output of command by color <eos> I am running a utility that doesn't offer a way to filter its output. Nothing in the text of the output indicates that a particular function failed but it does show in red. The output is so long that at the end when it reports some # of errors I can't always scroll to see the output where the error occurred.How can I filter out non-red text?pseudo code:dolongtask | grep -color redEditThe command outputs other colors as well and I need to be able to filter out all text that isn't red. Also the text coloring is multiline.",
    "target": "grep;colors;text;filter"
  },
  {
    "id": "_unix.56799",
    "source": "Bash Globbing Variable Substitution? <eos> Possible Duplicate:Batch renaming files I want to rename files using their existing name as a base for the new one.So if I can ls these files withls blue*+(.png)I'd want to rename them something likemv blue$(*)+(.png) $(1).pngexcept that doesn't work obviously. Is there syntax for these kind of variables in bash globbing or is there an easier way?",
    "target": "bash;shell;rename;wildcards;variable substitution"
  },
  {
    "id": "_codereview.106374",
    "source": "Warshall's algorithm for transitive closure <eos> I was going through this code for implementing Warshall's algorithm. I think the time complexity for this simple problem is huge because there are too many loops running here. The time complexity for this code should be \\$O(n^3)\\$. Is there a way to optimize this code so that the time complexity can be reduced a bit?#include<stdio.h>#include<unistd.h>#include<math.h>int maximum(int,int);void warshal(int p[10][10],int n){int i,j,k;for(i=1;i<=n;i++) for(j=1;j<=n;j++)   for(k=1;k<=n;k++)     p[i][j]=maximum(p[i][j],p[i][k]&&p[k][j]);}int maximum(int a,int b){                                                       ;if(a>b)return(a);elsereturn(b);}void main(){int p[10][10]={0},n,e,u,v,i,j; printf(\\n Enter the number of vertices:); scanf(%d,&n); printf(\\n input values now\\n); for(i=1;i<=n;i++)  for(j=1;j<=n;j++)   scanf(%d,&p[i][j]);   printf(\\n Matrix of input data: \\n); for(i=1;i<=n;i++) {   for(j=1;j<=n;j++) printf(%d\\t,p[i][j]); printf(\\n); } warshal(p,n); printf(\\n Transitive closure: \\n); for(i=1;i<=n;i++) { for(j=1;j<=n;j++) printf(%d\\t,p[i][j]); printf(\\n); }  }",
    "target": "performance;beginner;c"
  },
  {
    "id": "_softwareengineering.38905",
    "source": "What makes a large and complex software product slow? <eos> For a reason that is largely irrelevant, I installed Delphi 7 once again in such a long time. I have to say, I was completely blown away - in a way I haven't been for rather a while. This is not how I remember things at all. The installation took around 30 seconds. Launching it took 2 seconds, and it was immediately usable. I can press Run the second after it started, and less than a second later the blank program is already visible and running. Hurray for computers getting so much faster!But the reason I've been blown away like this is because usually I use Visual Studio 2010, that doesn't feel snappy like this at all. Granted, Delphi 7 is a much smaller system than Visual Studio 2010, but it does have the appearance of having all the really necessary things there: a control palette, a form designer, a code editor with code completion. I realise that the language might be simpler, and the code completion might be a lot less powerful, and the IDE might not be nearly as extensible and feature-rich, but still: I do not understand how (i.e. through what mechanism) does having a lot of extra features (that I might not have even triggered yet) cause a system like Visual Studio to always feel sluggish in comparison.I would like to ask people experienced in working with systems the scale of Visual Studio: what is it that makes them slow? Is it the layers upon layers of abstractions required to keep the codebase within the human comprehension capabilities? Is it the sheer amount of code that needs to be run through? Is it the modern tendency towards programmer-time-saving approaches at the (mindbogglingly huge) expense in the clock cycles / memory usage department?",
    "target": "architecture;performance"
  },
  {
    "id": "_unix.72341",
    "source": "How iconify xterm when it loses focus? <eos> I am attempting iconify a xterm terminal when it loses focus in fluxbox.I am following this wiki:http://fluxbox-wiki.org/index.php?title=Make_xterm_act_like_a_PC_game_consoleAnd so far, I've got it appending this lineControl T : If {Matches (xterm)} {Delay {Iconify} 1}to ~/.fluxbox/keys file, which iconify the terminal when I press Control T shortcut.How can I get that behavior when xterm loses the focus?",
    "target": "linux;xterm;slackware;fluxbox"
  },
  {
    "id": "_unix.331475",
    "source": "Not mounting NFS shared folders with vagrant libvirt provider in Debian Jessie <eos> I have a problem with VM virtualization and vagrant libvirt provider for mounting NFA shared folders.With the help of @Infernix in github, I was able to properly install the instance of libvirt but the problem now is to mount the shared directory with the VM.References to installation:https://github.com/vagrant-libvirt/vagrant-libvirt/issues/710Ow, never see error in mount nfs with vagrant before. :o==> default: Exporting NFS shared folders...==> default: Preparing to edit /etc/exports. Administrator privileges will be required... nfs-kernel-server.service - LSB: Kernel NFS server supportLoaded: loaded (/etc/init.d/nfs-kernel-server)Active: active (exited) since Sun 2016-12-18 20:21:10 BRST; 15h ago=> default: Mounting NFS shared folders...The following SSH command responded with a non-zero exit status.Vagrant assumes that this means the command failed!mount -o vers=3,udp 192.168.121.1:/home/tosystems/Documents/projects /home/vagrant/vagrant_projectsresult=$?if test $result -eq 0; thenif test -x /sbin/initctl && command -v /sbin/init && /sbin/init 2>/dev/null --version | grep upstart; then    /sbin/initctl emit --no-wait vagrant-mounted MOUNTPOINT=/home/vagrant/vagrant_rojectsfielse    exit $resultfiStdout from the command:Stderr from the command:stdin: is not a ttymount.nfs: rpc.statd is not running but is required for remote locking.mount.nfs: Either use '-o nolock' to keep locks local, or start statd.mount.nfs: an incorrect mount option was specified.I follow the @HalosGhost hints in link below, but I not succeeded.mount Linux NFS. rpc.statd is not runningI changed the synced_folders parameter in Vagrant file and added:config.vm.synced_folder ~/Documents/projects, /home/vagrant/vagrant_projects, type: nfs, nfs_version: 4, nfs_udp: false, mount_options: [rw, vers=4, tcp]but output here yet:==> default: Preparing to edit /etc/exports. Administrator privileges will be required... nfs-kernel-server.service - LSB: Kernel NFS server support   Loaded: loaded (/etc/init.d/nfs-kernel-server)   Active: active (exited) since Sun 2016-12-18 20:21:10 BRST; 19h ago==> default: Mounting NFS shared folders...The following SSH command responded with a non-zero exit status.Vagrant assumes that this means the command failed!mount -o vers=4,rw,vers=4,tcp 192.168.121.1:/home/tosystems/Documents/projects /home/vagrant/vagrant_projectsresult=$?if test $result -eq 0; thenif test -x /sbin/initctl && command -v /sbin/init && /sbin/init 2>/dev/null --version | grep upstart; then/sbin/initctl emit --no-wait vagrant-mounted MOUNTPOINT=/home/vagrant/vagrant_projectsfielseexit $resultfiStdout from the command:Stderr from the command:stdin: is not a ttymount.nfs: Connection timed outOur efforts did not help in the end.. EDIT: Uzing rsync: ==> default: Rsyncing folder: /home/tosystems/ => /vagrantThere was an error when attempting to rsync a synced folder.Please inspect the error message below for more info.Host path: /home/tosystems/Guest path: /vagrantCommand: rsync --verbose --archive --delete -z --copy-links --no-owner --no-group --rsync-path sudo rsync -e ssh -p 22 -o     LogLevel=FATAL  -o ControlMaster=auto -o ControlPath=/tmp/ssh.661 -o ControlPersist=10m  -o IdentitiesOnly=yes -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -i '/home/tosystems/.vagrant/machines/default/libvirt/private_key' --exclude .vagrant/ /home/tosystems/ vagrant@192.168.121.229:/vagrantError: symlink has no referent: /home/tosystems/.config/google-chrome/SingletonCookiesymlink has no referent: /home/tosystems/.config/google-chrome/SingletonLockrsync: write failed on /vagrant/.vagrant.d/boxes/ubuntu-amd64/0/libvirt/box.img: No space left on device (28)rsync error: error in file IO (code 11) at receiver.c(393) [receiver=3.1.1]rsync: [sender] write error: Broken pipe (32)Please, I need you help.",
    "target": "debian;nfs;vagrant;libvirt"
  },
  {
    "id": "_unix.77630",
    "source": "Installing video driver on Arch Linux <eos> I have Arch Linux installed in console mode on an Intel-PC machine. My task is to write and run an OpenGL display program on the machine to check whether it meets the following conditions:It would take at most 10% of total CPU usageIt would take at most 20% of total RAMHere are more info about the device:uname -a3.6.5-1-ARCH #1 SMP PREEMPT Wed Oct 31 .. x86_64 GNU/Linuxcpu MHz: 1866.717RAM: 2GBPreemptible: YESlspci -v | grep -i graphic*VGA compatible controller: intel corporation Mobile 4 Series Chipset Integrated Graphics Controller (rev 07) (prog-if 00 [VGA controller])(same for Subsystem and Graphics Controller)Now, what I want if to install the relevant graphics driver. However, I cannot do anything as it is run in console mode. It has no X window. I try ALT+F8 but it does not start X window. also tried startx,but I get -bash:startx: command not foundCould anyone guide me how to install the graphics driver please. Considering that I think the kernel is compiled in preemptive mode.",
    "target": "arch linux;drivers;console;graphics"
  },
  {
    "id": "_unix.74055",
    "source": "bash - reading user variable into bash script grep <eos> I've tried every possible combination to get this bash script working. It's part of a larger script, and it basically prompts for a username (to check if it exists) and returns the appropriate response:#! /bin/bash# Script to see if User existsclearecho -n Enter user to check: read $uzergrep -c '^${uzer}:' /etc/passwdif [ $? -eq 0 ]; then  echo User does exist :)else  echo No such userfiIn terminal the following works fine:grep -c '^devuser1:' /etc/passwdRETURNS: 1grep -c '^devuser1234:' /etc/passwdRETURNS: 0I've tried many combinations of passing the read variable into '^${uzer}:' with no joy. Any ideas what else I can try?",
    "target": "bash;regular expression;variable"
  },
  {
    "id": "_unix.273713",
    "source": "Filtering the colored output of grep <eos> I'm on OSX, but I suspect this doesn't make a big difference for this question.In my .bash_profile, I aliased grep to get color outputs by default:alias grep='grep --color=always'I commonly run searches for content within files in my repositories in ways similar to:grep --include=*.cpp -Ern . -e (foo|bar)but I often want to further refine the results, typically piping with say grep -v colorbar.The problem is that the second grep command then runs on the colored ouput, and doesn't seem to be able to match the exclusion patterns because of this.Obviously I could run the first search without colors and then everything would work fine, but I would prefer to keep them if there is a way to work around this?",
    "target": "grep;colors"
  },
  {
    "id": "_unix.297772",
    "source": "Merge lines between keywords into one-line comma separated values <eos> Between first occurrence of Cat to next occurrence of Cat, it should create a separate line with delimiter as ,.File input  as below.CatAABBCCCatAA-1BB-1CC-1Output expected:Cat,AA,BB,CCCat,AA-1,BB-1,CC-1",
    "target": "text processing;awk;sed;perl"
  },
  {
    "id": "_webmaster.3119",
    "source": "Does duplicate content on another site affect my ranking? <eos> A competitors set up a new site and copy and pasted some copy from our home page.When doing a comparison with a duplicate content tool the result was that the pages where 21% similiar.Does the fact they have copied our content affect our site?Their site has seen an increase in their ranking recently and ours ahs dropped slightly",
    "target": "seo;google;content;ranking"
  },
  {
    "id": "_webapps.15628",
    "source": "Is there a Google Docs (or -spreadsheets) API to scroll the view? <eos> If I want to scroll to a particular paragraph in Google Docs, or a particular cell in Google spreadsheets, is there a way to do that via Google Apps script?",
    "target": "google drive;google spreadsheets"
  },
  {
    "id": "_codereview.76978",
    "source": "Faster way to perform function calculation in Python? <eos> I'm interested in whether there is a way to further improve a fast version of a function used in a homework assignment I received recently (I've already submitted the completed work).from math import logdef func_fast(mass, density):    return sum(map((log(mass * density)).__truediv__, range(1,10001)))def func_slow(mass, density):     total = 0.0     for i in range(10000):         masslog = log(mass * density)         total += masslog/(i+1)    return totalmass = 2.5 density = 12.0The fast version times in around 2-2.5ish seconds while the slow version nets 6-7 seconds.",
    "target": "python;performance;python 3.x"
  },
  {
    "id": "_unix.194825",
    "source": "How to achieve root privilege in Metasploitable 2 Linux? <eos> Suppose, I have just entered the Metasploitable 2 Linux like the following command:username : msfadminpassword : msfadminNow, I need to gain 'root' privilege so that I do not need to use 'sudo' - command again and again. For example, in order to shutdown the machine I just want to type:shutdown -h 1not,sudo shutdown -h 1How to do that?",
    "target": "metasploit"
  },
  {
    "id": "_unix.157809",
    "source": "pf blocks all in/out traffic instead of just the one port I wanted to block <eos> I need to block one incoming port with pf. I'm new to pf, and I can't figure out what I'm doing wrong here.Here is my entire rule file, made to block incoming port 22:set block-policy droppass in all keep statepass out all keep stateblock in proto tcp to port 22After I start pf with sudo /sbin/pfctl -e -f /path/to/my/rule/file, all my network traffic is blocked. I try to load a webpage, and it won't load until I do sudo /sbin/pfctl -d to disable pf.If I remove the fourth line (block in proto tcp to port 22) from my rule list, nothing is blocked. So what did I do wrong on the fourth line that is causing it to block everything instead of just incoming TCP port 22? All the examples did this similarly.If it matters, my OS is OS X 10.8.5.",
    "target": "osx;firewall;pf"
  },
  {
    "id": "_webapps.52587",
    "source": "Show only weekends in Google Calendar <eos> Is there a way to only display weekends in Google calendar and not the week days?",
    "target": "google calendar"
  },
  {
    "id": "_unix.219924",
    "source": "Installing jre-8u51-linux-x64.rpm on SLES 11 SP3: Failed dependencies <eos> I tried to update my Java installation on a SLES 11 SP3 system usingrpm -i jre-8u51-linux-x64.rpm(for some reasons I want to run the original Java and not the IBM Java provided by SUSE) and I got the following error message:error: Failed dependencies:    /usr/sbin/alternatives is needed by jre1.8.0_51-1.8.0_51-fcs.x86_64I see that SLES 11 has /usr/sbin/update-alternatives in place of /usr/sbin/alternatives. I am not versed with the details of rpm packaging, how can I fix the rpm package to install on my box? Please give the details, not only the greater picture.P.S. The java installation is meant for a servlet container (Apache tomcat) running some services including a Fedora Commons repository.EDIT (update): With jre-8u65-linux-x64.rpm the dependencies are no longer needed, but the rpm still needs /usr/sbin/alternatives to complete sucessfully (so either provide it as a softlink or edit the rpm file as described in the accepted answer).",
    "target": "rpm;java;dependencies;sles;alternatives"
  },
  {
    "id": "_unix.45646",
    "source": "How do I exit or cancel a bad bash command? <eos> I expect to get some flak for this, but I can't find the answer anywhere. It seems like it should be so obvious. Sometimes, when I type a bad command in a bash terminal, the cursor just jumps down to the next line without any error or anything. I can't tell what I did wrong. It's like I'm stuck in the program. Reenactment:$ tidyMe: Oops! That's not what I meant to type...:qMe: That didn't work...:exit:quitexitquit/exit/quit-exit-quit-wtf???I know I screwed up but how do I get back to the prompt without closing the terminal?",
    "target": "shell;command line;terminal;kill"
  },
  {
    "id": "_softwareengineering.335290",
    "source": "concurrency in hierarchical filesystem databases <eos> I am writing a small program that is a client of some protocol. I wanted this program to have a filesystem database. the main directory would contain one directory for a server that is configured, and the server directory would contain things like server settings in json and other data, this time those are certificates, not sure if certificates would be stored in separate dirs.The question is: if it is possible, even though rare, that multiple instances of this app could access the database, and also this program can run in daemon mode multithreaded, what kinds of locks may be needed for thread and for jvm?For example, should I use a read/write lock for inter thread synchronization + a shared or exclusive file lock? should I lock the whole database, or only the directory near the set of files I want to change, like the server directory?",
    "target": "java;database"
  },
  {
    "id": "_webmaster.44969",
    "source": "Google Sites: code block - how to disable wrapping <eos> I'm using Google Sites to host the wiki-like website. I noticed that code blocks have text wrapped in them. Instead, I would like to have the code non-wrapped and with horizontal scrollbar when needed. Has anyone accomplished this?I would like to do this without Html-markup editing of each post that contains a code block.",
    "target": "google sites;code"
  },
  {
    "id": "_unix.260481",
    "source": "Debian 8 - Run scripts after boot <eos> I've tried run some scripts after boot via /etc/rc.local./etc/rc.local#!/bin/sh -e## rc.local## This script is executed at the end of each multiuser runlevel.# Make sure that the script will exit 0 on success or any other# value on error.## In order to enable or disable this script just change the execution# bits.## By default this script does nothing./home/startup.shexit 0/home/startup.shmount -t vboxsf test /home/testHere is the result on bootHere is the output of systemctl status rc-local.servicerc-local.service - /etc/rc.local Compatibility   Loaded: loaded (/lib/systemd/system/rc-local.service; static)   Active: failed (Result: exit-code) since Sun 2016-02-07 22:48:23 ICT; 18min ago  Process: 432 ExecStart=/etc/rc.local start (code=exited, status=1/FAILURE)Feb 07 22:48:23 debian rc.local[432]: /sbin/mount.vboxsf: mounting failed with the error: No such deviceFeb 07 22:48:23 debian systemd[1]: rc-local.service: control process exited, code=exited status=1Feb 07 22:48:23 debian systemd[1]: Failed to start /etc/rc.local Compatibility.Feb 07 22:48:23 debian systemd[1]: Unit rc-local.service entered failed state.I've tried manually running sudo bash /home/startup.sh and it works fine. I've also applied this method on Ubuntu 14.04 and no errors occurr.What is the reason behind this failure? How can I fix it?",
    "target": "debian;ubuntu;virtualbox"
  },
  {
    "id": "_webmaster.47928",
    "source": "Sitemap file linked from another Sitemap file <eos> I currently have a site setup that, in addition to regular static pages, also has a WordPress blog. This results in my main site having a sitemap.xml file listing the basic pages and then a sitemap for the WordPress blog posts. I understand that I could create a sitemap_index file and point to each of the sitemap files, but would it be possible to just link to the WordPress sitemap from my regular sitemap file?For instance:<urlset xmlns=http://www.sitemaps.org/schemas/sitemap/0.9 xmlns:video=http://www.google.com/schemas/sitemap-video/1.1><url>    <loc>https://www.example.com/wordpress_sitemap.xml</loc>    <changefreq>weekly</changefreq>    <lastmod>2013-04-30T14:10:03+00:00</lastmod>    <priority>1.0</priority></url>",
    "target": "wordpress;sitemap"
  },
  {
    "id": "_unix.265847",
    "source": "How to execute a file without execute permissions <eos> Let's say user wants to execute a script test.sh but ls -l test.sh gives -rwxrwxr-- 1 root root 96 Feb 25 21:44 test.shNow if user doesn't want to make a copy of test.sh (on which he does chmod +x), he can simply dosh test.shto execute test.sh.Is there an analogue way to execute binary programs which one doesn't have execute permissions?",
    "target": "permissions"
  },
  {
    "id": "_unix.7998",
    "source": "Which bash will expand  {1..$VAR} in the same way that zsh does <eos> In response to a comment of mine to this question on SF the OP asserts that the for i in {1..$NUM}expands correctly in bash. I have access to bash 4.0.33 (Ubuntu), 3.2.25 (Centos) and 3.00.16(1) (solaris 10). None of these will expand the {1..$NUM}. Does anyone know which versions of bash do the expansion? If it's not bash what is it ? I know zsh will do the expansion but in the OP's script the shebang should remove the possibility of an alias ?",
    "target": "bash"
  },
  {
    "id": "_unix.184084",
    "source": "Write bash function which operates on list of filenames <eos> I want to define the function cpfromserver in bash so that when I run$ cpfromserver xxx yyy zzzthe result is the same as if I had typed$ scp user@remote.server:/some/location/xxx/xxx.txt /some/location/xxx/xxx.pdf /some/location/yyy/yyy.txt /some/location/yyy/yyy.pdf /some/location/zzz/zzz.txt /some/location/zzz/zzz.pdf /somewhere/else/where it works for any number of arguments.(That is, the function should copy filename.txt and filename.pdf from the directory /some/location/filename/ on the remote.server to the local directory /somewhere/else/ for every filename I specify as an argument to the function. And do it all in a single ssh connection.)Currently, I have written a function that works for a single argument, and I just loop over it, but this establishes separate ssh connections for each argument, which is undesirable.My difficulty is that I only know how to use function arguments individually by their position ($1, $2, etc.)  not how to manipulate the whole list.[Note that I am writing this function as a convenience tool for my own use only, and so I would prioritize my own ease of understanding over handling pathological cases like filenames with quotation marks or linebreaks in them and whatnot. I know that the filenames I will be using this with are well-behaved.]",
    "target": "bash;scp;function;for"
  },
  {
    "id": "_codereview.67326",
    "source": "Showing a list of plugins to filter <eos> How can I refactor this function? I show a list of plugins in JSF, and I should filter them. I added function filterPlugins but I have some questions:Should we simplify block with conditional expression?I reassign global variable plugins to introduce my filter function (is it not bad practice?)load()@NotNull@DataModel(plugins)List<Plugin> plugins;public void load() {    plugins = pluginManager.getPlugins();    plugins = filterPlugins(searchParam);    SortingUtil.sort(plugins, SortingUtil.SortType.ID_ASC);    if (plugins.size() > 0) {        if (plugin != null && plugins.contains(plugin)) {            selectPlugin(plugin);        } else {            selectPlugin(plugins.get(0));        }    } else {        plugin = null;    }}@SuppressWarnings(unchecked)private List<Plugin> filterPlugins(final String searchParam ){      return (List)Iterables.filter(plugins, new Predicate<Plugin>() {        @Override        public boolean apply(@Nullable Plugin plugin) {            return  plugin.getName().contains(searchParam)                    || plugin.getNetworkClasses().contains(searchParam)                    || plugin.getClassName().contains(searchParam);        }    });}@Overridepublic void selectPlugin(Plugin p) {    plugin = p;        }Plugin.javapublic class Plugin {    private static final long serialVersionUID = -8424575107726996696L;    @NotNull    private Long id;    @NotNull    private String name;    @NotNull    private String networkClasses;    + setters and getters}I want to pay your attention this code interacts with JSF page:<a:support event=onRowClick action=#{configPlugins.selectPlugin(p)} reRender=pluginList/><a:commandLink action=#{configPlugins.removePlugin(true)} reRender=pluginList/>",
    "target": "java;plugin"
  },
  {
    "id": "_cogsci.7693",
    "source": "When does anchoring improve our judgement? <eos> Anchoring is the behavioral pattern where the first piece of information we receive about a situation is what all other data points are compared to. For example, the price of the first menu item we see at dinner, the degree of physical pain experienced when exercising, or perceived positivity or negativity in an interaction with a person -- whatever our first experience of these contexts might be, we're likely to view all information received afterward as being either worse or better than those initial impressions. When Ive read about anchoring, its been discussed as a cognitive bias, and it appears to be viewed as a huge blind spot in human reasoning. But if this is such a strong tendency, it must serve us in some contexts (or have served us at one point in time).So, does anchoring ever improves our judgement, instead of deprecating it?",
    "target": "perception;behaviorism"
  },
  {
    "id": "_cs.6895",
    "source": "Scala as a language for Generic Programming <eos> I posted the same Q at programmers.SE, but nobody really helps.In the paper An Extended Comparative Study of Language Support for Generic Programming by Garcia et al. an interesting comparison of programming languages features for generic programming is given:with the brief explanation of terminology:Can anyone assess Scala programming language support for generic programming in a view of this framework? I.e. add a column in the first table with explanations and examples if possible.",
    "target": "programming languages;typing"
  },
  {
    "id": "_softwareengineering.256303",
    "source": "How to design RESTful URI to get all unread messages? <eos> I'm developing an ASP.NET MVC Web Api 2 with .NET Framework 4.5.1 and C#.I have these entities in database:Users, which are members of groups.Groups.Messages. Users can sent messages to a groups.I have this route:config.Routes.MapHttpRoute(    name: GroupMessagesApiRoute,    routeTemplate: api/groups/{groupId}/messages/{messageId},    defaults: new    {        controller = GroupMessages,        messageId = RouteParameter.Optional    });With this route I can get all group's messages and one message, with {messageId}, sent to {goupId}.But now I want to get all messages with an ID greater than {messageId}. How can I do that?I've thought to create another route like this one:config.Routes.MapHttpRoute(    name: GroupMessagesApiRoute,    routeTemplate: api/groups/{groupId}/messages/{messageId}/unread,    defaults: new    {        controller = GroupUnreadMessages    });I will need another controller, `GroupUnreadMessages, to get all unread messages. But I don't know if this is the better approach.",
    "target": "asp.net;rest"
  },
  {
    "id": "_unix.35672",
    "source": "what is inode for, in FreeBSD or Solaris <eos> I know a little about linux kernel. BUt for Freebsd, the vnode actually is similar to the inode in Linux kernel.And there is a inode concept in FreeBSD or Solaris.So my question is: what is inode in FreeBSD for?Below is good to read.Thank you.http://hub.opensolaris.org/bin/view/Community+Group+advocacy/solaris-linux-freebsdAll three operating systems use a data abstraction layer to hide file  system implementation details from applications. In all three OSes,  you use open, close, read, write, stat, etc. system calls to access  files, regardless of the underlying implementation and organization of  file data. Solaris and FreeBSD call this mechanism VFS (virtual file  system) and the principle data structure is the vnode, or virtual  node. Every file being accessed in Solaris or FreeBSD has a vnode  assigned to it. In addition to generic file information, the vnode  contains pointers to file-system-specific information. Linux also uses  a similar mechanism, also called VFS (for virtual file switch). In  Linux, the file-system-independent data structure is an inode. This  structure is similar to the vnode on Solaris/FreeBSD. (Note that there  is an inode structure in Solaris/FreeBSD, but this is  file-system-dependent data for UFS file systems). Linux has two  different structures, one for file operations and the other for inode  operations. Solaris and FreeBSD combine these as vnode operations.",
    "target": "filesystems;freebsd;solaris;inode"
  },
  {
    "id": "_webmaster.38229",
    "source": "How can I find the approximate daily traffic of a site which I don't own? <eos> Possible Duplicate:Is there any way to discover the traffic of a site I dont control? I want to find the approximate daily traffic of a site which isn't ours, and the site is located in other country than US (in Greece - hence no Quantcast or Compete.com afaik) and it doesn't use Google Ads (hence no Google Ad Planner).I know about Alexa but the site(s) has/have relatively low traffic and the Alexa's rank isn't very useful (same stands to Google Trends). Or perhaps I should look more at Alexa's data?Any other ideas?PS: I looked before posting here and here. No luck.",
    "target": "traffic;statistics;suggestions"
  },
  {
    "id": "_webapps.28784",
    "source": "How can we delete a card in Trello? <eos> Possible Duplicate:How do I delete a list or card in Trello? I've added some test cards on this project, I wish not to have them anywhere.I've archived them but that's absurd. Trying to find a trash can or delete text, no luck so far.How can we delete cards ?",
    "target": "trello"
  },
  {
    "id": "_unix.378934",
    "source": "How to allow apache to serve a file written by rsyslogd (selinux) <eos> I have a an application which is run as a systemd service on RHEL7 that makes use of the system journal for logging.  To ease monitoring of this application I have configured rsyslogd to write logs from this service (only) to a dedicated log file.I would now like to serve this log file using httpd so that users can easily monitor the application.The problem I am facing is that no matter how I setup the file contexts it seems selinux will prevent me from doing what I want:rsyslog is allowed to write to var_log_thttpd is allowed to read from httpd_sys_content_tAs far as I can tell there is no context that will allow writing by rsyslogd and reading from httpd.What can I do to get around this problem?  Will I end up needing to create a custom policy module?",
    "target": "apache httpd;selinux;rsyslog"
  },
  {
    "id": "_unix.89098",
    "source": "Ideas how to get my usb audio interface to work with Linux? <eos> PulseAudio does not appear to recognize the Focusrite Scarlett 6i6 USB audio interface. The 2i2, however, is properly recognized and it works as expected. I can't seem to get the 6i6 to work on the same system where the 2i2 worked. Both are said to be class compliant USB devices. I also tried the 6i6 on another computer with a fresh system installation (Kubuntu 12.04) and the result is the same -- PulseAudio doesn't see the 6i6.Here's the only official info I found:Linux and Focusrite / Novation products | Focusrite Developmenthttp://focusritedevelopmentteam.wordpress.com/2012/04/23/linux-and-focusrite-novation-products/Should work: Scarlett 2i2, 2i4, 8i6, 18i6, 6i6, 18i8, 18i20, Saffire 6 USB MkII (USB audio class 2.0 compatible), Forte and iTrack Solo.My experience is that the 6i6 does not work (while the 2i2 does). I'm hoping someone here has figured it out or can tell me the steps I need to figure it out.$ lsusb[snip other h/w]Bus 001 Device 006: ID 1235:8012 Novation EMS $ cat /proc/asound/cards[snip other h/w] 1 [USB            ]: USB-Audio - Scarlett 6i6 USB                      Focusrite Scarlett 6i6 USB at usb-0000:00:1a.0-1.2, high speed$ pacmd list-cardsWelcome to PulseAudio! Use help for usage information.>>> 1 card(s) available.[the 6i6 is not shown, only the built-in sound card is shown]I'm running Kubuntu 12.04 LTS (KDE) and System Settings -> Multimedia -> Phonon does not show the 6i6 at all.Previously the 2i2 was recognized like this:#lsusb[snip other h/w]Bus 003 Device 002: ID 1235:8006 Novation EMS $ cat /proc/asound/cards1 [USB            ]: USB-Audio - Scarlett 2i2 USB                      Focusrite Scarlett 2i2 USB at usb-0000:04:00.0-1, high speed$ pacmd list-cards      Welcome to PulseAudio! Use help for usage information.      >>> 3 card(s) available.      [snip other cards]    index: 2    name: <alsa_card.usb-Focusrite_Scarlett_2i2_USB-00-USB>Thanks",
    "target": "drivers;kde;audio;pulseaudio;kubuntu"
  },
  {
    "id": "_webmaster.92994",
    "source": "IIS sub-domain reverse proxy based on host name <eos> I have a virtual machine in azure running three self hosted applications (not hosted in IIS) on three different ports.I can access them at the urls below:my-server.cloudapp.azure.com:8080 my-server.cloudapp.azure.com:8081my-server.cloudapp.azure.com:8082I've purchased a domain name (my-server.company.com) and want to create three subdomains pointing to each respective applicationsapplication-1.my-server.company.comapplication-2.my-server.company.comapplication-3.my-server.company.comMy first thought is to install IIS on the virtual machine and setup a reverse proxy using URL Rewrite on the default website as mentioned in this article (http://weblogs.asp.net/owscott/creating-a-reverse-proxy-with-url-rewrite-for-iis).So in this scenario, I would setup CNAME records for each of the sub-domains to point to my-server.cloudapp.azure.com and then configure the reverse proxy to forward to the different ports (8080, 8081, 8082) based on the host header.Is this possible / the best way to go about this?The second question is once I get this working, how can I add ssl? Would each sub-domain need its own ssl certificate, in which case how can this work with the setup above (there are no iis websites to bind each certificate to). Or could I just use a certificate for my-server.company.com and then offload at the reverse proxy?",
    "target": "dns;subdomain;iis"
  },
  {
    "id": "_softwareengineering.341380",
    "source": "CQRS + Event sourcing - event groups and event propagation <eos> This is my current CQRS use-case setup:Command DTO is received in application layer handler where we map Command DTO to appropriate domain objects if needed, re-hydrate aggregate root from repo and call some method on AR class CommandHandler{    handle(Command command){        Dom1 dom1 = new Dom1(command.d1);        Dom2 dom2 = new Dom2(command.d2);        AggregateRoot ar = repo.rehydrate(command.arId);        ar.doSmth(dom1, dom2, command.int1);    }}Inside doSmth method in AR, I don't have immediately event to apply, but I have to pass some args to entity that is part of this AR. So inside doSmth method I have  class AggregateRoot{    void doSmth(Dom1 dom1, Dom2 dom2, Integer int1){        subEnt = new OrherSubEntity();        subEnt.doSmth(int1);    }}Now I have sub entity that is activated and generates one DomainEvent. This domain event should be part of event stream that is saved in EventStore and at same time, it is propagated to any listener in this aggregate root. class SubEntity{    void doSmth(Integer int1){        //validate int1        apply(new SubEntityEvent(int1));    }     void when(SubEntityEvent event){        //just modify local fields        //used also in event sourcing rehydration     }}Since second sub entity that is listening to SubEntityEvent is now activated, it performs CPU intense operation and generates SomeCPUIntenseCalcHappened DomainEvent. This event should also be part of the event stream that is saved in EventStore. It is also propagated to other sub-entities in same AR but since nobody else listens to it then we have no further processing.class OtherSubEntity{    void listen(SubEntityEvent event){        data = SomeCPUIntenseCalc();        apply(SomeCPUIntenseCalcHappened(data));    }    void when(SomeCPUIntenseCalcHappened event){        //just modify local fields        //used also in event sourcing rehydration    }}Questions:Since AggreagateRoot is responsible for saving all of the events to event store, how can it know for existence of all of this sub events that happened in it's tree.In this transaction we generated 2 events. Should we store them inside event store as array of events, or we should store them simply one event after another. In order for AR to be in consistent state, both events must be applied in single transaction.In OtherSubEntity we have listen method that is listening to SubEntityEvent. Since on re-hydration from event store we will call SubEntity.when(SubEntityEvent event), how to prevent OtherSubEntity.listen to be called at the same time?Since aggregate root needs to send 1 resulting message down the pipeline (in my case AMQP message), I suppose that this message will actually be projection of this 2 domain events - basically a read model DTO. Where should I create this model? Something similar as read model just with propagation?",
    "target": "domain driven design;cqrs;event sourcing"
  },
  {
    "id": "_webapps.44943",
    "source": "How can I search for Gmail messages on a particular date? <eos> I'm searching for a message on or about a particular date and rather than scrolling through my emails to go back about a year, I'd like to know a search method to only find emails from a particular date or date range. How can I do this with Gmail?",
    "target": "gmail;search;date"
  },
  {
    "id": "_unix.369255",
    "source": "ERR_SSL_PROTOCOL_ERROR apache hosting gitlab <eos> I am hosting Gitlab on digital ocean and I have setup Gitlab to use Apache. When I create a VirtualHost for gitlab I get SSL. It works when VirtualHost is set to <VirtualHost *:80> but then when I change it to my domain I get an error in chrome saying ERR_SSL_PROTOCOL_ERROR. Below is my configuration, I don't understand why it doesn't work. I'm no expert in Apache and this is the configuration that I got on the Gitlab website for Apache. <VirtualHost example.com:80>  ServerName example.com  ServerSignature Off  RewriteEngine on  RewriteCond %{HTTPS} !=on  RewriteRule .* https://%{SERVER_NAME}%{REQUEST_URI} [NE,R,L]</VirtualHost><VirtualHost example.com:443>  SSLEngine on  SSLHonorCipherOrder on  SSLCipherSuite ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:ECDH+3DES:DH+3DES:RSA+AESGCM:RSA+AES:RSA+3DES:!aNULL:!MD5:!DSS  Header add Strict-Transport-Security: max-age=15768000;includeSubdomains  SSLCompression Off  SSLCertificateFile /etc/letsencrypt/live/example.com/cert.pem  SSLCertificateKeyFile /etc/letsencrypt/live/example.com/privkey.pem  SSLCACertificateFile /etc/letsencrypt/live/example.com/chain.pem  ServerName example.com  ServerSignature Off  ProxyPreserveHost On  AllowEncodedSlashes NoDecode  <Location />    Require all granted    ProxyPassReverse http://127.0.0.1:8181    ProxyPassReverse http://example.com  </Location>  RewriteEngine on  RewriteCond %{DOCUMENT_ROOT}/%{REQUEST_FILENAME} !-f [OR]  RewriteCond %{REQUEST_URI} ^/uploads/.*  RewriteRule .* http://127.0.0.1:8181%{REQUEST_URI} [P,QSA,NE]  RequestHeader set X_FORWARDED_PROTO 'https'  RequestHeader set X-Forwarded-Ssl on  DocumentRoot /opt/gitlab/embedded/service/gitlab-rails/public</VirtualHost>I want to set multiple sites up on the same server and I only want to get to my gitlab server with a certain domain, which is why I am setting this up in Apache",
    "target": "apache httpd;apache virtualhost;gitlab"
  },
  {
    "id": "_codereview.28490",
    "source": "searching word or phrase among files <eos> I've written a program:import java.io.File;import java.io.FilenameFilter;import java.io.IOException;import java.util.ArrayList;import org.apache.commons.io.FileUtils;/** * * @author Mohammad Faisal */public class FileContentMatcher {public static void main(String[] args) throws IOException {    String textToMatch = Quick Styles gallery on;    ArrayList<String> paths = new ArrayList<String>();    String content;    int found = 0;    int notFound = 0;    FilenameFilter filter = new FilenameFilter() {        public boolean accept(File dir, String name) {            return name.endsWith(.txt);        }    };    File path = new File(E:\\\\anchit\\\\temp);    File[] listOfFiles = path.listFiles(filter);    for (File file : listOfFiles) {        content = FileUtils.readFileToString(file);        if (content.contains(textToMatch)) {            //System.out.println(Found in:  + file.getAbsolutePath());            paths.add(file.getAbsolutePath());            found++;        } else {            //System.out.println(No found\\n + content);            notFound++;        }    }    for (String pth : paths) {        System.out.println(pth);    }    System.out.println(Found in  + found +  files.\\nNot found in  + notFound +  files.);}}In which I've used Apache Commons IO api.My actual requirement is to list all the files in the given directory which contains the search phrase textToMatch in minimum amount of time about 4-5 seconds, where number of files could be upto 100000. But this program takes much more time than that.So I need to optimize this code but not getting how?Is there any API which can help me? I've heard of Lucene but not getting how to work with it.",
    "target": "java;optimization;search"
  },
  {
    "id": "_webapps.91208",
    "source": "How can I copy the subject title in Inbox by Gmail to clipboard? <eos> Is there a way to access the subject title of an email in Inbox by Gmail to copy it to clipboard?Figure 1. Example subject title in Inbox by Gmail",
    "target": "inbox by gmail"
  },
  {
    "id": "_cs.26080",
    "source": "What type of HMM-GMM I need <eos> Context: I have 100 speech sentences that I asked my friend to speak. The vocabulary in the sentences are same but only the order of words are changed. My friend says that he spoke exactly what was asked for each sentence. But I don't know whether he spoke exactly that sentence or something else. What I have here is those 100 reference sentences against which I need to match his speech samples. As I want to do it by computer and not by listening manually therefore I am seeking your guidance.Data: I have been able to segment the words in each speech sample of my friend. So I have 100 sentences each segmented into individual words with sequence of each word preserved for each sentence. I have extracted required features from each word (MFCC + Delta and Delta Delta).What I am looking for: I need your guidance and help in informing how can I recognize these words with over 95% accuracy. As I read many papers and articles, GMM + HMM is the reasonably good way to do this. But I have a confusion, when I have already segmented every sentence, why should I try to match the entire speech sentence by transitioning state to state using HMM? I can simply match each word and see if the sequence is same with respect to the reference sentence word sequence. Is GMM + HMM the way to go for this? Can I use DTW or Neural Network or SVM to classify (matching or not matching) each word and get high accuracy?",
    "target": "hidden markov models;speech recognition"
  },
  {
    "id": "_softwareengineering.273388",
    "source": "Tree search for path finding - algorithm critiques <eos> So, I'm pretty new to AI in general, and am trying to implement a tree-based search from a textfile input (a maze). An example would be:||||||||||||||||||||||| ||        | |      |    \\|    |||||| | |||||| |     \\||||||       |    P  |      \\|   .| |||||| || |||||       \\  P = Start| |||| |         |   |       /  . = Goal|        ||| |||   | |      /||||||||||    |||||| |     /|          ||        |    /||||||||||||||||||||||I understand the basic algorithms in general (BFS, DFS, A*, etc.), but I want to make sure I'm implementing them correctly, and not somehow cutting corners because I know where the best path is. My basic idea is:Parse the file into a 2D arrayWhile parsing, if I encounter P, note the Start indexWhile parsing, if I encounter ., note the Goal indexBegin at Index(Start), and evaluate surrounding [blank] spacesCreate Nodes for these, and add the appropriate actions to the current Node's available actions --- Add these Nodes to my frontier que[continue whichever algorithm from here]So I guess my main question is, am I generating my world correctly? Is it right to not really create Nodes until I encounter them during the search? It seems wasteful to get to a [blank] space, scan the surrounding 4 directions for other [blank] spaces, and if they exist add them to the available actions and create Nodes for all possible actions.Another alternative would be to generate Nodes as I encounter the [blank] spaces, but this would be hard (since I wouldn't be aware of the upcoming blanks) ... should I parse the file completely, and the traverse the stored array to create all possible Nodes/Links/Actions? Or is that considered cheating somehow...",
    "target": "python;artificial intelligence;search"
  },
  {
    "id": "_unix.23913",
    "source": "Getting input from a USB device listed with lsusb <eos> I have a CF-1KB barcode reader connected to an RS232 to PS/2 adaptor and a PS/2 to USB adaptor. I'm not sure how the device works so I'm trying to figure it out by looking at what information I'm getting from the device.When connected to my computer, it gives me[ 3673.610054] usb 4-1: new low speed USB device using uhci_hcd and address 3[ 3673.900448] input: Generic USB K/B as /devices/pci0000:00/0000:00:1a.1/usb4/4-1/4-1:1.0/input/input16[ 3673.900746] generic-usb 0003:13BA:0017.0003: input,hidraw0: USB HID v1.10 Keyboard [Generic USB K/B] on usb-0000:00:1a.1-1/input0[ 3673.916733] input: Generic USB K/B as /devices/pci0000:00/0000:00:1a.1/usb4/4-1/4-1:1.1/input/input17[ 3673.916890] generic-usb 0003:13BA:0017.0004: input,hidraw1: USB HID v1.10 Mouse [Generic USB K/B] on usb-0000:00:1a.1-1/input1Output from sudo cat /dev/hidraw0 and sudo cat /dev/hidraw1 gives me either unreproducible gibberish each time I scan something or nothing at all.Where can I look to find useful data from the device?",
    "target": "usb;hardware"
  },
  {
    "id": "_webmaster.27595",
    "source": "Magento not responding to payment gateway notifications fast enough or at all? <eos> Some of our customers are getting to the confirmation of payment step in purchasing from our Magento store, and then they are getting a timeout error, where the SagePay payment gateway is trying to contact our server to tell it that a payment was successful (or not) but it cannot contact our server, or cannot get a response from our server in a timely manner, and then the payment/order is being cancelled.I've raised this question to my hosting company, but all they told me was:This is down to the way the software is configured on your serverThis is currently a Magento 1.4.0.1 standard installation as far as payment gateways are concerned. What on earth could this statement mean?Is there some configuration that I need to do to make Magento listen to these requests and respond properly?",
    "target": "magento"
  },
  {
    "id": "_unix.293209",
    "source": "How to check if currently running Linux kernel has been loaded with kexec? <eos> By checking I mean something quite rock-solid, i. e., trying to analyse loader's configuration or available kernel files and matching to uname's output clearly isn't an option.",
    "target": "linux;kexec"
  },
  {
    "id": "_unix.83144",
    "source": "Installing cppman <eos> I've tried to install cppman in Fedora 19 or Linux mint 15 and it installs successfully. But when I try to use it I get the error:Python IOError: [Errno 13] Permission deniedI've installed it in Ubuntu 12.04 and had no problem. Can you help me?Update: I fixed this problem, but I have a new problem. when for example I enter cppman cout the output shown is not in right format:1mNAME0m       std::cout - Standard output stream1mTYPE0m       object       <iostream>1mSYNOPSIS0m       extern ostream cout;1mDESCRIPTION0m       Object of class ostream that represents the standard output stream oriented to narrow characters (of type         char       ). It corresponds to the C stream stdout.It seems that I need to install or configure something. Can you help me?",
    "target": "fedora;vim;linux mint;software installation;python"
  },
  {
    "id": "_cs.28187",
    "source": "Superscalar processors and complex instructions <eos> I read that a supercalar processor has redundant functional units. One can read this e.g. on Wikipedia.How do such redundant units work? Is a complex instruction (for accelerating heavy process, for example Instructions used in Intel IPP, Integrated Performance Primitives) decomposed in micro operations befaure being dispatched among these redudant functional units?What about hardware instructions? Like AES-NI?I also read the Wikipedia article SMT and did not understand the following sentence:Superscalar means executing multiple instructions at the same time while thread-level parallelism (TLP) executes instructions from multiple threads within one processor chip at the same time.I don't understand very well the distinction between these two things. Can somebody explain the subtleties?",
    "target": "computer architecture;parallel computing;concurrency"
  },
  {
    "id": "_codereview.11995",
    "source": "Mocking the class under test with private method calls <eos> Consider the scenario below. It covers multiple methods of my unit under test.public class OriginalSample{    public bool Foo(ISomeEntity entity)    {        return entity.IsThatSo ? entity.IsThatSo : Bar(entity);    }    public bool Bar(ISomeEntity entity)    {        return entity.IsThatAsWell;    }}[TestClass]public class OriginalSampleTest{    [TestMethod]    public void Foo_EntityWithSo_ReturnsTrue    {        // Arrange        Mock<ISomeEntity> someEntityMock = new Mock<ISomeEntity>();        mock.SetupGet(m => m.IsThatSo).Returns( false );        mock.SetupGet(m => m.IsThatAsWell).Returns( true );        // Act        private bool result = _OriginalSample.Foo( someEntityMock.Object );        // Assert        Assert.IsTrue(result);    }}However, in my production code there is a lot that I need to Mock away that is then used in more method calls. I need to find a way to test the Foo method without hitting the Bar method.I came up with the scenario as below. However the disadvantage is that i need a interface and pass the instance in each method. I do not like this design. Any feedback?public interface INewSample{    bool Foo(ISomeEntity entity, INewSample sample);    bool Bar(ISomeEntity entity);}public class NewSample : INewSample{    public bool Foo(ISomeEntity entity, INewSample sample)    {        return entity.IsThatSo ? entity.IsThatSo : sample.Bar(entity);    }    public bool Bar(ISomeEntity entity)    {        return entity.IsThatAsWell;    }}[TestClass]public class NewSampleTest{    [TestMethod]    public void Foo_EntityWithSo_ReturnsTrue    {        // Arrange        Mock<ISomeEntity> someEntityMock = new Mock<ISomeEntity>();        mock.SetupGet(m => m.IsThatSo).Returns( false );        Mock<INewSample> sampleMock = new Mock<INewSample>();        sampleMock.Setup(m => m.Bar).Returns(false).Verify();        // Act        private bool result = _OriginalSample.Foo( someEntityMock.Object, sampleMock.Object );        // Assert (that the logic tried to use the 'bar' method        sampleMock.Verify();    }}",
    "target": "c#;unit testing;moq"
  },
  {
    "id": "_webapps.104915",
    "source": "Can I set a different Reply-To address from the From address for a Mailchimp campaign? <eos> As the title indicates, I'd like replies to my Mailchimp campaign to go to a different email address from the From address appearing as the sender. Is this possible? I couldn't see an obvious way to do it when I created a test campaign, but I thought it might be worth asking anyway.",
    "target": "mailchimp"
  },
  {
    "id": "_unix.296885",
    "source": "Load plaintext output without write files <eos> I have a program (than I run from terminal) that generates 4 plaintext files.For example./myproggenerates file1.dat, file2.dat, file3.dat, file4.dat.I want to create a script that allows me run myprog and load (read) this four file outputs but without write the physical files (may be, load that files only in ram). Is this possible?The reason is that I need about 70000 of this files, so I don't want to lose time saving extra files, I just need to use the information.=============================================Specific example that was asked me in commentstriangle software (free software to generate meshes for numerical calculus, written in C) read the file mesh.poly::4 2 0 11   0     0     202   1     0     203   1     1     104   0     1     104 11 1 2   20 # bottom side2 2 3   20 # right side3 3 4   10 # top side4 4 1   20 # left side011 0.5 0.5 1 0.0005The commandtriangle mesh.poly generate the following files:mesh.node:4  2  0  1   1    0  0    20   2    1  0    20   3    1  1    10   4    0  1    10and mesh.ele2  3  0   1       4     1     2   2       2     3     4and other two files, in total: four output files.After generate this files I need to use the information in other program, written by me on fortran, that need the *.node and *.ele information. I'm thinking to write a .sh file to do this automatically, but I can use python or any language that allows me to run executable programs.To load (read) the mesh.node and mesh.ele is easy. But I need to generate thousands physical files as output of triangle and input of my fortran code. For that reason, I'm looking for a way to write virtual files thinking that will be more efficient and clean.My problem is that I have about 70000 mesh.poly generating 70000x4 output (and little) files.",
    "target": "shell script"
  },
  {
    "id": "_codereview.3926",
    "source": "Repository wrapper <eos> The following implementation is of a repository proxy.I will post only the code for NHibernate Repository here.  Everything else (including configurers and tests) can be found on the pastebin.P.S. : I changed all the XML-like comments to their more readable representation, so the actual code still has nice XML documentation.public interface IRepository{    // Retrieves every entity of the specified type stored in the repository.    IQueryable<T> RetrieveEntities<T>() where T : IRepositoryEntity;    // Retrieves every entity filtered by the supplied expression.    // As long as the result is models 'IQueryable', it implies on the lazy result    // evaluation and therefore doesn't have significant performance impact.    IQueryable<T> RetrieveEntities<T>(Expression<Func<T, bool>> expression) where T : IRepositoryEntity;    // New items are added to the repository and existing are updated.    void AddEntities<T>(IQueryable<T> sequence) where T : IRepositoryEntity;    void AddEntities<T>(params T[] entities) where T : IRepositoryEntity;    // Removes every entity of the specified type stored in the repository.    void RemoveEntities<T>() where T : IRepositoryEntity;    // Removes entities of the specified type which fit under the specified expression.    void RemoveEntities<T>(Expression<Func<T, bool>> expression) where T : IRepositoryEntity;    // Removes every entity in the sequence from the repository. Throws if at least one entity    // from the sequence doesn't belong to the database.    void RemoveEntities<T>(IQueryable<T> sequence) where T : IRepositoryEntity;    void RemoveEntities<T>(params T[] entities) where T : IRepositoryEntity;}public class NHibernateRepository : IRepository{    private readonly Configuration configuration;    private readonly ISessionFactory sessionFactory;    private readonly ISession session;    public NHibernateRepository(NHibernateRepositoryConfigurer repositoryConfigurer)    {        // Build and store the NHibernate-specific configuration.        configuration = repositoryConfigurer.Configuration.BuildConfiguration();        // Build the corresponding session factory and open the session.        sessionFactory = repositoryConfigurer.SessionFactory;        session = sessionFactory.OpenSession();    }    public IQueryable<T> RetrieveEntities<T>() where T : IRepositoryEntity    {        CheckTypeMappings(typeof(T));        return session.Query<T>();    }    public IQueryable<T> RetrieveEntities<T>(Expression<Func<T, bool>> expression) where T : IRepositoryEntity    {        CheckTypeMappings(typeof(T));        return session.Query<T>().Where(expression);    }    public void AddEntities<T>(IQueryable<T> sequence) where T : IRepositoryEntity    {        CheckTypeMappings(typeof(T));        WithinTransaction(() =>        {            foreach (var entity in sequence)            {                session.Merge(entity);            }        });    }    public void AddEntities<T>(params T[] entities) where T : IRepositoryEntity    {        CheckTypeMappings(typeof(T));        AddEntities(entities.AsQueryable());    }    public void RemoveEntities<T>() where T : IRepositoryEntity    {        CheckTypeMappings(typeof(T));        WithinTransaction(() =>        {            foreach (var entity in session.Query<T>())            {                session.Delete(entity);            }        });    }    public void RemoveEntities<T>(Expression<Func<T, bool>> expression) where T : IRepositoryEntity    {        CheckTypeMappings(typeof(T));        WithinTransaction(() =>        {            foreach (var entity in session.Query<T>().Where(expression))            {                session.Delete(entity);            }        });    }    public void RemoveEntities<T>(IQueryable<T> sequence) where T : IRepositoryEntity    {        CheckTypeMappings(typeof(T));        WithinTransaction(() =>        {            foreach (var entity in sequence)            {                session.Delete(entity);            }        });    }    public void RemoveEntities<T>(params T[] entities) where T : IRepositoryEntity    {        CheckTypeMappings(typeof(T));        RemoveEntities(entities.AsQueryable());    }    // Performs the entire specified action within a single unit of work.    private void WithinTransaction(Action action)    {        var transaction = session.BeginTransaction();        try        {            action();            transaction.Commit();        }        catch (Exception)        {            transaction.Rollback();            throw;        }        finally        {            transaction.Dispose();        }    }    // Throws if the type is not mapped to the database.    private void CheckTypeMappings(Type type)    {        if (type.IsInterface) return;        if (configuration.ClassMappings.Any(x => x.MappedClass == type)) return;        // The 'type' is definitely doesn't have an appropriate persister.        throw new MappingException(Type  + type.FullName +  doesn't have an appropriate persister);    }",
    "target": "c#;beginner;repository"
  },
  {
    "id": "_unix.334860",
    "source": "Can I copy a kernel changes to a new machine? <eos> In order to install ORACLE database on Fedora, I had to make A LOT of changes in fedora... How can I copy all those changes and install them on my new fedora installation ?Or is it even possible to copy the whole partition (OS and software included) and install that partition on a new HDD and launch it ?",
    "target": "fedora;kernel;migration"
  },
  {
    "id": "_softwareengineering.322360",
    "source": "What is the meaning of the data inside wave_format_ieee_float? <eos> I made a program that connected to the microphone and captured wave_format_ieee_float data from it. I noticed that if I made a really loud noise the data seems to fluctuate between -1 and 1 (when I cast the buffer pointer into float*). What is the significance of this? How do I connect this to deciBel Sound Pressure Level, Pascals from ambient pressure or the voltage being sent through the microphone cable? I know the microphone has -38dB sensitivity. Any explanation or further reading tips that casts light on what the numbers inside the wave represents in real life are welcome.",
    "target": "specifications"
  },
  {
    "id": "_softwareengineering.343205",
    "source": "How to document REST API before coding <eos> My team is working on a web application using Micro Service Architecture and Angular + Spring MVC. We follow Agile development. For each story, we create few implementation and test tasks. Documenting REST API is the first task to be done in the story.We currently document it in Confluence so that developers and testers can work on implementation and test cases respectively. We are looking to generate REST API documentation with Swagger automatically using codegen. It looks like documenting in Confluence and generating with Swagger is redundant. However, swagger generates accurate documentation. What is the best way to document REST API before coding ? Are there any other tools ?",
    "target": "rest;documentation;api design;swagger"
  },
  {
    "id": "_vi.10287",
    "source": "How to highlight a search range? <eos> I'd like to test the range pattern, same as Vim highlights the text while searching (e.g. :/), but for the range command instead.So in other words, instead of executing::/<head/,/\\/head>/dI'd like to test only /<head/,/\\/head>/ range pattern in form of highlight to check whether the pattern is correct, before I'm going to run any command on that range.Sample text to play with can be retrieved by: vim http://www.example.com/.",
    "target": "search;highlight;range"
  },
  {
    "id": "_softwareengineering.333878",
    "source": "Assigning variables as lines of code <eos> I know in lua you can do something along the lines ofprint=System.out.printlnprint(Hello)But is there something similar in java?",
    "target": "java;lua"
  },
  {
    "id": "_unix.25649",
    "source": "Is it possible to stop emacs from down translating my key chords? <eos> emacs has the default behaviour of double-guessing which key-combo (chord) I've pressed. It automatically down-translates to a lesser chord when the key-combo I pressed is unassigned, eg. <C-M-up> (translated from <C-M-S-up>) How can I turn this off?   I really can't see any value in it, but it must be for some users. I'd also like to know what advantage this (dubious) feature offers...",
    "target": "emacs;keyboard shortcuts"
  },
  {
    "id": "_cstheory.38754",
    "source": "Languages that lack contraction, weakening or exchange <eos> When learning about generalized arrows, a question arised to me: Are there any languages (or potential languages) that lack one or more of the structural rules: contraction, weakeing and exchange?Under Curry-Howard isomorphism, these rules, used frequently in logic, map into programming concepts. If we denote $A, B, C \\vdash D$ a program (corresponding to a natural deduction proof) that computes a value of type $D$ from inputs of types $A$, $B$ and $C$, we get:Contraction: $\\Gamma, A, A\\vdash B$ can be transformed into $\\Gamma, A\\vdash B$.That is, a single input can be used twice.Weakening: $\\Gamma\\vdash B$ can be transformed into $\\Gamma, A\\vdash B$.That is, it's possible to add arbitrary, unused inputs.Exchange: $\\Gamma_1, A, B, \\Gamma_2 \\vdash C$ can be transformed into $\\Gamma_1, B, A, \\Gamma_2 \\vdash C$.That is, the order of inputs doesn't matter.An example for language lacking contraction would be quantum computing. There the allowed operations can be described with unitary matrices, and duplicating a value can't be expressed as such.It also seems to me that weakening isn't an admissible rule for quantum computing, at least in the above form, as we can't forget a value with a unitary matrix. But we could have a weaker rule such as $\\Gamma\\vdash B$ can be transformed into $\\Gamma, A\\vdash A\\otimes B$, and the $A$ in the output can be dropped when extracting the results of such a computation.The exchange rule is clearly permissible in quantum computing.Are there any other examples, in particular a language that doesn't allow exchange, or where weakening isn't allowed even in such a weaker form?",
    "target": "lo.logic;pl.programming languages;curry howard"
  },
  {
    "id": "_softwareengineering.287155",
    "source": "New created custom list shape doesn't work in Microsoft Visio 2013 x64 <eos> Objective:First, I should say what I want to do, and then I'll describe what I've done to achieve to my goal in the next (Descriptions) part.I want to create a Custom List Master Shape from the Plain Container of the Diagram Parts section in the Insert tab of the ribbon. Then, I want to create another Master Shape that can use as the member shape for the Created Custom List Master Shape.In other words, I want to add my Created Master Shape to my Custom List Master Shape like attaching the Member and Separator Master Shapes to the Class Master Shape of the UML Stencil.So, I've faced with some problems in achieving to my goal that I've described them in the next parts.Descriptions:I've created some new Master Shapes in a Visio Stencil (.vssx) file as follows:Figure 1 - New Created Master Shapes with used Master ShapeProperty Master Shape (Green Box): that is created from the Member Master Shape of the UML Class Stencil (Blue Box).Object Master Shape (Red Box): that is created from the Plain Container of the Diagram Parts section in the Insert tab of the ribbon.The Property Master Shape is created to use as the member shape in the Object Master Shape like the Member Master Shape to use in the Class Master Shape of the UML Stencil.Figure 2 - Class Master Shape with its Initial MembersThe Property Master Shape that is created from Member Master Shape has changed as follows:I added one Shape Data to it (Figure 3).Figure 3 - Shape Data dialogue box of the Property Master ShapeI added one Data Graphic Item to it (Figure 4).Figure 4 - Data Graphic and Data Graphic Item dialogue boxes of the Property Master ShapeI changed the User.MemberName Formula in the User-defined cells' section of the ShapeSheet window as follows (Figure 5):=MID(SUBSTITUTE(TRIM(SHAPETEXT(TheText)),[,),1,FIND( ,SUBSTITUTE(TRIM(SHAPETEXT(TheText)),[,))-1)instead of:=SHAPETEXT(TheText)Figure 5 - ShapeSheet window of the Property Master ShapeThe Object Master Shape that is created from the Plain Container has changed as follows:I changed the contents of the cells in the User-defined cells' and Events sections of the ShapeSheet window as Figure 6:Figure 6 - Cells in the User-defined cells' and Events sections of the ShapeSheet window after changing their contentsinstead of:Figure 7 - Cells in the User-defined cells' and Events sections of the ShapeSheet window before changing their contentsQuestions:1st Question:Why isn't/aren't instance(s) of the Property Master Shape arranged and placed correctly after adding it/them to the instance(s) of the Object Master Shape like adding instance(s) of the Member Master Shape to the instance(s) of the Class Master Shape of the UML Stencil (Figure 8)?Figure 8 - Comparing an instance of the Object Master Shape and one instance of the Property Master Shape with an instance of the Class Master Shape of the UML Stencil and its Initial Members2nd Question:Why do(es)n't instance(s) of the Object Master Shape add its Initial Members after attaching it/them to the page like adding Initial Members after adding Instance(s) of the Class Master Shape of the UML Stencil to the page (Figure 9)?Figure 9 - Comparing an instance of the Object Master Shape with an instance of the Class Master Shape of the UML StencilI've added the following Formula for achieving to this objective; However, I think that it doesn't work:=IF(LISTMEMBERCOUNT()=0,DOCMD(2270),0)3rd Question:Why isn't displayed a Bar in the instance(s) of the Object Master Shape to insert instance(s) of the Property Master Shape like displaying the Bar in the instance(s) of the Class Master Shape of the UML Stencil to insert its Members (Figure 10)?Figure 10 - Comparing an instance of the Object Master Shape with an instance of the Class Master Shape of the UML Stencil for displaying the Bar to insert related Members4th Question:Why do(es) instance(s) of the Object Master Shape accept instance(s) of All Master Shapes except than only instance(s) of the Property Master Shape, instead of the instance(s) of the Class Master Shape of the UML Stencil that only accept(s) the instance(s) of the Member and Separator Master Shapes of the UML Stencil (Figure 11)?Figure 11 - Comparing an instance of the Object Master Shape that accepts instance(s) of All Master Shapes with an instance of the Class Master Shape of the UML Stencil that only accepts the instance(s) of the Member and Separator Master Shapes of the UML StencilI've set =USE(Property) for the User.msvSDListItemMaster in the User-defined cells' section of the ShapeSheet window; However, I think that it doesn't work.5th Question:Why isn't/aren't displayed options for inserting Members on the added instance(s) of the Property Master Shape to the instance(s) of the Object Master Shape like attached instance(s) of the Member and Separator Master Shapes of the UML Stencil to the instance(s) of the Class Master Shape of the UML Stencil (Figure 12)?Figure 12 - Comparing an instance of the Object Master Shape and one instance of the Property Master Shape with an instance of the Class Master Shape of the UML Stencil and its Members for displaying Options of the inserting members on the added members6th (Final) Question:Why do(es) instance(s) of the Object Master Shape behave and act like the Container while I've changed its/their Master Object to a List?",
    "target": "visio"
  },
  {
    "id": "_unix.103567",
    "source": "Vim paste string with non-ASCII characters <eos> I am trying to paste a string from a register in VIM which contains non-ASCII characters such as Ctrlr, how can I paste this string into a file, but escape the non-ASCII characters automatically?Essentially, what I am trying to achieve is recording a macro which has some (non-ascii) characters, such as CtrlW which vim will show as ^W.  I want to be able to take the macro (by examining the registers and taking the macro string (i.e @a=^W)) and copying it into a .vimrc file as a key-map, so that when I press the key it will run that macro. I want to do this automatically (or as fast as possible) without having to change ^W into CtrlW in the .vimrc file, or wherever I paste it too.",
    "target": "vim;paste"
  },
  {
    "id": "_unix.14730",
    "source": "view stdout for another pts <eos> Here is the situation. I left my pc at home doing an rsync from a 2TB hard drive to another 2TB hard drive (it's going to take a while since they are both USB 2.0). I am now at work and I have ssh-ed into my home pc. If I do ps aux | grep rsync I can see the following:1000  7214 18.8  0.1  30636  1368 pts/0 S+   00:52 134:00 rsync -vr /media/master /media/slaveHowever I want to see exactly what rsync is doing. When I was at home, the standard output was shown in my terminal and the verbose mode of rsync showed which files were currently being copied. Is there any way to read stdout for another pts?$ ps -t pts/07214 pts/0    02:14:42 rsyncI did a little bit of googling and it seems that /proc/pid/fd may hold the answer but I'm not sure about this...P.S. I have sudo privileges of course.",
    "target": "terminal;process;rsync;io redirection"
  },
  {
    "id": "_unix.270221",
    "source": "Can't connect to Tomcat on port 8080 (port 80 works) <eos> We have a bunch of Centos 6 dedicated servers hosting our web applications that are set up behind a reverse proxy. The reverse proxy is running Haproxy and forwards web requests to the backend servers. We periodically have to add a new server which we configure using Puppet (software, users, firewall), so they should theoretically be set up the same.I have an issue with the latest server I've added where for some reason I can't connect when running Tomcat on port 8080 (our default Puppet setup), however it connects fine if I manually amend server.xml and haproxy.cfg to use port 80.I initially thought I'd made a mistake in iptables but I've tried temporarily allowing all traffic, with no luck. My rules were initially port specific and I've tried expanding them to all ports, although the original rule included port 80 and 8080 together along with 443 and 8443, so this was unlikely to be the issue.I can connect locally on the server via localhost (http://localhost:8080/sitename), but I can't connect remotely, either by domain name through the proxy, or directly by hostname or IP address.I've tried monitoring port 8080 on eth0 using sudo tcpdump -i eth0 port 8080 and got nothing.Not sure what to try next. Any advice/help would be appreciated, thanks.Edit: Netstat output looks like this...tcp        0      0 :::8080       :::*      LISTEN      29875/jsvc.execEdit2: Regarding iptables, I've tried temporarily setting the default policy to accept (it's normally drop) on both the reverse proxy and the backend server. Also the rules all come from the same file that Puppet uses to set iptables on all our backend servers.",
    "target": "linux;centos;tomcat"
  },
  {
    "id": "_webapps.104759",
    "source": "Getting spam by Gmail filter match <eos> I recently noticed some spam messages getting labeled by some of my filters. For example:I have a filter that labels any message coming from @domain but if a message come from @xxxxx-domain the filter is getting triggered labeling the message too.Does anyone know how to fix my filter?",
    "target": "gmail;gmail filters;spam prevention"
  },
  {
    "id": "_softwareengineering.133950",
    "source": "OCCI for non-web application <eos> I am writing a non-web application (written in java) which will allocate cloud resources. I want to make it compatible with as many providers as possible. Is it wise to use OCCI interface? Will it be too complicated?",
    "target": "java;cloud computing;rest"
  },
  {
    "id": "_webapps.8988",
    "source": "Why can I add members to FB groups instead of just inviting them? <eos> I was under the impression group membership is voluntary - that you can't add someone to a group, but rather you can invite them.I want to create a Facebook entity that:Is open to everyone - everyone can leave or join at willThe only one that can make use X be in the group is an action by user XWill be accessible to users that aren't signed to FacebookA group doesn't seem to follow rules 2 and 3. Should I use a Fan page ? Or ... what is the best Facebook entity to capture this?",
    "target": "facebook"
  },
  {
    "id": "_cs.7578",
    "source": "Multisets of a given set <eos> A multiset is an unordered collection of elements where elements may repeat anynumber of times. The size of a multiset is the number of elements in it countingrepetitions.(a) What is the number of multisets of size $4$ that can be constructed from $n$distinct elements so that at least one element occurs exactly twice?(b) How many multisets can be constructed from $n$ distinct elements?For part b, infinite is correct.For part a, taking $n=3$ and elements $\\{1,2,3\\}$ we have multisets as:$\\{1,1,2,2\\}, \\{1,1,3,3\\}, \\{1,1,2,3\\}, \\{2,2,3,3\\}, \\{2,2,1,3\\}, \\{3,3,1,2\\}$, for a total of $6$.Similarly for $n=4$ and using elements $\\{1,2,3,4\\}$, we have $18$ multisets. There must be some formula, or we have to develop one!I am in particular looking for a formula when there is a restriction on the number occurrences in the multiset.",
    "target": "combinatorics;sets"
  },
  {
    "id": "_unix.222033",
    "source": "iptables - why do I get Table does not exist (do you need to insmod?) <eos> I need to install some iptable ruels to block traffic that originates from a certain country, I found this script example on http://www.cyberciti.biz/faq/block-entier-country-using-iptables/ it works great on another host I have but on this one (an embedded box) I get: ./iptable_rules.sh modprobe: module ip_tables not found in modules.depiptables v1.4.16.3: can't initialize iptables table `filter': Table does not exist (do you need to insmod?)Perhaps iptables or your kernel needs to be upgraded.Now upgrading the kernel due to the nature of the device, is not an option. Does anyone know a way I can get around this? This system running on kernel 3.2.34",
    "target": "kernel;iptables;firewall"
  },
  {
    "id": "_webapps.72751",
    "source": "What does Gmail really mean when the login page offers me an option to stay signed in? <eos> Gmail's sign in page offers the checkbox stay signed in. Does this mean that it will stay signed in indefinitely? If not, then for how long?The need help? link is not immediately helpful.",
    "target": "gmail"
  },
  {
    "id": "_webmaster.35076",
    "source": "How to remove page/menu from page title in Joomla 2.5 and 3+ on front page only <eos> I have a Joomla 2.5 website and I would like to remove the page/menu name from appearing in the title so it does not display in Google or the browser tab. Currently the homepage is appending 'HOME' to the page title i.e:<title>Example Sitename - Page/Menu Name</title>I know that the Browser Page Title can be found within Page Display Options, but if I leave it empty, it uses the Menu Item Title.Please note that I only want to remove the page/menu name on the front page of site, also the solution should be working for bilingual (or multilingual) websites, that means My Website - Home will be My Website and other languages will follow the same rule, i.e. Mon Website - Accueil will be Mon Website.",
    "target": "joomla;title;page"
  },
  {
    "id": "_unix.224087",
    "source": "How to differentiate 2 NICs with the same PCI address <eos> I am running Fedora 22, and have a GPU that I passthrough to a KVM guest. I accomplished this by adding pci-stub.ids=<pci id 2>,<pci id 2> to my Grub boot option. The two PCI IDs I'm using now are for the same GPU, but the IDs are different. I recently purchased a TP-Link NIC, and the manual says it is using a Realtek 8xxx chipset. Apparently this is the same chipset used by my integrated NIC, as lspci -nn shows the same output, except the PCI bus ID is 08:00 instead of 06:00 for my integrated NIC. Given that the pci-stub.ids line uses the 8 hexadecimal values for the PCI ID, how do I attach only one of my NICs to the PCI stub driver?EDIT: Here is some of the lshw output:*-pci:5         description: PCI bridge         product: SB700/SB800/SB900 PCI to PCI bridge (PCIE port 0)         vendor: Advanced Micro Devices, Inc. [AMD/ATI]         physical id: 15         bus info: pci@0000:00:15.0         capabilities: pci pm pciexpress msi ht normal_decode bus_master cap_list         configuration: driver=pcieport       *-network            description: Ethernet interface            product: RTL8111/8168/8411 PCI Express Gigabit Ethernet Controller            vendor: Realtek Semiconductor Co., Ltd.            physical id: 0            bus info: pci@0000:06:00.0            logical name: enp6s0            version: 06            serial: 90:2b:34:xx:xx:xx            size: 1Gbit/s            capabilities: pm msi pciexpress msix vpd bus_master cap_list ethernet physical tp mii 10bt 10bt-fd 100bt 100bt-fd 1000bt 1000bt-fd autonegotiation            configuration: autonegotiation=on broadcast=yes driver=r8169 driverversion=2.3LK-NAPI duplex=full firmware=rtl8168e-3_0.0.4 03/27/12 ip=192.168.1.10 latency=0 link=yes multicast=yes port=MII speed=1Gbit/s*-pci:7         description: PCI bridge         product: SB900 PCI to PCI bridge (PCIE port 2)         vendor: Advanced Micro Devices, Inc. [AMD/ATI]         physical id: 15.2         bus info: pci@0000:00:15.2         configuration: driver=pcieport       *-network            description: Ethernet interface            product: RTL8111/8168/8411 PCI Express Gigabit Ethernet Controller            vendor: Realtek Semiconductor Co., Ltd.            physical id: 0            bus info: pci@0000:08:00.0            logical name: enp8s0            version: 06            serial: c4:e9:84:xx:xx:xx            size: 1Gbit/s            capabilities: pm msi pciexpress msix vpd bus_master cap_list ethernet physical tp mii 10bt 10bt-fd 100bt 100bt-fd 1000bt 1000bt-fd autonegotiation            configuration: autonegotiation=on broadcast=yes driver=r8169 driverversion=2.3LK-NAPI duplex=full firmware=rtl_nic/rtl8168e-2.fw ip=192.168.1.142 latency=0 link=yes multicas",
    "target": "virtual machine;kvm;pci"
  },
  {
    "id": "_unix.89657",
    "source": "Why doesn't my udev rule work? <eos> I created a file /etc/udev/rules.d/60.alsa.rules with the following content:KERNEL==0000:00:1b.0, SUBSYSTEM==pci, ATTR{label}==Realtek High Definition Audio Device, ATTR{vendor}==0x8086, SYMLINK+=jumanjiThen I restarted udev using init.d but the symbolic link /dev/jumanji was not created.What should I do?Additional information:udevadm info -a -n /dev/snd/by-path/pci-0000\\:00\\:1b.0looking at device '/devices/pci0000:00/0000:00:1b.0/sound/card0/controlC0':    KERNEL==controlC0    SUBSYSTEM==sound    DRIVER==  looking at parent device '/devices/pci0000:00/0000:00:1b.0/sound/card0':    KERNELS==card0    SUBSYSTEMS==sound    DRIVERS==    ATTRS{id}==PCH    ATTRS{number}==0  looking at parent device '/devices/pci0000:00/0000:00:1b.0':    KERNELS==0000:00:1b.0    SUBSYSTEMS==pci    DRIVERS==snd_hda_intel    ATTRS{irq}==45    ATTRS{subsystem_vendor}==0x8086    ATTRS{broken_parity_status}==0    ATTRS{class}==0x040300    ATTRS{index}==1    ATTRS{label}==Realtek High Definition Audio Device    ATTRS{consistent_dma_mask_bits}==64    ATTRS{dma_mask_bits}==64    ATTRS{local_cpus}==ff    ATTRS{device}==0x1c20    ATTRS{msi_bus}==    ATTRS{local_cpulist}==0-7    ATTRS{vendor}==0x8086    ATTRS{subsystem_device}==0x2042    ATTRS{d3cold_allowed}==1  looking at parent device '/devices/pci0000:00':    KERNELS==pci0000:00    SUBSYSTEMS==    DRIVERS==",
    "target": "ubuntu;audio;udev;pci"
  },
  {
    "id": "_codereview.93224",
    "source": "Proper use of timer in windows service <eos> I have following code to use timer (System.Timers.Timer) in windows service. The goal is that new time handler should not occur if previous one didn't finish its job. Here is how I achieve this:protected override void OnStart(string[] args){            try            {                //                // Create and start a timer.                //                m_mainTimer = new System.Timers.Timer();                m_mainTimer.Interval = 60000;   // every one min                m_mainTimer.Elapsed += new System.Timers.ElapsedEventHandler(this.timer1_Tick);                m_mainTimer.AutoReset = false;  // makes it fire only once                m_mainTimer.Enabled = true;            }            catch (Exception ex)            {              // omitted            }}And:protected override void OnStop()    {        try        {            // Service stopped. Also stop the timer.            m_mainTimer.Enabled = false;            m_mainTimer = null;        }        catch (Exception ex)        {        }    }Also in handler:private void timer1_Tick(object sender, ElapsedEventArgs e)        {            try            {            }catch(Exceptione x)            {            }            finally            {            if (null != m_mainTimer)            {                m_mainTimer.Start(); // re - enable the timer            }            }}It works but my question is is this approach safe? Maybe I should make m_mainTimer volatile? Because of the null check inside finally?",
    "target": "c#;timer"
  },
  {
    "id": "_unix.28116",
    "source": "How to create a tar.gz file from a folder excluding a folder <eos> How do I exclude a file or folder while creating a tar.gz file with tar command?",
    "target": "tar;compression"
  },
  {
    "id": "_webmaster.57774",
    "source": "How to make visits count on Google Analytics if someone visits my own JSFiddle on my website? <eos> I'm a developer and I often write JSFiddles for example. I use Google Analytics on my personal website to monitor traffic. jsfiddle.net is not my own domain, but in a way, snippets I'm publishing on belongs to me.How can I make traffic my own JSFiddles' generate counts for my own domain's one? In other words, when someone visits a JSFiddle I have written, I'd like it counts for one visits on Google Analytics.",
    "target": "google analytics;visitors"
  },
  {
    "id": "_softwareengineering.298135",
    "source": "What are the standards for dealing with pluralia tantum in your code? <eos> When using variables of which their plural and singular are both the same, how do you name them? Are there any standards out there?For example:Series[] series  // PluralSeries series    // SingularIndepth:To be specific, my collection of series needs to be called series (due to JSON formatting), would you consider naming the singular form of Series that gets added to the collection Series s?As in:List<Series> series = new List<Series>();Series s;while (someBool){    s = new Series();    s.Name = Name;    while (anotherBool)    {        s.AddValue(someValue);    }    series.Add(s);}",
    "target": "c#;naming;naming standards;language discussion"
  },
  {
    "id": "_codereview.158971",
    "source": "Solution to Google Code Jam 2008 round 1C problem B <eos> This is my solution to Google Code Jam 2008 round 1C problem B (Ugly Numbers). I think it's very elegant. However, I wonder if it's too concise. What could I improve here?The problem:Once upon a time in a strange situation, people called a number ugly  if it was divisible by any of the one-digit primes (2, 3, 5 or 7).  Thus, 14 is ugly, but 13 is fine. 39 is ugly, but 121 is not. Note  that 0 is ugly. Also note that negative numbers can also be ugly; -14  and -39 are examples of such numbers.One day on your free time, you are gazing at a string of digits,  something like:123456You are amused by how many possibilities there are if you are allowed  to insert plus or minus signs between the digits. For example you can  make1 + 234 - 5 + 6 = 236which is ugly. Or123 + 4 - 56 = 71which is not ugly.It is easy to count the number of different ways you can play with the  digits: Between each two adjacent digits you may choose put a plus  sign, a minus sign, or nothing. Therefore, if you start with D digits  there are 3^D-1 expressions you can make.Note that it is fine to have leading zeros for a number. If the string  is 01023, then 01023, 0+1-02+3 and 01-023 are legal  expressions.Your task is simple: Among the 3^D-1 expressions, count how many of  them evaluate to an ugly number.InputThe first line of the input file contains the number of cases, N. Each  test case will be a single line containing a non-empty string of  decimal digits.OutputFor each test case, you should output a lineCase #X: Ywhere X is the case number, starting from 1, and Y is the number of  expressions that evaluate to an ugly number.Code:from functools import lru_cacheM = 2*3*5*7uglies = list(filter(lambda n: (int(n)%2 == 0 or                                int(n)%3 == 0 or                                int(n)%5 == 0 or                                int(n)%7 == 0),                     range(M)))@lru_cache(maxsize=None)def f(line, k=None):    if k == None:        return sum([f(line, k) for k in uglies])    return sum([        (1 if (int(line) % M) == k else 0),        sum([f(line[:p],               (k-int(line[p:])) % M)             for p in range(1, len(line))]),        sum([f(line[:p],               (k+int(line[p:])) % M)             for p in range(1, len(line))]),        ])if __name__ == '__main__':    import sys    data = sys.stdin.read().splitlines()[1:]    case = 1    for line in data:        print('{:.0%}'.format(case/len(data)), file=sys.stderr)        print('Case #{}: {}'.format(case,                                    f(line)))        case += 1",
    "target": "python;programming challenge;python 3.x;dynamic programming"
  },
  {
    "id": "_unix.310374",
    "source": "Switching disks <eos> We currently have two servers with SATA disks. The box load on the box every so often jumps. We see a direct correlation between the IO wait and the system usage going up. When ever the IO is high the system CPU usage jumps as well. The server has hardware raid with the drive showing as /dev/sda. We re running CentOS. We want to install two SSD's in a raid 1 as well, boot from a USB key and then use dd to copy from the SATA disks over to the SSD's. Once we copy everything over we will remove the original array and leave just the second. Will this work? How does Linux assign which disk is /dev/sda or /dev/sdb?",
    "target": "centos;hard disk;dd"
  },
  {
    "id": "_unix.40781",
    "source": "How to reduce size of swap after a system is already installed? <eos> I'm running Debian Squeeze 6.0.5. Does the use of swap memory make my computer run slower? If so, how can I reduce the size of the swap memory after the system is already installed?",
    "target": "linux;debian;swap"
  },
  {
    "id": "_webmaster.42385",
    "source": "Network unreachable: robots.txt unreachable <eos> I am trying to add a valid sitemap to Google Webmaster. Yet, it says:     Network unreachable: robots.txt unreachableWe were unable to crawl  your Sitemap because we found a robots.txt file at the root of your  site but were unable to download it. Please ensure that it is  accessible or remove it completely.and Network unreachable: robots.txt unreachableWe were unable to crawl  your Sitemap because we found a robots.txt file at the root of your  site but were unable to download it. Please ensure that it is  accessible or remove it completely.Yet, I can access both my robots.txt and sitemap.xml. I have reading other posts here and there, but could not solve/understand what is causing this issue. Anyone knows?",
    "target": "google search console;sitemap;robots.txt"
  },
  {
    "id": "_webapps.19532",
    "source": "How Can I Delete My YouTube Account? <eos> My school email address is not @gmail.com, however, it is managed by GMail, so I log into a special school log-in and it takes me to my email with the familiar GMail tools and GMail inbox. Unfortunately, it linked itself to a youtube account. I want to either delete this YouTube account or unlink it.However, as you can see, there is no unlink button nor are there delete account options. I also tried this question : How do I unlink my YouTube account from my Gmail account? and followed the link to Unlink Youtube and Google Accounts, but it doesn't do anything and simply redirects me back to my Manage Account page. ",
    "target": "youtube;account management"
  },
  {
    "id": "_cs.38236",
    "source": "How do you prove two languages are equivalent using the definition of acceptance? <eos> I need to prove that $L(f(M)) = L(M)\\cup \\{\\varepsilon\\}$where $M$ is a DFA and $f$ is the function $f(M) := (Q\\cup \\{q_f\\}, \\Sigma, \\delta', q_f, F\\cup\\{q_f\\})$ and $q_f$ is a new state not in $Q$ and $\\delta'(q,a) =       \\begin{cases}        \\delta (q,a)  & \\text{if }q\\in Q\\\\        \\delta (q_0,a) & \\text{if }q= q_f.      \\end{cases}$I'm assuming I need to use induction but I'm not sure how to go about it",
    "target": "formal languages;regular languages;finite automata;proof techniques;induction"
  },
  {
    "id": "_unix.4656",
    "source": "Mirror for Fedora core 4 still available? <eos> I'm trying to rebuild ELDK 4.0, which uses Fedora Core 4 as its base. Can anyone direct me to a mirror that still hosts the files? ",
    "target": "linux;fedora"
  },
  {
    "id": "_codereview.149277",
    "source": "Validating only attributes that are present in a form <eos> I want to skip validations based on attributes. If certain attributes are not in form so I do not want to validate them.Currently, if I post them from one form which has 1 field, it still validates other 9 fields and show me errors that it cant be blank.If I check from big form which has 10 fields, it passes successfully.The below code did trick for me but my main intention is to refactor so it will fullfil its purpose as i stated above.Code is:validates :teacher_number, presence: true, if: teacher_number && teacher_number.blank?  validates :title, presence: true, if: title && title.blank?  validates :name, presence: true, if: name && name.blank?  validates :gender, presence: true, if: gender && gender.blank?  validates :location, presence: true, if: location && location.blank?  validates :dob, presence: true, if: dob && dob.blank?  validates :contact_mobile, presence: true, if: contact_mobile && contact_mobile.blank?  validates :contact_home, presence: true, if: contact_home && contact_home.blank?  validates :street, presence: true, if: street && street.blank?  validates :city, presence: true, if: city && city.blank?  validates :state, presence: true, if: state && state.blank?  validates :zip_code, presence: true, if: zip_code && zip_code.blank?  validates :country, presence: true, if: country && country.blank?  validates :teacher_number, uniqueness: {scope: :school_id}, if: teacher_number && teacher_number.blank?  validate  :teacher_number_existance, :on => :create, if: self.teacher_number && self.teacher_number.blank?  validate  :school_existance, :on => :create, if: self.teacher_number && self.teacher_number.blank?I simply wants to do something like:before_validation :skip_validationsdef strip_validations    [:teacher_number, :title, :name, :gender, :location, :dob, :contact_mobile, :contact_home, :street, :city, :state, :zip_code, :country].each do |attr|      errors.add(Teacher,  #{attr} can't be blank) if attr && attr.blank?    end  endBut above code does not work for my cases. Any good work around?",
    "target": "ruby;ruby on rails;validation"
  },
  {
    "id": "_unix.196599",
    "source": "cp won't work on current bash script's directory <eos> I'm trying to copy some files from current directory in a bash script but the problem is that the cp command doesn't work with the current directory. I can use the following command without any problem on Backtrack 5 (based on Ubuntu) but not in Kali linux (based on Debian):cp -f -v *.{html,txt,php} /var/www/I can execute this command directly from the terminal by first changing directory to the directory where these files are. But using script I get the following error:cp -f -v *.{html,txt,php} /var/www/cp: cannot stat `*.{html,txt,php}': No such file or directoryAgain I have no problem with this command in the script when I use Ubuntu.",
    "target": "bash;file copy"
  },
  {
    "id": "_codereview.36573",
    "source": "Calculating shopping cart discounts <eos> I have a method that checks to see if a hash of given items should have discounts applied and if so, determines and returns the discount:def get_discounts  @items.each do |name, attr|    @specials.each do |special|      while name == special.sale_item && attr[:quantity] >= special.quantity        @discounts << special.discount        attr[:quantity] = attr[:quantity] - special.quantity      end      end    end  determine_discountenddef determine_discount  if @discounts.empty?    @discounts = 0  else    @discounts = @discounts.inject(:+)   end   endThis works perfectly, but is there a more concise way to write it?  I'm looking especially at the two each loops.  I'm also a bit iffy about the while loop - it was an if statement (if name == special.sale_item) but it felt like too much so I combined it into the while loop.",
    "target": "ruby;e commerce"
  },
  {
    "id": "_unix.387786",
    "source": "Setting up custom bash script to run only as sudo <eos> I made a script (name of the file is update) to update and upgrade in one command. All it is is:#! /bin/bashsudo /usr/bin/apt-get updatesudo /usr/bin/apt-get upgradeI used the full paths, as well putting this in its own directory, /home/user_name/custom_scripts. I also made sure to designate this directory as root, the permissions are listed as drwxr-xr-x.  2 root root 4096 Aug 23 00:12 custom_scriptsand the executable script is:-rwx------. 1 root root 73 Aug 23 00:12 updateI edited my path to look like this /home/user_name/custom_scripts:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games yet for some reason this won't execute if I type sudo update. The weirdest thing is if I just try update, I get a permission denied exception. I'm not really sure what's wrong.",
    "target": "shell script;permissions;path"
  },
  {
    "id": "_webmaster.83936",
    "source": "Subdomain redirect to website.com/wp-signup.php?new=example after multisite - WordPress <eos> I have a question and I hope that someone can help me! I have a Website powered by WordPress with some articles and I wanted to make a Network, so a multisite installation.I followed the steps that are present on the WordPress Codex, inserting first the function to enable multisite in wp-config.php and then I went in my wp-admin to and followed the instruction to complete the procedure.This is my code added in wp-config.php:define('MULTISITE', true);define('SUBDOMAIN_INSTALL', true);define('DOMAIN_CURRENT_SITE', 'website.com');define('PATH_CURRENT_SITE', '/');define('SITE_ID_CURRENT_SITE', 1);define('BLOG_ID_CURRENT_SITE', 1);While this is the code in my .htaccess:RewriteEngine OnRewriteBase /RewriteRule ^index\\.php$ - [L]# add a trailing slash to /wp-adminRewriteRule ^wp-admin$ wp-admin/ [R=301,L]RewriteCond %{REQUEST_FILENAME} -f [OR]RewriteCond %{REQUEST_FILENAME} -dRewriteRule ^ - [L]RewriteRule ^(wp-(content|admin|includes).*) $1 [L]RewriteRule ^(.*\\.php)$ $1 [L]RewriteRule . index.php [L]When I did this, then I realized that even creating a new site in the network it couldn't be loaded: in fact, when I was going to the site test.website.com, the server didn't responded, giving a Chrome error that now I don't remember: it was something to do with DNS.So I've searched online and I read that I needed to create a WildCard.As how I understood, I needed to create a new DNS record of A type and redirect it to the IP of my website, with the * as subdomain.I did this, but I created a subdomain with cPanel too: I named it *.website.com and its folder was the root of my WebSite, then I did a redirect to my website IP for this subdomain.For some hours anything happened: this is I guess because I had to wait for the DNS change, and in fact, this morning, I saw that test.website.com was loading!But there's a strange thing: if I type a non existing subdomain like wp.website.com, it redirect to my Principal WebSite (the domain in itself) with this on the link:/wp-signup.php?new=wpThe wp after the = is because the subdomain is wp in itself.In the page there appears like a registration module: what I mean is that if I'm not logged in my website, a page like this (that could be asd.website.com or java.website.com and redirects to website.com/wp-signup.php=?new=ads), shows up a registration requiement and if I proceed, it seems like if a new user could register a new subdomain or something like that. Because appears a Username box and a password box, then I can click on Next in the bottom of the page. It feels like a registration form for my network... but it's right that this appears when an user writes an not existent subdomain of my website?Anyway in the very bottom of the page, there comes out (I translate from Italian, so maybe isn't the real english WordPress text): The Website you were looking for, hello.website.com doesn't exists. Oh, I forgot to say: this page comes with the layout of my Wordpress theme, but it's sovrasting it: infact buttons and text box aren't of my WP theme, but of WordPress itself.That's all!What I would know is: it's a normal thing or I messed up with something?And if it's normal, how could I make this not to happen?Thank you anyone will help me!",
    "target": "wordpress;dns;cpanel"
  },
  {
    "id": "_softwareengineering.289480",
    "source": "Django API design <eos> I recently followed the Django API tutorial. http://www.django-rest-framework.org/tutorial/6-viewsets-and-routers/When I initiate a POST request my intent is that after inserting the record into database, launch a process. Example:POST server/Will insert a new server record, return 201 to API client and behind the scenes I want to launch a process that will install and discover the server via some ssh/icmp.Where is the best place to put this code any tutorial or advise?How can I return a 201 and after that execute my discovery process. Is it better to monitor the db for new records and have a different process doing it? @csrf_exemptdef snippet_list(request):        List all code snippets, or create a new snippet.        if request.method == 'GET':        snippets = Snippet.objects.all()        serializer = SnippetSerializer(snippets, many=True)        return JSONResponse(serializer.data)    elif request.method == 'POST':        data = JSONParser().parse(request)        serializer = SnippetSerializer(data=data)        if serializer.is_valid():            serializer.save()            <? is here?>            return JSONResponse(serializer.data, status=201)        return JSONResponse(serializer.errors, status=400)",
    "target": "api design;django"
  },
  {
    "id": "_webmaster.10337",
    "source": "What is user agent Issbot <eos> I am seeing a lot of traffic to my website from user agent Issbot.  This certainly looks like a bot, but is not listed in the www.user-agents.org listing, and I have not been able to find anything useful on Google.  Does anyone know what or who this is?",
    "target": "web crawlers;user agent"
  },
  {
    "id": "_unix.118413",
    "source": "Can Synapse launcher be installed in Debian? <eos> I am thinking of changing from Linux Mint Cinnamon to Linux Mint Debian Cinnamon, but Synapse launcher is something I can't work without. It doesn't seem to be available in Debian.Does anyone know if it is possible to install it and use all the features it offers?",
    "target": "debian;synapse"
  },
  {
    "id": "_codereview.108332",
    "source": "Slicing time spans into calendar months <eos> I have apparently correct code that still runs for weeks on my data (tens of millions of rows). I show the entire code for reference (and maybe other gains to be made), but the key operation is in the loop between lines 66 and 79. Basically, if a spell (spent in hospital) extended over a single calendar month, I wanted to have separate lines counting the number of days spent in hospital for each of those calendar months.I thought things won't be this bad iterating over rows if I allocate space for all the new rows in a single step (the concatenation before the loop) and only reset values row by row in the loop. # -*- coding: utf-8 -*-import numpy as npimport pandas as pdall_treatments = list()filelist = ['slutenvard1997','slutenvard2011','slutenvard2012','slutenvard19982004','slutenvard20052010']tobacco_codes = '|'.join([C{}.format(i) for i in range(30, 40)] + [F17])nutrition_codes = '|'.join([D{}.format(i) for i in range(50, 54)] +  [E{}.format(i) for i in range(10, 15)] + [E{}.format(i) for i in range(40, 47)] +  [E{}.format(i) for i in range(50, 69)])mental_codes = 'F'alcohol_codes = '|'.join([K70] + [F0])circulatory_codes = 'I'dental_codes = '|'.join([K0{}.format(i) for i in range(2, 4)])accident_codes = '|'.join([X{}.format(i) for i in range(10, 60)] + [V] + [X0])selfharm_codes = '|'.join([X{}.format(i) for i in range(60, 85)])cancer_codes = 'C'endonutrimetab_codes = 'E'pregnancy_codes = 'O'other_stress_codes = '|'.join([J{}.format(i) for i in range(11, 48)] + [L{}.format(i) for i in range(20, 66)] + [K{}.format(i) for i in range(20, 60)] + [X{}.format(i) for i in range(86, 99)] + [Z{}.format(i) for i in range(10, 77)] + [R] + [J0] + [Z0])items = {}conds = ['tobacco','nutrition','mental','alcohol','circulatory','dental','accident','selfharm','cancer','endonutrimetab','pregnancy','other_stress']for c in conds:    items[c] = eval(c + '_codes')treatment_summaries = {item: list() for item in items.keys()}for file in filelist:    filename = '/PATH/' + file +'.txt'    treatments = pd.read_table(filename,usecols=[0,8,9,11])    if file == 'slutenvard20052010':        treatments.loc[treatments['INDATUMA']==20060230,'INDATUMA'] = 20060203        treatments.loc[treatments['INDATUMA']==20108024,'INDATUMA'] = 20100824    if file == 'slutenvard19982004':        treatments.loc[treatments['UTDATUMA']==2003071,'UTDATUMA'] = 20030701        treatments.loc[treatments['UTDATUMA']==2003091,'UTDATUMA'] = 20030901                treatments = treatments[(treatments['INDATUMA'] !='.') & (treatments['UTDATUMA'] > 19971231)]        treatments['INDATUMA'] = treatments['INDATUMA'].astype(float)    all_treatments.append(treatments)    del treatmentsall_treatments = pd.concat(all_treatments, ignore_index=True)print Remember datatypes for future use:print all_treatments.dtypesall_treatments['indate'] = pd.to_datetime(all_treatments['INDATUMA'], errors='coerce',format='%Y%m%d')all_treatments['outdate'] = pd.to_datetime(all_treatments['UTDATUMA'], errors='coerce',format='%Y%m%d')# Separating months:all_treatments['monthlyindate'] = all_treatments['indate']all_treatments['monthlyoutdate'] = all_treatments['outdate']micolix     = all_treatments.columns.get_loc('monthlyindate')mocolix     = all_treatments.columns.get_loc('monthlyoutdate')ocolix      = all_treatments.columns.get_loc('outdate')all_treatments['extramonths'] = 12*(all_treatments['outdate'].dt.year-all_treatments['indate'].dt.year)+(all_treatments['outdate'].dt.month-all_treatments['indate'].dt.month)emcolix     = all_treatments.columns.get_loc('extramonths')originalN   = len(all_treatments)newrowcount = int(all_treatments['extramonths'].sum())newN        = int(originalN+newrowcount)all_treatments  = pd.concat([all_treatments,all_treatments.iloc[:newrowcount,:]],ignore_index=True) # this fills the new rows with the wrong data instead of NaNs, but will be overwrittenBOMoffset = pd.tseries.offsets.MonthBegin()newrowix    = originalNfor i in range(0,originalN):    monthstoadd = all_treatments.iloc[i,emcolix].astype('int')    for x in range(0,monthstoadd):        all_treatments.iloc[newrowix,:] = all_treatments.iloc[i,:]        if x==0:            all_treatments.iloc[i,mocolix] = BOMoffset.rollforward(all_treatments.iloc[i,micolix])        all_treatments.iloc[newrowix,micolix] = BOMoffset.rollforward(all_treatments.iloc[i,micolix] + pd.tseries.offsets.DateOffset(months = x))        if x < monthstoadd-1:            all_treatments.iloc[newrowix,mocolix] = BOMoffset.rollforward(all_treatments.iloc[newrowix,micolix]+ pd.tseries.offsets.DateOffset(months = 1))        else:            all_treatments.iloc[newrowix,mocolix] = all_treatments.iloc[newrowix,ocolix]        newrowix += 1all_treatments['monthlyyear'] = all_treatments['monthlyindate'].dt.yearall_treatments['monthlymonth'] = all_treatments['monthlyindate'].dt.monthall_treatments['monthlystay'] = (all_treatments['monthlyoutdate']-all_treatments['monthlyindate']).astype('timedelta64[D]')# Cleaning up:all_treatments = all_treatments.drop(['INDATUMA','indate','UTDATUMA','outdate','extramonths'], axis=1)print Non-missing values across columns (missing will be dropped):print all_treatments.count(axis=0)all_treatments = all_treatments.dropna()treatment_summaries = {name: all_treatments[(all_treatments.DIAGNOS.str.contains('{0}'.format(code)))].groupby(by=['LopNr','monthlyyear','monthlymonth'],as_index=False,sort=False).sum().astype(int, copy=False,raise_on_error=False) for name, code in items.iteritems()}del all_treatments# Finally, save the aggregated results to files.[treatment_summaries[name].to_csv('PATH/inpatient_treatments_monthly_sliced_{0}.csv'.format(name)) for name in items.keys()]I haven't done extensive profiling of where the memory or processing bottlenecks are with the current model.",
    "target": "python;performance;numpy;pandas"
  },
  {
    "id": "_cs.35455",
    "source": "Is order of bits in byte really not of concern? <eos> What I can't wrap my head around is sentence repeated everywhere I look, that order of bits in byte is not important(not of my, as a programmer, concern).My question then is if there is possibility that it makes difference?For example, I crate a binary file with just 0x1 in it (represented on my machine as 00000001). What keeps other machine to read the same byte as 128(10000000) ?Is there standard for msb placement in file, memory that guarantees compability or am I missing something trivial/obvious along?EDIT:Thanks to dirk5959's answer I found out that my machine is little-endian for bytes and the same is for bits in byte. Additional question is, if it is a rule or there is some architecture that behaves different?",
    "target": "computer architecture;memory access"
  },
  {
    "id": "_unix.90898",
    "source": "Summing up an array inside of awk? <eos> I have the following piece of code:sum1=sum2=    declare -a aecho $temp | awk '{split($0,a,,); name=a[1] ; for(i=2;i<=4;i++) sum1+=a[i] ; for(i=5;i<=7;i++) sum2+=a[i] }'This code is not working. Here temp is a string of type:abc,1,2,3,4,5,6I am beginner and need some suggestions. Actually I am parsing data from a file.The input file is like:abc,1,2,3,4,5,6de,3,5,7,8,4,2xyz,6,5,3,7,8,2I am reading it usingwhile  read tempdo #do somethingdone < sample.csvAnd expected output is of the form:Name   Sum1  Sum2abc      6    15de      15    14xyz     14    17 ",
    "target": "bash;shell;shell script;scripting;awk"
  },
  {
    "id": "_reverseengineering.12705",
    "source": "radare2 search first occurrence before <eos> Is it possible to use radare2 to perform a search like the following:first occurence of ldr r1 before address 0x000048b4In the following example it should return:0x000048b2 ldr r1, [pc, 0x20]radare2 is able to guess the value of [pc, 0x20] (511). Would it be possible to retrieve that separately ?",
    "target": "radare2"
  },
  {
    "id": "_cs.60893",
    "source": "Is there a philosophical counterpart question to P != NP? <eos> Gdels motivation to prove his incompleteness theorems was the philosophical statement This sentence is wrong.. Is there a philosophical counterpart to the statement P != NP? For example such statement might be This Theorem is practically unprovable. The consequences of an existence of such theorem would be: If the sentence is true, than there is no practical way to prove it. If it is not true, then there is a practical way to prove it, hence it must be true, which is a contradiction. Since P!=NP is such a deep question, I wonder if philosophist have a counterpart question in the sense given above.",
    "target": "complexity theory;p vs np"
  },
  {
    "id": "_webmaster.24371",
    "source": "Best semantic structure & SEO optimised approach for image replacement for badges? <eos> In the past, I extensively used CSS image replacement techniques for SEO purposes and to separate presentation from content.  But from my reading of the Google Webmaster guidelines and other comments recently, I'm starting to question whether it is better to use <img> with alt attributes in most cases, reserving CSS image replacement for cases where there isn't an alternative.For example, I'm trying to display a 'badge' image showing the ISO9001 certification of a client. Am I right in concluding that the best approach would be to mark up something like...HTML:<div class=accreditationItem>  <h4>ISO9001 Accreditation</h4>  <p>Quality ISO 9001 Certified System</p>  <p>FM 999999</p>  <img alt=Quality ISO 9001 Certification - FM 999999       src=iso9001-badge.jpg/></div>CSS:div.accreditationItem h4, div.accreditationItem p {    display: none;}",
    "target": "seo;google;css;images"
  },
  {
    "id": "_webmaster.7228",
    "source": "How to create / find static targeted ads <eos> I'm not sure how to ask the right question but I noticed on this website, each post has very specific targeted ads that fit the overall theme of the blog post.www.ma-petite-chou.comI'm only familiar with google adsense, in which a text box just displays dynamic ads.I just don't understand how this blog is displaying permanent very specific ads. Any pointers will be helpful.",
    "target": "advertising;static content;ad targeting"
  },
  {
    "id": "_webapps.13037",
    "source": "How to add friends on Ultranet? <eos> My Government Primary school where I am a student, has just given us Ultranet and I was wondering how do I add friends on it so that I can see their blog posts and their wall or just at least see their blog.",
    "target": "blog;friends"
  },
  {
    "id": "_cstheory.27999",
    "source": "$NP$-complete problems on cubic Hamiltonian graphs <eos> The class of cubic Hamiltonian graphs is well studied class. I came across the fact that independent set problem is $NP$-complete when restricting input to cubic Hamiltonian graphs. I am interested in other hard problems on this class.Which $NP$-complete problems on cubic graphs remain hard when restricted to cubic Hamiltonian graphs?A survey of such hard problems would be very nice.MotivationGiven two NP-complete problems on a restricted graph class, I would like to understand the intractability boarderline when we further restrict input instances.UPDATE: I am not interested in decision version of optimization problem such as clique problem (or maximum independent set). However, Dominating Clique problem is the kind of $NP$-complete problem that would interest me if it was hard on cubic Hamiltonian graphs. Dominating clique in graph $G(V,E)$ is a dominating set of $V$ and a clique of $G$. Dominating clique problem is interesting for me because the problem definition does not contain a parameter ( unlike clique or MIS for which we must specify the size of the required solution). ",
    "target": "cc.complexity theory;graph theory"
  },
  {
    "id": "_webmaster.33584",
    "source": "Converting web.config from IIS6 to IIS7 format <eos> I'm a bit stuck, kinda been lumbered with a website developed over a year ago. The company that designed it and the company that own it dont now speak so I have been lumbered with trying to get it to work. Bought the web space and have loaded it on to one of our sub domains while I get it working. Problem is that the Hosting provider is running ISS7 and the web.config was designed in IIS6 so am getting an error500 cause the tags are wrong. Could anyone give me some pointers on how to migrate the current web.config file over to IIS7.",
    "target": "iis7;iis6"
  },
  {
    "id": "_softwareengineering.283046",
    "source": "Parallelising processing of users <eos> Update I updated my question to reflect the fact I'm working with a database.I need to process user actions:The actions for each user change the user's balance which is then persisted to a database.A user's action must be processed sequentially. Otherwise, we might corrupt the balance in the database.Some actions are associated with 2 users in which case they can't run in parallel with either user's actions. The volume of actions per user varies considerably during the day.Update The processes are going to be distributed over several machines. I am trying to find a way to distribute the actions between processes so that the above requirements are met.Is there a known paradigm, architecture or algorithm that solves such a problem?I'm looking for a solution that does not involve processes talking to each other except through a message queue or some other scalable mediator.",
    "target": "distributed computing;parallelism;load balancing"
  },
  {
    "id": "_unix.373771",
    "source": "What is the difference between NSS and PAM? <eos> From my readings, NSS seems to be a superset of PAM. PAM on the other hand are just limited to authentication/authorization. Am I correct ?",
    "target": "authentication;pam"
  },
  {
    "id": "_softwareengineering.131736",
    "source": "How can I convince a team member to use a web framework? <eos> The question is this and the detail follows: is there anything I can say/bring up, as a programmer, to bring him to my side? I'd love to hear valid arguments for both sides on this one, but mostly suggestions for how to talk him around.My situation is this: I'm working on a team project on my degree course, building a mid-sized website as a prototype for the university. All are considered equals in the group and there is no one appointed leader so the answer to this problem can't be pull rank. All are equals, however there is a huge gap in knowledge between members. The team member in question and I are both capable developers, though he holds no industry experience. The other three members are less capable, and two have opted out of development entirely. All three have declined to comment on the situation due to lack of knowledge.As as a group, we are coming to decide on what technologies to use in the implementation of the website; specifically, whether to use a PHP framework (Code Igniter) or not. I am arguing in favour, citing:Not reinventing the wheelWell written and tested code base to work fromGetting going (the deadline is closer than we'd like)Speed of developmentSound and maintainable design patterns and good practicesHe is arguing in favour of working in the way he's used to: Writing bespoke, one-time functions in to a library file as when he needs them Functions for data access and rendering that data the page, getting/setting to and from session and get/post data etcHaving 1 file per page (resulting in no separation of concerns amongst control, presentation and data)His reasons against using are framework are mostly based on him not being able to see the point: he can do all those things already. The framework doesn't change that, it just makes it harder because he has to learn the framework; he doesn't want to use code he hasn't personally written. He has also said that it doesn't matter the quality of the code base, since the project is only a prototype and will never be maintained. For me, that is no excuse to write unmaintainable code.I can see why he makes those arguments, but I hold issue with his lack of concern over maintainability and his disregard for good design, or even separation of concerns. However, I suspect he has never studied design patterns, so I don't know how effective demonstrating why his method could prove unmaintainable would be.I want to get going on this project, but I don't want to do it without regard for everything I've learnt over the years. As I said before, there is no possibility of pulling rank here, nor are other team members willing to pitch in. Should I just back down and do things his way? Is he too stubborn and inexperienced to know better? Or am I being the stubborn one here?TL;DRInexperienced team member is being stubborn, how can I win him over?",
    "target": "professionalism"
  },
  {
    "id": "_unix.5996",
    "source": "Adding kill to a sudoers group <eos> How can I give permissions in sudoers such that each member of a group is able to kill the process owned by another member of the group?Scenario: I have two users -- bill and dev-cron -- who are members of the group tech. I'd like bill to be able to kill processes started by dev-cron.",
    "target": "sudo;kill;group"
  },
  {
    "id": "_unix.293496",
    "source": "Install Linux to SSD or HDD for virtualizing Windows with QEMU? <eos> In my PC I have 1 TB slow HDD and 120 GB fast SSD. I am curious which one of my drives should be used for Ubuntu installation.I plan to use Windows without dual-boot - by virtualizing it with QEMU (IOMMU, VT-d). E.g. I am going to use QEMU virtual HDD files as HDD in guest Windows.I wonder if there is any difference if the virtual HDD file will be on clean SSD, or it will share same drive with Ubuntu installation. Can I improve Windows guest performance by keeping host OS on another HDD than guests's HDD, or it is completely irrelevant for QEMU?",
    "target": "virtual machine;performance;qemu;ssd"
  },
  {
    "id": "_webapps.12813",
    "source": "How to revert a test account to a normal account on Facebook <eos> I want to start developing some Facebook applications and I came across this page that allows me to create a test account.Please do not click the Make [Your Name] Test AccountBecome a Platform App Test AccountI went against my urge to click and decided to google a bit and it seems this option converts your actual Facebook account into a  test account.How can one revert this change ?",
    "target": "facebook"
  },
  {
    "id": "_unix.290175",
    "source": "How to specify memory region for ramdrive <eos> We are setting up a Linux based benchmarking cluster. Each node is going to be a headless, diskless machine, booted via tftp, the OS copied to a local ramdrive, and the same ramdrive is used as local drive by the benchmarked application. My problem is the following: The machines have 2 CPUs, each has its own memory banks and have 4 memory channels to those banks (so the banks are populated with multiples of 4 memory chips to get maximum memory throughput). If I can't control which memory regions are used for the ramdisk, then it may be possible that it will be created in a region that is on one single channel, and uses all memory on that chip. Which means that when my application is running then the threads running on the CPU from whose memory bank the ramdisk was taken would have 25% less memory bandwidth to their local memory than the threads on the other cpu. That would be BAD. Hence the desire to control which memory regions are used by the ramdisk.Or is this a non-issue and I can just trust the memory controller to lay out contiguous memory addresses in a strided fashion among the chips on the 4 channels? That would make sense, since that would maximize the memory bandwidth when pulling in large chunks of memory into cache.I just don't know how these things work and would appreciate some enlightment...",
    "target": "linux;memory;ramdisk"
  },
  {
    "id": "_unix.79798",
    "source": "Need to configure network card manually after each reboot <eos> I am using SUSE Linux Enterprise Server 11 (x86_64) as VM Ware virtual machine (that was cloned). Not sure why but network card cannot be configured via yast2. If I go to edit and hit enter Yast will go back to Control Center. Also in yast2 I can see that the card is not connected. No idea what it means though.But if I go command line and issue these two commands the network is up and running.ifconfig eth1 10.0.0.xxx netmask 255.255.255.0 broadcast 10.0.0.255route add default gw 10.0.0.1 eth1From /var/log/messagesJun 18 14:20:19 Edumate kernel: [  221.986998] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: NoneJun 18 14:20:19 Edumate kernel: [  221.988366] ADDRCONF(NETDEV_UP): eth1: link is not readyJun 18 14:20:19 Edumate kernel: [  221.988482] ADDRCONF(NETDEV_CHANGE): eth1: link becomes readyJun 18 14:20:29 Edumate kernel: [  232.399704] eth1: no IPv6 routers presentQ1: Would anybody know how to fix the network configuration orQ2: What files I update with above two commands so I can have network up and running after each reboot?EDITsremoving /etc/udev/rules.d/70-persistent-net.rules and rebooting didn't helpcontent of /etc/sysconfig/networkEdu:/var/lib/edu/bdrs # cd /etc/sysconfig/networkEdu:/etc/sysconfig/network # lltotal 108-rw-r--r-- 1 root root 13192 Jun  5 16:30 config-rw-rw-rw- 1 root root 13181 Jun  5 15:42 config.backup.by.convert_to_netconfig-rw-r--r-- 1 root root  7482 Jun 18 14:10 dhcp-rw-r--r-- 1 root root  7686 Jun  5 15:42 dhcp.backup.by.convert_to_netconfigdrwxr-xr-x 2 root root  4096 Jun  5 15:42 if-down.ddrwxr-xr-x 2 root root  4096 Jun  5 15:42 if-up.d-rw------- 1 root root   172 Jan 31 23:45 ifcfg-lo-rw-r--r-- 1 root root 29333 Jan 31 23:45 ifcfg.template-rw-r--r-- 1 root root   239 Jan 31 23:45 ifroute-lodrwx------ 2 root root  4096 May  6  2010 providers-rw-r--r-- 1 root root    22 Jun 18 14:07 routes-rw-r--r-- 1 root root     0 Jun 18 14:07 routes.YaST2savedrwxr-xr-x 2 root root  4096 Jun  5 15:42 scripts",
    "target": "virtual machine;init script;suse;networkcard"
  },
  {
    "id": "_unix.332414",
    "source": "How to fix error: symbol lookup error: /usr/local/lib/libQt5DBus.so.5: undefined symbol? <eos> I was using GNS3 network simulator fine for a while & then after few daysWhen I start GNS3 Network Simulator, it is giving out following error, not sure what caused this.$ sudo gns3 GNS3 GUI version 1.5.2Copyright (c) 2007-2016 GNS3 Technologies Inc.your locale en_IN.ISO8859-1 encoding is not UTF-8, switching to the UTF-8 version...2016-12-23 22:57:53 INFO logger.py:107 Log level: INFO/usr/share/gns3/gns3-gui/bin/python: symbol lookup error: /usr/local/lib/libQt5DBus.so.5: undefined symbol: _Z28qEnvironmentVariableIntValuePKcPbI tried reinstalling gns3 but the error persisted.While Un-installing, I got the following warnings:dpkg: warning: while removing gns3-gui, directory '/usr/share/gns3/gns3-gui/lib/python3.4/__pycache__' not empty so not removeddpkg: warning: while removing gns3-gui, directory '/usr/share/gns3/gns3-gui/bin' not empty so not removedRemoving gns3-server (1.5.2~trusty1) ...dpkg: warning: while removing gns3-server, directory '/usr/share/gns3/gns3-server/lib/python3.4/__pycache__' not empty so not removeddpkg: warning: while removing gns3-server, directory '/usr/share/gns3/gns3-server/bin' not empty so not removedSo I removed /usr/share/gns3* and then tried installing GNS3 no luck.Tried the following suggestions made in this answerCommented the line /usr/local/lib in the file /etc/ld.so.conf.d/libc.conf but no use.Also when I tried installing GNS3 through Ubuntu Software Center",
    "target": "ubuntu;python;libraries;python3"
  },
  {
    "id": "_unix.295729",
    "source": "Tar - Transform stdin without extracting <eos> I am attempting to transform the paths of a tar file coming from standard input without having to extract the tar first.This is an apparent duplicate of this question, I am looking for a solution that can be accomplished without having to extract in order to simplify my script, so I do not care if the performance is the same as extracting.Use Case:I am creating a tar from git archive, and piping the result to an ssh process that will run on another machine that does not have the --transform option for tar. I will therefore need to transform before sending it over to ssh. I could always extract to a temporary directory, and then recreate another tar with the transform, but I am looking for a one-line solution to temporarily pop into an existing script.",
    "target": "tar;git"
  },
  {
    "id": "_softwareengineering.138683",
    "source": "DCVS and Bug Database <eos> I am considering implementing the following policy and would like to run it by the community before implementing it:All mercurial commits must have a bug id corresponding to our bug reporting database.All commits immediately preceding a push for a new feature must have a bug id (it's a new feature but the id is still a bug id in the database)This will do several things. First, it will ensure that an entry is always put into the bug database for all code changes. Second, it will provide a diff of each change made for each bug fix. This would also simplify commenting in the mercurial commits and put most details about the commit into the bug report.Do you know of any reasons why this would be a bad idea? Also, do you think I should make some additions to this policy?",
    "target": "project management;version control;issue tracking"
  },
  {
    "id": "_reverseengineering.14721",
    "source": "Parseable Windows API documentation <eos> For a project I'm in need of a parseable version of the Windows API (i.e. the functions described in msdn).I tried to crawl it myself, but there seem to be more than 5 formats for signatures and parameters used. The MsdnApiExtractor project does not seem to work anymore.I've seen some projects using help files, but I can't seem anything to parse .hlp files. Sadly, using the header files is no alternative, since it lacks argument names.I'm mainly interested in the High-Level API (e.g. ReadFile, CloseHandle etc.)edit:Seems I've been looking at the wrong header files",
    "target": "windows;api;documentation"
  },
  {
    "id": "_softwareengineering.201156",
    "source": "In general, is it ethical to make a copy of work source code and take it home as reference? <eos> Is it ethical to make a copy of my work's source code, for the sole purpose of my own reference? By reference, I mean as reference where I can refer to it about how I (and my teammates) implemented various design patterns, architecture, etc. It does not contain any trade secret, product, secret algorithm or anything like that.Note that I wrote many parts of the source code, and also the added value from me studying the code will also indirectly benefit the company I am working on.",
    "target": "copyright;source code;ethics"
  },
  {
    "id": "_codereview.145221",
    "source": "Disproving Euler proposition by brute force in C <eos> I wrote a little bit of code to brute force disprove the Euler proposition that states:$$a^4 + b^4 + c^4 = d^4$$has no solution when \\$a\\$, \\$b\\$, \\$c\\$, \\$d\\$ are positive integers.I'm no mathematician, but reading around this, at least one solution was found by Noam Elkies in 1987 (a = 95800; b = 217519; c = 414560; d = 422481). I wanted to get an idea of how much firepower it would take to solve by brute force, so I wrote the following in C:#include <stdio.h>#include <time.h>#include <math.h>int prop(long int A, long int B, long int C, long int D) {    return (pow(A, 4) + pow(B, 4) + pow(C, 4) == pow(D, 4));}int main() {    long int a, b, c, d;    clock_t t;    t = clock();    for (a = 1; a < 100000; a++) {        for (b = 1; b < 300000; b++) {            for (c = 1; c < 500000; c++) {                for (d = 1; d < 500000; d++) {                    if (prop(a, b, c, d))                        printf(FOUND IT!\\na = %ld\\nb = %ld\\nc = %ld\\nd = %ld\\n, a, b, c, d);                }                if (!(c%1000))                    printf(a = %ld, b = %ld, c = %ld, time = %fs\\n, a, b, c, ((double)(clock() - t))/CLOCKS_PER_SEC);            }            printf(a = %ld, b = %ld, time = %fs\\n, a, b, ((double)(clock() - t))/CLOCKS_PER_SEC);        }        printf(a = %ld, time = %fs\\n, a, ((double)(clock() - t))/CLOCKS_PER_SEC);    }}I ran it for a while, and worked out that it would take roughly \\$85 \\times 10^6\\$ years for it to get to the answer above on my current machine.I mean, maybe if I waited a few thousand years, I'd have a slightly better machine, but my question is (and I am new to C and computer science in general - so please be gentle); what strategies could I take to make the above code run faster? I thought about threading, and using some sort of bit shifting in place of the pow() calls.Would there be any way (on my current machine) to get this to run in my lifetime?",
    "target": "beginner;c;multithreading;time limit exceeded;mathematics"
  },
  {
    "id": "_unix.318898",
    "source": "How to list users without a strong password? <eos> I would like to list the username of the users which do not have a strong password in a LAN.How can I do it?I do not want to force the password of the users, I want to force the users that have no password or not strong one to change it and use a stronger one.",
    "target": "linux;security;password"
  },
  {
    "id": "_unix.254219",
    "source": "Alsa capturing mono microphone as right channel of stereo <eos> The laptop microphone is mono but audio seems to get captured as stereo.The resulting recording has the sounds captured by the mic in the right channel and for some reason whatever sound is currently playing (speaker or headphones) is recorded as the left channel.Telling arecord to use one channel doesn't seem to have any effectarecord -c 1 -d 3 -f dat foo.wavAnd setting audacity to capture mono instead of stereo results in nothing getting recorded.What could be causing this and how do I get capture to work properly?amixer output: http://pastebin.com/0r09Ln1E",
    "target": "alsa;recording"
  },
  {
    "id": "_softwareengineering.287800",
    "source": "Why can't I use an operator like plus sign to concatenate strings? <eos> Why in Objective-C we should be typing explicit references to methods like stringByAppendingString to concatenate strings, when in some other languages we can use operators for that?For example, Java and C++ let us just concatenate strings in a similar fashion to the way we make our programs add two numbers.",
    "target": "language design;history;objective c;strings"
  },
  {
    "id": "_webmaster.88452",
    "source": "Will using Google's PageSpeed module help to speed up a site with Magento? <eos> I'm considering installing Google's PageSpeed module on a Debian Linux / Apache 2.4 web server to speed up a Magento CE website. Will using Google's PageSpeed module help to speed up a website using Magento?",
    "target": "apache2;performance;magento;google pagespeed;debian"
  },
  {
    "id": "_webmaster.93724",
    "source": "Two sitemap.xml with wordpress in subfolder <eos> I have a site at example.com which also hosts a wordpress blog at example.com/blog/I am generating a sitemap.xml at my main site which also includes urls from my wordpress blog.  What is the proper way to do this?  Should I let wordpress generate its own sitemap.xml under /blog/ and only include urls from my main website in the root sitemap.xml?Is it hurting anything if they both exist?",
    "target": "seo;sitemap"
  },
  {
    "id": "_unix.162293",
    "source": "Use Bash for Irssi <eos> Alright I am writing a shell script to open Irssi and then automatically connect to freenode. Should I edit the file at ~/.irssi/config or is there a way to simulate me typing /connect irc.freenode.net? I have used echo, send, and expect but it hasn't worked. Here is the code I have so far.irssiecho /connect irc.freenode.net",
    "target": "bash;irssi"
  },
  {
    "id": "_unix.372997",
    "source": "ddrescue - avoiding sectors that shut the controller down <eos> I have a problem with my SSD drive  it would appear that the controller started acting up. What happens is that if requested to read specific sectors, it will completely shut down the access to disk. At this point not even restarting or ACPI power off helps  I actually need to physically unplug and plug the cord back to make it work again.I naturally want to rescue as much as possible, but its extremely time consuming with ddrescue, given the way it works. I played with i option, trying to force it to skip specific areas of the disk, but either I do not fully understand the way it works, or the tool ignores the option most of the times. Mind that I do understand that i by design may be ignored depending on the direction ddrescue attempts to read sectors from, yet many times it was ignored despite the right order of reading - e.g. in case my i byte was X+1000 but ddrescue upon starting still attempted to read byte X in forward direction.My question here is whether there is a way to mark some byte untouchable, so that ddrescue avoids reading it altogether - possibly by manually editing the log file? If not, do you have any other tips on how to recover the data efficiently?EDIT: just found Mapfile (logfile) documentation and based on what I see there, it should be fairly easy to prepare it to make ddrescue do what I want it to.",
    "target": "ssd;ddrescue"
  },
  {
    "id": "_softwareengineering.120477",
    "source": "What Part of Your Project Should be in Source Code Control? <eos> A fellow developer has started work on a new Drupal project, and the sysadmin has suggested that they should only put the sites/default subdirectory in source control, because it will make updates easily scriptable.  Setting aside that somewhat dubious claim, it raises another question -- what files should be under source control?  And is there a situation where some large chunk of files should be excluded?My opinion is that the entire tree for the project should be under control, and this would be true for a Drupal project, rails, or anything else. This seems like a no-brainer -- you clearly need versioning for your framework as much as you do for any custom code you write.That said, I would love to get other opinions on this.  Are there any arguments for not having everything under control?",
    "target": "version control;drupal"
  },
  {
    "id": "_cs.42467",
    "source": "Running the Double Tree Heuristic in a given graph - some slight confusion <eos> I'm working on an exam question that asks me to run the Double-Tree Heuristic algorithm on the following graph:This algorithm starts by finding a minimum cost spanning tree. My solution: Minimum spanning tree contains edges ec, cb, dc, daDoubling these edges to find an Euler tour: a, d, c, b, c, e, c, d, aRemoving duplicate edges: a, d, c, b, e, aActual solution:Minimum spanning tree contains edges ed, ec, cb, daDoubling these edges to find the Euler tour: a d e c b c e d aRemoving duplicate edges: a d e c b a (cost: 51)I want to know if I have used the algorithm correctly. Can there be more than 1 specific solution to this problem?  ",
    "target": "graphs"
  },
  {
    "id": "_softwareengineering.286788",
    "source": "What is faster? Using REST API or querying a database directly? <eos> What is faster performance wise? Creating a REST API and having your web app use the REST API to do all interactions with your database OR querying your database directly (i.e. using whatever typical object your language uses to query a database such as JDBC for Java)?The way I see it with REST:You make an object in your code to call the REST methodCall http methodCode inside your REST API queries the databaseDatabase returns some data REST API code packs up the data into Json and sends it to your clientClient receives Json/XML response Map response to an object in your codeOn the other hand, querying a database directly:You make an object with query string to query the databaseDatabase returns some dataMap response to an object in your codeSo wouldn't this mean that using a REST API would be slower? Maybe it depends on the type of database (SQL vs NoSQL)?",
    "target": "database;rest;sql"
  },
  {
    "id": "_softwareengineering.132977",
    "source": "How-to convince company to start documenting for legacy software <eos> It has been less than a year since I joined my current company. Their majority of sales have come from a single product that has been alive since the last 10 years. However, there is minimal (if at all) documentation. Not only do the developers in the company struggle with the lack of documentation but also there is a high amount of turnover, causing everyone to lose their time. This is because experienced developers have left the company and there is less and less resources to communicate/brain storm with.Without getting into too much detail, I have suggested to the previous manager that there needs to be some sort of documentation (at least an Architecture document) that outlines the product. I also suggested using JavaDoc and other automatic documentation tools. These suggestions were responded to by slight smiles and statements of the sort We do not have enough time, We need short-term improvements right now and even The code itself should be the documentation from the programmers themselves.I have already wasted enough time trying to find out if what I needed per requirement/bug had existed in this big (really) code base. I am looking for any suggestions that you might give regarding the need of documentation. Or, rather, if this is a lost case for this legacy system or organization.",
    "target": "documentation;source code;legacy;documentation generation"
  },
  {
    "id": "_softwareengineering.121640",
    "source": "How to develop complex applications <eos> I want to know the approach in developing big complex application regardless of which programming language to use. I want to know how developers make such big applications such as internet banking, API's and big database management application. How should one approach to make  such applications. I have only 1 year programming experience so far and I work as a freelancer so when I saw such applications lots of questions came in my mind. How to understand the basic need of information technology. What actually it is? How it can be useful for common people of small towns. I want everyone to make use of technology no matter they are educated or not, rich or not. Please post some suggestions.",
    "target": "programming languages;database"
  },
  {
    "id": "_webmaster.106549",
    "source": "Meta description showing other content other than specified in meta tag when inspected <eos> Please see the link as given.https://bhetincha.com/gurkha-technologiesWhen searched for in google the meta description is different.But when i view page source it the meta description is different.Why is google not showing the coded meta description ?",
    "target": "seo;local seo;meta description"
  },
  {
    "id": "_codereview.36563",
    "source": "Is this a good structure for my website? <eos> I have been building a site using php and would like advice to improve the structure of my site and the best way to lay out my code for SEO. I'm also a little concerned about echoing large chunks of HTML and how SEO will work with my structure.Ok here's my structure...My site contains many pages with only the body content changing for each page. So I have created template functions in PHP for echoing HTML. I use $_GET['page_id'] in a switch statement to determine what page content to load. .my pages look something like this....Header();                            //echo header HTML switch ($_GET['page_id'])            //Echo body content {   default: homePage(); break;   case 1:  servicesPage(); break;   case 2:  galleryPage(); break;   case 3:  contactPage(); break;  } Footer();                           //Echo footer HTMLAnd my php functions look like this function header() {      echo <div>             <h1>Header</h1>            </div>; } function footer() {      echo <div>             <h1>Header</h1>            </div>;} function homePage()  {    echo <div>            <h1> Home </h1>           <ul>             <li> Home1 </li>            <li> Home1 </li>           </ul>           <p>This is home page</p>          </div>; }I'm really looking for any pointers to improve my code but my main concerns are...Is it ok to echo large chucks of HTML like that from php? especially with my site growing?Does Google crawler bot still crawl my site ok using $_GET['page_id'] for all my pages?P.S I'm new here, so sorry if any code formatting is a little off!",
    "target": "php;html"
  },
  {
    "id": "_scicomp.5240",
    "source": "FFT - function only in sine series? Can be done with MKL / Lapack? <eos> please can I ask, how one can make from function sine series (Fourier transform) with MKL? I can do normal exponential FFT with MKL (Lapack of course), how can I say that I want only sine series?Many thanks",
    "target": "lapack;fftw"
  },
  {
    "id": "_computergraphics.4593",
    "source": "How to get the GLFW_CONTEXT_VERSION_MAJOR value? <eos> This code snippet:GLint versionMajor;glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 2);glGetIntegerv(GLFW_CONTEXT_VERSION_MAJOR, &versionMajor);std::cout << Version major: << version << std::endl;prints 3 in my screen, but in the first line I set the the GLFW_CONTEXT_VERSION_MAJOR to 2. How I can get back that value?",
    "target": "opengl;c++"
  },
  {
    "id": "_datascience.13601",
    "source": "Pandas Data Frame: Calculating custom moving average <eos> I have a time series containing stock price data.I would like to calculate the Money Flow Index (MFI) for each row.Given that the MFI, uses the previous approx. 14 rows to calculate the current MFI, what would be the best approach to doing this?The below calculates the current MFI (http://www.investopedia.com/terms/m/mfi.asp) for a given DataFrame, but I would like to implement this for each row in the data frame# Typical Price =(high price + low price + closing price) / 3tp=(hst['High']+hst['Low']+hst['Close'])/3    tp=tp.to_frame(name='Price')# Raw money flow = typical price x volumetp['Raw']=tp['Price'] * hst['Volume']# Identify flow (upwards or downwards)tp['Direction'] = np.where(np.nan_to_num(tp['Raw'].shift(1))>tp['Raw'], 'up', 'down')mfr=0# Money flow ratio = (14-day Positive Money Flow) / (14-day Negative Money Flow)if tp.loc[tp['Direction']=='down']['Price'].sum(axis=0) != 0:    mfr=tp.loc[tp['Direction']=='up']['Price'].sum(axis=0) / tp.loc[tp['Direction']=='down']['Price'].sum(axis=0)# MFI = 100 - 100 / (1 + money flow ratio)100-(100/(1+ mfr))I managed to work this using the 'apply' function, but this function only allows for 1 argument, whilst I would need to pass more than 1 argument to compute the above.",
    "target": "python;time series;pandas"
  },
  {
    "id": "_codereview.32901",
    "source": "Displaying the calenday day <eos> I have this (working) code:class CalendarDay  attr_accessor :from_month, :to_month, :year  def self.line_of_day_numbers(month,year,start,offset)    @line=''    @offset=offset    finish = (start+6)-@offset    self.first_line_padding(start)    start-= @offset    self.day_numbers(month,year,start,finish)  end   private  def self.first_line_padding(start)    if start < 7       @line=' ' * (@offset * 3)      @offset=0    end   end   ...But the methods are tangled and there's a mix of instance and local variables.Tests include:it shows the day numbers do  expect(CalendarDay.line_of_day_numbers(2,2000,1,2)).to eq '       1  2  3  4  5'endit shows the day numbers do  expect(CalendarDay.line_of_day_numbers(10,2000,1,0)).to eq ' 1  2  3  4  5  6  7'endit shows the day numbers do  expect(CalendarDay.line_of_day_numbers(1,2000,8,6)).to eq ' 2  3  4  5  6  7  8'end",
    "target": "ruby;datetime;rspec"
  },
  {
    "id": "_webapps.90075",
    "source": "Any way to send Gmail auto-response at certain times every week? <eos> I have a Gmail account that it is only monitored Monday through Thursday.  I would like to set something up to automatically send a canned reply for emails received between Thursday afternoon and Monday morning informing the sender that the email will not be seen until Monday morning, and giving emergency contact information.  I don't think this can be done directly in Gmail right now.  (Vacation replies need to be manually turned on and off, and filters for canned email do not include any date/time options.) Can I set Gmail out of office replies for every week recurring? also suggests that this is was possible in Gmail, at least at the time of that question. Is there any work-around or way to do some simple coding to accomplish this?  I have a software development background, but I'm not aware of what (if any) options are available to the general public to extend Gmail.",
    "target": "gmail;automation"
  },
  {
    "id": "_unix.56175",
    "source": "Implement Java/JavaFX on ARM <eos> I am working on ARM Linux.I have found this link that says that JavaFX could work on ARM.I am confused about Embedded Java SE and JavaFx ARM. Do I need to setup a JVM for those or not?I have compiled my own kernel and built a functional root file system with busybox, glibc library and ARM cross compiler toolchains.Should I need to implement a JVM to get the J2SE and JavaFX platform?I just want to build a small Java based OS especially using JavaFX. I have the glibc-2.9 library to run the framework as said by the requirement to run Embedded J2SE. But there is no tutorial about how to install or set it up to work. Can anyone help me?",
    "target": "linux;java;embedded;arm"
  },
  {
    "id": "_codereview.154515",
    "source": "Multiple enumerations of IEnumerable <eos> I have a snippet of code here that uses C# and Linq. The ganttData variable I have has 12 warnings stating:possible multiple enumerations of IENumerableShould I change it to a List or leave it the way it is?private IEnumerable<ProductLineDto> FilterAtHighestLevel(IEnumerable<ProductLineDto> ganttData, GanttFilterDto ganttFilterDataModel)        {            if (ganttFilterDataModel.ProjectId == null)                return ganttData;            //Check if it's a productLine, project, or subproject that was selected from the project filter            ProductLine productLine = UnitOfWork.ProductLineRepository.GetAll().SingleOrDefault(x => x.ProductLineID == ganttFilterDataModel.ProjectId.Value);            Project project = UnitOfWork.ProjectRepository.GetAll().SingleOrDefault(x => x.ProjectID == ganttFilterDataModel.ProjectId.Value);            SubProject subProject = UnitOfWork.SubProjectRepository.GetAll().SingleOrDefault(x => x.SubProjectID == ganttFilterDataModel.ProjectId.Value);            if (productLine != null)                ganttData = GetProuctLinesFromDto(ganttData, ganttFilterDataModel.ProjectId.Value);            else if (project != null)            {                ganttData = GetProuctLinesFromDto(ganttData, project.ProductLineID);                //its always the first one                ganttData.ElementAt(0).Projects = ganttData.ElementAt(0).Projects.Where(x => x.ProjectId == ganttFilterDataModel.ProjectId.Value);            }            else if (subProject != null)            {                ganttData = GetProuctLinesFromDto(ganttData, subProject.Project.ProductLineID);                /// Don't just filter for the subproject get the project and show the entire project tree                /// What's the point of this filter then?                var rootProject = SubProjectService.EntityRepo.GetAll().FirstOrDefault(x => x.SubProjectID == ganttFilterDataModel.ProjectId.Value);                ganttData.ElementAt(0).Projects = ganttData.ElementAt(0).Projects = ganttData.ElementAt(0).Projects.Where(x => x.ProjectId == rootProject.ProjectID);            }            return ganttData;        }        private IEnumerable<ProductLineDto> GetProuctLinesFromDto(IEnumerable<ProductLineDto> ganttData, Guid id)        {            return ganttData.Where(x => x.ProductLineId == id);        }",
    "target": "c#;linq"
  },
  {
    "id": "_unix.245425",
    "source": "Script for backup each DB on server but omit system databases <eos> I have read a lot of post around this topic but I didn't found the one to fit my needs. So, basically I want to make two backups: one at mid day (12 PM) and the other at midnight (12 AM) for each database on a MySQL server but I want to leave out system databases: mysql and information_schema (as far as I know is there is another one please let me know). After read a lot of topics I come with this bash script:#!/bin/shnow=$(date +'%d_%m_%Y_%H_%M_%S')filename=db_backup_$now.gzbackupfolder=/home/backupsfullpathbackupfile=$backupfolder/$filenamelogfile=$backupfolder/backup_log_$(date +'%Y_%m').txtecho mysqldump started at $(date +'%d-%m-%Y %H:%M:%S') >> $logfilemysqldump --user=userbackup --password=***** --default-character-set=utf8 database | gzip > $fullpathbackupfileecho mysqldump finished at $(date +'%d-%m-%Y %H:%M:%S') >> $logfilefind $backupfolder -name db_backup_* -mtime +7 -exec rm {} \\;echo old files deleted >> $logfileecho operation finished at $(date +'%d-%m-%Y %H:%M:%S') >> $logfileecho ***************** >> $logfileexit 0This script made a backup for database database and keep 7 last .tar.gz files. Can any help me to improve this script so I can backup each database other than system ones and keep 7 last copies for each?",
    "target": "bash;shell script;scripting;cron;backup"
  },
  {
    "id": "_cstheory.11735",
    "source": "Algorithm to find a polyhedral embedding <eos> A polyhedral embedding of a graph on a surface is an embedding without edge crossings such that all the faces are bounded by simple cycles, and any two faces share a common vertex, share a common edge, or do not intersect at all.I need an algorithm that, given a graph, finds a polyhedral embedding if the graph admits it. I have been looking around but haven't found it. I also need to know the time order of the algorithm.Deciding whether a graph admits a polyhedral embedding is NP-complete (proved here: B. Mohar, Existence of polyhedral embeddings of graphs, Combinatorica 21 (2001), 395401, http://www.fmf.uni-lj.si/~mohar/Papers/Fw3npc.pdf). I don't expect an efficient algorithm, just something that works.Note: I should mention that I am only interested in the combinatorial aspect of this problem. An embedding of a graph can be described by specifying the cyclic orderings of the edges incident on any vertex, and a signature for each edge, which is +1 or -1 according to whether the cyclic orderings of the two vertices on this edge are consistent along this edge. A face-walk is a walk in the graph where at all vertices the next edge is the leftmost edge according to the cyclic ordering on the vertex. A polyhedral embedding is an embedding where all the face-walks are simple cycles. The problem is then to find a circular ordering of edges around each edge and a signature for each edge such that all face-walks are simple cycles.",
    "target": "ds.algorithms;reference request;co.combinatorics;topological graph theory"
  },
  {
    "id": "_opensource.2274",
    "source": "How can I prevent abandoning a project due to a lack of time? <eos> I have a somewhat popular open source project. It's used by enough people to get a good number of bug reports and some pull requests per month, but not popular enough to have a development team or steady project managers or contributors.Due to a lack of time, I haven't had the time to properly maintain the project. Even though I currently have some spare time that I can spend on the project, the time that's needed to get the project up to quality looks beyond my reach.How do I salvage this project, instead of it coming abandoned?Edit: I'm looking for a specific solution, preferably someone who has experienced the same issue and managed to overcome it. Answers like 'Trying asking for help' without more detail are not useful.",
    "target": "project management"
  },
  {
    "id": "_vi.10357",
    "source": "Uncomment multiple lines <eos> In vim I can use for instance 10j to go 10 lines down. And I can use . to repeat the last deletion.Now, in bash script I have many commented lines like this:# ...# ...# ...# ...# ...# ...# ...# ...# ...etc...Say, there are 52 such lines. Is there a way to combine moving 52j and repeating the deletion of the # via x and delete 52 lines at once?",
    "target": "normal mode;comments"
  },
  {
    "id": "_codereview.123564",
    "source": "Simple maze game with four rooms <eos> I'm starting to learn Lua and in one part of the book I need to convert a Maze Game that uses goto to another one that doesn't use goto.The maze is the simplest ever made, starting from room #1:---------| 1 | 2 |---------| 3 | 4 |---------This is the original version using goto from the book:goto room1 -- initial room::room1:: do  local move = io.read()  if move == south then goto room3  elseif move == east then goto room2  else    print(invalid move)    goto room1 -- stay in the same room  endend::room2:: do  local move = io.read()  if move == south then goto room4  elseif move == west then goto room1  else    print(invalid move)    goto room2  endend::room3:: do  local move = io.read()  if move == north then goto room1  elseif move == east then goto room4  else    print(invalid move)    goto room3  endend::room4:: do  print(Congratulations, you won!)endAnd this is my attempt:local rooms = {}rooms[1] = {  south=3,  east=2}rooms[2] = {  south=4,  west=1}rooms[3] = {  north=1,  east=4}currentRoom = 1repeat  local move = io.read()  local room = rooms[currentRoom][move]  if room == nil then    room = currentRoom    print(Invalid move)  elseif room == 4 then    print(Congratulations, you won!)  end  currentRoom = room or currentRoomuntil currentRoom == 4 The above code is working but I was wondering if there is something I need to change to improve it somehow.",
    "target": "lua;adventure game"
  },
  {
    "id": "_cstheory.2391",
    "source": "The Warren Buffett Problem <eos> Here is an abstraction of an online learning / bandit problem that I've been working on in the summer. I haven't seen a problem like this before, and it looks quite interesting. If you know of any related work, I would appreciate references. The ProblemThe setting is that of multi-armed bandits. You have N arms. Each arm i has an unknown but fixed probability distribution over rewards that can be earned by playing it. For concreteness, let's assume that each arm i pays reward $10 with probability p[i] and reward $0 with prob. 1-p[i]. In every round t you select a set S[t] of arms to play. For each arm you select, you pay a fee of $1 up front. For each selected arm, you collect a reward that is drawn from the (unknown) reward probability distribution of that arm. All rewards are credited to your bank account, and all fees are deducted from that account. In addition, you get a credit of $1 at the beginning of every iteration. The problem is to develop a policy to select a subset of arms to play in each iteration to maximize profit (i.e. rewards minus fees for playing) over a long enough horizon, subject to the constraint that it must maintain a non-negative account balance at all times.I did not specify whether the per-arm reward distributions are chosen from a prior distribution or chosen by an adversary. Both choices make sense. The adversary formulation is more appealing to me, but probably harder to make progress on. Here, the adversary chooses a vector (D1, D2, .., DN) of distributions. Given the distributions, the optimal budget balanced policy is to play all arms whose expected reward is greater than $1. Let P be the per-step profit of this optimal omniscient policy. I want my online policy to minimize regret (i.e. loss of profit over a time window T) wrt this omniscient policy.",
    "target": "machine learning;lg.learning;online learning"
  },
  {
    "id": "_codereview.98536",
    "source": "Extracting the last component (basename) of a filesystem path <eos> fn basename<'a>(path: &'a str, sep: char) -> Cow<'a, str> {    let pieces = path.split(sep);    match pieces.last() {        Some(p) => p.into(),        None => path.into(),    }}Usage:println!('{}', basename(foo, '/'));    // outputs 'foo'println!('{}', basename(bob/, '/'));   // outputs ''println!('{}', basename(/usr/local/bin/rustc, '/')); // outputs 'rustc'I think the split() into a match on last() is kind of elegant.I know there is some work needed to handle both str and String, I am not sold on the use of Cow and needing to define a lifetime for the string.I am not sold on Cow because later on I need to extract from it.let prog = basename(&args[0], '/').into_owned();It feels like I am working too hard.",
    "target": "strings;memory management;url;rust"
  },
  {
    "id": "_codereview.112526",
    "source": "A function for block allocation <eos> During Jonathan Blow's video where he muses about a games-focused programming language, he presents C++ code that allocates a single big block of memory and has N pointers into that block. The purpose being to avoid heap allocating N blocks of memory for N arrays.That code looked to me like it could use some genericity... so I first came up with the following where we would allocate three arrays into a single block of memory:using memory_block = std::unique_ptr<char[]>;template<typename A, typename B, typename C>memory_block block_allocate(A*& p, size_t a, B*& q, size_t b, C*& r, size_t c){    memory_block z = std::make_unique<char[]>(a * sizeof(A) + b * sizeof(B) + c * sizeof(C));    p = reinterpret_cast<A*>(z.get());    q = reinterpret_cast<B*>(p + a);    r = reinterpret_cast<C*>(q + c);    return z;}Improving for any number of arrays gives us:using memory_block = std::unique_ptr<char[]>;namespace detail{    template<typename T>    size_t block_size(T* const, size_t const n)    {        return sizeof(T) * n;    }    template<typename T, typename U, typename... Args>    size_t block_size(T* const t, size_t const m, U* const u, size_t const n, Args&&... args)    {        return block_size(t, m) + block_size(u, n, args...);    }    template<typename T, typename U>    void block_assign(T* const p, size_t const offset, U*& u, size_t const)    {        u = reinterpret_cast<U*>(p + offset);    }    template<typename T, typename U, typename... Args>    void block_assign(T* const p, size_t const offset, U*& u, size_t const n, Args&&... args)    {        block_assign(p, offset, u, n);        block_assign(u, n, args...);    }}template<typename T, typename... Args>memory_block block_allocate(T*& t, size_t const n, Args&&... args){    memory_block b = std::make_unique<char[]>(detail::block_size(t, n, args...));    detail::block_assign(b.get(), 0, t, n, args...);    return b;}It's understood that Jonathan's Blow's desire is for a language solution to this problem and not the library solution that I present but I had fun coming up with it nonetheless.So, after simple testing the code appears to behave as expected but do you see something missing that would make production-ready?",
    "target": "c++;memory management"
  },
  {
    "id": "_codereview.80353",
    "source": "Optimization of sieve of Erathosthenes <eos> #include <iostream>    #include <conio.h>    #include <windows.h>    #include <math.h>    using namespace std;    #define RUNS 1000    char z[100000];    int i,j,k,c;    void main(void)      {      DWORD starttime,endtime;      float totaltime;      starttime = GetTickCount();//get start time      for(k=0;k<RUNS;k++)      {          c=0;       //for (i=0;i<10000;i++) z[i]=0; //clear array      memset(z,0,100000);        z[0]=1; // 0 is not a prime        z[1]=1;  // 1 is not a prime            //now remove all evens from 4 up            for(i=4;i<100000;i=i+2) z[i]=1; //remove evens            //now loop through remaing up to square root of max number            for(i=3;i<316;i=i+2)            {            if(z[i]==0) for(j=2*i;j<100000;j=j+i) z[j]=1;            }      }      endtime=GetTickCount();//get finish time      //calc time      for(i=0;i<100000;i++)      {      if(z[i]==0) {cout<<i<< ;c++;}      }      cout<<primes found=<<c<<endl;      totaltime=((float)endtime-(float)starttime)/(1000.0*RUNS);//calculate total time in secs      cout<<Totaltime=<<totaltime<< sec\\n;      printf(Press any key to end);      getch();      }I'm trying to find any optimization for my sieve of Eratosthenes code for counting first 100000 prime numbers.The program first mark all even numbers, than square root of max number.The program already does take fraction of the seconds to count these prime numbers, but I`m looking for any optimization to make it even quicker.",
    "target": "c++;optimization;primes;sieve of eratosthenes"
  },
  {
    "id": "_unix.120602",
    "source": "Bash tab completion stop searching <eos> When I am typing into bash and I press the tab key to auto complete, sometimes it takes a significant time. E.g., file IO to read directories takes >5 seconds, and thus I am hung waiting for IO to complete before I can continue typing. I get frustrated and Ctrl-C so that I can redo what I was typing.Ctrl-C is unfortunate, since I must retype everything again. How can I tell bash to stop trying to fulfill my auto complete request.$ /long/path/to/some/d     # once I've typed this, I press <TAB>. I now will be                           # stuck waiting for perhaps 10 seconds. The only thing I                           # know to do is Ctrl-C. When I press Ctrl-C, I am forced                           # to retype the original command string.$",
    "target": "bash;autocomplete"
  },
  {
    "id": "_unix.12193",
    "source": "Transcoding MJPEG Stream to FLV or MP4 <eos> I want to transcode MJPEG stream that comes from IP camera (http://xx.yy.zz.tt:8080/video.cgi) to FLV or MP4 stream under Linux OS so that users can play the file using a web based Flash player such as Flowplayer.I discovered VLC for that purpose but I cannot figure out the exact command line string. I also need HTTP authentication feature since IP camera access is password protected.I also interested in any non-VLC solution if any (ffmpeg?).",
    "target": "video;ffmpeg;vlc;conversion"
  },
  {
    "id": "_webmaster.87386",
    "source": "Bing gives NET::ERR_CERT_COMMON_NAME_INVALID on my website <eos> I have added my site https://greymeter.com on Bing Webmaster. But when I search greymeter on bing.com, it gives https://www.greymeter.com as the result, and navigating to it, gives a crossed https with error NET::ERR_CERT_COMMON_NAME_INVALID, and this message is displayed:Your connection is not privateAttackers might be trying to steal your information from www.greymeter.com (for example, passwords, messages, or credit cards). NET::ERR_CERT_COMMON_NAME_INVALIDIt works perfectly with google.com though. Can you please give me any idea, what I am missing, or what needs to be done here?",
    "target": "https;security certificate;bing"
  },
  {
    "id": "_unix.21335",
    "source": "How do I cause a watchdog reset of my embedded Linux device <eos> Is there a command likevi > outvi | outThat I could use to cause a watchdog reset of my embedded linux device?",
    "target": "linux;bash;kernel;embedded;watchdog"
  },
  {
    "id": "_unix.150125",
    "source": "Samba prompts for a password twice <eos> I have a relatively new samba install configured to give Windows users access to some log files on a syslog server (littleEngineer). However it's prompting for a password to just get a share listing by accessing \\\\littleEngineer\\, is there a way to disable this behavior so that it will only prompt for a password if the user tries to access a secured share?This is my testparm output:root@littleEngineer /var/log/samba $ testparmLoad smb config files from /etc/samba/smb.confrlimit_max: increasing rlimit_max (1024) to minimum Windows limit (16384)WARNING: The idmap uid option is deprecatedWARNING: The idmap gid option is deprecatedProcessing section [aviationLogs]WARNING: The security=share option is deprecatedLoaded services file OK.Server role: ROLE_STANDALONEPress enter to see a dump of your service definitions[global]        workgroup = BIZCO        realm = BIZCO.COM        server string = Samba Server Version %v        security = SHARE        password server = BIZCO.COM        log file = /var/log/samba/log.%m        max log size = 50        utmp = Yes        template shell = /bin/bash        winbind use default domain = Yes        idmap config * : range = 16777216-33554431        idmap config * : backend = tdb        cups options = raw[aviationLogs]        comment = Apache httpd Log Files (Access and Error)        path = /var/log/central-logs/aviation        force user = root        guest ok = YesEDIT:Client: Windows 7 SP1Client machine is VPN'd into the customer's local network but is not part of their AD domain. Samba is configured for Bizco.com (our client), let's say my laptop is part of the Fuzzypants.com domain.From log.%m when I pull the share up and click cancel on the prompt:[2014/08/13 21:56:28.812088,  3] lib/access.c:338(allow_access)  Allowed connection from xxx.xxx.28.194 (xxx.xxx.28.194)[2014/08/13 21:56:28.812201,  3] smbd/oplock.c:922(init_oplocks)  init_oplocks: initializing messages.[2014/08/13 21:56:28.812372,  3] smbd/oplock_linux.c:226(linux_init_kernel_oplocks)  Linux kernel oplocks enabled[2014/08/13 21:56:28.812519,  3] smbd/process.c:1662(process_smb)  Transaction 0 of length 159 (0 toread)[2014/08/13 21:56:28.812569,  3] smbd/process.c:1467(switch_message)  switch message SMBnegprot (pid 2467) conn 0x0[2014/08/13 21:56:28.813049,  3] smbd/negprot.c:598(reply_negprot)  Requested protocol [PC NETWORK PROGRAM 1.0][2014/08/13 21:56:28.813104,  3] smbd/negprot.c:598(reply_negprot)  Requested protocol [LANMAN1.0][2014/08/13 21:56:28.813143,  3] smbd/negprot.c:598(reply_negprot)  Requested protocol [Windows for Workgroups 3.1a][2014/08/13 21:56:28.813177,  3] smbd/negprot.c:598(reply_negprot)  Requested protocol [LM1.2X002][2014/08/13 21:56:28.813212,  3] smbd/negprot.c:598(reply_negprot)  Requested protocol [LANMAN2.1][2014/08/13 21:56:28.813247,  3] smbd/negprot.c:598(reply_negprot)  Requested protocol [NT LM 0.12][2014/08/13 21:56:28.813315,  3] smbd/negprot.c:598(reply_negprot)  Requested protocol [SMB 2.002][2014/08/13 21:56:28.813350,  3] smbd/negprot.c:598(reply_negprot)  Requested protocol [SMB 2.???][2014/08/13 21:56:28.813514,  3] smbd/negprot.c:401(reply_nt1)  not using SPNEGO[2014/08/13 21:56:28.813553,  3] smbd/negprot.c:704(reply_negprot)  Selected protocol NT LM 0.12[2014/08/13 21:56:46.975628,  1] smbd/process.c:457(receive_smb_talloc)  receive_smb_raw_talloc failed for client xxx.xxx.28.194 read error = NT_STATUS_CONNECTION_RESET.[2014/08/13 21:56:46.975865,  3] smbd/server_exit.c:181(exit_server_common)  Server exit (failed to receive smb request)I can give the log output from a successful authentication but it's probably not as informative.EDIT #2Since the last log didn't have anything telling I went through with the login prompt and began to see check_ntlm_password in log.%m:[2014/08/14 12:33:59.988239,  3] auth/auth.c:219(check_ntlm_password)  check_ntlm_password:  Checking password for unmapped user []\\[]@[] with the new password interface[2014/08/14 12:33:59.988274,  3] auth/auth.c:222(check_ntlm_password)  check_ntlm_password:  mapped user is: []\\[]@[][2014/08/14 12:33:59.988328,  3] auth/auth.c:268(check_ntlm_password)  check_ntlm_password: guest authentication for user [] succeeded[2014/08/14 12:33:59.988379,  3] smbd/process.c:1467(switch_message)  switch message SMBtconX (pid 6290) conn 0x0[2014/08/14 12:33:59.988450,  3] lib/access.c:338(allow_access)  Allowed connection from XXX.XXX.29.76 (XXX.XXX.29.76)[2014/08/14 12:33:59.988613,  3] auth/auth.c:219(check_ntlm_password)  check_ntlm_password:  Checking password for unmapped user [bizco]\\[davisja5]@[XXX.XXX.29.76] with the new password interface[2014/08/14 12:33:59.988651,  3] auth/auth.c:222(check_ntlm_password)  check_ntlm_password:  mapped user is: [XXXXXXVLP01]\\[davisja5]@[XXX.XXX.29.76][2014/08/14 12:33:59.988735,  3] auth/check_samsec.c:399(check_sam_security)  check_sam_security: Couldn't find user 'davisja5' in passdb.[2014/08/14 12:33:59.988772,  2] auth/auth.c:319(check_ntlm_password)  check_ntlm_password:  Authentication for user [davisja5] -> [davisja5] FAILED with error NT_STATUS_NO_SUCH_USER[2014/08/14 12:33:59.988819,  3] auth/auth.c:219(check_ntlm_password)  check_ntlm_password:  Checking password for unmapped user [BIZCO]\\[davisja5]@[XXX.XXX.29.76] with the new password interface[2014/08/14 12:33:59.988853,  3] auth/auth.c:222(check_ntlm_password)  check_ntlm_password:  mapped user is: [XXXXXXVLP01]\\[davisja5]@[XXX.XXX.29.76][2014/08/14 12:33:59.988927,  3] auth/check_samsec.c:399(check_sam_security)  check_sam_security: Couldn't find user 'davisja5' in passdb.[2014/08/14 12:33:59.988964,  2] auth/auth.c:319(check_ntlm_password)  check_ntlm_password:  Authentication for user [davisja5] -> [davisja5] FAILED with error NT_STATUS_NO_SUCH_USER[2014/08/14 12:33:59.989005,  3] auth/auth.c:219(check_ntlm_password)  check_ntlm_password:  Checking password for unmapped user [BIZCO]\\[davisja5]@[XXX.XXX.29.76] with the new password interface[2014/08/14 12:33:59.989039,  3] auth/auth.c:222(check_ntlm_password)  check_ntlm_password:  mapped user is: [XXXXXXVLP01]\\[davisja5]@[XXX.XXX.29.76][2014/08/14 12:33:59.989092,  3] auth/check_samsec.c:399(check_sam_security)  check_sam_security: Couldn't find user 'davisja5' in passdb.[2014/08/14 12:33:59.989126,  2] auth/auth.c:319(check_ntlm_password)  check_ntlm_password:  Authentication for user [davisja5] -> [davisja5] FAILED with error NT_STATUS_NO_SUCH_USER[2014/08/14 12:33:59.989167,  3] auth/auth.c:219(check_ntlm_password)  check_ntlm_password:  Checking password for unmapped user [BIZCO]\\[davisja5]@[XXX.XXX.29.76] with the new password interface[2014/08/14 12:33:59.989201,  3] auth/auth.c:222(check_ntlm_password)  check_ntlm_password:  mapped user is: [XXXXXXVLP01]\\[davisja5]@[XXX.XXX.29.76][2014/08/14 12:33:59.989253,  3] auth/check_samsec.c:399(check_sam_security)  check_sam_security: Couldn't find user 'davisja5' in passdb.[2014/08/14 12:33:59.989286,  2] auth/auth.c:319(check_ntlm_password)  check_ntlm_password:  Authentication for user [davisja5] -> [davisja5] FAILED with error NT_STATUS_NO_SUCH_USER[2014/08/14 12:33:59.989359,  3] smbd/password.c:721(authorise_login)  authorise_login: ACCEPTED: guest account and guest ok (root)[2014/08/14 12:33:59.989566,  3] passdb/lookup_sid.c:1754(get_primary_group_sid)  Forcing Primary Group to 'Domain Users' for root[2014/08/14 12:33:59.989752,  3] smbd/service.c:872(make_connection_snum)  Connect path is '/tmp' for service [IPC$]",
    "target": "samba;authentication"
  },
  {
    "id": "_unix.320403",
    "source": "How to unninstall linux distro in trialboot? <eos> I have ubuntu, fedora and windows installed in my laptop. I installed ubuntu after windows and then I installed fedora. How can I unninstall fedora without messing up the grub, which was reinstalled during the fedora installation?",
    "target": "grub"
  },
  {
    "id": "_softwareengineering.214158",
    "source": "How would I implement a self-destruct feature into the free trial version of my software? <eos> There is the ongoing argument of free trial versus a freemium model (that is, a free-for-life version of their software with restricted and/or stripped down features) for allowing potential customers and users to test run their product. Upon my research, I can conclude that the free trial is the way to go on both for the benefit of the user experience of the individual using the software and for the benefit of the vendor in both aspect of sales and maximizing usage. There are many factors for a free trial software that can greatly maximize user usage like the length of the free trial.One keyword that reoccurs on my research for freemium is frustrating. Many individuals chose to uninstall the software instead of having to use a piece of software where some features were unavailable to them. At the same time, these users never had the chance to use the paid features. Unbeknownst to them, and hidden by the very own vendors who are selling the software, they don't know and cannot know what benefits the Pro features will bring. Without first having to use them, a user will not know they have the feeling of needing something. Which brings me onto my next point of a free trial model.Some opinions of a free trial user is I cannot imagine using this software without the Pro features. This goes back to the point of the user not knowing they need something until they first understanding the feeling of have. Those that have had 14 days to use a the full version features said they cannot imagine not having or using the features provided there. So when fourteen days were over, they were more likely to dish out money than someone who's never experienced the full features. The length of the free trial is also an important factor is creating a lasting impression on users. In an experiment conducted by Visual Website Optimizer, they noticed that for a 14 day free trial versus a 30 day free trial, while the number of sign ups and installs were the same, the usage for the 14 day trial increased 102%. This, of course, in turn increased their revenue as well.Another very important point to mention is that offering a useful and fully functional free version of the product is VERY IMPORTANT. Fully functional free trials are effective in getting media coverage, and this publicity for new software and/or software vendors are fairly crucial.One other relevant aspect is the importance for users to give feedback. Consider, in the fully functional time-limited free trial, the ability for users to give feedback.One other feature important for our software is the need for telemetric data, that is, quantitative and comprehensive data on how a user uses our software. Some of usage statistics may fall into a legal grey area, as laws are different depending on the location in the United States, and the world. One way to combat this legal issue is to have an opt-in feature for gathering anonymous usage statistics. An opt-in feature would mean giving the user an option to turn off statistics gathering and at the same time, the user must be very well aware of what the gathering of anonymous usage information does. It is important to make it CLEAR to the user what data will be collected, what we will be doing with it, and make it easy to turn off any time, including allowing them to change their mind for turning it on or off. For more detailed statistics, like tracking individual activities of users, it could lead to legal issues. The Eclipse IDE logs detailed usage statistics, but it does it by the full consent of the user. We may have to potentially prepare a consent form with our legal team. The Eclipse Usage Information Collection collects this information:1. Plug-ins that are started by the system.2. Commands accessed via the keyboard shortcuts and actions invoked via menus or toolbars.3. When the view of the editor is given focus.4. System information like the version of the software being used, the operating system being used.5. Description of internal errors.Kill SwitchA kill switch for our software can be managed logging the initial data, encrypting it with a salt, and whenever it's an invalid date, that is, the user tried to change it, it would disable the software. Another option is to have internet authentication on install, log that date to a central web database, and check the date every time the application is opened.On disabling the software, we can delete vital DLLs. The option of having to pay to generate a report cannot be considered.I am interested in implementing a free trial version to my existing software. I plan on having the trial last 14 days. Upon the 14th day, my software would prompt the user to either pay for the paid version, or have the consequence of not being able to use it. The free trial version is entirely unlocked, meaning all paid features are there.However, my dilemma is about the best way to implement what to do for an end-of-trial solution. Do I delete vital DLLs? Have a user authentication system upon installation or use? Encrypt the initial time and date of use with a salt, and if it's an invalid date (AKA they try to change their initial date), disable the software?I am interested in knowing what are some effective measures of disabling software.",
    "target": "software;development"
  },
  {
    "id": "_softwareengineering.221986",
    "source": "Inheritance in test classes <eos> I have an interface Serializer with methods serialize and isSerializerFor. I created a first implementation of this using TDD, and ended up with a nice clean test case fully covering a nice clean implementation. To get a more concrete idea, here is one relevant commit.Now someone else (who is not used to doing TDD) started with writing the second implementation of this Serializer interface. This person figured the test needed for the second implementation would have some overlap with my initial test. So an abstract base class for serializer tests was created, holding the methods that are suspected to be common to all serializer test cases.I'm not happy with this for two main reasons. First of all, the only reason inheritance is used here is for code reuse, which is a big code smell. Secondly, this breaks the TDD cycle. If I now want to create another implementation of Serializer, and create a derivative of the base test class, I end up having to implement all production code in one step.On the other hand, simply duplicating the common code in the test classes seems rather odd as well. I'm hoping composition can be used here in a sane way to avoid these problems.This seems like a reasonably common situation. How would you solve this? What would you do differently?",
    "target": "design;unit testing;tdd;inheritance;composition"
  },
  {
    "id": "_unix.192732",
    "source": "Any serious risk if Mint 17 thinks it is Ubuntu? <eos> Running Mint 17, just ran apt-get upgrade for the first time in a while, with 350MB download. It stops halfway to tell me /etc/issue is not the package maintainers versions. Ditto for issue.net and lsb-release, where the diff looks like:-DISTRIB_ID=LinuxMint-DISTRIB_RELEASE=17-DISTRIB_CODENAME=qiana-DISTRIB_DESCRIPTION=Linux Mint 17 Qiana+DISTRIB_ID=Ubuntu+DISTRIB_RELEASE=14.04+DISTRIB_CODENAME=trusty+DISTRIB_DESCRIPTION=Ubuntu 14.04.2 LTSOK, I've said no to each of those three file updates (i.e. keep it as Mint). Now I'm just wondering if this is a symptom of a more serious problem? Could apt-get be corrupted? Is there some simple check I can do to tell myself everything is OK? Google, so far, tells me no-one else has this problem, which seems strange if it is a mess-up in Mint packaging.Sorry, that is a bit of a wishy-washy question. I guess it boils down to: Is it fine to shrug and think nothing about those three files?UPDATEHere is the output of apt-cache policy base-files:base-files:  Installed: 7.2ubuntu5.2  Candidate: 7.2ubuntu5.2  Version table: *** 7.2ubuntu5.2 0        500 http://archive.ubuntu.com/ubuntu/ trusty-updates/main amd64 Packages        100 /var/lib/dpkg/status     7.2ubuntu5 0        500 http://us.archive.ubuntu.com/ubuntu/ trusty/main amd64 Packages        500 http://archive.ubuntu.com/ubuntu/ trusty/main amd64 PackagesHowever there are some mint packages still, here is apt-cache policy | grep -i mint: 700 http://extra.linuxmint.com/ qiana/main i386 Packages     release v=17,o=linuxmint,a=qiana,n=qiana,l=linuxmint,c=main     origin extra.linuxmint.com 700 http://extra.linuxmint.com/ qiana/main amd64 Packages     release v=17,o=linuxmint,a=qiana,n=qiana,l=linuxmint,c=main     origin extra.linuxmint.com 700 http://packages.linuxmint.com/ qiana/import i386 Packages     release v=17,o=linuxmint,a=qiana,n=qiana,l=linuxmint,c=import     origin packages.linuxmint.com 700 http://packages.linuxmint.com/ qiana/upstream i386 Packages     release v=17,o=linuxmint,a=qiana,n=qiana,l=linuxmint,c=upstream     origin packages.linuxmint.com 700 http://packages.linuxmint.com/ qiana/main i386 Packages     release v=17,o=linuxmint,a=qiana,n=qiana,l=linuxmint,c=main     origin packages.linuxmint.com 700 http://packages.linuxmint.com/ qiana/import amd64 Packages     release v=17,o=linuxmint,a=qiana,n=qiana,l=linuxmint,c=import     origin packages.linuxmint.com 700 http://packages.linuxmint.com/ qiana/upstream amd64 Packages     release v=17,o=linuxmint,a=qiana,n=qiana,l=linuxmint,c=upstream     origin packages.linuxmint.com 700 http://packages.linuxmint.com/ qiana/main amd64 Packages     release v=17,o=linuxmint,a=qiana,n=qiana,l=linuxmint,c=main     origin packages.linuxmint.com",
    "target": "linux mint;apt"
  },
  {
    "id": "_unix.84814",
    "source": "Health check of web page using curl <eos> I'd like to do a health check of a service by calling a specific url on it. Feels like the simplest solution would be to use cron to do the check every minute or so. In case of errors, cron sends me an email. I tried using cUrl for this but I can't get it to output messages only on errors. If I try to direct output to /dev/null, it prints out progress report.  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current                                 Dload  Upload   Total   Spent    Left  Speed100  5559  100  5559    0     0   100k      0 --:--:-- --:--:-- --:--:--  106kI tried looking through the curl options but I just can't find anything to suit the situation where you want it to be silent on success but make noise on errors.Is there a way to make curl do what I want or is there some other tool I should be looking at?",
    "target": "bash;curl"
  },
  {
    "id": "_softwareengineering.208763",
    "source": "Is it a good idea to use Twitter Bootstrap 3 for production? <eos> So in the past few weeks I was introduced to Bootstrap 3-RC1. I made some web sites using it, and I actually enjoyed it. Then, recently, I discovered Twitter Bootstrap has already released version 3-RC2. It makes me wonder if it's okay for me to use Bootstrap RC2 for production now? Is it wise if I used it considering it still in RC phase or should I just wait for the official, completed version 3?",
    "target": "web development"
  },
  {
    "id": "_unix.4109",
    "source": "ls command: what does the first line mean? <eos> When I do ls -l I get this:calico@A000505:~/Documentos$ ls -ltotal 2020-rwxr-xr-x 1 calico calico    8559 2010-11-16 11:12 a.out-rwxrw-rw- 1 smt    smt    2050138 2010-10-14 10:40 Java2.pdf-rwxrw-rw- 1 ocv    ocv        234 2010-11-16 11:11 test.cBut what does the total 2020 mean? I only have 3 files so it's not the number of files or directories, and I guess it's not the size either. So what is it?",
    "target": "shell;ls"
  },
  {
    "id": "_webmaster.52471",
    "source": "Will Google crawl a news/RSS aggregator site? <eos> I know how to code. I know how to set up a news/RSS aggregator site. But I don't know if Google will crawl it. Will Google crawl such a site?The site will have a listing of all the aggregated news with the title, a short snippet of the news, and an image (not all will have an image) of the original news article.When a user clicks the article the user will get redirected to the source.Something like drudgereport. I haven't seen a drudgereport link when I search so I can't tell. (Maybe because it has something to do with my location I don't know.)Anyway any ideas?",
    "target": "googlebot;aggregators"
  },
  {
    "id": "_softwareengineering.159435",
    "source": "What's the best lesson you have learned in your career? <eos> I think mine is there's no such thing as a five minute job - that programmers tend to be overly optimistic about development and that we should really think through a the implications before promising a quick solution to a problem and then diving in to code",
    "target": "interview;career development;experience"
  },
  {
    "id": "_codereview.43991",
    "source": "Checking opcode values <eos> What troubles me are the empty /**/ brackets. Is there a cleaner way of handling this logic?if (opcode == OP_0) { /* continue */}    else if (opcode == OP_1NEGATE) { /* continue */}    else if (opcode >= OP_1 && opcode <= OP_16) { /* continue */}    else { throw new Exception(decodeFromOpN called on non OP_N opcode); }",
    "target": "c#"
  },
  {
    "id": "_unix.16348",
    "source": "AES-NI not passed to guest in Virtualbox <eos> I'm trying to use encryption inside a virtual machine. The problem is that the AES-NI doesn't seem to be passed to the guest virtual machine.I have Vt-x enabled.This is my host cpuinfo:processor       : 0vendor_id       : GenuineIntelcpu family      : 6model           : 42model name      : Intel(R) Core(TM) i7-2600 CPU @ 3.40GHzstepping        : 7cpu MHz         : 1600.000cache size      : 8192 KBphysical id     : 0siblings        : 8core id         : 0cpu cores       : 4apicid          : 0initial apicid  : 0fpu             : yesfpu_exception   : yescpuid level     : 13wp              : yesflags           : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 x2apic popcnt aes xsave avx lahf_lm ida arat epb xsaveopt pln pts dts tpr_shadow vnmi flexpriority ept vpidbogomips        : 6801.03clflush size    : 64cache_alignment : 64address sizes   : 36 bits physical, 48 bits virtualpower management:This is my guest cpuinfo:processor       : 0vendor_id       : GenuineIntelcpu family      : 6model           : 42model name      : Intel(R) Core(TM) i7-2600 CPU @ 3.40GHzstepping        : 7cpu MHz         : 3399.615cache size      : 6144 KBphysical id     : 0siblings        : 2core id         : 0cpu cores       : 2apicid          : 0initial apicid  : 0fpu             : yesfpu_exception   : yescpuid level     : 5wp              : yesflags           : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx lm constant_tsc rep_good nopl pni ssse3 lahf_lmbogomips        : 6799.23clflush size    : 64cache_alignment : 64address sizes   : 36 bits physical, 48 bits virtualpower management:Am I missing some configuration option? Or is this a problem of Virtualbox?",
    "target": "virtual machine;virtualbox;encryption;i386"
  },
  {
    "id": "_unix.265092",
    "source": "How can I check the first process that is run? I can see both init and linuxrc in root folder <eos> I get a modified Linux installation on QNAP x86 based NAS. In the initrd image file, I noticed there are both a init script /initand a symbolic link that points to a different program(busybox): linuxrc ->/bin/busybox.How can I figure out which one is the init process that is run every time the system is booted?",
    "target": "linux;boot;busybox"
  },
  {
    "id": "_unix.134868",
    "source": "ldconfig not following user-created symbolic link <eos> I'm attempting to run Inkscape 0.48.4-15 (armv7) which is installed via pacman from Arch Linux ARM. $ inkscapeinkscape: error while loading shared libraries: libMagick++-6.Q16HDRI.so.3: cannot open shared object file: No such file or directoryAs expected, the shared object is not available in /usr/lib:$ ll /usr/lib | grep libMagick+lrwxrwxrwx   1 root root       30 Jun  5 03:04 libMagick++-6.Q16HDRI.so ->     libMagick++-6.Q16HDRI.so.4.0.0lrwxrwxrwx   1 root root       30 Jun  5 03:04 libMagick++-6.Q16HDRI.so.4 -> libMagick++-6.Q16HDRI.so.4.0.0-rwxr-xr-x   1 root root   379428 Jun  5 03:06 libMagick++-6.Q16HDRI.so.4.0.0So I make a symbolic link linking *.so.3 to *.so.4.0.0:$ sudo ln -s libMagick++-6.Q16HDRI.so.4.0.0 libMagick++-6.Q16HD.so.3lrwxrwxrwx   1 root root       30 Jun  5 03:04 libMagick++-6.Q16HDRI.so -> libMagick++-6.Q16HDRI.so.4.0.0lrwxrwxrwx   1 root root       30 Jun  6 15:15 libMagick++-6.Q16HDRI.so.3 -> libMagick++-6.Q16HDRI.so.4.0.0lrwxrwxrwx   1 root root       30 Jun  5 03:04 libMagick++-6.Q16HDRI.so.4 -> libMagick++-6.Q16HDRI.so.4.0.0-rwxr-xr-x   1 root root   379428 Jun  5 03:06 libMagick++-6.Q16HDRI.so.4.0.0and verify that *.so.3 is indeed linked to *.so.4.0.0.$ readlink -f libMagick++-6.Q16HDRI.so.3/usr/lib/libMagick++-6.Q16HDRI.so.4.0.0Now I reconfigure the dynamic linker run time bindings and rerun Inkscape:$ sudo ldconfig $ ldd $(which inkscape) | grep libMagick++libMagick++-6.Q16HDRI.so.3 => /usr/lib/libMagick++-6.Q16HDRI.so.3 (0x75cf9000)Why is *.so.3 linking to itself and not following the symbolic link created earlier?",
    "target": "symlink;dynamic linking"
  },
  {
    "id": "_softwareengineering.112730",
    "source": "Windows Phone 7 app development - Is it worth it? <eos> I've written a Windows Phone 7 application to display the Ordnance Survey maps that are loved so much in the UK (I am amazed that no-one else has done this yet). However I was about to shell out the 65 to pay for the app hub and get my app to the marketplace when I started investigating how you actually get paid for the apps that people buy. Apparently if you are not a US developer then you have to start sending over forms e.g. W8BEN form? and even after this the IRS takes another 30% (after MS have taken their 30% share). It also mentions VAT so maybe there is more money taken off after this as well???Has anyone from outside the US actually got all the paperwork sorted so they got paid? Did you get tax taken off as well? What percentage of the sales do you actually end up with? Is it all worth it? I don't expect to make much from the app but I would like to think I could recoup my 65 and have enough to buy a couple of beers as well.",
    "target": "windows phone 7"
  },
  {
    "id": "_unix.261760",
    "source": "Sort files by highest number in filename <eos> I've got a bunch of files all named like this:name_file-1.txtname_file-2.txtname_file-3.txtsome_other_file-1.txtsome_other_file-2.txtThere are thousands of different filenames, some with just one -1.txt at the end, some with -1.txt, -2.txt ... -60.txtI need to copy the highest numbers of each file, so name_file-3.txt, some_other_file-2.txt. How do I do that on a Linux command line?",
    "target": "shell script;files"
  },
  {
    "id": "_softwareengineering.103102",
    "source": "What tools do PHP Developers use? <eos> Possible Duplicate:What would you consider best practice workflow tools for web application (PHP) development? I start my new job next week as a PHP Developer which is my dream job but it's going to be object-orientated which I've only done in Java whilst at university.My question is regarding PHP tools - what are the best IDE's (I use notepad++), what versioning packages work best and bug trackers etc, so I was just wondering what tools the PHP developers out there use in their working lives.",
    "target": "php;self improvement"
  },
  {
    "id": "_unix.311896",
    "source": "Is it possible to run fc without showing my inputted commands? <eos> If I'm in bash and I type fc, write echo hello world and save it, it will double print:echo hello worldhello worldinstead of justhello worldIs there any way of avoiding it printing my own commands?",
    "target": "bash"
  },
  {
    "id": "_unix.252479",
    "source": "How to diagnose SSH connection timeout issue? <eos> I am Debain and Linux beginner so please bare with me.I have a VPS running Debian 7, that I connect to using PuTTY from my Windows machine. Most of the time, PuTTY connects fine and I can log in fine. However, occasionally, PuTTY will report that Connection Timeout.When this happened last time, I attempted to telnet to the port that is running SSH and it could not connect. I then attempted to telnet to another port on the VPS that I knew was running a service and it connected fine.When it starts to play up, if I try 5-10 times to connect, I can successfully connect. I checked the syslog and I could not see anything interesting in there that could help with this problem. If it is worth anything, when I do connect to the server when it is playing up, it appears to be slow (I will type a command and it will take a second or two to appear in the SSH window).I don't believe this to be a firewall issue as it will work most of time, then sometimes just not work. Maybe my host is doing some maintenance? As I said, I am a beginner so any help would be appreciated.EDIT: TCPKeepAlive is enabled. It played up again just now and when attempting to telnet to the SSH port, it could in fact connect. Weird.",
    "target": "debian;ssh;openssh"
  },
  {
    "id": "_unix.285414",
    "source": "(Ethernet cables): Can a straight wire work (slightly) where a crossover-wire is necessary (without MDX)? <eos> If I connect a straight Ethernet cable where a crossover cable should be used. Can I get the behaviour that it works occassionally, once in a while? Too me it seems it would either work or not, not occassionaly -is this correct?I have a situation where Ethernet sometimes work, and sometimes after reboot it stops working. The question is then -can crossover wiring be the culprit or not? One end is not auto MDI-X but the other probably is.It would seem it would rather have something to do with speed negotiation or so but I don't know.",
    "target": "ethernet"
  },
  {
    "id": "_unix.98764",
    "source": "How do I redirect only stderr? <eos> I am having a bit of trouble doing this. I am required to run a compiled .java file and redirect only stderr to a file called error. So the .java file is named javaProgram.java.This is what I have tried:java javaProgram 2> errorHowever when Icat errorit appears that there is stuff in there, even when I know for a fact that the specific .java file has no errors. Am I doing something wrong? All I want this error file to display is errors, not anything else.",
    "target": "bash;compiling;io redirection"
  },
  {
    "id": "_softwareengineering.299682",
    "source": "Does algorithm design belong to software engineering? <eos> In academic meaning, it seems to me that algorithm design is studied in a high/abstract level of computation (computability, complexity), although software engineering is also studied in high/abstract level in academia.software engineering is about the process of creating a software program for solving a problem. That seems to make algorithm design part of the process.But from the limited references on software engineering that I have taken a glanced at, algorithm design isn't discussed (but I may miss something).Instead, pattern design (or is it called design pattern instead?) is discussed in software engineering.My questions are:Does algorithm design belong to software engineering? Is algorithm design a step in the process of software engineering?what are the differences and relations between algorithm design, pattern design, program design, and system design? These words can be heard often from industry as buzzwords.  Can you share the definitions of these various kinds of designs? ",
    "target": "design;design patterns;algorithms;software;system"
  },
  {
    "id": "_unix.271936",
    "source": "Why does a USB drive only mount as read-only after copying a disk image to it? <eos> I was preparing a USB thumb drive for installing Debian 8.3. Per the installation instructions, it suggests:cp debian.iso /dev/sdX     # e.g. /dev/sdb, no /dev/sdb1syncSo I gave this a try. I noticed after doing this that if I try to mount /dev/sdb1, it does mount, however it always mounts as read-only, regardless of whatever options I pass. I tried with a few USB drives, with the same result.Why will the drive only mount as read-only after doing the above? Is there a way to still mount it as rw?",
    "target": "mount"
  },
  {
    "id": "_unix.174343",
    "source": "F2FS vs ext3/ext4 <eos> We are using Beaglebone black Based custom board,we are planning to use eMMC in our board.We are in the process of checking different filesystem options,What are the different file system we can use for eMMC ?Usage of ext3/ext4 is very famous, but is it worth investing in evaluating Btrfs or F2fs.We are bit worried when we think of using F2FS file system, because it is being developed by Samsung, we are worried about roadmap of F2FS file system and further update of the same.What approach should we use to evaluate different filesystems?  Any suggestions/pointers for the same ?",
    "target": "linux;filesystems;embedded"
  },
  {
    "id": "_unix.168020",
    "source": "Find duplicity files after using PhotoRec <eos> I've partly formatted a disc where my duplicity files was stored. I have used PhotoRec to recover the files but now they're all unsorted and without the correct filename. I have the files separated by extension. Is there a way to discover the duplicity files and recover my backup?",
    "target": "ext4;duplicity"
  },
  {
    "id": "_codereview.104407",
    "source": "Synchronize access to an instance method using a static serial queue <eos> In my current project I have a number of data services classes, each one dedicated to a specific source of data so that it's responsible of downloading data from its API, checking for local database and doing inserts or updates as necessary. I needed to synchronize access to the entry point method for each of these classes as they may be consumed by other classes (like view models in the project architecture). My first thought was to use @synchronized, but it uses locks under the hood and Apple's advice was to avoid that and use serial queues instead.I ended up creating a static shared serial queue for every data service class to be used by its instance entry point method as those classes are not singletons.I also used dispatch_suspend and dispatch_resume to control the flow of blocks being executed by this serial queue.It's working, and now for a specific data service class (DS), if we have 2 instances of it DS1 and DS2 then called DS1.loadData() and DS2.loadData successively, DS2.loadData would be executed after DS1.loadData() has finished. This also has the benefit of other instances of the other data services classes working concurrently.Could this approach impose any risks or issues?Data service class:// UserDataService.m@interface UserDataService () @property (strong, nonatomic) dispatch_queue_t serialQueue;@end@implementation UserDataService- (instancetype)init {    self = [super init];    if (self) {        _serialQueue = [self sharedQueue];    }    return self;}// Private Method- (dispatch_queue_t)sharedQueue{    static dispatch_queue_t sharedQueue;    static dispatch_once_t onceToken;    dispatch_once(&onceToken, ^{        sharedQueue = dispatch_queue_create(com.UserDataService.queue, DISPATCH_QUEUE_SERIAL);    });    return sharedQueue;}// Public Method// This is the entry point method for this data service class- (void)loadDataWithSuccess:(DataSuccessBlock)success failure:(DataFailureBlock)failure {    // Check for data in database (Realm database), if not download from server    dispatch_async(self.serialQueue, ^{        NSArray *results = [User allObjects];   // User is RLMObject (Realm object)        if (results && results.count > 0) {            dispatch_async(dispatch_get_main_queue(), ^{                success([User allObjects]);                 });        } else {            dispatch_suspend(self.serialQueue);            // Start to download data and persist it into local database            [self downloadAndPersistDataWithSuccess:^(RLMResults *result) {                dispatch_async(dispatch_get_main_queue(), ^{                    dispatch_resume(self.serialQueue);                    success(result);                });            } failure:^(NSString *errorMsg) {                dispatch_resume(self.serialQueue);                failure(errorMsg);            }];        }    });}- (void)downloadAndPersistDataWithSuccess:(DataSuccessBlock)success failure:(DataFailureBlock)failure {    // Download data from server and persist it in local database    APIService *apiService = [APIService new];  //APIService class wraps AFNetworking GET methods    [apiService getUsersWithsuccess:^(NSDictionary *result) {        //persist data        [self persistData:result withSuccess:^(RLMResults *persistedObjects) {            success(persistedObjects);        } failure:^(NSString *errorMsg) {            failure(errorMsg);        }];    } failure:^(NSString *errorMsg) {        failure(errorMsg);    }];}- (void)persistData:(NSDictionary *)data withSuccess:(DataSuccessBlock)success failure:(DataFailureBlock)failure {    if (data) {        NSArray *users = [data valueForKey:@users];        RLMRealm *realm;        @try {            realm = [RLMRealm defaultRealm];            [realm beginWriteTransaction];            for (NSDictionary *userData in users) {                // Create user realm object                User *user = [[User alloc] initWithDictionary:userData];                [realm addOrUpdateObject:user];            }            [realm commitWriteTransaction];            success([User allObjects]);        }        @catch (NSException *exception) {            if ([realm inWriteTransaction]) {                [realm cancelWriteTransaction];            }            failure([NSString stringWithFormat:@%@ - %@, exception.name, exception.reason]);        }    }}@end",
    "target": "objective c;synchronization;grand central dispatch"
  },
  {
    "id": "_unix.214966",
    "source": "Black screen when I move from X session to tty session <eos> I've the ATI proprietary drivers. When I power on the computer and I do the login all works well, but when I run xorg  I can't change tty or exit from xorg because if I try I see only a black screen (the monitor backlight stays on).If I change tty (ctrl alt f2) I've the black screen, if then Ireturn to xorg (ctrl alt f1) it works.If I close or kill xorg I've the black screen and I must reset thecomputer.This is the Xorg log when I go to tty2 and during the blackscreen[   312.470] (**) Option fd 24[   312.470] (**) Option fd 17[   312.470] (**) Option fd 23[   312.470] (**) Option fd 33[   312.470] (**) Option fd 20[   312.471] (**) Option fd 22[   312.471] (**) Option fd 21[   312.471] (II) AIGLX: Suspending AIGLX clients for VT switch[   312.471] (II) fglrx(0): Backup framebuffer data.[   312.560] (II) fglrx(0): Backup complete.[   312.596] (II) systemd-logind: got pause for 13:68[   312.596] (II) systemd-logind: got pause for 13:67[   312.596] (II) systemd-logind: got pause for 13:69[   312.596] (II) systemd-logind: got pause for 13:65[   312.596] (II) systemd-logind: got pause for 13:64[   312.596] (II) systemd-logind: got pause for 13:66[   312.596] (II) systemd-logind: got pause for 13:70What can I do?",
    "target": "arch linux;xorg;tty;ati;fglrx"
  },
  {
    "id": "_cs.72046",
    "source": "What is the role of abstract machines in the Curry-Howard isomorphism? <eos> By abstract machines I mean things like the SECD machine, Krivine's machine or more generally machines with states/memory/registers/stack/accumulator...According to Wikipedia page of the Curry-Howard isomorphism, we have a correspondence with the Sequent Calculus where the left/right introductions rule matches with the constructors of codes and evaluation stacks. And the priority of rules application is related to call-by-value and call-by name reduction.So I'm looking for more information than what we can find in Wikipedia.",
    "target": "reference request;logic;computation models;curry howard"
  },
  {
    "id": "_codereview.140995",
    "source": "Populating a ComboBox from a Range <eos> I recently had quite a lot of fun answering a Stack Overflow question, and I think I've gone a bit overboard and ended up with a fairly decent way of populating a ComboBox from a Range.Given a simple UserForm featuring some ComboBox1 control that I'd want to populate from a ListObject on Sheet1, the calling/client code looks like this:Option ExplicitSub Test()    With New UserForm1        .PopulateFromList Sheet1.ListObjects(1)        .Show vbModal    End WithEnd Sub(thanks to Thomas Inzina for helping with the column headings)...the Change handler in the form's code is just to illustrate that the hidden ID column is effectively being used as the Combobox.Value:Private Sub ComboBox1_Change()    If Not IsNull(ComboBox1.Value) Then Debug.Print ComboBox1.Value, ComboBox1.TextEnd SubAnd it works! 3            Star Wars 1            Lord of the RingsHere's the rest of the form's code-behind, the actual code under review - I'm wondering what's the best way to reuse it, I haven't decided whether it's best to extract it into a class module as a utility; with a WithEvents foo As ComboBox field I could be having a dynamic control there... it's certainly not practical in the code-behind of some random form though.I'm not very happy with GetColumnWidths, I'm sure there's a better way to do this. As for the PopulateFromXxxx methods, ...they're perfect, aren't they? ;-)Option ExplicitPublic Sub PopulateFromList(ByVal source As ListObject, Optional ByVal valueColumn As Long = 1, Optional ByVal hasHeader As Boolean = True)    With Me.ComboBox1        .ColumnCount = source.Range.Columns.Count        .ColumnWidths = GetColumnWidths(source.Range)        .ListWidth = IIf(ComboBox1.Width > source.Range.Width, ComboBox1.Width, source.Range.Width)        .RowSource = source.Name & [#Data]        .BoundColumn = valueColumn        .ColumnHeads = hasHeader    End WithEnd SubPublic Sub PopulateFromArray(ByVal source As Range, Optional ByVal valueColumn As Long = 1, Optional ByVal hasHeader As Boolean = True)    With Me.ComboBox1        .ColumnCount = source.Columns.Count        .ColumnWidths = GetColumnWidths(source)        .ListWidth = IIf(ComboBox1.Width > source.Width, ComboBox1.Width, source.Width)        .List = source.Range(source.Rows(IIf(hasHeader, 2, 1)).EntireRow, source.Rows(source.Rows.Count).EntireRow).Value        .BoundColumn = valueColumn    End WithEnd SubPrivate Function GetColumnWidths(ByVal source As Range) As String    Dim cols As Long    cols = source.Columns.Count    Dim widths()    ReDim widths(1 To cols)    Dim col As Long    For col = 1 To cols        widths(col) = source(, col).Width    Next    GetColumnWidths = Join(widths, ,)End FunctionIs there any way to clean this up? The .List assignment in PopulateFromArray seems particularly painful.",
    "target": "vba;excel"
  },
  {
    "id": "_webmaster.19176",
    "source": "Does google always downrank pages with hidden texts <eos> I'm creating a FAQ for my page. To help the user to get a better overview I want to hide all answers and only display the questions. If the user clicks on a question the answer is set to display:block.I know that google also reads and indexes hidden content, but I also know that hiding text is a common technique for spammers and thus probably discredited by google, resulting in getting wiped from search results.But I'm wondering; Does google always downrank pages that have large amounts of hidden text? I mean an FAQ like this is not that uncommon. Should I not use this kind of FAQ?",
    "target": "seo;google;hidden text"
  },
  {
    "id": "_codereview.142177",
    "source": "Wheel of Fortune -- The ES6 Version <eos> I have taken my original code from here and turned it into an es6 version of the same game.Any code review and critiques are useful.Side note: Bankrupt and Lose a Turn do not do anything right now as it is a non-multiplayer game right now and I do not think it adds anything to the dynamic, but the wheel I have has those values. Here is a jsfiddle link to play with https://jsfiddle.net/maniator/4azoqbpv/59/class OnListener {  constructor() {    this.events = {};  }  on(event, callback) {    this.events[event] = callback.bind(this);  }  trigger(event, ...value) {    if (Object.keys(this.events).includes('all')) {      return this.events['all'](event, ...value);    }    for (let _event in this.events) {      if (event.indexOf(_event) > -1 || _event.indexOf(event) > 1) {        this.events[_event](event, ...value);      }    }  }}class Wheel extends OnListener {  constructor({    element,    button,    values = []  }) {    super();    this.element = element;    this.values = values;    this.modifier = Wheel.spinModifier();    this.slowdownSpeed = 0.5;    this.currentRotation = 0;    this.spinTimeout = null;        const clickFn = this.click.bind(this);    element.addEventListener('click', clickFn, false);    button.addEventListener('click', clickFn, false);  }  static spinModifier() {    return Math.random() * 10 + 20;  }  stop() {    clearTimeout(this.spinTimeout);  }  click() {    this.trigger('spin:start');    return this.spin().then((value) => {      this.trigger('spin:end', value);      return value;    });  }  rotate(degrees) {    this.element.style.transform = `rotate(-${degrees}deg)`;    this.currentRotation = degrees;    return this;  }  spin(amount = this.currentRotation, modifier = this.modifier) {    this.stop();    modifier -= this.slowdownSpeed;    this.rotate(amount);    return new Promise((res, rej) => {      if (modifier > 0) {        this.spinTimeout = setTimeout(() => {          res(this.spin(amount + modifier, modifier));        }, 1000 / 5)      } else {        const dataRotation = this.currentRotation;        const divider = 360 / this.values.length;        const offset = divider / 2; // half division        const wheelValue = this.values[Math.floor(Math.ceil((dataRotation + offset) % 360) / divider)];        this.modifier = Wheel.spinModifier();        switch (wheelValue) {          case 0:            return res(0);          case -1:            return res(Free Spin);          case -2:            return res(Lose a turn);          default:            return res(wheelValue);        }      }    })  }}class Board extends OnListener {  static randomize(arr) {    //fisher yates from https://codereview.stackexchange.com/a/12200/3163    let i = arr.length;    if (i === 0) return [];    while (--i) {      const j = Math.floor(Math.random() * (i + 1));      const tempi = arr[i];      const tempj = arr[j];      arr[i] = tempj;      arr[j] = tempi;    }    return arr;  }  constructor({    answers = [],    element,    button  }) {    super();    this.element = element;    this.answers = Board.randomize(answers);    this.currentBoard = -1;    button.addEventListener('click', () => this.next(), false);  }  clear() {    const displayArea = this.element;    while (displayArea.hasChildNodes()) { //remove old puzzle      displayArea.removeChild(displayArea.firstChild);    }  }  solve(solution) {    return (this.answers[this.currentBoard].toUpperCase() === solution.toUpperCase());  }  getNextBoard() {    try {      const board = this.answers[++this.currentBoard].toUpperCase();      const boardArray = board.split('');      this.trigger('new:puzzle', board);      return boardArray;    } catch (e) {      throw new Error('No more levels!');    }  }  inputLetter(_letter) {    let count = 0;    this.letters.forEach((obj) => {      const {        letter,        element      } = obj;      if (!obj.seen && _letter === letter) {        element.textContent = letter;        obj.seen = true;        count += 1;      }    });    return count;  }  next() {    const boardArray = this.getNextBoard();    const displayArea = this.element;    this.clear();    this.letters = [];    let word = document.createElement('div');    word.classList.add('word');    const words = boardArray.reduce((words, currentLetter, index) => {      const letter = document.createElement('div');      letter.classList.add('wordLetter');      letter.id = `letter_${index}`;      if (currentLetter !== ' ') {        letter.classList.add('letter');        this.letters.push({          letter: currentLetter,          element: letter        });        word.appendChild(letter);      } else {        words.push(word);        word = document.createElement('div');        word.classList.add('word');      }      return words;    }, []);    // push the last one    words.push(word);    words.forEach((wordElement) => {      displayArea.appendChild(wordElement);    });  }}class Game {  constructor({    wheel,    board,    vowelButton,    solveButton,    moneyElement  }) {    this.wheel = wheel;    this.board = board;    this.vowels = ['A', 'E', 'I', 'O', 'U'];    this.totalScore = 0;    this.moneyElement = moneyElement;    vowelButton.addEventListener('click', () => {      if (this.totalScore >= 100) {        this.totalScore -= 100;        this.guessLetter(0, true);      } else {        // @todo an else case      }    }, false);    solveButton.addEventListener('click', () => {      const solution = prompt('What is the solution?');      if (board.solve(solution)) {        solution.split('').forEach((letter) => {          this.board.inputLetter(letter.toUpperCase())        });        setTimeout(() => alert('Puzzle solved!'), 10);      } else {        alert('Puzzle not solved!');      }    }, false);  }  start() {    this.listen();    this.board.next();  }  guessLetter(value, asVowel = false) {    const letter = prompt(`Guess a ${asVowel ? 'vowel' : 'letter'}`);    try {      if (!(/^[a-zA-Z]$/.test(letter))) {        throw new Error('Must input an actual letter A-Z');      }      const capitalLetter = letter.toUpperCase();      const letterIsVowel = this.vowels.includes(capitalLetter);      if (asVowel && !letterIsVowel) {        throw new Error(`Must input a vowel: [${this.vowels.join(', ')}]`);      } else if (!asVowel && letterIsVowel) {        throw new Error(`Cannot input a vowel: [${this.vowels.join(', ')}]`);      }      const count = this.board.inputLetter(capitalLetter);      console.log(`Found ${letter} ${count} times worth $${value * count}`);      if (!asVowel) {        this.totalScore += (value * count);      }      this.moneyElement.textContent = this.totalScore;    } catch (error) {      alert(error.message);      this.guessLetter(...arguments);    }  }  listen() {    this.wheel.on('spin:end', (event, value) => {      if (isNaN(value) || value === 0) {        console.log('SPUN SOMETHING BAD', value);      } else {        console.log('CAN GUESS A LETTER', value);        this.guessLetter(value);      }    });    this.board.on('new:puzzle', (event, ...value) => {      console.log(`${event} ${value}`);      this.wheel.stop();    });  }}const wheel = new Wheel({  element: document.getElementById('wheel'),  values: [5000, 600, 500, 300, 500, 800, 550, 400, 300, 900, 500, 300, 900, 0, 600, 400, 300, -2, 800, 350, 450, 700, 300, 600],  button: document.getElementById('spin'),});const board = new Board({  element: document.getElementById('display'),  answers: [    doctor who, the dark knight rises, wheel of fortune,    facebook, twitter, google plus, sea world, pastrami on rye,    i am sparta, whose line is it anyway, google chrome  ],  button: document.getElementById('newpuzzle')});const game = new Game({  wheel,  board,  vowelButton: document.getElementById('vowel'),  solveButton: document.getElementById('solve'),  moneyElement: document.getElementById('money')});game.start();console.log(game);@import url(//fonts.googleapis.com/css?family=Changa+One);#game {  font-family: 'Changa One' serif;}#wheel {  top: 0;  left: 0;  width: 500px;  -moz-border-radius: 250px;  -webkit-border-radius: 250px;  border-radius: 250px;  -webkit-transition: -webkit-transform 0.5s linear;  -moz-transition: -moz-transform 0.5s linear;  -opera-transition: -opera-transform 0.5s linear;  -ms-transition: transform 0.5s linear;}#tick {  margin-left: 244px;  font-family: Arial;  font-size: 14pt;}#display {  background-color: #43759f;  padding: 1em 2em;  text-align: center;  border-radius: 40px;  border: 4px double #fff;}#display div.word {  display: inline-block;}#display div.word:not(:first-child) {  padding: 0 30px;}#display div.wordLetter {  display: block;  width: 50px;  height: 65px;  margin: 2px;  border: 2px solid #43759f;  float: left;  line-height: 65px;  font-size: 40px;}#display div.wordLetter.letter {  border-color: #eee;}#playArea {  clear: both;}#playArea button {  text-transform: uppercase;  z-index: 1000;  border: 4px double #fff;  background-color: #43759f;  padding: 6px 14px;  color: white;  font-family: inherit;  font-size: 12pt;}#playArea #moneyArea {  float: right;  position: relative;  padding: 10px;  border: 2px black solid;  width: 200px;  margin: 5px;  font-size: 14pt;}.clear {  clear: both;}<div id=game>    <div id=display></div>    <div id=playArea>        <button id=spin>spin wheel</button>        <button id=vowel>buy vowel</button>        <button id=solve>solve puzzle</button>        <button id=newpuzzle>new puzzle</button>        <div id=moneyArea>            Score: $<span id=money>0</span>        </div>    </div>    <div class=clear></div>    <div id=tick></div>    <img id=wheel src=//i.imgur.com/R7JYazp.png data-rotation=0 /></div>",
    "target": "javascript;game;ecmascript 6"
  },
  {
    "id": "_unix.203038",
    "source": "How can I resolve duplicates in yum? <eos> In a moment of confusion and impatience, I severely damaged my OS. Here's the deal...System: CentOS 7Problem: essential packages like SAMBA do not work, and yum will not do anything.How it started: I installed kmod-xpad, which required a kernel update. This new kernel never worked, but I could boot from the old kernel on the boot loader. I did a routine package update via yum. Later on, I tried to remove kmod-xpad, but that failed. Now the system permanently tells me that I need to restart in order to install updates. Even worse, I cannot mount a network drive via Samba. I get an error message like.../sbin/mount.cifs: /usr/lib64/samba/libreplace.so: version SAMBA_4.1.1' not found (required by /lib64/libwbclient.so.0)/sbin/mount.cifs: /usr/lib64/samba/libwinbind-client.so: version `SAMBA_4.1.1' not found (required by /lib64/libwbclient.so.0)While trying to fix SAMBA, I found that yum is completely confused, and had unfinished transactions. I searched around for solutions without luck (e.g. such as Why does yum update fails with many duplicates, after many months of no upgrades?)Yum error messages:When I run yum clean all and yum update I run into an error with dependency resolution, and am then told that there are 374 pre-existing rpmdb problems, which are basically a bunch of duplicate packages. Here is a snippet:--> Finished Dependency ResolutionError: Package: avahi-libs-0.6.31-13.el7.x86_64 (@anaconda)           Requires: avahi = 0.6.31-13.el7           Removing: avahi-0.6.31-13.el7.x86_64 (@anaconda)               avahi = 0.6.31-13.el7           Updated By: avahi-0.6.31-14.el7.x86_64 (base)               avahi = 0.6.31-14.el7Error: avahi-libs conflicts with avahi-0.6.31-14.el7.x86_64Error: avahi-autoipd conflicts with avahi-0.6.31-14.el7.x86_64...You could try using --skip-broken to work around the problem ** Found 374 pre-existing rpmdb problem(s), 'yum check' output follows: 1:NetworkManager-1.0.0-14.git20150121.b4ea599c.el7.x86_64 is a duplicate with 1:NetworkManager-0.9.9.1-29.git20140326.4dba720.el7_0.x86_64...avahi-libs-0.6.31-14.el7.x86_64 is a duplicate with avahi-libs-0.6.31-13.el7.x86_64avahi-ui-gtk3-0.6.31-14.el7.x86_64 has installed conflicts avahi < ('0', '0.6.31', '14.el7'): avahi-0.6.31-13.el7.x86_64avahi-ui-gtk3-0.6.31-14.el7.x86_64 is a duplicate with avahi-ui-gtk3-0.6.31-13.el7.x86_64bash-4.2.46-12.el7.x86_64 is a duplicate with bash-4.2.45-5.el7_0.4.x86_64...yum logAnd here are the main events from my yum.log:Apr 24 11:34:08 Updated: linux-firmware-20140911-0.1.git365e80c.el7.noarchApr 24 11:34:13 Installed: kernel-3.10.0-229.1.2.el7.x86_64Apr 24 11:34:14 Installed: kmod-xpad-0.0.6-3.el7.elrepo.x86_64May 08 13:38:28 Updated: libgcc-4.8.3-9.el7.x86_64May 08 13:38:28 Updated: centos-release-7-1.1503.el7.centos.2.8.x86_64May 08 13:38:28 Updated: python-urlgrabber-3.10-6.el7.noarchMay 08 13:38:28 Updated: 1:control-center-filesystem-3.8.6-18.el7.x86_64May 08 13:38:28 Updated: hyperv-daemons-license-0-0.25.20141008git.el7.noarch... (a bunch of packages)...May 08 13:40:31 Updated: xorg-x11-server-common-1.15.0-33.el7_1.x86_64May 08 13:40:31 Updated: xorg-x11-server-Xorg-1.15.0-33.el7_1.x86_64May 08 14:02:03 Erased: kmod-xpad-0.0.6-3.el7.elrepo.x86_64Is this a good solution?Right now, I'm considering removing the duplicates by following the advice on the CentOS forum: rpm -e --justdb <package-version>This sounds tedious, and I'm not confident that it will really resolve my problem. Is this a situation that calls for reinstallation?Any advice will be appreciated.",
    "target": "centos;yum"
  },
  {
    "id": "_unix.64394",
    "source": "How to manage 2 vm using upstart? <eos> I use an upstart script to monitor a vm and respawn it when it gets killed. I would like to simulate a failover by doing the following. Create a clone of the VM1 say VM2. When either of them is running , I have the other VM in saved state. As soon as one gets killed , I resume the other and start the killed vm but keep it paused.How should I modify this single vm script to work for 2 vms or maybe multiple vms even?start on (local-filesystems and net-device-up IFACE=eth0)stop on runlevel [016]console outputrespawnrespawn limit 5 10pre-stop scriptsu pankajm -c VBoxManage controlvm ubuntu-server savestateend scriptexec su pankajm -c VBoxHeadless startvm ubuntu-server",
    "target": "virtualbox;virtualization;upstart"
  },
  {
    "id": "_webmaster.92564",
    "source": "Can I start a Microdata after  and end the same just before ? <eos> I want to use itemscope Website. Can I start it just after <head> and end it just before </body>?For Website itemscope, which itemprop should I use to define the logo for the Website?",
    "target": "microdata;schema.org"
  },
  {
    "id": "_unix.323059",
    "source": "Keyboard issue with Ctrl button in X11 <eos> I've an issue. I think it started several month ago, suspiciously near the update to newest Fedora version. I've used to blame this on hardware, however when I've attached USB keyboard to my laptop (which I've only managed couple of days ago), issues still prevailed, so I think it might be somehow a software issue.Issue:When I press Ctrl button, nothing happens. E.g., it is not being sent to windows. however, if I chain-press buttons (e.g. ctrl-t, etc), it works. also if I first press Alt, and then press Ctrl, and then release Alt, Ctrl keypress is being sent to the applications.xev log for the issue:With only Ctrl, only this happens: (doesn't matter left or right ctrl)https://paste.kde.org/p1rwqrgsrAs you can see, there is NO KeyPress event, nor KeyRelease event.With Alt-Ctrl-Release Alt sequence, this happens:https://paste.kde.org/pbqg6vk9sAs you can see, everything is as expected. What can be the issue behind this? More importantly, what are my options to fix that?software details: fedora desktop stable latest, gnome flavor. all system configs are default.",
    "target": "x11;keyboard"
  },
  {
    "id": "_unix.144097",
    "source": "Converting and rescaling a lot of png images to jpeg <eos> I have a lot of .png images in a folder. Is there a command (or software) that can convert all them to .jpg and (simultaneously) rescale the created .jpg files to 25% of their original size?",
    "target": "scripting;conversion;images"
  },
  {
    "id": "_codereview.147505",
    "source": "Iterative counting change implementation in mit-scheme <eos> Here is my iterative implementation of the Counting change example in SICP. Please note that I'm a beginner, which means I only know the basic syntax for the time being.Requirement:How many different ways can we make change of $ 1.00, given  half-dollars, quarters, dimes, nickels, and pennies? More generally,  can we write a procedure to compute the number of ways to change any  given amount of money?Code:(define (count-change-iterative amount)  ;; penny is not in the signiture, bacause it equals (- amount  ;;                                                     (* half-dollar 50)  ;;                                                     (* quarter 25)  ;;                                                     (* dime 10)  ;;                                                     (* nickeli 5))  (define (count-iter half-dollar quarter dime nickeli)    (cond ((> (* half-dollar 50) amount)           0)          ((> (+ (* half-dollar 50)                 (* quarter 25)) amount)           (count-iter (+ half-dollar 1) 0 0 0))          ((> (+ (* half-dollar 50)                 (* quarter 25)                 (* dime 10)) amount)           (count-iter half-dollar (+ quarter 1) 0 0))          ((> (+ (* half-dollar 50)                 (* quarter 25)                 (* dime 10)                 (* nickeli 5)) amount)           (count-iter half-dollar quarter (+ dime 1) 0))          (else (+ 1                   (count-iter half-dollar quarter dime (+ nickeli 1))))))  (count-iter 0 0 0 0))If you run (count-change-iterative 100), it would tell you 292.I think this is the best scheme code I've written by now. How can I improve it?",
    "target": "beginner;combinatorics;scheme;iteration;sicp"
  },
  {
    "id": "_datascience.15956",
    "source": "Feeding data to Xgboost for recomender system <eos> I am using xgboost for a recommender system. There are 3-4 recommended content on each page. My data consists of columns like page_id and advertisement_id. Currently for every page_id, there are 3-4 rows of advertisement_id in data. Xgboost then gives me the probability of likelihood of an ad being clicked.It is known that one content(advertisement_id) from each page(page_id) is definitely clicked. I want to leverage this fact while training xgboost. How can I tell xgboost that one ad_id from each page_id is definitely clicked?Can this be done somehow by using a vector of advertisement_id for each row of page_id? ",
    "target": "xgboost;recommender system"
  },
  {
    "id": "_softwareengineering.333525",
    "source": "Best choice of SDLC <eos> I am studying SDLC models from a book. While attempting the exercise questions, I found these questions:What is the best choice among process models to address tight schedules and cost of the software precisely?What should be the best choice among different process models for development of any general software, such as library information system or inventory management system?What are the best best areas of application of V-shape model?Based on what I've learned, I think the answers are:Spiral model. In this model risk analysis is done repeatedly at the start of any iteration.I am not sure if we can have a generalized model for a general software. The most generalized model according to my learning is Waterfall as it has phases applicable to almost all types of software. But again it has its own limitations.I can't think of applications where V-model is the best as it too is an extension of Waterfall model and is not considered to be practical.Please correct me if I am wrong in answering these questions.",
    "target": "development process;sdlc"
  },
  {
    "id": "_softwareengineering.236688",
    "source": "Ensuring non conflicting components in a modular system <eos> So lets say we are creating a simple modular system framework.The bare bones might be the user management. But we want things like the Page Manager, the Blog, the Image Gallery to all be optional components.So a developer could install the Page Manager to allow their client to add a static home page and about page with content they can easily edit with a wysiwyg editor.The developer could then also install the Blog component to allow the client to add blog entries.The developer could then also install the Gallery component to allow the client to show off a bunch of images.The thing is, all these components are designed to be independent, so how do we go about ensuring they don't clash? E.g. ensuring the client doesn't create a /gallery page with the Page Manager and then wonder why the gallery stopped working, or the same issue with the Blog component, assuming we allow the users to customize the URL structure of the blog (because remember, the Page Manager doesn't necessarily have to be there, so we might not wan't our blog posts to be Date/Title formatted), likewise our clients aren't always going to be happy to have their pages under pages/title formatting.My core question here is, when building a modular system how to we ensure that the modules don't conflict without restricting functionality?Do we just leave it up to the clients/developer using the modules to ensure they get setup in a way that does not conflict?",
    "target": "design;php;architecture;cms;modules"
  },
  {
    "id": "_unix.299971",
    "source": "Find And Delete <eos> I want to find and delete first 10 largest files. Below is the command to find out 10 largest files.du -a * | sort -n -r | head -n 10",
    "target": "command line;files;rm"
  },
  {
    "id": "_vi.5351",
    "source": "Color Configuration in xterm <eos> I have been using NVIM on Ubuntu machine for about 3 month now, and like most noobs started with gnome terminal, I would like to graduate to plain xterm, but having trouble with the color in xterm.  Below, on the left is the gnome terminal and on the right is the xterm:Below is my xterm configuration:File ~/.xinitrc contents[[ -f ~/.Xresources ]] && xrdb -merge -I$HOME ~/.XresourcesFile ~/.Xresources contentsxterm*faceName: Ubuntu Mono for Powerlinexterm*faceSize: 11xterm*loginshell: truexterm*savelines: 16384! double-click to select whole URLs :Dxterm*charClass: 33:48,36-47:48,58-59:48,61:48,63-64:48,95:48,126:48*customization: -colorXTerm*termName:  xterm-256colorxterm*rightScrollBar: falsexterm*ScrollBar: falseXTerm*selectToClipboard: true! hard contrast: *background: #1d2021*background: #282828! soft contrast: *background: #32302f*foreground: #ebdbb2! Black + DarkGrey*color0:  #282828*color8:  #928374! DarkRed + Red*color1:  #cc241d*color9:  #fb4934! DarkGreen + Green*color2:  #98971a*color10: #b8bb26! DarkYellow + Yellow*color3:  #d79921*color11: #fabd2f! DarkBlue + Blue*color4:  #458588*color12: #83a598! DarkMagenta + Magenta*color5:  #b16286*color13: #d3869b! DarkCyan + Cyan*color6:  #689d6a*color14: #8ec07c! LightGrey + White*color7:  #a89984*color15: #ebdbb2In the xterm running the 256color.pl script show following:It seems like this is all that I need.  Am I missing something?  Also my configs can be found at:https://github.com/sittim/configsNOTE:  I use nvim, so for configuration look at the .nvimrc, but doing some testing the colours are the same for NVIM and VIM.",
    "target": "colorscheme"
  },
  {
    "id": "_cstheory.17657",
    "source": "Syntactic Complexity Class ${\\bf X}$ such that ${\\bf PP} \\subseteq {\\bf X} \\subseteq {\\bf PSPACE}$ <eos> It is known that some (non-relativized) syntactic complexity classes between ${\\bf P}$ and ${\\bf PSPACE}$ have the following property, ${\\bf P} \\subseteq {\\bf CoNP} \\subseteq {\\bf US} \\subseteq {\\bf C_=P} \\subseteq {\\bf PP} \\subseteq {\\bf PSPACE}$. I am wondering if there exists a (non-relativized) syntactic complexity class ${\\bf X}$ such that ${\\bf PP} \\subseteq {\\bf X} \\subseteq {\\bf PSPACE}$? What are the implications of existence or non-existence of complexity class ${\\bf X}$ ?  ",
    "target": "cc.complexity theory;complexity classes"
  },
  {
    "id": "_unix.29418",
    "source": "What are the proper tools to setup a remote compilation and running (something like ideone)? <eos> I'm trying to achieve similar functionality in a server for community programming and I've drafted this to wrap up another take on oneide's functions:From a Perl CGI I build a script like this (not even pseudocode):compiler_response = timeout (params) compiler (params)result = timeout compiledprogram (params)save result in databaseI think timeout is the tool I need to restrain the program from executing or compiling more than X seconds, The problem I have is that I need to limit the compiled program from writing to anything other than STDOUT or reading from anything other than STDIN.  Also I need to limit the size of the program to a certain limit, 128KB for example, and the ammount of RAM it can use, 64 MB for example.What are the proper tools to do this from bash? Thanks in advance.",
    "target": "bash;scripting;process management"
  },
  {
    "id": "_unix.291443",
    "source": "How to update steam from command line? <eos> Is there a quick way to update steam from the command line?  I would prefer to update steam without a GUI running so it can be done in the background (headless).",
    "target": "steam"
  },
  {
    "id": "_unix.307497",
    "source": "GNOME: disable sleep on lid close <eos> Is it possible to stop my laptop going to sleep when I close the lid?GNOME 3.20, Fedora 24.My laptop does not reliably wake from sleep.  (It happens to be a hardware issue... I think I basically killed it while trying to replace a wifi card.  But I want to keep using it for a while longer).",
    "target": "gnome;suspend;laptop"
  },
  {
    "id": "_webmaster.85724",
    "source": "Impact of Blogger's country level redirect on traffic and ranking <eos> As many of you know blogger displays different URL for the same blog in the different country. Apart from so many domains, do you see any impact on traffic and ranking? I read that it does affect that as link juice, social counts are lost, but there is no official word on this. Please share if you have any experience. ",
    "target": "blogger"
  },
  {
    "id": "_opensource.4478",
    "source": "Does the license of jaxb apply to the java class files it autogenerated? <eos> Each generated java file has this header comments// This file was generated by the JavaTM Architecture for XML Binding(JAXB) Reference Implementation, v2.2.8-b130911.1802 // See <a href=http://java.sun.com/xml/jaxb>http://java.sun.com/xml/jaxb</a> // Any modifications to this file will be lost upon recompilation of the source schema. whole scenario:  xml schema(input) -> jaxb library -> java class(output) Jaxb generates java class files based out of the input given to them via xml schema file.The generated class file has the above mentioned comments on the top. Rest of the lines contains normal java code that is generated as per the inputs defined in the xml schema.There is no comments related to license apart from the above mentioned.jaxb has dual license cddl + lgplI am wondering whether the license of jaxb applies to my generated files as well?",
    "target": "java"
  },
  {
    "id": "_codereview.97095",
    "source": "Function that check's file type based on certain keywords <eos> I have a function that breaks up a source file and checks each token against a keyword list to determine whether its a particular file type. How can I improve this function? Tokenization is a class that contains a function to break up the source code.public static boolean validationTypeOfSQL(String sourceFile, Tokenization tokenization,ArrayList<String> uniqueKeywordList) {    ArrayList<Token> createSourceCodeTokens = tokenization.createSourceCodeTokens(sourceFile);    for (Token x : createSourceCodeTokens) {        String smallerTokens[] = tokenization.tokenToSmallerToken(x.getToken());        for (String smallerTOkenValue : smallerTokens) {            Boolean result = smallerTOkenValue.contains(,);            if (result == true) {                String[] tokenSplit = smallerTOkenValue.split(,);                for (String ts : tokenSplit) {                    for (String t : uniqueKeywordList) {                        if (t.toLowerCase().equals(ts.toLowerCase().replace((, ).replace(,, ).replace(), ).replace(\\t, ))) {                            // System.out.println(This is a mysql file Mysql);                            return true;                        }                    }                }            }            else {                for (String uniqueKeyword : uniqueKeywordList) {                    if (uniqueKeyword.toLowerCase().equals(smallerTOkenValue.toLowerCase().replace((, ).replace(,, ).replace(), )))                     {                        return true;                    }                }            }        }    }    return false;}",
    "target": "java;performance;strings;parsing"
  },
  {
    "id": "_webmaster.13322",
    "source": "Need metrics for expectations/targets <eos> After our relaunch, we are wanting to find some standard metrics for our first year of performance. We can compare our numbers to last year and set our targets and expectations, but we would like to find an industry standard for B2B websites in Year 1 - whether as a new site or a relaunch. Is there a way to find that information? ",
    "target": "metrics"
  },
  {
    "id": "_unix.140923",
    "source": "Amplify quiet passages in an mp3 file <eos> I have an mp3 file where is a dialog with two voices and oneof the voices is very quiet.Is there a command or application that is able the detect thequiet passages and amplify them? The two voices are alternating.I already tried to do it manually with Audacity but this is verytime-consuming job.",
    "target": "command line;audio;application"
  },
  {
    "id": "_unix.358991",
    "source": "Use both libinput ClickMethod options : two fingers and right button <eos> I'm using Ubuntu Gnome 17.04 (gnome 24), with libinput drivers for touchpad, and I want to be able to right click using both methods : two fingers click, and click on the bottom right of the touchpad.My touchpad id is ELAN1300:00 04F3:3028 TouchpadThe command xinput list-props 12 | grep Click gives me libinput Click Methods Available (294): 1, 1libinput Click Method Enabled (295):    0, 1The 0, 1 option corresponds to the two fingers click, and the 1, 0 corresponds to the bottom right click. But I can set only those two options : when I try xinput set-prop 12 295 1, 1, I get X Error of failed request:  BadValue (integer parameter out of range for operation)  Major opcode of failed request:  131 (XInputExtension)  Minor opcode of failed request:  57 ()  Value in failed request:  0x127  Serial number of failed request:  19  Current serial number in output stream:  20Is it possible to use the two options with my touchpad? ",
    "target": "drivers;touchpad;xinput;libinput"
  },
  {
    "id": "_softwareengineering.202601",
    "source": "Make a flowchart to demonstrate closure behavior <eos> I saw below test question the other day in which the authors used a flowchart to represent the logic of loops, and I got to thinking it would be interesting to do this with some more complex logic. For example, the closure in this immediately-invoked function expression (IIFE) sort of boggles me:while (i <= qty_of_gets) {    // needs an IIFE    (function(i) {        promise = promise.then(function(){            return $.get(queries/html/ + product_id + i + .php);        });    }(i++));                       }I wonder if seeing a flowchart representation of what happens in it could be more elucidating. Could such a thing be done? Would it be helpful, or just messy? I haven't the foggiest clue where to start, but thought maybe someone would like to take a stab. Probably all the ajax could go and it could just be a simple return within the IIFE.",
    "target": "javascript;programming practices;closures;flowchart"
  },
  {
    "id": "_reverseengineering.11087",
    "source": "How to dynamically load address of USER32.DLL in shellcode? <eos> Assuming I'm injecting a shellcode into a Windows GUI application, I know I could:  Gets kernel32.dll base address through the PEB (Process Environment Block);  Finds address of LoadLibrary;  Call LoadLibrary(user32.dll);  Finally call GetProcAddress.This is the classic way and that's what I would do, however I'd like to know if there's a better/improved/faster/clever/different/smaller or simpler way to do this.Any ideas?",
    "target": "windows;shellcode"
  },
  {
    "id": "_cstheory.2637",
    "source": "Weighted Hamming distance <eos> Basically my question is, what kind of geometry do we get if we use a weighted Hamming distance. This is not necessarily Theoretical Computer Science but I think similar things come up sometimes, for instance in randomness extraction. Define:$d(x,y)=$ the Hamming distance between binary strings $x$ and $y$ of length $n$, $=$ the cardinality of $\\\\{k: x(k)\\ne y(k)\\\\}$. For a set of strings $A$, $d(x,A)=\\min \\\\{ d(x,y): y\\in A\\\\}$.The $r$-fold boundary of $A\\subseteq \\\\{0,1\\\\}^n$ is$$\\\\{x\\in\\\\{0,1\\\\}^n: 0 < d(x,A)\\le r\\\\}.$$Balls centered at $0$ are given by$$ B(p)=\\\\{x: d(x,0)\\le p\\\\}, $$where $0$ is the string of $n$ many zeroes.A Hamming-sphere is a set $H$ with $B(p)\\subseteq H\\subseteq B(p+1)$. (So it's more like a ball than a sphere, but this is the standard terminology...)Now, Harper in 1966 showed that for each $k$, $n$, $r$, one can find a Hamming-sphere that has minimal $r$-fold boundary among sets of cardinality $k$ in $\\\\{0,1\\\\}^n$. So a ball is a set having minimal boundary -- just like in Euclidean space.The cardinality of $B(p)$ is ${n\\choose 0}+\\cdots {n\\choose p}$. The $r$-fold boundary of $B(p)$ is just the set $B(p+r)\\setminus B(p)$, which then has cardinality ${n\\choose p+1}+\\cdots+{n\\choose p+r}$.So far, so good. But now suppose we replace $d$ by a different metric $D$: first let $d_j(x,y)$ be the Hamming distance between the prefixes of $x$ and $y$ of length $j$, and then$$ D(x,y)=\\max_{j\\le n}\\ \\frac{d_j(x,y)}{f(j) }$$where $0\\le f(j)\\le j$. (For example we could have $f(j)=\\sqrt{j}$, or $f(j)=j/\\log j$.) This is supposed to make $D(x,y)$ small if the differences of $x$ and $y$ do not clump together at small values of $j$.  QuestionsIs the minimum $r$-fold boundary (under $D$) realized by a $D$-ball? Is there a better definition of $D$?Under the metric $D$, what's the minimum size of the $r$-fold boundary of a subset of $\\\\{0,1\\\\}^n$ having cardinality $k$? (A reasonable lower bound would be nice.)(Cross-posted on MathOverflow).",
    "target": "co.combinatorics;randomness"
  },
  {
    "id": "_softwareengineering.109281",
    "source": "How important is multithreading in the current software industry? <eos> I have close to 3 years experience writing web applications in Java using MVC frameworks (like struts). I have never written multithreaded code till now though I have written code for major retail chains.I get a few questions on multithreading during interviews and I answer them usually (mostly simple questions). This left me wondering how important is Multithreading in the current industry scenario ?",
    "target": "multithreading"
  },
  {
    "id": "_softwareengineering.326238",
    "source": "How can I maintain a database record of an entity that belongs to several categories of another entity, per year, per season, etc <eos> I am building a kind of School Management System.I want to be managing the database records of things like assessment, term/season, academic years. every info must belong to a particular academic year so at anytime the admin can query for info pertaining to a particular year. Assessment too can belong not only to an academic year, but term, class, subject, student too.I have been figuring out on how to develop a scalable database schema for this. I thought of having separate databases for each year, or combine them each on a very different table but how to properly reference each assessment down to a particular student, subject, class, term and year is still my confusion over the whole matter.",
    "target": "php;web development;database design;relational database;scalability"
  },
  {
    "id": "_unix.24591",
    "source": "Controlling users' default printer as an administrator <eos> What are the necessary steps to change the default printer for individual users on a reasonably recent Linux system using CUPS? (i.e. not the system-wide default)The CUPS lpr manpage indicates that setting the PRINTER environment variable is looked to first  by the printing system. But does this also affect the default printer for GNOME & KDE applications?Does this also override whatever the user has changed by going to, for instance, the 'Printing' setup application in Ubuntu? Or the equivalent in RHED?How can I cover all my bases?",
    "target": "linux;printing;cups"
  },
  {
    "id": "_webmaster.15463",
    "source": "How could a web developer go about offering free hosting to clients that buy a website? <eos> Lots of web design companies offer a year free hosting service when purchasing a website. How do they offer this service? Do these companies use their own server to host sites or do they buy a years hosting from somewhere and use that?I understand that not all companies would use the same method, but in general, how would it be done?Thanks for any answers :)",
    "target": "web hosting;server;web development"
  },
  {
    "id": "_datascience.22549",
    "source": "feature scoring <eos> I am preparing my data to be training data so that I woud bbe able too use it with some algorithms of classifications and I have to score some fetures depending on its value, What is the best way to do it with python",
    "target": "machine learning;python;feature engineering;scoring"
  },
  {
    "id": "_cs.45764",
    "source": "Help interpreting this deadlock question <eos> I have this assignment question but I am a bit unsure how to go about answering it. The question is as follows and accompanied by the image below: Three processes are competing for six resources labelled A to F as shownbelow.Using a resource allocation graph, show the possibility of a deadlock inthe implementation above.I know how to do the graph but what I am struggling to understand is, do I take the Release(); methods into consideration or only the Get(); methods. And also, would P0() access resources A, B and C first or will each process run simultaneously meaning P0() access resource A, P1() access resource D and P2() access resource C, and then the second set of Get() methods are requested simultaneously? Lastly it does not specify how many instances (dots) are in each resource, is there any indication as to how to determine/go about working with this? As soon as I can clear up these misunderstandings I can draw the diagram",
    "target": "deadlocks;resource allocation"
  },
  {
    "id": "_unix.43293",
    "source": "Backup and synchronization <eos> I want to synchronize my personal document repository between my different computers in my home. Today this folder is under a dedicated partition of the hard drive of a dual boot workstation.My configuration is the following one:Dual boot Workstation running Ubuntu 11 and windows Xp (the documents are simply shared using the dedicated partition)Laptop running Ubuntu 12.04 (Today no access to the documents)A freebox with an external hard drive pluged to itWhat I want is to be able to synchronize this document folder also with the laptop and in addition to have a backup of this on the hard drive attached to the freebox.What tools should I use for this (rsync, unison, others?)",
    "target": "linux;rsync;synchronization;unison"
  },
  {
    "id": "_webmaster.98594",
    "source": "Htaccess redirect a page with a query string hosted on a temporary IP address? <eos> I have a site that was temporarily set up as 111.222.333.444/~mysite because the real URL was not ready. 111.222.333.444/~mysite/?page_id=123 was a valid page on that site. My site is live now. I no longer want or need to use 111.222.333.444/~mysite to access the site.However Google has indexed a search for a term on page ?page_id=123 as 111.222.333.444/~mysite/?page_id=123. But ?page_id=123 no longer exists. It's now on a new page, and I want to redirect Google's link to www.example.com/newpageThe closest I have come to implemeting this redirect is:RewriteCond %{HTTP_HOST}  ^111\\222\\.333\\.444$ [NC]RewriteCond %{QUERY_STRING}  ^\\?page_id=123$ [NC]RewriteRule ^~mysite/$ //www.example.com/newpage [R=301,NE,NC,L]But this doesn't work, and gives me an internal server error.I have also tried:Redirect 301 /?page_id=195 /newpageBut that had no effect.  Can anyone suggest how to do this? I don't have a problem redirecting single pages, but the temporary/alternate URL with the IP address is throwing me. ",
    "target": "htaccess;url rewriting"
  },
  {
    "id": "_unix.316138",
    "source": "How to get gcc-4.7 to /usr/bin/gcc-4.7 as second gcc in Debian Jessie? <eos> I would like to keep my gcc 4.9 but let Matlab use gcc 4.7 because Stable Debian does not support 4.7, as observed in the thread Debian Jessie: Why gcc-4.7 conflicts with gcc-4.8? I do the following but nothing in Jessie because Matlab 2016 wants gcc 4.7.x# https://packages.debian.org/search?keywords=gcc-4.7apt-cache search gcc-4.7 However, I think apt-get is not the way to go because I just want to get gcc-4.7 in my system for Matlab, not for any other purpose. Example of the warning when using wrong gcc in MatlabMEX completed successfully.Building with 'gcc'.Warning: You are using gcc version '4.9.2'. The version of gcc is not supported. The versioncurrently supported with MEX is '4.7.x'. For a list of currently supported compilers see:http://www.mathworks.com/support/compilers/current_release. OS: Debian 8.5 64 bitLinux kernel: 4.6 of backportsHardware: Asus Zenbook UX303UA     ",
    "target": "debian;gcc;matlab"
  },
  {
    "id": "_reverseengineering.2830",
    "source": "Reversing DLink DIR100 firmware <eos> I'm trying to extract this firmware but I'm running into some issues. The first lecture of the firmware with binwalk shows this:DECIMAL     HEX         DESCRIPTION-------------------------------------------------------------------------------------------------------------------48          0x30        LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 992240 bytes275832      0x43578     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 65011 bytes312165      0x4C365     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 6425 bytes314338      0x4CBE2     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 6198 bytes316542      0x4D47E     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 11645 bytes319496      0x4E008     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 9923 bytes322366      0x4EB3E     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 3981 bytes323721      0x4F089     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 1269 bytes324228      0x4F284     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 9785 bytes327024      0x4FD70     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 9717 bytes329754      0x5081A     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 9957 bytes332630      0x51356     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 4544 bytes334066      0x518F2     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 378 bytes334305      0x519E1     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 1019 bytes334787      0x51BC3     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 12756 bytes338395      0x529DB     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 16497 bytes343482      0x53DBA     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 11019 bytes347416      0x54D18     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 39577 bytes358366      0x577DE     JPEG image data, JFIF standard  1.02358907      0x579FB     JPEG image data, JFIF standard  1.02359442      0x57C12     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 1787 bytes361070      0x5826E     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 893 bytes361902      0x585AE     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 637 bytes362528      0x58820     JPEG image data, JFIF standard  1.02363522      0x58C02     JPEG image data, JFIF standard  1.02364963      0x591A3     JPEG image data, JFIF standard  1.01376049      0x5BCF1     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 683 bytes376714      0x5BF8A     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 761 bytes377462      0x5C276     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 225 bytes377638      0x5C326     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 4146 bytes378953      0x5C849     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 1487 bytes379723      0x5CB4B     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 2240 bytes380729      0x5CF39     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 1527 bytes381510      0x5D246     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 8294 bytes384148      0x5DC94     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 10412 bytes385299      0x5E113     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 16812 bytes389806      0x5F2AE     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 9294 bytes391417      0x5F8F9     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 9108 bytes392764      0x5FE3C     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 4796 bytes393633      0x601A1     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 3710 bytes394440      0x604C8     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 7870 bytes395948      0x60AAC     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 10764 bytes398896      0x61630     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 6804 bytes400960      0x61E40     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 2135 bytes401785      0x62179     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 2864 bytes402878      0x625BE     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 3747 bytes404192      0x62AE0     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 2776 bytes405196      0x62ECC     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 6761 bytes407148      0x6366C     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 1582 bytes407859      0x63933     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 6849 bytes409864      0x64108     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 4678 bytes411440      0x64730     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 11297 bytes414011      0x6513B     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 3990 bytes415534      0x6572E     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 12540 bytes418894      0x6644E     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 3623 bytes420239      0x6698F     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 13366 bytes423782      0x67766     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 5498 bytes425717      0x67EF5     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 1524 bytes426450      0x681D2     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 28728 bytes434580      0x6A194     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 18125 bytes439538      0x6B4F2     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 36719 bytes445116      0x6CABC     LZMA compressed data, properties: 0x5D, dictionary size: 33554432 bytes, uncompressed size: 1940 bytesChecking the hexdump code I found that binwalk detects the lzma magic number '5d 00' but I think that this is inconsistent and a false positive:root@kali:~/Desktop/Firmwares/DLink# cat hexdump.txt | grep '5d 00'00000030  5d 00 00 00 02 f0 23 0f  00 00 00 00 00 00 20 20  |].....#.......  |0000c7b0  f9 5d 00 0e e6 e7 55 ca  16 5f d1 c9 67 67 30 c7  |.]....U.._..gg0.|00049900  ac 00 5d 00 00 00 02 c9  1d 00 00 00 00 00 00 00  |..].............|0004a2c0  6e 93 3d d1 e8 e3 96 5a  f9 17 38 b1 28 5d 00 00  |n.=....Z..8.(]..|0004bb30  25 14 f9 96 26 85 58 20  18 07 b9 fa e3 5d 00 00  |%...&.X .....]..|0004c360  9f f6 e9 d8 28 5d 00 00  00 02 19 19 00 00 00 00  |....(]..........|0004cbe0  f6 20 5d 00 00 00 02 36  18 00 00 00 00 00 00 00  |. ]....6........|0004d470  3f 38 df 6f 97 98 4b 41  0d 83 14 d8 4d 00 5d 00  |?8.o..KA....M.].|0004e000  78 c4 bc c4 11 98 56 00  5d 00 00 00 02 c3 26 00  |x.....V.].....&.|0004eb30  e6 73 64 e2 bc fa 37 7a  11 0d 3c b1 d2 af 5d 00  |.sd...7z..<...].|0004f080  57 ad 80 5f 20 ef 40 0e  7c 5d 00 00 00 02 f5 04  |W.._ .@.|]......|0004f280  1a 1c ab 00 5d 00 00 00  02 39 26 00 00 00 00 00  |....]....9&.....|0004fd70  5d 00 00 00 02 f5 25 00  00 00 00 00 00 00 1e 12  |].....%.........|After this I browsed the hexdump and found some strings in 00000000 and 00042fa0:00000000  41 49 48 30 4c 0f c1 fb  80 00 01 00 00 04 2f 74  |AIH0L........./t|00042fa0  6e 23 00 00 41 49 48 30  4c 0f c1 fb 00 00 00 00  |n#..AIH0L.......|Googling for AIH0L I did not find anything useful and now I'm stuck.Other things I tried was to search bin img sqsh sq sh and other strings in the hexdump without result.Also the entropy analysis seems weird for me. Did anyone faced this issues or can figure out how to extract this?Regards.EDIT:Searching for filesystems 'fs' in the hexdump file I found a zfs header:t@kali:~/Desktop/Firmwares/DLink# cat hexdump.txt | grep zfs0000b990  65 a7 0c aa 7a 66 73 24  1e bc b6 e8 d7 c4 29 1a  |e...zfs$......).|I'm not sure wether this points to a real zfs or it's just a coincidence. I copied the firmware from that position to the end but the new file is not recognized and the binwalk lecture is the same as above.",
    "target": "firmware"
  },
  {
    "id": "_codereview.166022",
    "source": "Simulation of a mechanical arm <eos> The code that I am doing is to simulate a scenario where a mechanical arm search pieces closer and these pieces selected the mechanical arm leaves in a position defined closer.Clear[Global`*]BezierCircleArc[{x_,y_},r_,{1_,2_}]:= Module[{,p0,p1,p2,p3},  =4/3Tan[(2-1)/4];  p0={x,y}+r{Cos[1],Sin[1]};  p3={x,y}+r{Cos[2],Sin[2]};  p1=p0+ r{-Sin[1],Cos[1]};  p2=p3+ r{Sin[2],-Cos[2]};BezierCurve[{p0,p1,p2,p3}]]Initial positionpInitial={106.8,0};ArmlenghtInitialArm=90;arm={BezierCircleArc[{lenghtInitialArm+16.8,0},20,{2.57,3.72}],Line[{{0,12.5},{lenghtInitialArm,12.5},{lenghtInitialArm,12.5},{lenghtInitialArm,10.87}}],Line[{{0,-12.5},{lenghtInitialArm,-12.5},{lenghtInitialArm,-12.5},{lenghtInitialArm,-10.87}}],{EdgeForm[Black],GrayLevel[0.84],Disk[armCenter={0,0},18]},{EdgeForm[Black],GrayLevel[0.50],Disk[armCenter={0,0},6]}};Clawsclaws={EdgeForm[Black],GrayLevel[.84],FilledCurve[{BezierCircleArc[{lenghtInitialArm+16.8,0},rClaws=20,claw1a={0.8,2.9}],BezierCircleArc[{lenghtInitialArm-5,5.6},2.5,claw1b={6.03-2,2.9-2}][[;;,2;;]],BezierCircleArc[{lenghtInitialArm+16.8,0},25,Reverse@claw1a-2][[;;,2;;]],BezierCircleArc[{lenghtInitialArm+32.54,16.07},2.5,claw1c={0.8,-2.35}][[;;,2;;]]}]};Arm + Clawsrobot={GeometricTransformation[{arm,u=GeometricTransformation[claws,{RotationTransform[0Degree,{85,5.6}]}],GeometricTransformation[u,ReflectionTransform[{0,1},{85,0}]]},RotationTransform[initialPosition=0Degree,{0,0}]]};BoxespBox=6;recX1=160;recY1=-80;recX2=recX1+6rClaws+4espBox;recY2=-30;posPieces={{150,105},{32,220},{320,175}};posPiecesFinal={{recX1+espBox+rClaws,(recY1 + recY2)/2},{recX1+3 rClaws+espBox+5,(recY1 + recY2)/2},{recX1+5 rClaws+espBox+10,(recY1 + recY2)/2}};boxGoal={EdgeForm[{Thickness[0.005],Black}],White,Rectangle[{recX1,recY1},{recX2,recY2}]};pieces={EdgeForm[Black],RGBColor[0.35,0.30,0.25],Disk[posPieces[[1]],20],Disk[posPieces[[2]],20],Disk[posPieces[[3]],20]};piecesFinal={Dashed,EdgeForm[Red],White,Disk[posPiecesFinal[[1]],20],Disk[posPiecesFinal[[2]],20],Disk[posPiecesFinal[[3]],20]};The function below determines the shortest route that the arm mechanism must follow to perform this procedure.Route Logicf[pG_, pI_] := {pos =    Position[      EuclideanDistance[pI, Evaluate@pG[[#]]] & /@ Range[Length[pG]],      Min[EuclideanDistance[pI, Evaluate@pG[[#]]] & /@          Range[Length[pG]]]],  Extract[(EuclideanDistance[pI, Evaluate@pG[[#]]] & /@      Range[Length[pG]]), First@pos]};sol = Flatten[f[posPieces, pInitial]] // N;p1 = posPieces[[First[sol]]];posPieces = Drop[posPieces, {First[sol]}];f[pG_, pI_] := {pos =    Position[      EuclideanDistance[pI, Evaluate@pG[[#]]] & /@ Range[Length[pG]],      Min[EuclideanDistance[pI, Evaluate@pG[[#]]] & /@          Range[Length[pG]]]],  Extract[(EuclideanDistance[pI, Evaluate@pG[[#]]] & /@      Range[Length[pG]]), First@pos]};sol = Flatten[f[posPiecesFinal, p1]] // N;p2 = posPiecesFinal[[First[sol]]];posPiecesFinal = Drop[posPiecesFinal, {First[sol]}];f[pG_, pI_] := {pos =    Position[      EuclideanDistance[pI, Evaluate@pG[[#]]] & /@ Range[Length[pG]],      Min[EuclideanDistance[pI, Evaluate@pG[[#]]] & /@          Range[Length[pG]]]],  Extract[(EuclideanDistance[pI, Evaluate@pG[[#]]] & /@      Range[Length[pG]]), First@pos]};sol = Flatten[f[posPieces, p2]] // N;p3 = posPieces[[First[sol]]];posPieces = Drop[posPieces, {First[sol]}];f[pG_, pI_] := {pos =    Position[      EuclideanDistance[pI, Evaluate@pG[[#]]] & /@ Range[Length[pG]],      Min[EuclideanDistance[pI, Evaluate@pG[[#]]] & /@          Range[Length[pG]]]],  Extract[(EuclideanDistance[pI, Evaluate@pG[[#]]] & /@      Range[Length[pG]]), First@pos]};sol = Flatten[f[posPiecesFinal, p3]] // N;p4 = posPiecesFinal[[First[sol]]];posPiecesFinal = Drop[posPiecesFinal, {First[sol]}];f[pG_, pI_] := {pos =    Position[      EuclideanDistance[pI, Evaluate@pG[[#]]] & /@ Range[Length[pG]],      Min[EuclideanDistance[pI, Evaluate@pG[[#]]] & /@          Range[Length[pG]]]],  Extract[(EuclideanDistance[pI, Evaluate@pG[[#]]] & /@      Range[Length[pG]]), First@pos]};sol = Flatten[f[posPieces, p4]] // N;p5 = posPieces[[First[sol]]];posPieces = Drop[posPieces, {First[sol]}];f[pG_, pI_] := {pos =    Position[      EuclideanDistance[pI, Evaluate@pG[[#]]] & /@ Range[Length[pG]],      Min[EuclideanDistance[pI, Evaluate@pG[[#]]] & /@          Range[Length[pG]]]],  Extract[(EuclideanDistance[pI, Evaluate@pG[[#]]] & /@      Range[Length[pG]]), First@pos]};sol = Flatten[f[posPiecesFinal, p5]] // N;p6 = posPiecesFinal[[First[sol]]];posPiecesFinal = Drop[posPiecesFinal, {First[sol]}];positions = {pInitial, p1, p2, p3, p4, p5, p6};This graphic serves basically to illustrate the route to be coveredgArrow = {Red, Arrowheads[0.05], Thickness[0.008], Arrow[positions]};Graphics[{boxGoal, pieces, robot, piecesFinal, gArrow}, Axes -> True,  ImageSize -> 500, Background -> White];With the function below I determine the angles needed to perform the routeangList[p_] := (p - armCenter)angList = ArcTan @@ angList[#] & /@ positions/Degree // N;numberTotalFrames = 300;framesClaws = 4;numberFramesStopped = framesClaws*(Length[angList] - 1);framesStoppedAng = Transpose[Table[Rest@angList, framesClaws]];restFrames = numberTotalFrames - numberFramesStopped;diffAng = Differences[angList];accDiffAng = Accumulate@Abs@diffAng;sumAllAng = Last@accDiffAng;quantRestFrames =    Round[N[Abs@diffAng[[#]]/Last@accDiffAng]*restFrames] & /@        Range[Length[accDiffAng]];subListsAng =    Map[Most,      Subdivide @@@          Transpose@{Most@angList, Rest@angList, quantRestFrames}];angListAnim = Flatten[Riffle[subListsAng, framesStoppedAng]];ListLinePlot[angListAnim, PlotTheme -> Monochrome,  ImageSize -> {1200, 800},  AxesLabel -> {HoldForm[Frames], HoldForm[Angles]},  PlotLabel -> HoldForm[Angles x Frames],  LabelStyle -> {FontFamily -> Arial, 12, GrayLevel[0]}]With the function below I determine the lenghts needed to perform the routeplenghtArm =    EuclideanDistance[      positions[[#]], {0, 0}] - (106.8 - (lenghtInitialArm = 90)) & /@        Range[Length[positions]] // N;quantFramesLenghtArm = quantRestFrames;subListsLenghtArm =    Map[Most,      Subdivide @@@          Transpose@{Most@plenghtArm, Rest@plenghtArm,            quantFramesLenghtArm}];framesStoppedLenghtArm =    Transpose[Table[Rest@plenghtArm, framesClaws]];plenghtArmAnim =    Flatten[Riffle[subListsLenghtArm, framesStoppedLenghtArm]];ListLinePlot[plenghtArmAnim, PlotTheme -> Monochrome,  ImageSize -> {1200, 800},  AxesLabel -> {HoldForm[Frames], HoldForm[Length]},  PlotLabel -> HoldForm[Length x Frames],  LabelStyle -> {FontFamily -> Arial, 12, GrayLevel[0]}]Here I present my solution for the arm mechanic collection the pieces and can put this pieces in place appropriateFlatten @@    Table[Graphics[{boxGoal, pieces,      piecesFinal,      {GeometricTransformation[{{BezierCircleArc[{plenghtArmAnim[[#]] +          16.8, 0}, 20, {2.57, 3.72}],        Line[{{0, 12.5}, {plenghtArmAnim[[#]],          12.5}, {plenghtArmAnim[[#]],          12.5}, {plenghtArmAnim[[#]], 10.87}}],        Line[{{0, -12.5}, {plenghtArmAnim[[#]], -12.5},          {plenghtArmAnim[[#]], -12.5}, {plenghtArmAnim[[#]], -10.87}}],        {EdgeForm[Black], GrayLevel[0.84],          Disk[armCenter = {0, 0}, 18]}, {EdgeForm[Black],          GrayLevel[0.50], Disk[armCenter = {0, 0}, 6]}},        u = GeometricTransformation[{EdgeForm[Black],          GrayLevel[0.84],          FilledCurve[{BezierCircleArc[{plenghtArmAnim[[#]] + 16.8,            0}, rClaws = 20, claw1a = {0.8, 2.9}],            BezierCircleArc[{plenghtArmAnim[[#]] - 5, 5.6}, 2.5,              claw1b = {6.03 - 2*Pi, 2.9 - 2*Pi}][[1 ;; All,                2 ;; All]],            BezierCircleArc[{plenghtArmAnim[[#]] + 16.8, 0}, 25,              Reverse[claw1a] - 2*Pi][[1 ;; All, 2 ;; All]],            BezierCircleArc[{plenghtArmAnim[[#]] + 32.54, 16.07},              2.5, claw1c = {0.8, -2.35}][[1 ;; All,                2 ;; All]]}]}, {RotationTransform[          0 Degree, {85, 5.6}]}],        GeometricTransformation[u,          ReflectionTransform[{0, 1}, {85, 0}]]},        RotationTransform[          initialPosition = angListAnim[[#]] Degree, {0, 0}]]}},      Axes -> True, ImageSize -> 500, Background -> White,      PlotRange -> {{400, -40}, {-90, 250}}], 1] & /@ Range[300];The question would be as follows:Could someone propose some improvement to shorten this code?",
    "target": "performance;wolfram mathematica"
  },
  {
    "id": "_webmaster.23525",
    "source": "Will google remove the old caches if noarchive is added to robots.txt <eos> If you want google's cache of your site to remain unchanged is it a good idea to add noarchive to robots.txt? Or will this wipe out your caches?",
    "target": "google;robots.txt"
  },
  {
    "id": "_softwareengineering.204342",
    "source": "Choosing the language to build an app in based on hiring market vs performance and maintainability <eos> I'm facing a choice of whether to start building Haskell components for a certain production app that is all done in Ruby.I'm leaning toward Haskell for several reasons, primarily speed (compiled Haskell is like 4-8x faster), greater transparency (via Haskell type system), and safer refactorability (type system).  I've written a few open source and production programs in Haskell already and enjoy writing it very much.Feasibility is not an issue. I've played around with the Haskell Snap web framework and database libraries like PostgreSQL.Simple and am satisfied that rewriting a Rails app and various backend programs with Haskell is feasible.The real issue is hiring programmers when we need to scale the dev team, or eventually handing off the programming responsibilities altogether. It's a lot easier to find programmers in Ruby than in Haskell. On the other hand, the Haskell community seems to be growing, and it's not too hard to train programmers to modify parts of a Haskell program if you approach it as a DSL (much like Ruby on Rails). The Haskell type system also seems to promise much safer collaboration than dynamic Ruby does.In his essay Beating the Averages (http://www.paulgraham.com/avg.html), Paul Graham argues that using a superior language can be a decisive advantage. But when does it make sense to forgo using a superior language in order to make it easier to add programmers to your team?",
    "target": "programming languages;teamwork;hiring;haskell"
  }
]