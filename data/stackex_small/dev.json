[
  {
    "id": "_unix.285646",
    "source": "Is X11 cross-linux-platform and free from platform quirks? <eos> Does X11 work across all linux operating systems? If I code a application that has an X11 window, will it look and operate the same across linux os's or will I have different tweaks I need to perform?Is there an alternative to X11 that is in c/c++ and low-level cross linux platform? *I'm aware of QT and GTK.  What is the lowest level linux graphical system/windowing system?",
    "target": "linux;x11"
  },
  {
    "id": "_softwareengineering.194582",
    "source": "How can one measure contributions to a project? <eos> Has anyone ever come across this problem? When you have a team of developers working on a project, how can you measure their contributions to said project? Is there a formal way of doing it? Number of commits? Number of bug fixes? Lines committed? Or maybe on a ticket basis? I'm trying to think of a workflow where a group of developers can work seamlessly interchanging tasks and at the end of the month, getting paid for they contributions (or merit if you will).I hope this question is not entirely out of place here, if it is, feel free to close it.",
    "target": "workflows;contribution;measurement"
  },
  {
    "id": "_unix.259111",
    "source": "key_read: type mismatch: encoding error <eos> Seeing very strange error on newly install CentOS7, I didn't create or touch any ssh-key. ~/.ssh/ directory is also empty. [john@server1 ~]$ ssh server1key_read: type mismatch: encoding errorkey_read: type mismatch: encoding errorjohn@server1's password:If i try ssh localhost i am not getting that error. what will be the issue? Update:[john@server1 ~]$ ssh -vvv server1OpenSSH_6.4, OpenSSL 1.0.1e-fips 11 Feb 2013debug1: Reading configuration data /etc/ssh/ssh_configdebug1: /etc/ssh/ssh_config line 49: Applying options for *debug2: ssh_connect: needpriv 0debug1: Connecting to server1 [10.1.1.10] port 22.debug1: Connection established.debug3: Incorrect RSA1 identifierdebug3: Could not load /home/john/.ssh/id_rsa as a RSA1 public keydebug1: identity file /home/john/.ssh/id_rsa type 1debug1: identity file /home/john/.ssh/id_rsa-cert type -1debug1: identity file /home/john/.ssh/id_dsa type -1debug1: identity file /home/john/.ssh/id_dsa-cert type -1debug1: identity file /home/john/.ssh/id_ecdsa type -1debug1: identity file /home/john/.ssh/id_ecdsa-cert type -1debug1: Enabling compatibility mode for protocol 2.0debug1: Local version string SSH-2.0-OpenSSH_6.4debug1: Remote protocol version 2.0, remote software version OpenSSH_6.4debug1: match: OpenSSH_6.4 pat OpenSSH*debug2: fd 3 setting O_NONBLOCKdebug3: load_hostkeys: loading entries for host server1 from file /home/john/.ssh/known_hostsdebug3: load_hostkeys: found key type ECDSA in file /home/john/.ssh/known_hosts:2debug3: load_hostkeys: loaded 1 keysdebug3: load_hostkeys: loading entries for host server1 from file /etc/ssh/ssh_known_hostskey_read: type mismatch: encoding errordebug3: load_hostkeys: loaded 0 keys...... omitted some output...debug2: kex_parse_kexinit: none,zlib@openssh.comdebug2: kex_parse_kexinit: none,zlib@openssh.comdebug2: kex_parse_kexinit:debug2: kex_parse_kexinit:debug2: kex_parse_kexinit: first_kex_follows 0debug2: kex_parse_kexinit: reserved 0debug2: mac_setup: found hmac-md5-etm@openssh.comdebug1: kex: server->client aes128-ctr hmac-md5-etm@openssh.com nonedebug2: mac_setup: found hmac-md5-etm@openssh.comdebug1: kex: client->server aes128-ctr hmac-md5-etm@openssh.com nonedebug1: sending SSH2_MSG_KEX_ECDH_INITdebug1: expecting SSH2_MSG_KEX_ECDH_REPLYdebug1: Server host key: ECDSA 45:9e:70:1d:89:49:d9:dd:ed:df:4b:b0:56:6e:11:31debug3: load_hostkeys: loading entries for host server1 from file /home/john/.ssh/known_hostsdebug3: load_hostkeys: found key type ECDSA in file /home/john/.ssh/known_hosts:2debug3: load_hostkeys: loaded 1 keysdebug3: load_hostkeys: loading entries for host server1 from file /etc/ssh/ssh_known_hostskey_read: type mismatch: encoding errordebug3: load_hostkeys: loaded 0 keysdebug3: load_hostkeys: loading entries for host 10.1.1.10 from file /home/john/.ssh/known_hostsdebug3: load_hostkeys: found key type ECDSA in file /home/john/.ssh/known_hosts:2debug3: load_hostkeys: loaded 1 keysdebug3: load_hostkeys: loading entries for host 10.1.1.10 from file /etc/ssh/ssh_known_hostskey_read: type mismatch: encoding errordebug3: load_hostkeys: loaded 0 keysdebug1: Host 'server1' is known and matches the ECDSA host key.debug1: Found key in /home/john/.ssh/known_hosts:2debug1: ssh_ecdsa_verify: signature correctAs per request here is the file output. $cat /etc/ssh/ssh_known_hostsserver1,server1,server1.example.com,10.1.1.10 ssh-dss AAAAB3NzaC1yc2EAAAADAQABAAABAQCjEZfdesyp4xtJslnXEvG0arhPAddsMFUmO/lbUoeT0p31QAnbfs3LvVc4EP/ziipJUiFZDaKeT3KB+4zmioIwR2pO67c9DDY4zTasVoZv1kL7EiHKYxNIjIMXhYMRm+MQBTiBJWW5NB9SRff/TQSBAnIcXqMZZYco1YO7b95XZR5fkO3LLE8Mr5LvuXwMNlzEu/+9vw69rxWbL+JnRJT2Ydv61h23bSL3reZ9ZvpEMVgF+DkgqxdBp9ao2GfTwLVx96E2/EnmWY2a/2KUlB9TwKGT7GI5VUcep1ia4esHid9wxXhjN/Iuw3k/VFzQSdTvIzg72DqkkPaBErxGJ83V",
    "target": "linux;ssh;key authentication"
  },
  {
    "id": "_softwareengineering.126936",
    "source": "What's an Elegant and OOP way to create a tree from arrays and render it as a nested UL <eos> I have a series of arrays which represent file system paths, so each next value is actually a directory deeper, for example:var a1 = [Desktop, Pictures, Summer 2011];is the equivalent of Desktop|-Pictures  |-Summer 2011I'm trying to find an elegant way to:Flatten/merge all the different arrays I have to come up with one object/dictionary/multi-dimensional-array.Parse the result and render a nested UL (html list) to the page which represents the hierarchy correctly.Write what I already have in a more 'OOP way'..I already have a working version:<!DOCTYPE html><html>    <head></head>    <body onload=init()>        <ul id=tree></ul>        <script>            var a = [ Desktop, Folder1,  InnerFolder1 ];            var b = [ Desktop, Folder1,  Inner 2 ];            var c = [ Documents, Folder 2, InnerFolder1, even deepper ];            var d = [ Something Else, Folder1,  Inner 2 ];            var all = [a, b, c, d];            var Tree = {};            var ul = document.getElementById(tree);            function init(){                for ( var i = 0; i < all.length; i++ ){                    addToTree(Tree, all[i] );                }                createList(Tree, ul);            }            //function from http://stackoverflow.com/questions/3663096/how-to-convert-array-to-tree            function addToTree(tree, array) {                for (var i = 0, length = array.length; i < length; i++) {                    tree = tree[ array[i] ] = tree[ array[i] ] || {};                }            }            function createList( obj, _pushTo  ){                for ( attr in obj ){                    var _doIHaveChildren = function ( ){                        for(var prop in obj[attr]) {                            if (obj[attr].hasOwnProperty(prop)) {                                return true;                            }                        }                        return false;                    }                    var li = document.createElement(li);                    li.id = attr.toString();                    li.innerHTML = attr.toString();                    if ( Tree.hasOwnProperty(attr) ){                        ul.appendChild(li);                    } else {                        _pushTo.appendChild(li);                    }                    if ( _doIHaveChildren() === true ){                        var ul2 = document.createElement(ul);                        li.appendChild(ul2);                    }                    createList( obj[attr], ul2 );                }            }        </script>    </body></html>Thanks!EDIT:I'm starting from strings which represent the paths i.e. Desktop/Pictures/Summer 2011 which are broken to arrays.",
    "target": "javascript;object oriented"
  },
  {
    "id": "_webapps.71506",
    "source": "Not receiving notifications when getting Likes on a comment on a page's post on Facebook <eos> When I receive Likes on my comment that I posted on the post of a page, I don't receive notifications. Where can I change these settings?",
    "target": "facebook"
  },
  {
    "id": "_webmaster.60834",
    "source": "Privacy concern to track every user actions in your website? <eos> We are building a system that track every user (logged in) actions, e.g. click, pageview, duration etc and store into a database.So all the user activities will be known and we are using them to create information our CRM so that we know more about our user, e.g. which products they have visited and how often they view that page.My questions:Are there any privacy concern since we identify the user, not just analytics.Is it legal in countries such as EU?What thing we need to pay attention to the data we gathered?",
    "target": "analytics;security;ecommerce;privacy;crm"
  },
  {
    "id": "_unix.24946",
    "source": "apt-get : no installation candidate for libxul-dev <eos> When I'm installing libxul-dev I end with this error message:$ sudo apt-get install libxul-devReading package lists... DoneBuilding dependency tree      Reading state information... DonePackage libxul-dev is not available, but is referred to by another package.This may mean that the package is missing, has been obsoleted, oris only available from another sourceE: Package libxul-dev has no installation candidateHow can I solve this?sources.list",
    "target": "ubuntu;software installation;apt;package management"
  },
  {
    "id": "_unix.97149",
    "source": "$! is used for? <eos> While going through:info coreutils 'dd invocation'I came across:dd if=/dev/zero of=/dev/null count=10MB & pid=$!What is $! used for?",
    "target": "shell"
  },
  {
    "id": "_webmaster.82761",
    "source": "Logging using Microsoft account <eos> I would like to create WordPress website with forum where people will be able to login with Microsoft account. I would like to do this to authorize their GamerTags from Xbox Live. Is that even possible?",
    "target": "wordpress;authentication;microsoft"
  },
  {
    "id": "_webmaster.59709",
    "source": "How to make sure Facebook knows that you're a publisher, not a brand? <eos> The past couple Facebook EdgeRank updates have penalized blatant advertisers & linkbait publishers like Upworthy, making it more difficult for many brand pages to get organic distribution. And it appears it will soon get even more difficult to achieve organic reach, especially for brand pages.How does Facebook determine what pages are owned by brands, and which are owned by publishers of substantive content. Are pages manually reviewed and added to a whitelist? Or is it all algorithmically determined.And is there anything a page manager can do to ensure his/her posts are viewed by Facebook as content and not an ad?",
    "target": "facebook"
  },
  {
    "id": "_unix.330103",
    "source": "PCIe Bus error when booting Archiso and when using wifi-menu <eos> I'm trying to install Arch Linux on a Acer Spin 5 Laptop. I'm booting the latest archiso from a USB-Stick in UEFI mode and even before the system has fully started these errors appear during the boot sequence:[...] pcieport 0000:00:1c.0: PCIe Bus Error: severity=Corrected, type=Physical Layer, id=00e0(Receiver ID)[...] pcieport 0000:00:1c.0: device [8086:9d16] error status/mask=00002001/00002000[...] pcieport 0000:00:1c.0: [0] Receiver Error[...] pcieport 0000:00:1c.0: PCIe Bus Error: severity=Corrected, type=Physical Layer, id=00e0(Receiver ID)[...] pcieport 0000:00:1c.0: device [8086:9d16] error status/mask=00002001/00002000[...] pcieport 0000:00:1c.0: [0] Receiver Error      (First)And lscpi tells me that 0000:00:1c.0 belongs toPCI bridge: Intel Corporation Sunrise Point-LP PCI Express Root Port #7 (rev f1)These errors also appear (sometimes) when using wifi-menu to connect to my wifi. Sometimes this error does not occur at all, and sometimes it's spamming my shell.Some times the error code also is [12] Replay Timer Timeout and sometimes [6] Bad TLP, but I don't know what it depends on.Does someone know what might cause this error and how to fix it?It's very annoying and hindering me from installing arch.",
    "target": "linux;arch linux;pci;acer"
  },
  {
    "id": "_unix.299854",
    "source": "Problem when trying a simple loop in bash <eos> #!bin/sha=0while[$a -lt 50]doecho $aa='expr $a+1'doneI get infinite echos of expr $a+1. what am I doing wrong?",
    "target": "bash;shell script"
  },
  {
    "id": "_codereview.171999",
    "source": "Specializing std::hash for std::array <eos> I want to have an std::unordered_map which uses arrays as keys. As long as a type has an operator== and an std::hash it can be used as a key.Here is my std::hash<std::array>template<class T, size_t N> struct std::hash<std::array<T, N>> {    auto operator() (const std::array<T, N>& key) const {        std::hash<T> hasher;        size_t result = 0;        for(size_t i = 0; i < N; ++i) {            result = result * 31 + hasher(key[i]); // ??        }        return result;    }};I copied the multiply by 31 from somewhere. An example here uses << and ^. I don't know which is better or how to apply the cppreference example to an array.// cppreference exampletemplate<> struct hash<S>    {        typedef S argument_type;        typedef std::size_t result_type;        result_type operator()(argument_type const& s) const        {            result_type const h1 ( std::hash<std::string>{}(s.first_name) );            result_type const h2 ( std::hash<std::string>{}(s.last_name) );            return h1 ^ (h2 << 1); // or use boost::hash_combine (see Discussion)        }    };It seems to work. All of the code compiles and the return values for std::hash<key_type> seem ok to me.using key_type = std::array<int, 2>;using hash_type = std::hash<key_type>;using map_type = std::unordered_map<key_type, int>;map_type map; // compileshash_type hasher; // compilesint main() {    // test return values of std::hash<key_type>    for(int y = -2; y < 3; ++y) {        for(int x = -2; x < 3; ++x) {            std::cout << hasher({x, y}) <<  ;        }        std::cout << std::endl;    }}The values printed from this code are:18446744073709551552 18446744073709551583 18446744073709551614 29 60 18446744073709551553 18446744073709551584 18446744073709551615 30 61 18446744073709551554 18446744073709551585 0 31 62 18446744073709551555 18446744073709551586 1 32 63 18446744073709551556 18446744073709551587 2 33 64I'm not sure what makes a good hash function for std::unordered_map, so I'd appreciate any feedback on how to make this hash function better.",
    "target": "c++;array;hash map"
  },
  {
    "id": "_webmaster.53008",
    "source": "Website traffic - with no money (backlinks, spam, likes, tweets) <eos> I read a lot of things around the web.I saw people selling 4K backlinks and social real users tweets, likes, sharing links on Facebook, Twitter, Instagram etc..Now, assuming you have opened a site which is on beta stage and users needs invitations to signupassuming you are not an administrator of any huge Facebook or social community (Facebook groups, meetup groups, forums, chats etc..),assuming you don't have much money to spend for a huge campaign on paying ads,assuming you want to stay out from venture capitalists, angels and so on (at least to check if you can do it without external/third parties help)so...Is trusted SPAM, or paying backlinks, the only way you can go for getting some traffic to your website?If not can you describe how can you promote your website on the web excluding all the points above?",
    "target": "backlinks;traffic;advertising;website promotion"
  },
  {
    "id": "_codereview.11874",
    "source": "Cross-browser double form submit prevention <eos> We developed a potential solution for the double form submit prevention and we need some review on it. To be able to execute this code on asp.net we needed to add our function call directly into the onsubmit event of the form. This cannot be handle by jQuery because asp.net use a dopostback function and called form.submit(). If onsubmit attribute of the form is empty then it wil not execute the code. We don't want to depend on a bloq-UI or disabled button actions.This is our form tag <form id=form1 runat=server onsubmit=return preventDoubleSubmit(event);>And this is our javascript that handle the double submit prevention//Double submit preventionsvar _preventDoubleSubmit = false;function preventDoubleSubmit(e) {    if (_preventDoubleSubmit) {        return cancelDoubleSubmit(e);    }    else {        _preventDoubleSubmit = true;        return true;    }}function cancelDoubleSubmit(e) {    if (!e) {        e = window.event;    }    if (e.returnValue != undefined) {        e.returnValue = false;    }    if (e.cancelBubble != undefined) {        e.cancelBubble = true;    }    if (e.stopPropagation) {        e.stopPropagation();    }    if (e.stopImmediatePropagation) {        e.stopImmediatePropagation();    }    if (e.preventDefault) {        e.preventDefault();    }    return false;}//END - Double submit preventionAny review on this we be appreciated.",
    "target": "javascript;asp.net"
  },
  {
    "id": "_codereview.114643",
    "source": "Matplotlib: Display y value as a marker <eos> I created a plot on which the y value is visible with the marker.What's your opinion ? I wonder if I could have done something simpler. (code should run in a Jupyter notebook)%matplotlib inlinefig = plt.figure()axes = fig.add_axes((1,1,1,1))  X = np.array([3,3.2,3.5,3.8,3.9,5,5.5,5.8,5.9,5])y = np.array([1,1,1,1,1,2,2,2,2,2])markers = ['^', 'o']for k, m in enumerate(markers):     i = (y == k+1)   flat = [1 for val in y[i]]   axes.scatter(X[i], flat, marker=m)axes.set_xlim([2,7])axes.set_ylim([0,3])The result:",
    "target": "python;matplotlib"
  },
  {
    "id": "_reverseengineering.1572",
    "source": "IDA Proximity viewer not finding obvious paths? <eos> Using IDA 6.2 (and also with IDA 6.4), I'm trying out the Proximity viewer to find the path between 2 functions as described at the hexblog post here.Using the Xrefs From/To (old option) it shows the clear path: AllocateVolume -> VolumeSortCmp -> CompareVolumeComponents as shown in the screenshot belowApart from the add name and hide childs options not existing in the context menu (as described in the blog) of the proximity browser as seen in the screenshot belowthe find path menu does list CompareVolumeComponents in the dialog that opens (so it has some knowledge of what is reachable). However when I press search I expected a nice clean graph (as again shown in the blog and added as reference below) showing only the the 3 relevant nodes, but instead nothing seems to change to the proximity browser layout as I still see 30 something nodes. Hexblog condensed Find path example resultMy resultIs the proximity viewer malfunctioning or are my expectations off? Or am i doing something wrong here?",
    "target": "ida"
  },
  {
    "id": "_computerscience.5014",
    "source": "Caustics: methods to render? <eos> What are the recommended ways to render caustics? I am aware bidirectional path tracing and photon mapping can do this. Could someone give a brief overview of photon mapping and a good resource of where to learn about implementation? ",
    "target": "pathtracing;photon mapping;caustics"
  },
  {
    "id": "_webmaster.29550",
    "source": "Why the difference between Tomcat and Tomcat7 regarding servlet mapping and defaults? <eos> With the following configuration:<servlet-mapping>    <servlet-name>default</servlet-name>    <url-pattern>*.css</url-pattern></servlet-mapping><servlet-mapping>    <servlet-name>default</servlet-name>    <url-pattern>*.html</url-pattern></servlet-mapping>then both Tomcat7 and Tomcat6 serves the following URL just fine: http://127.0.0.1:8087/mynet/index.htmlHowever, if I reduce the configuration to just mention the CSS pattern:<servlet-mapping>    <servlet-name>default</servlet-name>    <url-pattern>*.css</url-pattern></servlet-mapping>Then Tomcat6 works, but Tomcat7 fails with: The requested resource () is not available.Why is there a difference here?",
    "target": "java;localhost;tomcat"
  },
  {
    "id": "_softwareengineering.274645",
    "source": "Protect memory from a potentially seg faulting function call <eos> How can one safely call a function that might segfault without corrupting the stack or the heap?These SO questions cover using signal handlers and setjmp.h to regain control.Coming back to life after Segmentation ViolationBest practices for recovering from a segmentation faultThey neglect the likely memory corruption that occurs prior to a seg fault.What strategies can be used to isolate the memory space of a function and its caller?This is just a curiosity question, there's no specific problem I'm trying to solve. Let's just suppose we're programming something that absolutely cannot crash -- pacemaker, Mars orbiter, nuclear launch control, take your pick. We've already thoroughly unit tested all our code and formally proven its correctness. For bureaucratic reasons we have to use C++ and Linux.I was trying to sketch this out with clone(). My idea was to run the function with as much isolation as possible and pass data back and forth by squirreling it away at the bottom of the child's stack.Is that reasonable or is there a better way to do this?",
    "target": "c++;linux;error handling"
  },
  {
    "id": "_webmaster.31020",
    "source": "Is it possible to have a better sql editor for phpMyAdmin? <eos> I am studying database systems and using MySQL and phpMyAdmin.The editor that comes with phpMyAdmin is plain editor that does not highlight any special syntax like for example: gEdit in ubuntu.Can I change the editor?",
    "target": "database;phpmyadmin"
  },
  {
    "id": "_codereview.935",
    "source": "Developing a multistep form <eos> I implemented a multistep form with the method described by Ryan Bates in ep217 but I had some weird behavior when refreshing or moving between the steps Acts_as_good_style (old but still good) has a tip redirect when moving on that lead me to the change in the code that follows.In a nutshell, it says that if you're in the create action you should not render new (as I was doing).This solved the problem. But I had to manage the case of errors in the form, so I ended up with this code.#profiles_controller.rbdef create  # [...] save etc [...]  # render  if @profile.new_record?      # render 'new' # OLD    session[:profile_valid] = @profile.errors.blank?  # NEW    redirect_to new_profile_path # NEW  else     # [...]  endend def new    @profile = Profile.new(session[:profile_params])    # [...]  # rebuild errors (see create)  # check false because first time is nil and no error have to be displayed  @profile.valid? if session[:profile_valid] == false  session[:profile_valid] = trueendWhere in the new action I reload the errors otherwise lost depending on session[:profile_valid], that works fine.BUT this way doesn't look very good to me and I would appreciate to have your opinion, OR how do you manage your controllers in multispets forms?What was the strange behavior? Refreshing or going back and forth through the steps sometimes you jump to the wrong page, not clear what the logic is, probably depends on the validations in the model and the params hash.",
    "target": "ruby;ruby on rails;form"
  },
  {
    "id": "_datascience.11159",
    "source": "What algorithms can be used to predict the outcome of a cricket match? <eos> I am doing a project to predict the outcome of a cricket match, I have the data that states which matches were won by whom for ODIs. [Espn data]Which algorithm could be used to predict the outcome of the coming matches?Would Quadratic Regression be a good idea? Or would predicting based on probability algorithms such as the markov's algorithm is what is generally used?Any other algorithm I should use?So basically, I want to know which algorithm I should use, I will implement in C++ ultimately but I will do it in R or python first.P.S.:-I am a newbie in this field, hence pardon if the question sounds too stupid.I have learnt regression so far in data analytics.",
    "target": "machine learning;predictive modeling;regression;linear regression"
  },
  {
    "id": "_computergraphics.5067",
    "source": "Phong shading in OpenGL: line of light from the center of the world <eos> I implemented a Phong shader in GLSL, but there is a bug.What you are (supposed) to see down below:A point light source rotating around the center of the world,with a radiance of (0, 100, 0)A textured quad with kd of (1, 0, 0).The problem is:Why is there a a green line to the center of the world instead of a green spot light where the quad is lit? (where the center of the point light source is)(Btw in this case there would be only a yellow spot of light, because red + green = yellow)Vertex Shader:#version 330uniform mat4 ModelMatrix, ViewMatrix, ProjectionMatrix;   uniform vec4 wLiPos[5];       // pos of light source uniform vec3 wEye;         // pos of eyeuniform int lightSize;      //number of lightslayout(location = 0) in vec3 vtxPos;layout(location = 1) in vec3 vtxNorm;layout(location = 2) in vec2 vtxUV;out vec2 texCoord;out vec3 wNormal;           // normal in world spaceout vec3 wView[5];             // view in world spaceout vec3 wLight[5];            // light dir in world spacevoid main() {    gl_Position = ProjectionMatrix * ViewMatrix * ModelMatrix * vec4(vtxPos, 1);    texCoord = vtxUV;    vec4 wPos = ModelMatrix * vec4(vtxPos, 1);    wNormal = (vec4(vtxNorm, 0) * inverse(ModelMatrix)).xyz;    for(int i = 0; i < lightSize; i++) {        wView[i] = wEye * wPos.w - wPos.xyz;        wLight[i] = wLiPos[i].xyz * wPos.w - wPos.xyz * wLiPos[i].w;    }}Fragment shader:#version 330uniform sampler2D samplerUnit;uniform vec3 kd, ks, ka;   // diffuse, specular, ambient refuniform vec3 La, Le[5];    // ambient and point source raduniform float shininess;    // shininess for specular refuniform int lightSize;in vec2 texCoord;    in vec3 wNormal;       // interpolated world sp normalin vec3 wView[5];         // interpolated world sp viewin vec3 wLight[5];        // interpolated world sp illum dirlayout(location = 0) out vec4 fragmentColor;void main() {         vec3 color = vec3(0, 0, 0);    for(int i = 0; i < lightSize; i++) {        vec3 N = normalize(wNormal);        vec3 V = normalize(wView[i]);        vec3 L = normalize(wLight[i]);        vec3 H = normalize(L + V);        float cost = max(dot(N,L), 0);        float cosd = max(dot(N,H), 0);        color += ka * La + (kd * cost + (ks * pow(cosd, shininess)) * Le[i]) / pow(length(wLight[i]), 2);    }    vec3 gamma = vec3(1.0/2.2);    fragmentColor = vec4(pow(color * vec3(texture2D(samplerUnit, texCoord)), gamma), 1);}",
    "target": "opengl;shader;glsl"
  },
  {
    "id": "_unix.341568",
    "source": "How to explicitly set the tabname of a new gnome-terminal? <eos> I want to explicity rename a tab in gnome-terminal on startup of the tab. I don't want to use gnome-terminal --title flag as that gets reset by my systems bashrc file after whatever else is supposed to run. I have used  this command with success in a normal terminalexport PROMPT_COMMAND=echo -ne '\\033]0;TABNAME\\007'This command works fine to rename the current tab's name, but when I try to use it in conjunction with gnome-terminal execute command, I am not getting proper output.I have used gnome-terminal --e flag to execute simple commands with success, something like this will bring up a new terminal and echo hey then return to bashgnome-terminal -e bash -c 'echo hey';bashHere is what I am trying note the escaped   marks that I addedTABNAME=export PROMPT_COMMAND=\\echo -ne '\\033]0;TABNAME\\007'\\gnome-terminal --tab --e bash -c $TABNAME;bashI always get weird output no matter how I change the quotes, but I think that is where the problem is. ",
    "target": "bash;shell script;environment variables;quoting;gnome terminal"
  },
  {
    "id": "_webmaster.28087",
    "source": "Tips for managing internal and external links using WordPress <eos> So I'm looking for ways to optimize my site for user and search engine purposes.  I've read several articles and looked at several different plugins.  To say the least, I'm thoroughly confused as what are the best practices for managing internal and external links.  Here is a list of some of my questions:Which internal links should be set to nofollow?Which external links should be set to nofollow?To what degree does actively managing links contribute to your PR?Should you use nofollow blindly on all links in comments?If a link to an external site is broken (404 or whatever), should you nofollow that link?  What about noindex?As you can see, lots of questions.  I'm hoping that you experienced webmasters can give a newb some best-practice advice.",
    "target": "seo;links"
  },
  {
    "id": "_datascience.13028",
    "source": "Loading and querying a Spark machine learning model outside of Spark <eos> I'm currently working on a project where we're building a data pipeline. We have spark setup and have generated models. Sadly, loading the model in Spark and querying it isn't fast enough for us. What's the most straightforward way of exporting a model and loading it into memory on a local server? I've researched PMML and some libraries and that appears to be one path. ",
    "target": "apache spark"
  },
  {
    "id": "_unix.349565",
    "source": "Access ImageMagick's man page <eos> On my system I have ImageMagick and its documentation installed:$ apt-cache pkgnames imagemagickimagemagickimagemagick-6.q16imagemagick-dbgimagemagick-docimagemagick-commonI can access convert's man page, which tells me SEE ALSO ImageMagick(1) if I want to know more.man ImageMagick says No manual entry for ImageMagick.And finally, man -k imagemagick says:quantize (5)         - ImageMagick's color reduction algorithm.How do I access ImageMagic's man page on my system?Additional informationAbove I was mistaken.apt-cache pkgnames listed packages are not necessarily available to download, installable or installed (ref. APT-CACHE(8)).So, my command did not list the installed packages.Digging more, I ended up with$ apt list imagemagick*                                                                        Listing... Doneimagemagick/xenial-updates,xenial-security,now 8:6.8.9.9-7ubuntu5.4 amd64 [installed]imagemagick-6.q16/xenial-updates,xenial-security,now 8:6.8.9.9-7ubuntu5.4 amd64 [installed,automatic]imagemagick-common/xenial-updates,xenial-updates,xenial-security,xenial-security,now 8:6.8.9.9-7ubuntu5.4 all [installed,automatic]imagemagick-dbg/xenial-updates,xenial-security 8:6.8.9.9-7ubuntu5.4 amd64imagemagick-doc/xenial-updates,xenial-updates,xenial-security,xenial-security 8:6.8.9.9-7ubuntu5.4 allSo, apparently, imagemagick-doc was not installed.Nevertheless, this package installs the www documentation (/usr/share/doc/imagemagick-doc/www) and not the man one.Checking the content of the imagemagick package does not give away what the name of its man page is, or at least, I am not able to figure it out.$ dpkg -L imagemagick | grep man/usr/share/man/usr/share/man/man1/usr/share/man/man1/stream-im6.1.gz/usr/share/man/man1/display-im6.1.gz/usr/share/man/man1/animate-im6.1.gz/usr/share/man/man1/mogrify-im6.1.gz/usr/share/man/man1/composite-im6.1.gz/usr/share/man/man1/montage-im6.1.gz/usr/share/man/man1/import-im6.1.gz/usr/share/man/man1/identify-im6.1.gz/usr/share/man/man1/conjure-im6.1.gz/usr/share/man/man1/convert-im6.1.gz/usr/share/man/man1/compare-im6.1.gzBug reports hereImageMagick: I've opened a bug report here.Debian: another bug report here.Let's see if someting comes up.",
    "target": "man;imagemagick;documentation"
  },
  {
    "id": "_webmaster.26649",
    "source": "OpenGraph tags and HTML5 validity <eos> I have a HTML5 based page, and I inculded the OpenGraph tags according to it's documentation. Also I checked with Facebook Debug, and it can parse the metadata.But when I use W3C Validator, it reports the OG tags as error:Attribute content not allowed on element meta at this point.<meta property=fb:admins content=.... />Attribute content not allowed on element meta at this point.<meta property=og:url content=http://www....>They are all in the <head>.I would need my page be valid HTML5 and OG tags, as well. Could you help me giving a hint how can it be achieved?UPDATE:The name version also invalid: <meta name='fb:admins' content=''>",
    "target": "facebook;html5;validation;facebook graph"
  },
  {
    "id": "_datascience.19926",
    "source": "How can I visualize/analyze data that has percentages and numbers across multiple time periods? <eos> I have a large dataset like this:+-----+------+---------+-----------+------------------+-------+-----------------+---------+-------+| Mat | Cust | Qty(Ag) | Net V(Ag) | Demand Hits (Ag) | Qty%  | Demand Hits (%) | Net V % | Month |+-----+------+---------+-----------+------------------+-------+-----------------+---------+-------+| Y   | A    |     200 |      7000 |              200 | 76.9% | 95.7%           | 76.9%   |     1 || X   | A    |     100 |      1000 |               10 | 83.3% | 66.7%           | 33.3%   |     1 || Y   | C    |      50 |      1750 |                8 | 19.2% | 3.8%            | 19.2%   |     1 || X   | B    |      20 |      2000 |                5 | 16.7% | 33.3%           | 66.7%   |     1 || Y   | B    |      10 |       350 |                1 | 3.8%  | 0.5%            | 3.8%    |     1 || Y   | A    |     600 |     21000 |               78 | 86.0% | 86.7%           | 86.0%   |     2 || X   | B    |      60 |      6000 |               56 | 0.6%  | 50.5%           | 0.6%    |     2 || X   | C    |   10000 |   1000000 |               45 | 98.9% | 40.5%           | 98.9%   |     2 || Y   | B    |      98 |      3430 |               12 | 14.0% | 13.3%           | 14.0%   |     2 || X   | A    |      50 |      5000 |               10 | 0.5%  | 9.0%            | 0.5%    |     2 |+-----+------+---------+-----------+------------------+-------+-----------------+---------+-------+This data is about sale of materials (Mat) to customers (Cust). For each Mat-Cust combination I have the qty they ordered (Qty), net value of their orders (Net V) and the number of orders (Demand Hits) and the month (Month). I also have percentages of orders, net value, and quantity. For example: In the line one (Mat Y and Cust A) the Qty% is 76.9%. This means that 76.9% of the total quantity of material Y was ordered by customer A. So if you sum the Qty % of Mat Y-Cust A and Mat Y - Cust C and Mat Y - Cust B for month 1 it will add up to a 100%. The same has been done for the other percentages as well. I was looking for a good way to visualize this data (That could run into millions of records even for one month) and also to statistically analyse it to draw any conclusions. Any ideas for an exploratory visual and statistical analysis?Here are some questions I am thinking about?:Are there customers who make up a large portion of the sales of particular items? Are there specific Mat-Cust combos that can be considered Critical based on demand hits or net value? Can I cluster Mat-Cust into different categories and treat each category differently based on their unique characteristics? Is customer buying patterns repeating across time periods?",
    "target": "machine learning;data mining;clustering;statistics;visualization"
  },
  {
    "id": "_webmaster.7791",
    "source": "blog.domain.com(domain.com/blog) or another-domain.org <eos> I have a website which is going to show my shareware, another site for my blog. I will post all my thinkings/development tips/design tips/business experience on my blog, but most of them are not related to my shareware. Software users may not interested in my blog. In this case, is it still better to host my blog to another domain?Thanks.",
    "target": "domains;blog;business"
  },
  {
    "id": "_reverseengineering.15551",
    "source": "Debug a .dll file within powershell <eos> I have given a .ps1 file which loads a .dll via:Import-Module .\\decrypter.dllAfter that, a call to that module is performed by:get-decrypt( *Some Base64 Encoded string* )Only the .dll is given. The Dependency Walker returns no exported functions. IDA Pro Free shows only one moduleMy question:How do I debug this .dll file?Kindly regards",
    "target": "debugging;dll"
  },
  {
    "id": "_unix.212075",
    "source": "osx - dd command behaving weirdly <eos> I've been using dd for a couple of years now, most of the time successfully. I usually use it to dd Linux images to USB drives. My workflow doing so is as such:convert .iso image to a .img format using hdiutil convert -format UDRW output.img input.isounmount the drive using diskutil unmountDisk /dev/diskXdd the image to the drive using dd if=./image.img of=/dev/rdiskX bs=1mLately, and namely since I upgraded to Yosemite, dd has been showing some weird behavior. When I specify the block-size flag (bs=1m), it quits after about a minute, showing the default successful write message with the numbers of records in/out and bytes transferred and all that. What you would expect on a successful write. The problem is, it writes just a very small part of the image, then quits.When I do not specify the block-size flag dd behaves as expected, writing the image to the disk in the ordinary fashion. Does anyone have any idea why this is happening?",
    "target": "command line;osx;dd"
  },
  {
    "id": "_webmaster.36169",
    "source": "My parked domain was de-indexed by Google - what to do? <eos> I have a question about how to handle my domain.  In a nutshell, I bought a domain last year from Go Daddy.  My intention was to launch a real site with this domain and I have spent the last year working on my site.  For the last year, I have been using the default Go Daddy page display for an up and coming site.When I first bought this site, it was indexed by Google - you could search for alphabanter and my site would show up on the search result page for Google.  Several months ago, it seemed Google de-indexed my domain and if you type alphabanter, my domain no longer shows up on the list of search results.  However, if you search for www.alphabanter.com, that's the only way it shows up in the search results for Google.Anyways, I am about to launch my site for real.  However, I don't quite know if I can get my site back into Google's index.  I have a few questions:1) Was my domain permanently penalized by Google and removed from their index just because it was a parked domain?  I don't believe I have done anything abusive other than using the Go Daddy default page for almost a year because my site was not ready.2) Should I just launch my site, put a few backlinks to my site, and hope that Google indexes my site again?3) Should I submit my site to Google at Google submit your contentI assume getting Google to reconsider my site is the last option if none of the above works. ",
    "target": "seo;google search;google index"
  },
  {
    "id": "_scicomp.8524",
    "source": "Are HDF5 files suitable for git revision control? <eos> I am not familiar with the file format used in HDF5, but I am wondering if HDF5 files are suitable for revision control with git (or for example Mercurial or Subversion)? I guess what I mean is: are HDF5 files suitable for line-based diff'ing or will git have to treat an HDF5 as one big binary and store an entire copy for each revision?",
    "target": "data management;data storage"
  },
  {
    "id": "_unix.242722",
    "source": "Test for existence of multiple files, given by pipe <eos> I have a command that gives me a list of files, one on each line. Filenames are normal - no spaces, no need to escape parentheses etc.Now I want to pipe that command to something like test -f and return true if and only if all of the files exist. (Behaviour with 0 lines can be undefined, I don't really care.)So, something likemake_list_of_files | test -fbut actually working.Bashisms are allowed, since I need it in Bash.The files are not in the same directory, but they are in subdirectories of a current directory, and the paths have directory names in them, so for exampledir/file1dir/file2dir2/file3",
    "target": "bash;shell script;files"
  },
  {
    "id": "_softwareengineering.227735",
    "source": "Even distribution through a chain of resources <eos> I'm working on an algorithm which routes tasks through a chain of distributed resources based on a hash (or random number).For example, say you have 10 gateways into a service which distribute tasks to 1000 handlers through 100 queues. 10,000 connected clients are expected to be connected to gateways at any given time (numbers are very general to keep it simple).Thats10,000 clients 10 gateways (producers)100 queues 1000 workers/handlers (consumers)The flow of each task is client->gateway->queue->workerEach client will have it's own hash/number which is used to route each task from the client to the same worker each time, with each task going through the same gateway and queue each time. Yet the algorithm handles distribution evenly, meaning each gateway, queue, and worker will have an even workload.My question is what exactly would this be called? Does such a thing already exist? This started off as a DHT, but I realized that DHTs can't do exactly what I need, so I started from scratch.",
    "target": "algorithms;scalability;statistics"
  },
  {
    "id": "_unix.370892",
    "source": "1 FastCGI sent in stderr: PHP message: PHP Fatal error: session_start(): Failed to initialize storage module: <eos> I installed phpMyAdmin on my Arch Linux box. I then created a sym link named phpmyadmin in my /usr/share/nginx/html/ to /usr/share/webapps/phpMyAdmin/. When I visit http://127.0.0.1:8080/phpmyadmin/ in my browser I get 500 Internal server error. Checking in my nginx error log this' what I find:2017/06/13 19:10:42 [error] 4059#4059: *1 FastCGI sent in stderr: PHP message: PHP Fatal error:  session_start(): Failed to initialize storage module: files (path: ) in /usr/share/webapps/phpMyAdmin/libraries/session.inc.php on line 121 while reading response header from upstream, client: 127.0.0.1, server: localhost, request: GET /phpmyadmin/ HTTP/1.1, upstream: fastcgi://unix:/var/run/php-fpm/php-fpm.sock:, host: 127.0.0.1:8080Please how do I solve this error? How do I get my phpMyAdmin working?If you need my nginx.conf or php.ini let me know. Thanks.",
    "target": "arch linux;php;mariadb;phpmyadmin"
  },
  {
    "id": "_webapps.82994",
    "source": "Create facebook ad for people who like specific group or page (targetting)? <eos> I would like to boost a specific post and target people who liked a group or page that I do not own.Can this be done or it's forbidden to prevent spam (or whatever)?I used targeted advertising to create such group, but I was offered to (in/ex)clude people for my own page only. ",
    "target": "facebook;facebook ads"
  },
  {
    "id": "_unix.253548",
    "source": "How to set date with Epoch format <eos> I want to set date from a seconds since epoch value, for instance I want to set date with input value 1452053571.I read through date -help but not found anything.Is there any parameters to do it?",
    "target": "date"
  },
  {
    "id": "_webmaster.43059",
    "source": "Why is an email failing RFC2822 specifications? <eos> I am sending an email to a maximum of 14 gmail users. They are part of a small group of paid subscribers. In a send to all 14 1 or 2 are normally returned sayingReason: Remote host said: 550 5.7.1 RFC 2822 specifications for more informationIt is not an email to the same member each time and seems random. Has anyone ever expereinced this before?",
    "target": "email;gmail"
  },
  {
    "id": "_codereview.71210",
    "source": "Minimum Scalar Product <eos> Here's the problem statement for Minimum Scalar ProductYou are given two vectors v1=(x1,x2,...,xn) and v2=(y1,y2,...,yn). The scalar product of these vectors is a single number, calculated as x1y1+x2y2+...+xnyn.Suppose you are allowed to permute the coordinates of each vector as you wish. Choose two permutations such that the scalar product of your two new vectorsis the smallest possible, and output that minimum scalar product. Please review my code.#include<iostream>#include<vector>#include<algorithm>int main() {    int t;    std::cin >> t;    while (t--) {        std::size_t n;        std::cin >> n;        if (n != 0) {            int product = 0;            std::vector<int> x(n);            for (std::size_t x_index = 0; x_index < n; ++x_index) {                std::cin >> x[x_index];            }            std::vector<int> temp(n);            for (std::size_t t_index = 0; t_index < n; ++t_index) {                std::cin >> temp[t_index];            }            sort(x.begin(),x.end());            sort(temp.begin(),temp.end());            std::vector<int> y(n);            for (std::size_t y_index = 0; y_index < n; ++y_index) {                y[y_index] = temp[temp.size()-1-y_index];            }            for (std::size_t i = 0; i < n; ++i) {                product += x[i]*y[i];            }            std::cout << product << '\\n';        }    }}How can I make this code better and faster? Particularly without using an additional vector? And is there a better solution?",
    "target": "c++;c++11;programming challenge"
  },
  {
    "id": "_codereview.110510",
    "source": "Getting a value from shared preferences <eos> I use this code to get values from SharedPreferences.public static String getSharedPreferenceValue(Context context, String key) {    SharedPreferences sp = context.getSharedPreferences(    Utility.PREFERENCES_NAME, Context.MODE_PRIVATE);    String value = sp.getString(key, Utility.EMPTY_STRING);    return value;}Will this static method keep context (Activity) all time and are there memory leaks?Is there a better way to get values from SharedPreferences?I'm looking for the best way to do this.",
    "target": "java;performance;android"
  },
  {
    "id": "_codereview.36596",
    "source": "Opening social media links in a new window <eos> I'm rather new to jQuery but managed to get some social links to open in a new controlled window instead of new tab. I have a few functions that do the same thing, and this works, but there is always a better method.I did review the question and answer here and couldn't figure out which would apply to this case.jQuery(document).ready(function ($) {  $(#ssba_facebook_share).attr('title','opens in a new pop-up');  $(#ssba_facebook_share).click(function(){    w = parseInt((screen.width - 600)/2); h = parseInt((screen.height - 400)/2);    cwin = window.open($(this).attr('href'), 'closewin',   'status=0,toolbar=0,location=0,menubar=0,directories=0,resizable=0,scrollbars=0,height=400,width=600');    cwin.moveTo(w,h);    return false;  });  $(#ssba_twitter_share).attr('title','opens in a new pop-up');  $(#ssba_twitter_share).click(function(){    w = parseInt((screen.width - 600)/2); h = parseInt((screen.height - 400)/2);    cwin = window.open($(this).attr('href'), 'closewin',   'status=0,toolbar=0,location=0,menubar=0,directories=0,resizable=0,scrollbars=0,height=400,width=600');    cwin.moveTo(w,h);    return false;  });  $(#ssba_google_share).attr('title','opens in a new pop-up');  $(#ssba_google_share).click(function(){    w = parseInt((screen.width - 600)/2); h = parseInt((screen.height - 400)/2);    cwin = window.open($(this).attr('href'), 'closewin',   'status=0,toolbar=0,location=0,menubar=0,directories=0,resizable=0,scrollbars=0,height=400,width=600');    cwin.moveTo(w,h);    return false;  });});Now, I've attempted a few things to no avail, and one method was this:jQuery(document).ready(function ($) {  $(#ssba_facebook_share,#ssba_twitter_share,#ssba_google_share).attr('title','opens in a new pop-up');    $(this).click(function(){      w = parseInt((screen.width - 600)/2); h = parseInt((screen.height - 400)/2);      cwin = window.open($(this).attr('href'), 'closewin',      'status=0,toolbar=0,location=0,menubar=0,directories=0,resizable=0,scrollbars=0,height=400,width=600');      cwin.moveTo(w,h);      return false;    });});Does anyone have any pointers in this, if possible, with a description of where I went wrong? Or even post a link to a question that goes over this in laymen terms? (I've been looking around and found similar posts, which is how I arrived at where I am now, but still having trouble making complete sense of it.)",
    "target": "javascript;jquery"
  },
  {
    "id": "_codereview.31420",
    "source": "Serialize name/value pairs <eos> I have an array of objects that each have a name/value property.  The array can contain multiple objects with the same name property. I want to serialize this array into the form:  name:value,value|name:value|name:value,value,valueSo basically each property is separated by a | and each value by a ,. The above example is not exactly how I want it to look, just an example of the syntax, results will vary based upon input.Here is an example of the array:var objs = [    {name:name1, value: value1},     {name:name4, value: value4},    {name:name3, value: value3},    {name:name2, value: value2},    {name:name2, value: value2},    {name:name2, value: value3}];I wrote some code to perform this serialization, but I wanted to see if anyone could suggest improvements to this code, I know there are some Javascript experts on this site and wanted to get their opinion:function serialize(objs){    var out = ;    for(var i = 0; i < objs.length; i++){        var propKey = objs[i].name + :;        if (out.indexOf(propKey) == -1){            out += | + propKey;         }        var position = out.indexOf(propKey) + propKey.length;        out = out.substring(0, position) + objs[i].value + , + out.substring(position);    }    return out.substring(1,out.length-1).replace(/\\,\\|/g,|);}JS Fiddle: http://jsfiddle.net/BHsuM/BTW jQuery is acceptable.",
    "target": "javascript;jquery"
  },
  {
    "id": "_codereview.97534",
    "source": "Downloading all files in a FTP folder and then deleting them <eos> I've created two methods in a class that allow me to download  the contents of an FTP folder and if specified then delete them. Although the code operates as intended I think it's vastly bloated and I'm looking for direction on how to correct it.Of note I believe that there's far too many FTP connections opened in a single file move (three I believe - list directory, download files, delete files). I'm a bit unsure how to refine this.public void DownloadFolder(string localFilesPath, string remoteFTPPath, bool deleteAfterDownload = false){    remoteFTPPath = ftp:// + Hostname + remoteFTPPath;    var request = (FtpWebRequest)WebRequest.Create(remoteFTPPath);    request.Method = WebRequestMethods.Ftp.ListDirectory;    request.Credentials = new NetworkCredential(Username, Password);    request.Proxy = null;    FtpWebResponse response = (FtpWebResponse)request.GetResponse();    Stream responseStream = response.GetResponseStream();    StreamReader reader = new StreamReader(responseStream);    List<string> directories = new List<string>();    var line = reader.ReadLine();    while (!string.IsNullOrEmpty(line))    {        directories.Add(line);        line = reader.ReadLine();    }    reader.Close();    using (var ftpClient = new WebClient())    {        ftpClient.Credentials = new NetworkCredential(Username, Password);        for (var i = 0; i <= directories.Count - 1; i++)        {            if (!directories[i].Contains(.))            {                continue;            }            var path = remoteFTPPath + / + directories[i].Remove(0, directories[i].IndexOf(@/) + 1);            var transferPath = localFilesPath + @\\ + directories[i].Replace(@/, @\\);            PostEvent($Attempting to download File: {path} to: {transferPath}, Debug);            try            {                ftpClient.DownloadFile(path, transferPath);                PostEvent($Downloaded File: {path} to: {transferPath}, Info);                PostEvent($Preparing to delete file: {path}\\n\\n, Debug);                if (deleteAfterDownload)                {                    DeleteFile(path);                }            }            catch (WebException ex)            {                PostEvent($Error downloading or deleting file {path} to {transferPath}, Error);                PostEvent($Exception: {ex.Message}, Error);            }            catch (Exception ex)            {                PostEvent($General Exception: {ex.Message}, Error);            }        }    }    response.Close();}public void DeleteFile(string remoteFTPPath){    FtpWebRequest request = (FtpWebRequest)WebRequest.Create(remoteFTPPath);    request.Method = WebRequestMethods.Ftp.DeleteFile;    request.Credentials = new NetworkCredential(Username, Password);    request.Proxy = null;    FtpWebResponse response = (FtpWebResponse)request.GetResponse();    PostEvent($Deleting file {remoteFTPPath} returned status {response.StatusDescription}, Debug);    response.Close();}Here's the class initializer (where my credentials are passed into properties within this class):public FtpHelper(string ftpHostname, string ftpUsername, string ftpPassword){    Hostname = ftpHostname;    Username = ftpUsername;    Password = ftpPassword;}And the postevent method that's referred to here come's from a base class I inherit to this class (unsure if this is bad practice, please let me know if so):public class BaseHelper{    private EventHandler<BaseExceptionEventArgs> _onEvent;    public event EventHandler<BaseExceptionEventArgs> OnEventHandler    {        add { _onEvent += value; }        remove { _onEvent += value; }    }    /// <exception cref=Exception>A delegate callback throws an exception.</exception>    public void PostEvent(string message, BaseExceptionEventArgs.ExceptionLevel exceptionLevel,        Exception exception = null)    {        if (_onEvent == null) return;        if (exception == null)        {            var e = new BaseExceptionEventArgs(message, exceptionLevel);            _onEvent(this, e);        }        else        {            var e = new BaseExceptionEventArgs(message, exceptionLevel, exception);            _onEvent(this, e);        }    }}",
    "target": "c#;network file transfer"
  },
  {
    "id": "_unix.22219",
    "source": "When do environment variables get set in tcsh? <eos> I set a lot of environment variables in my .tcshrc file, using the setenv command.When I needed to have one of these unset today, I moved this file and opened a new terminal (this is all in a Gnome graphical environment) expecting environment variables I set in my .tcshrc to no longer be in the env.But some of these variables were still set; where else could they be being set?  I know my .login file is empty.Are setenv commands more global than I think they are?  When I open a new virtual terminal via alt-ctrl-F2 the variables were no longer set.",
    "target": "fedora;gnome;tcsh"
  },
  {
    "id": "_unix.273289",
    "source": "submitting jobs to get 3 nodes running parallel executions <eos> I have a submit script looks like below, it tries to run a large number of instances of csce.py in backgrounds with 3 nodes.... in a laptop, this usually could successfully automatically distribute all the background tasks into 16 cores.... However, I am not sure if in a cluster, it would also automatically distribute the 4*13*9 tasks in 3 nodes (48 cores).#!/bin/bash#SBATCH -N 3                   # Total number of nodes requested (16 cores/node)#SBATCH -n 48                  # Total number of mpi tasks requestedfor simplify in  0.1 0.15 0.2 0.25do for lmbda in 0.5 1 2  5 10 20  50 100 200 500 1000 2000 5000do for mu in 0.005 0.01 0.05 0.1 0.5 1 5 10 50 do rm eci.outcsce.py --mu $mu --lmbda $lmbda --simplify $simplify --favor-low-energy 0.01 --bias-stable --save-energies lmbda_$lmbda\\_mu_$mu\\_simplify_$simplify\\_ce-energies.dat --save-weights lmbda_$lmbda\\_mu_$mu\\_simplify_$simplify\\_ce-weights.dat  --casm-eci-file eci.in lmbda_$lmbda\\_mu_$mu\\_simplify_$simplify\\_eci.out --save-hull lmbda_$lmbda\\_mu_$mu\\_simplify_$simplify\\_ce-hull.dat  --preserve-ground-state 10000 2> lmbda_$lmbda\\_mu_$mu\\_simplify_$simplify\\_error 1> lmbda_$lmbda\\_mu_$mu\\_simplify_$simplify\\_output &done  done donewait",
    "target": "parallelism;batch jobs"
  },
  {
    "id": "_unix.257874",
    "source": "FreeBSD 10.2 - Is three-way HAST replication possible? <eos> I have a pair of FreeBSD 10.2 servers using HAST to keep a volume replicated between them. I'm introducing two new storage nodes that have much newer hardware and will eventually replace the existing servers but I want to introduce replication gradually without disrupting the existing setup.I'm attempting to use a configuration like this:# /etc/hast.conf# HAST - Highly Available Storagecompression     lzfchecksum       crc32timeout         10replication     memsyncresource ha0 {        # new storage node #1        on zsan1 {                local /dev/zvol/vmdata/targets/ha0                remote 10.10.30.11                remote 10.10.30.12                remote 10.10.30.14        }        # new storage node #2        on zsan2 {                local /dev/zvol/vmdata/targets/ha0                remote 10.10.30.11                remote 10.10.30.12                remote 10.10.30.13        }        # old storage node #1        on zfs-primary {                local /dev/zvol/tank/targets/ha0                remote 10.10.30.12                remote 10.10.30.13                remote 10.10.30.14        }        # old storage node #2        on zfs-secondary {                local /dev/zvol/tank/targets/ha0                remote 10.10.30.11                remote 10.10.30.13                remote 10.10.30.14        }}I have created new volumes to test the replication with this configuration on the new servers and the existing ones but when i run hastctl on the primary node it only shows a single 'remoteaddr':root@zsan1:~ # hastctl listha0:  role: primary  provname: ha0  localpath: /dev/zvol/vmdata/targets/ha0  extentsize: 2097152 (2.0MB)  keepdirty: 64  remoteaddr: 10.10.30.14  replication: memsync  status: degraded  workerpid: 7229  dirty: 3424649216 (3.2GB)  statistics:    reads: 1649    writes: 26117    deletes: 0    flushes: 27    activemap updates: 1651    local errors: read: 0, write: 0, delete: 0, flush: 0    queues: local: 0, send: 0, recv: 0, done: 0, idle: 255I would appreciate it if someone could help me out here, either what I'm doing is unsupported or I'm doing it wrong. Thank you!",
    "target": "freebsd;storage;cluster;high avability"
  },
  {
    "id": "_softwareengineering.224368",
    "source": "How to use mock objects [C++] without passing them as arguments to functions <eos> I'm in the process of integrating a Unit Testing Framework for an existing code base in C++. I've zeroed down on CxxTest, but as it turns out we can use other Mocking Frameworks (like googlemock) in conjunction with CxxTest too.After reading tutorials on CxxTest (Mocking) and googlemock (the infamous turtle example), I have the general idea that you have to define a mock class (using macros etc), declare an object of the mock class and then pass it to the function you are unit testing. Now, there are many occurences in the existing code base where it isn't possible to do that.Here's an pseudo example to clarify:class CCandidateForTest{    public:    bool foo(int a)    {        CAnotherClass obj;        int b = obj.bar(a+2);        if (a == b) {            return true;        } else {            return false;        }    }}(This is over-simplified, there are also exceptions and the primitive types may also be other objects etc.; but you get the general idea) (also, creation of objects is not always direct and may sometimes use a factory)I want to write a test for the function CCandidateForTest::foo. This method internally creates an object of CAnotherClass, which I need to mock so that CAnotherClass::bar returns different values so that different code paths in foo are traversed in unit testing.In a nutshell, the problem is that the function being tested internally creates an object of the class that needs to be mocked - hence passing an instance of the mocked object to the function is not possible.How do I use mocking in such a case? Is there a specific mocking framework that makes this possible?",
    "target": "c++;unit testing;mocking"
  },
  {
    "id": "_unix.308687",
    "source": "systemd-nspawn OS container is unusable because I can't set the root password <eos> I combined the detailed instructions from the original blog post, and the more up to date instructions from the man page (using dnf instead of yum).# sudo dnf -y --releasever=24 --installroot=$HOME/fedora-24 --disablerepo='*' --enablerepo=fedora --enablerepo=updates install systemd passwd dnf fedora-release vim-minimal# sudo systemd-nspawn -D fedora-24Spawning container fedora-24 on /home/alan-sysop/fedora-24Press ^] three times within 1s to kill container.-bash-4.3# passwdChanging password for user root.New password:Retype new password:Result:passwd: Authentication token manipulation errorand an AVC popup, i.e. SELinux error.  It says passwd is not allowed to unlink (replace) /etc/passwd.  One of the suggestions from the Troubleshoot button is that I could assign the label passwd_file_t to /etc/passwd.What's wrong, how can I fix it?",
    "target": "fedora;selinux;container;systemd nspawn"
  },
  {
    "id": "_unix.104419",
    "source": "Fedora and Samba on VirtualBox <eos> I have Linux Fedora 18 installed as a VM Guest.Trying to share directories from the Linux VM Guest box to the Windows 7 Host. (NOTE: VirtualBox is installed on Windows 7, and the Linux virtual machine is created on it).I made my Samba share using text on this link:http://www.howtoforge.com/fedora-19-samba-standalone-server-with-tdbsam-backendI made all proper changes in /etc/samba/smb.conf, added proper user, etc. I even disabled SeLinux, and flushed the Iptables configuration. Samba is up and running of course. Also, I can ping Linux from Windows.This is the error I'm getting:Error code 0x800704cf  The network location cannot be reached. For  information about network troubleshooting, see Windows HelpThere are lots of other resources, like:http://www.sevenforums.com/network-sharing/113729-password-protected-network-share.html#post978798I did what is described there, and still having same problem. In all of the cases, I have same error.Can you give me some tips on what I'm doing wrong in this case?",
    "target": "linux;fedora;windows;virtualbox;samba"
  },
  {
    "id": "_unix.374494",
    "source": "Write name of file before a pattern inside that file <eos> I have thousands of similar files and I'd like to write their respective names after a pattern inside them. For example:**file 1's name is nexus0000inside the file there is:>Pseudomonas_1MATGATCCGCTTCGAGCAGGTCGGCAAACGCTATC>Pseudomonas_2MGTGAGCTTCGAGCAGGTCGGCGAGCCGCTATCand I want to get this:nexus0000>Pseudomonas_1MATGATCCGCTTCGAGCAGGTCGGCAAACGCTATCnexus0000>Pseudomonas_2MGTGAGCTTCGAGCAGGTCGGCGAGCCGCTATC**file 2's name is nexus0001inside the file there is:>Pseudomonas_1MATGATCCGCTTCGAGCAGGTCGGCAAACGCTATC>Pseudomonas_2MGTGAGCTTCGAGCAGGTCGGCGAGCCGCTATCand I want to get this:nexus0001>Pseudomonas_1MATGATCCGCTTCGAGCAGGTCGGCAAACGCTATCnexus0001>Pseudomonas_2MGTGAGCTTCGAGCAGGTCGGCGAGCCGCTATCetc.Up to this point, I've only managed to write the name of the file in the first line using: for file in nexus*; do echo $file$$(cat -- $file) > $file; doneThanks for the help!",
    "target": "linux;bash;bioinformatics"
  },
  {
    "id": "_softwareengineering.353148",
    "source": "Reserving database independence using Spring JPA <eos> We are planning to use Spring Boot with JPA for our next project and I am wondering how much flexibility JPA gives in reality. If we start developing using a self-hosted PostgreSQL server and later want to change to Amazon RDS PostgreSQL or SQL Server, will we run into a lots of problems? On paper, JPA should serve as an abstraction layer, but If we start to use Database specific data types, views, functions/stored procedures we quickly lose the ability to change. Generally what is the best practice? Use only JPA even if It means performance loss or dive hard into database programming with plSQL or T-SQL and if platform change is needed, rewrites of those functions needs to happen.Another problem is the data types. PostgreSQL for example can be extended with ltree and it provides a good foundation for hierarchical data structures, but to use it, one need to extend JPA to use the ltree data type or solve every interaction with functions.",
    "target": "database;spring;jpa"
  },
  {
    "id": "_datascience.14167",
    "source": "Insignificant input variable but high R2 <eos> Can a linear regression model with a single input variable x with x not significant but the model has a high R2?Can this exist? If yes, what are the reasons?",
    "target": "regression;linear regression"
  },
  {
    "id": "_unix.374833",
    "source": "ssh private-public key map for client <eos> In ssh communication between server and client, client gets authenticated by its private key. I want to know that how does the server knows that which public key belong to client, if the server has more than 1 public key in its authorized_keys file.",
    "target": "ssh"
  },
  {
    "id": "_unix.385455",
    "source": "How do i create a complete new rpm including all dependencies - Ansible disconnected package <eos> I need to install Ansible on my node and the node doesn't have internet connection. So i had to download all the dependencies and installed the same. Now i would like to create a complete package which includes all the dependenciesMain rpm - ansible-2.3.0.0-3.el7.noarch.rpmDependenciespython2-pyvmomi-6.5-1.el7.noarch.rpmpython-crypto-2.0.1-1.el7.rf.x86_64.rpmpython-crypto-2.6.1-1.el7.rf.x86_64.rpmpython-ecdsa-0.11-3.el7.centos.noarch.rpmpython-httplib2-0.7.7-3.el7.noarch.rpmpython-keyczar-0.71c-2.el7.noarch.rpmpython-paramiko-1.15.1-1.el7.noarch.rpmpython-pyasn1-0.1.6-2.el7.noarch.rpmPyYAML-3.10-11.el7.x86_64.rpmsshpass-1.05-5.el7.x86_64.rpmI am listing out the complete list so in case if anyone needs this might help.Is there any specific process to create a package ? ",
    "target": "linux;rhel;package management;rpm;rpmbuild"
  },
  {
    "id": "_datascience.13040",
    "source": "How to move forward on Regression problem <eos> I'm an undergrad interested in machine learning, and I'm playing around with some data in order to get a better understanding of the field.DATAI'm working with the following data:To give you an idea of what you're looking at (sorry for the unlabeled axes) -- each data point corresponds to a basketball player's points per game (y-values) over a one-week period (x-values).END GOALI want to predict progress throughout the year, so in order to test/train, I start with the first two points, fit a regression model, and then predict the third point. I then add the actual value of the third point to the set, re-train, and predict the fourth point, etc.ISSUESAs you can see, the data is all over the place, and the predictions are just as messy (sometimes getting up to ~200 points per game, which is totally impossible).I've tested different degrees of linear regression (quadratic, cubic, etc.) and degree=1 is always the best predictor because of how wonky the data is.IDEASI have thought of the following ways to get more accurate predictions:Smoothing the data, maybe using a moving average or some variantSet an upper limit for predictions Non-linear regression But outside of smoothing the data, I'm not sure if the rest are even possible in a regression model (upper limit) or applicable to this situation (non-linear).QUESTIONAre any of the ideas I had above worth pursuing? If not, is there anything I should look into that might help me solve this problem?Thanks!",
    "target": "machine learning;regression;linear regression"
  },
  {
    "id": "_unix.45887",
    "source": "Send a command from the console to a running X server <eos> Is it possible to send a command from the console, say tty1, to the terminal currently occupied with X (in my case tty7 as I use Debian), to tell for example mplayer to play a movie?Edit - made a shorthand function with the commands I learned in the answer below:function movie () {  ORIG_TTY=`fgconsole`  chvt 7  DISPLAY=:0 mplayer -fs $1 > /dev/null 2> /dev/null  chvt $ORIG_TTY}",
    "target": "command line;x11;console;remote"
  },
  {
    "id": "_unix.177148",
    "source": "How to install Debian GNU/Linux on HP Chromebook 14? USB boot doesn't works! <eos> Following this guide from the debian wiki, I'm tring to install Debian on my HP Chromebook 14 (FALCO).The problem is that, when I choose Install in the Debian-Installer's menu, instead of the installation process I receive again the screen stating that the OS verification has been turned off (Developer mode).I want to install Debian Jessie on a SD, booting the Debian-Installer from a USB stick.",
    "target": "debian;debian installer;chrome book"
  },
  {
    "id": "_softwareengineering.237402",
    "source": "Exception when logging exception: is it correct to ignore them? <eos> My question is specific to php, but i think it can be useful in other languages.I log into a table all the exception a code can throw:try{ //Some code } catch (Exception $e) {      $log = new Log(basename($_SERVER['PHP_SELF']), $_SESSION['id'], LogType::EXCEPTION, $e);      try {           $log ->addLog();       } catch (Exception $e2) {                //       } }The function addLog insert the exception informations into a database.But (by example if the connection with the database is lost) this function can throw an exception. I can't see what i have to do with this exception except ignoring it.I know ignoring exception is a bad practice, but what can i do in this particular case?If there is no problem to ignore it, is there a better way to indicate that this exception should not be taken into account?",
    "target": "php;exceptions;logging;exception handling"
  },
  {
    "id": "_unix.387684",
    "source": "important debian packages auto-removable <eos> I'm in a situation where apt shows 1000+ packages on my system marked as auto-removable. Amongst those are many that I know I need. I've resolved the situation by setting those to manually installed. But that results in almost half the packages in my system showing up as 'manually installed'. I ran into trouble when upgrading my system to the current stable version of Debian (apt-get dist-upgrade), and none of the 'manually installed' packages were upgraded. Again, I resolved the situation by setting all the 'manually installed' packages to automatically installed. That made the upgrade possible. But now all the upgraded, formerly 'manually installed' packages are again auto-removable. I tried finding not installed meta-packages that through their dependencies would at least reduce the auto-removable list. But without success. - Is there no way to get back to a situation where the packages marked as auto-removable are really those I don't need?",
    "target": "apt"
  },
  {
    "id": "_codereview.55122",
    "source": "My first login class in PHP with PDO and bcrypt <eos> This is the first time using a class. Please review this and tell me if it's secure and if it's the right way to do it.  The code itself is working, but I have doubts in the way I used all this.// register.php<?php...$db_password = $hash = password_hash($pass, PASSWORD_BCRYPT, array(cost => 10)); .... // store in the 'users' table only the hash of the password provided by user.?>// clases/manageUsers.php<?phpinclude_once('connect.php');class ManageUsers{public $link;public $hash;   function __construct(){    $db_connection = new dbConnection();    $this->link = $db_connection->connect();    return $this->link;}           public function LogIn($id,$email,$pass,$hash){    $query = $this->link->prepare(SELECT id,username,email,pass FROM users WHERE email = :email AND activated = 'y' LIMIT 1);    $query->bindParam(':email', $email, PDO::PARAM_STR);    $query->execute();                  $data = $query->fetch(PDO::FETCH_ASSOC);            return $data;               if(password_verify($pass,$hash)){                                       return TRUE;                        }else{            return FALSE;        }           }public function logOut($id){    $query=$this->link->prepare(UPDATE users SET verify = '0', activenow = 'n' WHERE id= :id LIMIT 1);    $query->bindParam(':id', $id, PDO::PARAM_INT);    $query->execute();    $countsOut = $query->rowCount();    return $countsOut;      }   }?>// login.php<?phpsession_start();error_reporting(E_ALL);ini_set('display_errors', '1');$errorMsg = '';$email = '';$pass = '';$hash=;$id='';$token='';$token = md5(uniqid(rand(),TRUE));if (isset($_POST['e'])) {   $email = $_POST['e'];$pass = $_POST['p'];$email = stripslashes($email);$pass = stripslashes($pass);$email = strip_tags($email);$pass = strip_tags($pass);if ((!$email) || (!$pass)) {     //header(location: index.php);    $errorMsg = 'Please fill in both fields';} else {     include_once 'clases/manageUsers.php';     include_once 'clases/connect.php'; $loginUsers = new ManageUsers();$data = $loginUsers->LogIn($id,$email,$pass,$hash);            $hash=$data['pass'];    if(password_verify($pass,$hash) == TRUE){        $db = new dbConnection();// <- New connection to database to update members table        $dbh = $db->connect();   //  with new login data. I think this is WRONG...            session_regenerate_id(TRUE);            $id=$data['id'];                    $username=$data['username'];                            $query = $dbh->prepare(UPDATE users SET  verify= :token, lastlog=NOW(), activenow='y' WHERE id= :id LIMIT 1);            $query->bindParam(':id', $data['id'], PDO::PARAM_INT);            $query->bindParam(':token', $token, PDO::PARAM_STR);            $query->execute();                $_SESSION['id'] = $data['id'];                $_SESSION['username'] = $data['username'];                $_SESSION['token'] = $token;            header(location: profile.php?id=$id);             exit();    } else {             session_destroy();            header(location: login.php);            $errorMsg = Incorrect login data, please try again;    }}} ?>//logout.php<?phpsession_start();include_once 'clases/manageUsers.php';if(isset ($_SESSION['id']) && isset ($_SESSION['username']) && isset ($_SESSION['token'])){$id=$_SESSION['id'];    $LgOut = new ManageUsers();    $loggingOut = $LgOut->logOut($id);    if($loggingOut > 0){    session_destroy();    session_regenerate_id(TRUE);    header ('location: login.php');    }else{    echo 'Not Logged Out';    }}?>",
    "target": "php;object oriented;pdo;authentication"
  },
  {
    "id": "_unix.61282",
    "source": "Kernel and QEMU : Unable to mount root fs error <eos> I am trying to run a distro in the virtual disk image with a custom kernel,so that I can experiment and debug the kernel. I followed this to make a disk image and then install Debian to it. Now I tried running distro with the following command:-qemu-system-i386 -hda debian.img -kernel ../linux-3.6.11/arch/i386/boot/bzImage -append root=/dev/sda1To my dissappointment  it simply gives a Kernel panic-not syncing:VFS:unable to mount root fs on unknown-block(8,1). How can I fix the problem?Am I on the right path as far as kernel debugging is concerned? ",
    "target": "linux;kernel;linux kernel;debugging;qemu"
  },
  {
    "id": "_unix.236937",
    "source": "java installation in RHEL <eos> while installing java in redhat i'm facing some problems..i've attached the screen print ..if anyone could help me with it it would be appreciable..thank u.. i unzipped the file using tar command .once i created the softlink for it ,i should be able to see java version and all but which in this case i'm not able to see .. please need help here..",
    "target": "rhel;java"
  },
  {
    "id": "_webmaster.72841",
    "source": "Cached Bootstrap vs Custom CSS <eos> I am debating whether to use an existing framework such as Bootstrap which has a decent chance of being cached vs custom CSS which has zero chance of being cached.Which is better from a UX point of view and an SEO point of view?",
    "target": "cache;css framework"
  },
  {
    "id": "_cs.42573",
    "source": "Can the concatenation of two non-regular languages be regular? <eos> Can anyone give an example of two non-regular languages $A, B \\subseteq \\{0, 1\\}^$ for which the language $AB$ is regular?",
    "target": "regular languages"
  },
  {
    "id": "_webapps.103648",
    "source": "Creating Google Forms from Google Spreadsheet <eos> It is possible to use the FormCreator app to create Google Forms using Google Spreadsheet. My question: how did app manage to achieve that?",
    "target": "google spreadsheets;google forms;google sheets addons"
  },
  {
    "id": "_unix.112406",
    "source": "How do I switch to vi editing mode in readline? <eos> I want to switch to vi editing mode in a readline environment.  But I don't want to use 'set -o vi'.  I want to temporarily switch using a keyboard shortcut.  The man page says I can do this with M-C-j.  But that doesn't work for me.  I'm using Ubuntu and an xterm.  Doesn't work under gnome-terminal either.",
    "target": "bash;readline"
  },
  {
    "id": "_unix.182996",
    "source": "Nvidia linux drivers on Dell XPS L502X Nvidia GeForce GT 540M <eos> I have a Dell XPS L502X with an Nvidia GeForce GT 540M and I'd like help installing the official drivers off the Nvidia site. Every time I try I brick my installation and have to re-install. Even if I restore my Xorg.conf it still has some serious bugs. I'm currently running the drivers from inside the driver manager but I want to use the latest ones on the site.",
    "target": "linux;linux mint;drivers;nvidia;proprietary drivers"
  },
  {
    "id": "_unix.92108",
    "source": "Regular Expressions within a string in AWK using if/then control structure? <eos> PROBLEMI want to specifically use AWK (GAWK, MAWK, whatever) in an AWK script to sum up the values in field 9 for every record that contains runner__.jpx (the underscores are placeholders for two digits 0-9) in field 6 and good in FIELD 7.SAMPLE FILEFeb 14 11:33:16 ringer a[2388]: runner01.jpx good aa 3Feb 14 11:33:32 ringer a[2388]: runner24.jpx good xx 1Feb 14 11:33:39 ringer a[1894]: jogger02.jpx good aa 5Feb 14 11:33:45 ringer a[2388]: runner99.jpx stop cc 1ATTEMPTHow could I do this?  I tried using an if statement, like:BEGIN {    sum = 0}{    if (($6 == runner[0-9][0-9].jpx) && ($7 == good))        sum += $9}END {        printf sum}Is there way to do this by matching strings in fields using if statements?  Am I allowed to use regular expressions within the if statement?  What is an alternative method to do this?  Thanks.",
    "target": "shell script;scripting;awk;mawk"
  },
  {
    "id": "_unix.342753",
    "source": "Screen dims after xrandr <eos> I have an old P3 laptop with an 800x600 screen on which I've installed WattOS 7.5.  I know it is now on 10 but 7.5 is the latest one that will fit on a CD.  The later ones will only fit on DVD.  This is an old machine - it only has a CD reader, it will not boot off USB and it doesn't like microWatt (which still fits on a CD).  There is something wrong with the microWatt drivers - the entire screen appears as a 0.25 bar.  Anyway, it has WattOS 7.5.My login screen is very reddish.  If I run it from my desktop it is greenish - which is the correct colour.  Also, for some reason, the system thinks it has a 1024x768 screen.  After logging in, all the colours are OK.The obvious answer would have been to ask the WattOS site but it is a chicken and egg situation.  It wants me to sign in and in order to sign in, I need an invite key.  I've got no idea what one of those is.  To find out, I'd have to login and ask but I can't login because I haven't got an invite key.Before committing the settings in stone, I decided to try them out.  First, I set the screen sizexrandr -s 800x600The screen size changes and I can now see the taskbar but the brightness has also changed to half.  When I type xrandr -q, I getxrandr: Failed to get size of gamma for output defaultFollowed by the resolutionsI suspect it is assuming I have 24 or 32-bit colour but this is an old system so at most 16-bit colour, which possibly explains why it has all gone dim and why my login screen seems to have lost its blue/green component.The questionsI must be looking up the wrong keywords - I can't find how to set the number of colours to 65536 or to tell the system that it has 16-bit colour.  All the hits I am getting are how to set console window colours.Another lot of searches says gedit /etc/X11/xorg.conf  This file doesn't exist on my system.  Again, I think I'm looking up the wrong keywords.  Almost all the hits tell me where it is, none of them tell me what has replaced it. How do I make these settings permanent so that my login screen appears in the correct colour and the system knows what size my screen is.Edit I've found https://ubuntuforums.org/showthread.php?t=1493835 Apparently xorg.conf will be used if created.  I'll give that a try later today.  The laptop can only stray from a power supply for 5 minutes: after that it shuts down.Edit This question is now purely academic - the machine just died.",
    "target": "configuration"
  },
  {
    "id": "_softwareengineering.20652",
    "source": "Need clarification concerning Windows Azure <eos> I basically need some confirmation and clarification concerning Windows Azure with respect to a Silverlight application using RIA Services.In a normal Silverlight app that uses RIA services you have 2 projects:AppApp.Web... where App is the default client-side Silverlight and app.web is the server-side code where your RIA services go.If you create a Windows Azure app and add a WCF Web Services Role, you get:App (Azure project)App.Services (WCF Services project)In App.Services, you add your RIA DomainService(s). You would then add another project to this solution that would be the client-side Silverlight that accesses the RIA Services in the App.Services project. You then can add the entity model to the App.Services or another project that is referenced by App.Services (if that division is required for unit testing etc.) and connect that entity model to either a SQLServer db or a SQLAzure instance.Is this correct?If not, what is the general 'layout' for building an application with the following tiers:UI (Silverlight 4)Services (RIA Services)Entity/Domain (EF 4)Data (SQL Server)",
    "target": "silverlight;azure"
  },
  {
    "id": "_unix.289268",
    "source": "Editing the iptables file on Asus firmware <eos> I have downloaded the Asus DSL-n14u firmware, extracted the .trx file and located the iptables file, as linked below:https://www.dropbox.com/s/sanz5x2bw0o5xsu/iptables?dl=0I know the iptables rules that I need to add. However, I am just a little confused about two things:1) Is it possible to edit this file, add the rules, repackage the .trx file and then reload the firmware on the router?2) If #1 is possible, where in the file would I add my custom rules?Thanks, just need a little guidance :)",
    "target": "linux;iptables;firmware"
  },
  {
    "id": "_softwareengineering.230307",
    "source": "MVC: What is the difference between a model and a service? <eos> Why in some frameworks the logic layer is called Model whereas in some it is called Service. Are they different from each other or just different by naming conventions?UPDATE 1The reason I'm asking is because in Zend Framework, a classical MVC framework, everybody uses the concept of Model. Now I'm learning AngularJS and it seems that the word Model disappeared and was replaced by the word service.What I noticed is that a service is more like a singleton that can be reused again and again (example: a REST client) whereas a model is more related to the data manipulations coming from the controller in the MVC pattern.",
    "target": "mvc;model;service"
  },
  {
    "id": "_unix.216187",
    "source": "cpu temperature is higher than usual after installing xubuntu <eos> I have installed Xubuntu 14.04 on Asus S550CB but the system becomes warmer than usual. So I tried to configure lm-sensors and saw cpu temperature is about 50 degrees. I guessed that some drivers are not installed and runlshw -html > system.html && xdg-open ./system.htmlThen I noticed that 3 drivers are red. Does it mean they are not installed? Those drivers were:1)id: generic:0Description: signal processing controller2) id: serialDescription: SMBus3) id: generic:1Description: signal processing controllerNow if it means that they are not installed, how can I search for them and install them? Thanks for your help.",
    "target": "drivers;cpu"
  },
  {
    "id": "_webmaster.89972",
    "source": "Is dofollow linking from a long list of items allowed by Google? <eos> I've just finished writing a list of 190 items. I'd like to make some links of the list dofollow, but I don't know if Google still allows dofollow links and how many per article.",
    "target": "seo;google;links;dofollow"
  },
  {
    "id": "_cogsci.17447",
    "source": "Can a mother's untimely death lead to misogyny? <eos> Many years ago, in an undergraduate psychology class, we were discussing misogyny, and my professor told us that there was a significantly high number of misogynists who had lost their mothers (specifically that they had died) in their mid to late teens.  He said it was because the teen were angry at their mothers for leaving them, but were unable to process or express what they were feeling, so the anger was redirected into an anger towards all women.I have tried to find some mention of this theory elsewhere, but cannot seem to formulate the right Google search phrase.  Is this a theory that still has merit, or has it been disproven?  If it is a valid belief, can someone direct me to a book or online documentation which discusses it?",
    "target": "cognitive psychology"
  },
  {
    "id": "_softwareengineering.207848",
    "source": "object oriented analysis, missing methodology <eos> I've studied design pattern and oop principles, still feel that there is something missing in most design theories. Maybe the fact is that there is not a 'theory' as it is in database design. Let me explain with an example.Suppose that i want to model different ways to produce orange juice.Let say that i start by a class Oranges, that models a lot of oranges that will be of a certain variety, of a certain ripeness, they may have been froozen etc., ant these will by my Oranges class properties. Then i continue by providing Orange with a squeeze method. This seems to be correct, because ties togheter the method to the data it applies to, that is the precondition to achieve encapsulation and other valuable oop principles. But quickly it comes out that it has not been a good choiche because there is not just one way to squeeze an orange. It would be preferrable to have a Juicer class whose instances contains details of the juicing method: by hand, with an electric juicer, including the pulp, not to mention mixing different varieties of oranges. Where the latter opens an whole new cathegory of possibilities that were not available (or not achievable with ease) if each Oranges instance would have been processed using its squeeze method.Say that we have performed a 'refactoring' of our oo architecture and move to another similar example that will get us to the point.It is now a common practise to use an ORM to save class instances to database and get them back later. In what is it similar to the Oranges class example? Well, here i have a class whose instances may be persisted to a database, that is 'allow a particular process'. But the class itself does not contain the logic for doing so, that actually is in the ORM classes. So it seems that the same process of 'externalization' of the Oranges example has taken place in this case too.And here is the questionGiven that it is desireable to reduce the number of attempts-and-refactorings to the minimum, what are the questions that a programmer should put in order to determine precociously if a method should be externalized to another class? Are all the methods of a class exernalizable or is there a set of core methods that are inherently of the class itself and so not externalizable?IdeasAs i said in the beginning, i'm not completely clueless, i feel more like that a 'comprehensive' theory is missing.It's easy to put some examples: if i have a class whose instances represent invoices, i will have a method 'calculateTotalAmount'. This is clearly an inthrinsic, core method of that class, as oppsed to the methods for saving that invoice to the database that will be 'external' of the class itself. But this is not a 'final answer', but a starting point that serves to demonstrate that 'not all methods are equal', but methods may be divided into cathegories. How many (useful) cathegories can we make, and are there methodologies that put these questions?",
    "target": "object oriented;development methodologies"
  },
  {
    "id": "_softwareengineering.68876",
    "source": "A combined if/switch statement syntax with exception handling for a C#-inspired language <eos> It is sometimes necessary to try/catch exceptions inside the if condition, but not the body that follows. In C#, this is really rather cumbersome, requiring locals and code that isn't entirely obvious, at a glance, as to its operation.It is also sometimes necessary to write switch statements, which, unlike if, have more than two possible outcomes, although in C# this requires the use of a fairly unpopular syntax.Here's an idea for combining these.Merging switch with try/catchFirst, we change the fundamental syntax of switch to be close to that fairly popular replacement, but without the extra curlies:switch (condition)    case 1 { }    case 2 { }    default { }Next, we make it possible to catch exceptions in the condition. Under the hood, this inserts an appropriate try/catch block only when at least one catch is present:switch (condition)    catch FileNotFoundException e { } // use e    catch ArgumentException { }    catch { }    case 1 { }    case 2 { }    default { }Now we make it easier to chain several such statements akin to if/else chaining, by moving default one level up, and renaming it to else:switch (condition1)    catch FileNotFoundException { }    case 1 { }    case 2 { }else switch (condition2)    case abc { }    case def { }else    { }And so we have a switch merged with try/catch!Combining with 'if'Both switch and if now have else clauses, so why not allow you to mix them as you please:if (bool-condition1)    { }else if (bool-condition2)    { }else switch (string-expr)    catch FileNotFoundException { }    case thing { }else    { }(thanks ach_l!)Further improvementsSwitching on a list or range of values has been proposed and can be easily incorporated:switch (int-expression)    case 1 { }    case 2, 5 { }    case 10..50 { }else switch (string-expression)    case abc { }    case def { }else if (boolean-condition3)    { }else    { }In this case it could be really convenient to be able to reference the value in the condition clause. This can be easily incorporated by allowing one to declare a single variable in this clause the same way C#'s using allows:switch (var z = int-expression)    case 2, 5 { return z == 2 ? two : five; }    case 10..50 { return (z * 10).ToString(); }BenefitsAmong other benefits, one can now express a common error-handling scenario concisely, and yet not WTFy:switch (bool-condition)    catch FileNotFoundException e { }    case true { }    case false { }Would this solve any real-life coding difficulties you have encountered? Are there any tweaks you would apply to this?",
    "target": "language design;language features;syntax"
  },
  {
    "id": "_cogsci.13710",
    "source": "The line between fantasy and reality <eos> It is already well known that imagining certain things can have a physiological effect on us. For example, imagining an intense situation can cause the heart rate to go up, while imagining a quiet, safe place might have the opposite effect (or maybe that one is simply a result of distracting oneself from whatever may cause unrest).Another example would be imagining yourself doing something you don't want to do. From what I understand, this reduces the stress of anticipating work.I wonder, though, what exactly separates this from actually doing what you imagine? what are the differences in the physiological effects? How different is the activation of the brain? (aside from the obvious - for example, imagining something physical happening to you, such as being punched, won't actually cause any bruising)",
    "target": "visualization"
  },
  {
    "id": "_hardwarecs.848",
    "source": "How many TF2 servers would this VPS be able to run? <eos> I've been renting from a certain company for a while now, and I'm currently thinking of switching to NFOServers because I would get a cheaper deal since I plan to expand the servers further. However it's not going to be many servers, so I was wondering if it would be possible to at least get 3 servers running on NFOServers' Two Core VPS plan?Specs (If you're too lazy to open their site):Two full, dedicated HT CPU cores (Nehalem or better)2048 MB of RAM200 GB of RAID-protected storage8000 GB of bandwidth transferIf not, how many servers will I be able to have?",
    "target": "gaming;server"
  },
  {
    "id": "_unix.354339",
    "source": "upgrade openssl for old version xampp <eos> I am trying to enable TLS 1.1 on my xampp apache server, but it seems like the version of OpenSSL is too old for that. (Error: SSLProtocol: Illegal protocol 'TLSv1.1')Can anyone help me how I can upgrade OpenSSL? or something easier approach? I need to keep PHP version as 5.3.1.My configuration is Apache/2.2.14 (Win32) DAV/2 mod_ssl/2.2.14 OpenSSL/0.9.8l mod_autoindex_color PHP/5.3.1.Thank you so much!",
    "target": "openssl;xampp"
  },
  {
    "id": "_softwareengineering.344935",
    "source": "Are Timeseries Databases useful for non-numerical data? <eos> I have a huge time series (about 30 million) of network paths with the following format:timestamp, path, latencyThe path is a sequence of IP address, so it can be represented either as a string or an array of integers. Currently the data are stored in text files which makes it very slow the analysis and querying of paths. It was suggested to me to use a timeseries database (TSDB), such as InfluxDB or OpenTSDB, to store them efficiently, but some background reading I did suggests that TSDBs are appropriate for numerical values. For instance OpenTSDB mentions:OpenTSDB is a time series database. A time series is a series of numeric data points of some particular metric over time.Is there any optimization I'll gain from using a TSDB instead of a relational DB in my case, and generally for timeseries that include non-numerical values?The main queries I plan to do is basically to get all the paths between two timestamps, check if there are path changes, and how this changes affect the lattency. Additionally I may need to search for path with specific hops (e.g. select all records where the path includes the IP hop 1.2.3.4), or all the paths with latency over a certain threshold.",
    "target": "database;performance;relational database;analytics"
  },
  {
    "id": "_codereview.131496",
    "source": "Call Center Design <eos> Imagine you have a call center with three levels of employees: respondent, manager, and director. An incoming telephone call must be first allocated to a respondent who is free. If the respondent cant handle the call, he or she must escalate the call to a manager. If the manager is not free or not able to handle it, then the call should be escalated to a director. Design the classes and data structures for this problem. Implement a method dispatchCall() which assigns a call to the first available employee.package design;import java.math.BigInteger;import java.util.*;import java.util.concurrent.LinkedBlockingQueue;public class CallCenter {    Employee[] employees;    int size = 100;    Map<Employee,PhoneCall> callMap = new TreeMap<Employee, PhoneCall>(new Comparator<Employee>() {        @Override        public int compare(Employee o1, Employee o2) {            return 0;        }    });    Queue<PhoneCall> calls ;    PriorityQueue<Employee> dispatchQueue;    CallCenter(){      employees = new Employee[size];      calls = new LinkedBlockingQueue<PhoneCall>();      dispatchQueue = new PriorityQueue<Employee>(new Comparator<Employee>() {          @Override          public int compare(Employee o1, Employee o2) {              if(o1.id > o2.id) return -1;              else if(o1.id < o2.id) return 1;              else return 0;          }      });        for(int i = 0;i<size;i++){            if(i==0 || i==1){                employees[i] = new Director(i);            }            else if(i>=2 && i<=6){                employees[i] = new Manager(i);            }else{                employees[i] = new Respondent(i);            }            dispatchQueue.offer(employees[i]);        }    }    public void dispatchCall(PhoneCall p){        if(dispatchQueue.isEmpty()){            calls.offer(p);        }else{            callMap.put(dispatchQueue.poll(), p);        }    }    public void endCall(Employee emp){        if(callMap.containsKey(emp)){            callMap.remove(emp);            dispatchQueue.offer(emp);        }    }    public void processCallsQueue(){        while(!calls.isEmpty()){            if(dispatchQueue.isEmpty())break;            else dispatchCall(calls.poll());        }    }    public  Employee getRandomEmployee(){        Random rn = new Random();        int randomPosition = rn.nextInt(100);        return employees[randomPosition];    }}class PhoneCall{    int id;    String location;    String number;    PhoneCall(){        Random rand = new Random();        id = rand.nextInt();        location = US;        number = new BigInteger(130,rand).toString();    }}class Employee{    int id;    String designation;    int priority; //priority is the call priority 1. Respondent, 2. Manager , 3. Director    Employee(){    }    Employee(int id){        this.id = id;    }}class Manager extends Employee{    Manager(int id){        super(id);        designation = MANAGER;        priority = 2;    }}class Director extends Employee{    Director(int id){        super(id);        designation = DIRECTOR;        priority = 3;    }}class Respondent extends Employee{    Respondent(int id){        super(id);        designation=RESPONDENT;        priority=1;    }}Is this design too shallow to be done in an interview? Any feedback on the design is greatly appreciated.",
    "target": "java;object oriented;design patterns"
  },
  {
    "id": "_softwareengineering.308640",
    "source": "Is it bad to write object oriented C? <eos> I always seem to write code in C that is mostly object oriented, so say I had a source file or something I would create a struct then pass the pointer to this struct to functions (methods) owned by this structure:struct foo {    int x;};struct foo* createFoo(); // mallocs foovoid destroyFoo(struct foo* foo); // frees foo and its thingsIs this bad practice? How do I learn to write C the proper way.",
    "target": "c"
  },
  {
    "id": "_cs.48705",
    "source": "How to decide if a propositional formula is a well formed? <eos> So, I have the following propositional formula:(((P  Q)  S)  T)How do I decide if it's well formed?",
    "target": "propositional logic"
  },
  {
    "id": "_unix.21956",
    "source": "Pretty tail -f for log files <eos> Possible Duplicate:How to have tail -f show colored output Is there a bash/awk script or utility that pretty formats and colors tail -f from log files? At the moment I am specifically looking at Apache log files.",
    "target": "software rec;logs;tail"
  },
  {
    "id": "_webmaster.19003",
    "source": "Rel canonical link tag pointing to the same page <eos> I'm implementing the canonical tag in my page to avoid be penalized with duplicate content flag by search engines. My doubt are the following:If I have a page COPY with the canonical tag pointing to ORIGINAL, and in this ORIGINAL page I have the canonical tag pointing to ORIGINAL again, what are the consequences? The thing is, that for me is more easy to generate the tag in all pages, and not only in the copies.Can i put the <link rel=canonical href=ORIGINAL /> in anyplace, or should be in the <head> tag.",
    "target": "seo;canonical url;rel canonical"
  },
  {
    "id": "_unix.128520",
    "source": "can't get hello world shell script to run in FreeBSD <eos> Server is running FreeBSD 9.2.Using vim, I wrote the following script called hello:#!/bin/shecho hello worldThen I set it as executable:>chmod 755 helloThen I tried to run it from the command line (while in the same folder where the script was saved):>helloI got this error message:hello: Command not found.Is there something different I have to do to make an executable script in BSD?",
    "target": "shell script;executable"
  },
  {
    "id": "_webmaster.25886",
    "source": "Setting up funnel URLs with regular expressions <eos> I'm trying to set up Google Analytics to track my e-commerce checkout page. The URLs in the process are as follows:/checkout/[order number]/checkout/[order number]/your_details/checkout/[order number]/review/checkout/[order number]/completeI've used the regular expression for the first page (/checkout/[order number]:/checkout/\\d+That works fine, however the problem is I'm struggling to work out what the regular expression should be for the other pages. ",
    "target": "google analytics;analytics;goal tracking"
  },
  {
    "id": "_softwareengineering.6190",
    "source": "Windows Service or Windows Task Scheduler? <eos> I am planning to create a utility, which will query the database and store some information (on another table in the database). Its a multi-threaded utility and require to run for every 5 or 10 minutes/later may be thrice in a day.I see two options to achieve this in C#/DotNet programming. creating windows service having timer approach inside it.a console program and schedule it using windows task scheduler.Which one do you prefer and why? ",
    "target": ".net"
  },
  {
    "id": "_unix.210766",
    "source": "Why does sed replace all occurrences instead of only the first occurrence? <eos> I'm trying to replace the first occurrence in a file using sed:sed -i s/he/He/ dummy.txtInstead of replacing first occurrence, it replaces all the occurrences, even without /g.According to the documentation it should replace the first only. The sed version which is:GNU sed version 4.1.5Am I missing anything? Or does the behavior differ for different sed implementations?",
    "target": "sed"
  },
  {
    "id": "_unix.355925",
    "source": "How to append character to the end of line using SED? <eos> I have the following text:serverName: NZRC222total: 8.46 GBserverId: 259695serverName: NZRC333total: 50.13 TBserverId: 260582serverName: NZRC555total: 9.31 TBserverId: 260956My desired output would be: serverName: NZRC222,total: 8.46 GB,serverId: 259695,serverName: NZRC333,total: 50.13 TB,serverId: 260582,serverName: NZRC555,total: 9.31 TB,serverId: 260956,Basically, I want to generate a csv file which can be imported to the Excel.When I go with :sed '/\\w.*/ a ,' file I get this:serverName: NZRC222,total: 50.13 TB,serverId: 260582,serverName: NZRC333,total: 9.31 TB,serverId: 260956,Any suggestions? Thank you in advance!",
    "target": "text processing;sed;csv"
  },
  {
    "id": "_unix.359588",
    "source": "cp/rsync both grind to a halt when copying to USB/Micro SD <eos> I'm trying to transfer about 20GB of music from my Arch Linux laptop to a Micro SD card, via a USB reader. The process starts off fine; the first ~50 songs take a combined one second, although from what I've read that's just to do with caching (or something...) and doesn't represent the actual speed. Then it goes to what I'd consider a reasonable speed, where each song takes anywhere between one and five seconds (the files are lossless, so maybe ~15mb on average).However, after a few hundred songs, things just slow down completely. A single file will take about five minutes to transfer, and that's a conservative estimate. I left it running overnight and barely any progress had been made!The card is a recently purchased class 10 Sandisk, and I've tried using it in both a USB and a regular SD card adapter, so I'd like to try some OS-level solutions before I investigate further into the physical side of things. I've also tried all three USB ports on my laptop and they all face the same issue. I've tried using the regular cp -rv ~/music /mnt/sd command, as well as rsync -rvh ~/music /mnt/sd, and the same thing happens with both. If, for testing purposes, I copy to a destination on the same partition then everything's fine, so it's definitely to do with it being on a different partition. I've also tried the suggestion posted here which didn't help.My kernel version is 4.10.9.Any ideas?",
    "target": "arch linux;rsync;cp;file copy;sd card"
  },
  {
    "id": "_softwareengineering.124434",
    "source": "What is ethical/unethical while seeking help on the web with programming assignments? <eos> I have used the web and Stack Overflow extensively during the past month or so in creating my final project for my C# class. I have used so much code that I didn't write myself that I feel I am being unethical by not giving proper credit to the people who helped me; or the websites that have provided excellent examples.Is it unethical to publish work which was created by me, even though its hardest problems were solved by other people? Should I credit these people for helping me with my assignment? Or the web sites which provided examples?",
    "target": "ethics;credits;attribution"
  },
  {
    "id": "_unix.111629",
    "source": "Samba - releasing file lock <eos> Our (Windows) users are starting a program from a shared subdirectory on a Debian server. They use samba to access this directory.When we want to release a new version of the program the started files (program file and libraries) are locked. To release these locks we restart the samba service. After restarting all locks are released and the new files can be copied to the directory.The only disadvantage is that the users are losing all the handles to the files in all directories which are served by samba on this server. We are starting Keepass from another subdirectory and Keepass crashes afterwards.Is there a nicer way of releasing the locks (in a single directory) ?Is there a way to separate the samba shares ?",
    "target": "debian;windows;samba"
  },
  {
    "id": "_opensource.5535",
    "source": "Is the text in my open source project under the GPL? <eos> I have an open source project that used to be under the GPL licence (now it has no licence).In this repository I had many short stories. My intention was for the code to be open source but the stories to be our copyright. When I made the commit I had not considered this. Once I realized that this might be an issue I removed the license for all future versions of the code. What I am concerned about now is what licence do people have with these stories? Can they do whatever they want with them under the terms of the GPL? If (hypothetically) somebody wanted to write a book or a movie based on these stories would they be allowed to? If they wanted to make a complete copy of the website with all of the stories in it, can they?Another issue I have is that I would like to make the code open source again under the GPL or potentially some other licence. If I do this will all the code in-between the 2 versions which are open source, be under any license? For example after I removed the license the first time I continued to add more stories and text that I would not like people to be able to do whatever they want with. Now these are all in a database and not part of the source code. But if I make the project open source will they be able to use that content as well? ",
    "target": "copyright;gpl 3;github"
  },
  {
    "id": "_cs.27662",
    "source": "Relationship between an NP-hard problems with the subsets of them? <eos> I am writing a paper. I have a problem and I want to prove that it is an NP-hard problem. However, for simplicity, I select a subset from my problem to prove that it is an NP-hard problem. Although I think that it is reasonable that if a subset of problem is NP-hard, it result in the problem being NP-hard, but I think writing this sentence in a paper need a reference. I will be thankful if anyone helps and gives me a reference for it.......................More explanations : My problem includes N boxs, B(1) through B(N). Every box B(i) has a size called t(i) and t(i)<=t(i+1). Now, to prove that my problem is NP-hard, I have considered a subset of my problem  such that there are arbitrary number of boxes with size t(N). And for this subset I have proved that my problem is NP-hard, as a result the problem is NP-hard. is this an acceptable assumption?",
    "target": "complexity theory;np hard"
  },
  {
    "id": "_cs.14261",
    "source": "Implementation of datatypes in Haskell? <eos> In Haskell, are datatypes converted to the Church encoding i.e. folding the data type.  For example, given data N = Z | S Nin Haskell, it can be converted to its church encoding by foldN Z z s = zfoldN (S n) z s = s (foldN z s n)Where if we do foldN m, we get the church encoding:\\z s . s (  .... s n ... )In Proofs and Types, Girard shows how this works for any inductive datatype.  There are two questions I have: (1) is this actually how Haskell treats datatypes and (2) what is the equivalent construction for coinductive datatypes.",
    "target": "data structures;term rewriting;interactive proof systems"
  },
  {
    "id": "_unix.246755",
    "source": "What is .gnupg directory in the home directory? <eos> I found a strange directory in my home directory on Linux Mint 17.2 Cinnamon (though I'm pretty confident it's on all Linux distros) called .gnupg. It has no access given to ANYONE other than root. So I have three questions:What is this directory? What does it contain?Why is it placed in the user's home directory yet doesn't give them any access?Will it do any harm by just entering the directory as root? (I know that's a stupid question, but I want to be safe)",
    "target": "home"
  },
  {
    "id": "_unix.163338",
    "source": "How to uninstall compiled GTK+ <eos> A few days ago I compiled GTK+ 3.12 on my Ubuntu 14.04 and Linux Mint 17 (with Cinnamon) distros. It messed up the appearance. How can I remove it totally and safely? I didn't change the default installation location when compiling.I also have versions 3.10 and 2.24 (installed by default.)",
    "target": "gtk3;uninstall"
  },
  {
    "id": "_unix.52188",
    "source": "Hyperthreading not detected by Linux <eos> I have a Dell server with two Intel Xeon E5645 cpus, each cpu has 6 cores, and each core is hyperthreaded (i.e. should be equivalent to two virtual cores). I installed CentOS 6.2 on this server and it seems to detect only 12 cores (although there should be 24 virtual cores altogether).When I look at /proc/cpuinfo I get for each cpu:cpu cores: 6siblings: 6Which seems to indicate that number of cores equals number of virtual cores, or hyperthreading not detected/enabled.When I run dmidecode I can see that HT flag is turned on and I do see the following, which seem to indicate that the BIOS is configured correctly for hyperthreading.Core Count: 6Core Enabled: 6Thread Count: 12Is there some configuration that I am missing in order to make Linux detect all virtual cores?",
    "target": "linux;centos;cpu;hyperthreading"
  },
  {
    "id": "_unix.256596",
    "source": "Deploying a package through puppet from URL <eos> How can i install a package through puppet by using the URL of the .tar.gz of the package on centos 6 client. Is there any native support in puppet without installing anything extra on the puppet master.",
    "target": "centos;package management;puppet"
  },
  {
    "id": "_webapps.108847",
    "source": "Cognito Forms. Text Characters Calculation <eos> How to calculate numbers of characters in a text box, and to make sure it is not lesser than or greater than a specific amount of numbers",
    "target": "cognito forms"
  },
  {
    "id": "_unix.222315",
    "source": "U-Boot: Changing TTY columns and rows for virtual consoles <eos> Having installed GRUB as boot manager allows the operating system (Linux) to boot on specific video mode so the TTY virtual consoles change its columns and rows (width and height).For example, editing /etc/default/grub (for GRUB v2) :GRUB_GFXPAYLOAD_LINUX=1024x768But now I have an embedded Linux device: Utilite Pro from CompuLab, and I am testing Ubuntu 12.04 and Kali Linux v1.1.1 for it.They both work OK, but seem not to use GRUB as boot loader. According to the docs, they use U-Boot as boot manager.  Could I do this resolution change for virtual consoles (TTY, text mode) for U-Boot?I don't need to change the GUI video resolution, yet I can accept to change it too if it is needed.",
    "target": "video;tty;u boot"
  },
  {
    "id": "_codereview.128235",
    "source": "Have a class that holds all the interfaces <eos> I seriously didn't know how to write this in Google, there must be an answer lying around. Here it goes: I'm using Ninject (IoC) and ASP.NET MVC 5. I have a business layer with a couple of classes. Is it ok if I have one class that holds all these classes? Like this:    public class BusinessLayer : IBusinessLayer{    public IOrganizerLogic OrganizerLogic { get; }    public IParticipantLogic ParticipantLogic { get; }    public IPaymentLogic PaymentLogic { get; }    public ITournamentLogic TourmanetLogic { get; }    public BusinessLayer(IOrganizerLogic organizerLogic, IParticipantLogic participantLogic,        IPaymentLogic paymentLogic, ITournamentLogic tournamentLogic)    {        OrganizerLogic = organizerLogic;        ParticipantLogic = ParticipantLogic;        PaymentLogic = PaymentLogic;        TourmanetLogic = TourmanetLogic;    }}",
    "target": "c#;asp.net;interface"
  },
  {
    "id": "_unix.205031",
    "source": "CPanel / WHM // CentOS // SELinux <eos> The file config indicates SELinux mode is target.Is it enabled or disabled ?Terminal/SSH says 'disabled'.But several behaviours here and there act like it is enabled.Thanks.",
    "target": "centos;cpanel"
  },
  {
    "id": "_unix.178218",
    "source": "How to use Cut and Grep command to find data separated by : <eos> In my simple database, it contains text of like, example, soldiers.Name:Rank:Gender:Age:Years of ServiceTom Corporal:Recruit:Male:19:2Nicole Sergeant:Corporal:Female:30:10Daniel Recruit:Sergeant:Male:40:19And my script goes like this:echo Enter name: read nameecho Enter rank: read rankecho Enter gender: read genderecho Enter age: read ageecho Enter Years of service: read yearsgrep $name database.txtIf I enter Corporal into name, the output will showTom Corporal:Recruit:Male:19:2Nicole Sergeant:Corporal:Female:30:10because the string matches under the section name and rank.How do i use delimiter : to categories the search, so if i enter my conditions under rank, it will search just the rank category and not everything else. Thanks in advance.And do up my question instead of down voting.",
    "target": "grep;cut"
  },
  {
    "id": "_codereview.117039",
    "source": "Computing integer square roots in Java - follow-up <eos> (See the previous iteration.)My two previous methods for computing the integer square root of a number \\$N\\$ ran in the \\$\\mathcal{O}(\\sqrt{N})\\$ worst case time. Now I have added a method (intSqrt3) that runs in \\$\\mathcal{O}(\\log \\sqrt{N})\\$ time:Main.java:import java.util.Random;import java.util.function.Function;public class Main {    public static long intSqrt1(long number) {        long sqrt = 0L;        while ((sqrt + 1) * (sqrt + 1) <= number) {            sqrt++;        }        return sqrt;    }    public static long intSqrt2(long number) {        if (number <= 0L) {            return 0L;        }        long sqrt = 1L;        while (4 * sqrt * sqrt <= number) {            sqrt *= 2;        }        while ((sqrt + 1) * (sqrt + 1) <= number) {            sqrt++;        }        return sqrt;    }    public static long intSqrt3(long number) {        if (number <= 0L) {            return 0L;        }        long sqrt = 1L;        // Do the exponential search.        while (4 * sqrt * sqrt <= number) {            sqrt *= 2;        }        long left = sqrt;        long right = 2 * sqrt;        long middle = 0;        // Do the binary search over the range that is guaranteed to contain         // the integer square root.        while (left < right) {            middle = left + (right - left) / 2;            if (middle * middle < number) {                left = middle + 1;            } else if (middle * middle > number) {                right = middle - 1;            } else {                return middle;            }        }        // Correct the binary search noise. This iterates no more than 3        // times.        long ret = middle + 1;        while (ret * ret > number) {            --ret;        }        return ret;            }    public static long intSqrt4(long number) {        return (long) Math.sqrt(number);    }    private static void profile(Function<Long, Long> function, Long number) {        long result = 0L;        long startTime = System.nanoTime();        for (int i = 0; i < ITERATIONS; ++i) {            result = function.apply(number);        }        long endTime = System.nanoTime();        System.out.printf(Time: %.2f, result: %d.\\n,                           (endTime - startTime) / 1e6,                          result);    }    private static final int ITERATIONS = 1_000;    private static final long UPPER_BOUND = 1_000_000_000_000L;    public static void main(String[] args) {        long seed = System.nanoTime();        Random random = new Random(seed);        long number = Math.abs(random.nextLong()) % UPPER_BOUND;        System.out.println(Seed =  + seed);        System.out.println(Number:  + number);        profile(Main::intSqrt1, number);        profile(Main::intSqrt2, number);        profile(Main::intSqrt3, number);        profile(Main::intSqrt4, number);    }}The performance figures I get looks like this:Seed = 19608492647714Number: 54383384696Time: 531.18, result: 233202.Time: 218.41, result: 233202.Time: 1.81, result: 233202.Time: 0.43, result: 233202.Above, intSqrt3 took 1.81 milliseconds.Critique requestIs there something I could improve? Naming/coding conventions? Performance? API design?",
    "target": "java;algorithm;reinventing the wheel;numerical methods"
  },
  {
    "id": "_datascience.17455",
    "source": "Which graph will be appropriate for the visualization task? <eos> I have some terminal charging values for US and CHINA comes in a pandas DataFrame like the following,        value country  0      550.0     USA        1      820.0   CHINA        2      835.0   CHINA        3      600.0   USA        4      775.0   CHINA        5      785.0   USA        6      790.0   USA   This is the sample data and I have in total 5K+ entries. The data is cleared for the outliers and needs to be visualized. What kind of visualization can I use to plot my data meaningfully?     ",
    "target": "visualization;data;pandas;plotting"
  },
  {
    "id": "_codereview.8580",
    "source": "How do I make this C# code more efficient, in terms of FPS and time complexity? <eos> Image<Bgr, Byte> frame = _capture.QueryFrame();Image<Gray, Byte> grayFrame = frame.Convert<Gray, Byte>();grayFrame._EqualizeHist();MCvAvgComp[][] facesDetected = grayFrame.DetectHaarCascade(_faces, 1.1, 1,     Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.FIND_BIGGEST_OBJECT, new Size(20, 20));if (facesDetected[0].Length == 1){    MCvAvgComp face = facesDetected[0][0];    #region Search ROI based on Face Metric Estimation -    Int32 yCoordStartSearchEyes = face.rect.Top + (face.rect.Height * 3 / 11);    Point startingPointSearchEyes = new Point(face.rect.X, yCoordStartSearchEyes);    Size searchEyesAreaSize = new Size(face.rect.Width, (face.rect.Height * 3 / 11));    Rectangle possibleROI_eyes = new Rectangle(startingPointSearchEyes, searchEyesAreaSize);    #endregion    int widthNav = (frame.Width / 10 * 2);    int heightNav = (frame.Height / 10 * 2);    Rectangle nav = new Rectangle(new Point(frame.Width / 2 - widthNav / 2, frame.Height / 2 - heightNav / 2),         new Size(widthNav, heightNav));    frame.Draw(nav, new Bgr(Color.Lavender), 3);    Point cursor = new Point(face.rect.X + searchEyesAreaSize.Width / 2,         yCoordStartSearchEyes + searchEyesAreaSize.Height / 2);    grayFrame.ROI = possibleROI_eyes;    MCvAvgComp[][] eyesDetected = grayFrame.DetectHaarCascade(_eyes, 1.15, 3,         Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING, new Size(20, 20));    grayFrame.ROI = Rectangle.Empty;    if (eyesDetected[0].Length != 0)    {        frame.Draw(face.rect, new Bgr(Color.Yellow), 1);        foreach (MCvAvgComp eye in eyesDetected[0])        {            Rectangle eyeRect = eye.rect;            eyeRect.Offset(possibleROI_eyes.X, possibleROI_eyes.Y);            grayFrame.ROI = eyeRect;            frame.Draw(eyeRect, new Bgr(Color.DarkSeaGreen), 2);            frame.Draw(possibleROI_eyes, new Bgr(Color.DeepPink), 2);            if (nav.Left < cursor.X && cursor.X < (nav.Left + nav.Width)                 && nav.Top < cursor.Y && cursor.Y < nav.Top + nav.Height)            {                LineSegment2D CursorDraw = new LineSegment2D(cursor, new Point(cursor.X, cursor.Y + 1));                frame.Draw(CursorDraw, new Bgr(Color.White), 3);                int xCoord = (frame.Width * (cursor.X - nav.Left)) / nav.Width;                int yCoord = (frame.Height * (cursor.Y - nav.Top)) / nav.Height;                Cursor.Position = new Point(xCoord, yCoord);            }        }    }    imageBoxFrame.Image = frame;}",
    "target": "c#;.net;performance"
  },
  {
    "id": "_codereview.14405",
    "source": "Finding the largest product of four consecutive numbers in a grid <eos> Project Euler #11 asks to find the largest product of four numbers of a grid, where the four numbers occur consecutive to each other vertically, horizontally, or diagonally.Here is my solution in Python.  In addition to the usual code review, I have 2 extra questions (actually confessions of my laziness):Would it be better if I compared products as in traditional way instead of using max(list)? Like:if (current > max_product):    max_product = currentWould it be better if I used proper for loops instead of relying on try? Because in certain cases it gives KeyError. Because of these two shortcuts, I feel like I have cheated. Shall I worry about them or just ignore them?yy = 08 02 22 97 38 15 00 40 00 75 04 05 07 78 52 12 50 77 91 0849 49 99 40 17 81 18 57 60 87 17 40 98 43 69 48 04 56 62 0081 49 31 73 55 79 14 29 93 71 40 67 53 88 30 03 49 13 36 6552 70 95 23 04 60 11 42 69 24 68 56 01 32 56 71 37 02 36 9122 31 16 71 51 67 63 89 41 92 36 54 22 40 40 28 66 33 13 8024 47 32 60 99 03 45 02 44 75 33 53 78 36 84 20 35 17 12 5032 98 81 28 64 23 67 10 26 38 40 67 59 54 70 66 18 38 64 7067 26 20 68 02 62 12 20 95 63 94 39 63 08 40 91 66 49 94 2124 55 58 05 66 73 99 26 97 17 78 78 96 83 14 88 34 89 63 7221 36 23 09 75 00 76 44 20 45 35 14 00 61 33 97 34 31 33 9578 17 53 28 22 75 31 67 15 94 03 80 04 62 16 14 09 53 56 9216 39 05 42 96 35 31 47 55 58 88 24 00 17 54 24 36 29 85 5786 56 00 48 35 71 89 07 05 44 44 37 44 60 21 58 51 54 17 5819 80 81 68 05 94 47 69 28 73 92 13 86 52 17 77 04 89 55 4004 52 08 83 97 35 99 16 07 97 57 32 16 26 26 79 33 27 98 6688 36 68 87 57 62 20 72 03 46 33 67 46 55 12 32 63 93 53 6904 42 16 73 38 25 39 11 24 94 72 18 08 46 29 32 40 62 76 3620 69 36 41 72 30 23 88 34 62 99 69 82 67 59 85 74 04 36 1620 73 35 29 78 31 90 01 74 31 49 71 48 86 81 16 23 57 05 5401 70 54 71 83 51 54 69 16 92 33 48 61 43 52 01 89 19 67 48rows = yy.splitlines()d = {}x = 0for row in rows:    row_cels = row.split()    y = 0    d[x] = {}    for cell in row_cels:        d[x].update({y: int(cell)})        y+=1    x+=1def product(a, b, al=hori, r=4):    try:        res = 1        for xx in xrange(r):            if al == hori: #        -                res *= d[a][b+xx]            elif al == verti: #     |                res *= d[b+xx][a]            elif al == dia: #       \\                res *= d[a+xx][b+xx]            elif al == diarev: #    /                res *= d[a+xx][19-(b+xx)]        return res    except:        return 0hori = []verti = []dia = []diarev = []for x in xrange(0, 20):    for y in xrange(0, 20):        hori.append(product(x,y))        verti.append(product(x, y, verti))        dia.append(product(x, y, dia))        diarev.append(product(x, y, diarev))print max(max(hori), max(verti), max(dia), max(diarev))",
    "target": "python;programming challenge;matrix"
  },
  {
    "id": "_softwareengineering.134637",
    "source": "Can anybody recomend a good SEO book? <eos> Im currently developing a ASP MVC site.Is there any book out there for ASP MVC SEO or just SEO in general?",
    "target": "asp.net mvc;seo"
  },
  {
    "id": "_unix.188380",
    "source": "Named pipes: several experiments leads to confusion <eos> I've come across various articles and SO questions and I am still confused about something that I use on daily basis, but never realized how confusing it can be. I am experimenting with (named) pipes in Linux.1sttry was simple: figure out how pipe buffers are working:#1mkfifo /tmp/mypipe#2echo Hello World >/tmp/mypipectrl+c#3cat /tmp/mypipeObservation:When I killed echo before cat reads the data nothing was written to pipe (cat keeps running but nothing was read from pipe). I was assuming that when you type producent >named_pipe and you will exit producent then part of data that match pipe buffer size will be written to named_pipe and will remain here until it will be read by consument (now I know that this is not how it works). So what I did next was:2ndtry was to connect consument to other end of pipe:#1mkfifo /tmp/mypipe#2echo Hello World >/tmp/mypipe#3cat /tmp/mypipeObservation:cat command displays the Hello World message and both processes ends. The interesting discovery here was that during the #2 step ps -elf does not display the echo command. It seems that echo is waiting until somebody will read from pipe and this is explanation why nothing was printed to pipe in my first attempt.3rdtry was to pipe command that will run forever and constantly write to pipe and see what will happened:#1mkfifo /tmp/mypipe#2yes >/tmp/mypipe#3cat /tmp/mypipeObservation:This worked as expected and cat printed out what yes forwarded to pipe. However I have tried to replace cat with tail -f. When I did this then tail did not print anything until the yes command was killed.4thtry is the big mystery:# 1#mkfifo /tmp/mypipe# 2#for i in $(seq 1 10000); do echo -n $i|> /tmp/mypipe; done# 3#for i in $(seq 1 10); do echo ${i}# Read:; cat /tmp/mypipe && echo ; doneAfter this the 3# command start typing something like that:1# Read:1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19|20|21|22|23|24|25|26|27|28|29|30|31|32|33|34|35|36|37|38|39|40|41|42|43|44|45|46|47|48|49|50|51|52|53|54|55|56|57|58|59|60|61|62|63|64|65|66|67|68|69|70|71|72|73|74|75|76|77|78|79|80|81|82|83|84|85|86|87|88|89|90|91|92|93|94|95|96|97|98|99|100|101|102|103|104|105|106|107|108|2# Read:109|3# Read:110|4# Read:111|5# Read:112|6# Read:113|114|115|7# Read:116|8# Read:117|9# Read:118|119|120|121|122|123|124|125|126|127|128|129|130|131|132|133|134|135|136|137|138|139|140|141|142|143|144|145|146|147|148|149|150|151|152|153|154|155|156|157|158|159|160|161|162|163|164|165|166|167|168|169|170|171|172|173|174|175|176|177|178|179|180|181|182|183|184|185|186|187|188|189|190|191|192|193|194|195|196|197|198|199|200|201|202|203|204|205|206|207|208|209|210|211|212|213|214|215|216|217|218|219|220|221|222|223|224|225|226|227|228|229|230|231|232|233|234|235|236|237|238|239|240|241|242|243|244|245|246|247|248|249|250|251|252|253|254|255|256|257|258|259|260|261|262|263|264|265|266|267|268|269|270|271|272|273|274|275|276|277|278|279|280|281|282|283|284|285|286|287|288|289|290|291|292|293|294|295|10# Read:296|297|298|299|300|301|302|303|304|305|306|307|308|309|310|311|312|313|314|315|316|317|318|319|320|321|322|323|324|325|326|327|328|329|Questions:1st and 2nd try:Are the named pipes equivalent to classic | pipes as they areknows e.g. from bash in this particular case?Does producent always wait for consument? If yes then what is purpose of pipe buffers? Is this behavior known as blocking communication?How does Linux know when the consument is connected to pipe and thus when the communication can happen? I've tried lsof named_pipe but it gives me nothing, where is this information stored? I have also try following and result was that cat cannot read from pipe.#1mkfifo /tmp/mypipe#2echo 1 >/tmp/mypipe#3rm /tmp/mypipe#4mkfifo /tmp/mypipe#5cat /tmp/mypipeIs typing: producent >/tmp/mypipethe equivalent of typing command | I mean the situation when somebody wants to pipe one command to another but forget to type another command after pipe (ps in this case also did not show first command)?3rd try:What is difference between cat and tail -f in this particular case?4th try:What is going on here? Why the chunks of read data are not the exactsize? I was expecting output as:1# Read:   1|   2# Read:   2|   3# Read:   3|PS:Also I have tried different order of starting commands (reading first and writing after) but the result was the same.PPS:I hope this is clear but:Producer = process that writes to pipe.Consumer = process that reads from pipe.Is this possible explain to guy which has mostly scripting knowledge with bit of C? Thank you very much.EDIT in reply to: Joe SewellOK Clear 2. I understand that both run in parallel, or in other words, following two are not the same:find | lessvsfind > /tmp/file && less /tmp/fileMy further observation discovers that, when I run following, HDD is not working seems that it is stopped until less command has enough data to displayfind | lessWhen I hit shifg+g (go to the end of file in less) HDD starts immediately to work and data starts outputting. Does this mean that when less command has enough data to display it will somehow tell find to not produce further data? This is what you mean by synchronization? Also the amount of data writes to pipe corresponds to it buffer size? I have also noticed that find changes it state (ps aux - stat column) from S+ to D+ after I hit shift+g in lessS    interruptible sleep (waiting for an event to complete)D    uninterruptible sleep (usually IO)+    is in the foreground process group.[wakatana@~] [63 files, 178Mb]> ps aux | egrep -w 'less|find'wakatana     6071  0.0  0.0  12736  1088 pts/5    S+   23:15   0:00 findwakatana     6072  0.0  0.0   7940   928 pts/5    S+   23:15   0:00 lesswakatana     6183  0.0  0.0   7832   892 pts/6    S+   23:20   0:00 egrep --color=auto -w less|find[wakatana@~] [63 files, 178Mb]> ps aux | egrep -w 'less|find'wakatana     6071  0.0  0.0  12808  1304 pts/5    D+   23:15   0:00 findwakatana     6072  0.0  0.0   9556  2508 pts/5    S+   23:15   0:00 lesswakatana     6193  0.0  0.0   7832   892 pts/6    S+   23:21   0:00 egrep --color=auto -w less|findWho sends this signal, consument to producent? If yes then howconsument know that he is connected to the pipe which already hasproducent (e.g. my example with rm pipe)?OK ClearOK ClearI think that the new lines is not the case that confuses me. Based on my previous observations (and you confirmed that: Yes, both ends wait for each other.). I was expecting this:I. 1st iteration in 1st loop will write to pipe and because nobody isreading it will wait here.II. When 2nd loop is issued then the data which were written by 1stloop in 1st iteration will be read, nothing more was written here sonothing more can be read.III. 2nd loop will wait for next data to be written by 1st loop or(because order no matter) 1st loop will wait until written data willbe read by 2nd loop, and so on and so on.Because of this I was expecting that one write will corresponds to one read. I was also verifying if loop is not running so I modified a bit original command to see if something will be printed to STDOUT even if consument wont be reading, but nothing was printed.for i in $(seq 1 10000); do  if [ $(( $i % 5 )) -eq 0 ]; then    echo $i;  else    echo -n $i|> /tmp/mypipe;  fi;doneSince the writing process isn't sending any newlines, the reader simply reads until it's told it got enough.Who will tell consument that he's got enough?In the first case it's probably because the fifo's buffer filled up,How can I fill buffer if communication is blocked (as i described above)?and therefore got flushed through to the reader.What do you mean by this? Sorry for my english.While there are ways to make communication asynchronous ...Can you please briefly describe what is the difference between asynchronous and synchronous in this case?",
    "target": "pipe;fifo"
  },
  {
    "id": "_webapps.60616",
    "source": "Why are my photographs (or videos?) counted against my storage limit? <eos> I'm uploading photos to Google Storage using Picasa. I'm not using full resolution - I leave Google to resize them from full resolution.  Why is it using some of my storage limit? Might it be caused by uploaded videos? ",
    "target": "picasa web albums"
  },
  {
    "id": "_webapps.26782",
    "source": "How to programmatically add videos to YouTube playlist? <eos> I have a list of several YouTube URLs that I would like to add programmatically to a YouTube playlist (in my channel).  (Actually, I have several target playlists in mind, each getting a subset of the URLs in my list.)Is there a way I can add these programmatically (e.g. with Python or Perl, etc.)?p.s., (I imagine realize that there's a way to do this using the YouTube API, but my (very limited) understanding of this approach is that it would require me to create and register (with Google) a web app, and it would be this web app that would make API calls.  If this picture is correct, it looks like a lot of hassle for what I want to do.)Edit: By way of clarification:I am familiar with the info given Adding a video to a playlist, but, as I explained, I am hoping to find some otherway to do this.I have no problem with registering myself to get a developer key, nor I have any problem with including a developer key with every request; but, in principle, including a developer key in one's requests does not require a webapp (a simple script, or even a command-line one-liner, is perfectly adequate, technically speaking, to this task); therefore, the webapp business seems to me an extraneous artifact of Google's registration procedure, one that greatly complicates what would otherwise be a very simple programming task.",
    "target": "youtube;youtube playlist"
  },
  {
    "id": "_webmaster.90053",
    "source": "Does Blogger get a site better rankings for being owned by Google? <eos> given that I want to create a blog and purchase my own domain:The fact that Blogger is provided by Google, may it imply a higher indexing performance, compared both to the other weblog publishing tools (like Wordpress, Tumblr...) and creating a website fom scratch?",
    "target": "seo;google;indexing;blogger;blogspot"
  },
  {
    "id": "_unix.74327",
    "source": "Finding all partitions with filesystems <eos> I'm writing a script that will copy all of the files on a device to a directory. The problem is that some of the devices have multiple partitions and some of the partitions don't have filesystems to copy files from. At the moment, I'm thinking about using lsblk to get a list of partitions on the device and file -s to check for a filesystem on each partition.Is there a less brute way to do what I am trying to do?Here is information regarding the empty partition problem:# /dev/sdb is a flashdrive with two partitions# /dev/sdb1 has no filesystem# /dev/sdb2 has an ext4 partition$ lsblk -fi...sdb    vfat   CARRIER-R C84B-6A72                            |-sdb1 vfat   CARRIER-R C84B-6A72                            `-sdb2 ext4   CARRIER-R 33ebb632-68a5-4bf5-bd29-90733af9699e...$ lsblk -ln -o NAME,FSTYPE...sdb  vfatsdb1 vfatsdb2 ext4...# As confirmation, mounting the partition fails$ mount -t auto /dev/sdb1 /mntmount: wrong fs type, bad option, bad superblock on /dev/sdb1...$ dmesg | tail...[  985.933627] EXT4-fs (sdb1): VFS: Can't find ext4 filesystem[  985.935722] EXT4-fs (sdb1): VFS: Can't find ext4 filesystem[  985.937603] EXT4-fs (sdb1): VFS: Can't find ext4 filesystem[  985.939623] FAT-fs (sdb1): invalid media value (0xa7)[  985.939627] FAT-fs (sdb1): Can't find a valid FAT filesystem",
    "target": "filesystems;partition;block device"
  },
  {
    "id": "_softwareengineering.254911",
    "source": "Used with permission reusable in a GPLv2 derivative work? <eos> The LICENSE file of a GPLv2 application I am modifying contains a statement saying that certain resources used in the application were used with permission from 3rd parties - such as textual material from a published book and certain graphics.Question:  in my derivative work based off of this application, am I required to seek permission from those 3rd parties to use those same resources?  Or does the GPLv2 encompass the fact that the use of these resources was already permitted in the original work, and thus the 3rd-party permission flows through to my derivative work?",
    "target": "licensing;gpl"
  },
  {
    "id": "_unix.49714",
    "source": "Interactively deleting files from a list <eos> I'd like to remove a list of files and be asked for confirmation. The list is in the list.txt file. Why the following command doesn't work properly?while read i; do rm -i $i; done < list.txtThe previous command doesn't wait for me but fortunately no file is deleted.I'm using Bash.",
    "target": "bash;shell;io redirection;rm"
  },
  {
    "id": "_unix.63206",
    "source": "kgdb not returning control to gdb <eos> I've compiled a kernel with kgdb support and I'm trying to debug it. I have two machines running, a debug machine (running the kgdb kernel) and the machine I'm using to debug it. They are connected via two serial cables. I can operate the debug machine's serial console through ttyS0 (on both machines) and I can connect to kgdb with gdb over ttyS1 (on both machines).This works fine up until a point: I boot the debug machine; it waits for gdb to connect; gdb connects; I can set breakpoints or whatever using gdb; I tell gdb to continue; and the kernel continues to boot.The problem is when I next hit a breakpoint gdb doesn't seem to realize that a breakpoint has been hit. The kernel stops when it's meant to, but gdb doesn't do anything. It just sits there as if nothing has happened.Does anyone know what might cause this?",
    "target": "linux;kernel;linux kernel;debugging;gdb"
  },
  {
    "id": "_unix.312641",
    "source": "How to fix Opera and Google Chrome? <eos> Recently I've changed from mint 17 to linux mint 18. Unlike on mint 17, now Google Chrome border is like it is not selected (light-gray color) and returns [WARNING:flash/platform/pepper/pep_module.cpp(63)] SANDBOXEDthis error, and has some graphical problems, while playing screen sections are turning black for some seconds.I also installed Opera, it doesn't have any visual issues, but terminal shows[0927/131635:ERROR:object_proxy.cc(583)] Failed to call method: org.freedesktop.DBus.Properties.Get: object_path= /org/freedesktop/UPower: org.freedesktop.DBus.Error.InvalidArgs: No such interface 'org.freedesktop.UPower.Device'[WARNING:flash/platform/pepper/pep_module.cpp(63)] SANDBOXEDVector smash protection is enabled.[0927/131637:ERROR:ticl-message-validator.cc(212)] registration_digest must be non-empty[0927/131637:ERROR:ticl-message-validator.cc(319)] field registration_summary failed validation in { protocol_version: { version: { major_version: 3 minor_version: 2  }  } client_token: NWqcVMArVrn/FjkzTOaZ4A== registration_summary: { num_registrations: 0 registration_digest:   } server_time_ms: 0  }[0927/131637:ERROR:ticl-message-validator.cc(361)] field header failed validation in { header: { protocol_version: { version: { major_version: 3 minor_version: 2  }  } client_token: NWqcVMArVrn/FjkzTOaZ4A== registration_summary: { num_registrations: 0 registration_digest:   } server_time_ms: 0  }  }[0927/131637:ERROR:protocol-handler.cc(145)] Received invalid message: { header: { protocol_version: { version: { major_version: 3 minor_version: 2  }  } client_token: NWqcVMArVrn/FjkzTOaZ4A== registration_summary: { num_registrations: 0 registration_digest:   } server_time_ms: 0  }  }What does this errors mean and how can they be fixed?",
    "target": "linux mint;chrome;opera"
  },
  {
    "id": "_unix.224104",
    "source": "Using two memory controllers with SPARSE_MEM on AT91SAM9G45 <eos> There are lot posts on this problem in google, but I have tried all the solutions but they are not working for me, so I'm posting here I am working with AT91BootStarp 3.5.9 with linux kernel 3.6.9. My problem is that Linux does not use the second memory bank (128 MB on EBI_CS1 mapped at 0x20000000).The memory mapping is as follows:0x70000000 => 0xc0000000 (128 MB - DDRSDRC0) 0x20000000 => 0xc8000000 (128 MB - EBI_CS1)As per ATMEL evaluation (user) board.While booting I see this message: Ignoring RAM at 70000000-77ffffff (vmalloc region overlap).I have enabled SparseMem and also tried patches posted at:http://blog.linuxconsulting.ro/2010/05/ ... -with.htmlI have checked & verified my DDR2 initializations in AT91Bootstrap and I dont see any issues at Bootstrap. Tested both memory banks, dont see any issues.I have added uBoot boot args as:mem= mem=128M@0x20000000 mem=128M@0x70000000 console=ttyS0,115200 root=/dev/mmcblk0p2 rw rootdelay=2 rootwait=1When I boot, I am getting following warning and board is getting configured with 128 MB not with 256 MB.Ignoring RAM at 70000000-77ffffff (vmalloc region overlap).CPU: ARM926EJ-S [41069265] revision 5 (ARMv5TEJ), cr=00053177CPU: VIVT data cache, VIVT instruction cacheMachine: Atmel AT91SAM9M10G45-EKIgnoring RAM at 70000000-77ffffff (vmalloc region overlap).Memory policy: ECC disabled, Data cache writebackAT91: Detected soc type: at91sam9g45AT91: Detected soc subtype: UnknownAT91: sram at 0x300000 of 0x10000 mapped at 0xfef68000Clocks: CPU 400 MHz, master 133 MHz, main 12.000 MHzBuilt 1 zonelists in Zone order, mobility grouping on.  Total pages: 32512Kernel command line: mem=128M@0x20000000 mem=128M@0x70000000 console=ttyS0,115200 root=/dev/mmcblk0p2 rw rootdelay=2 rootwait=1PID hash table entries: 512 (order: -1, 2048 bytes)Dentry cache hash table entries: 16384 (order: 4, 65536 bytes)Inode-cache hash table entries: 8192 (order: 3, 32768 bytes)Memory: 128MB = 128MB totalMemory: 124424k/124424k available, 6648k reserved, 0K highmemVirtual kernel memory layout:    vector  : 0xffff0000 - 0xffff1000   (   4 kB)    fixmap  : 0xfff00000 - 0xfffe0000   ( 896 kB)    vmalloc : 0xc8800000 - 0xff000000   ( 872 MB)    lowmem  : 0xc0000000 - 0xc8000000   ( 128 MB)    modules : 0xbf000000 - 0xc0000000   (  16 MB)      .text : 0xc0008000 - 0xc04d5f18   (4920 kB)      .init : 0xc04d6000 - 0xc050022c   ( 169 kB)      .data : 0xc0502000 - 0xc05345a0   ( 202 kB)       .bss : 0xc05345c4 - 0xc055711c   ( 139 kB)NR_IRQS:16 nr_irqs:16 16AT91: 160 gpio irqs in 5 bankssched_clock: 32 bits at 100 Hz, resolution 10000000ns, wraps every 4294967286msConsole: colour dummy device 80x30",
    "target": "linux kernel;boot loader;arm"
  },
  {
    "id": "_webmaster.14556",
    "source": "Photos being copied all over the place <eos> We have a rather popular website with plenty of photos. Our whole business depends on our content - and the photos are important in this. We invest a lot of time, effort, and money into taking these pictures. On our website we have clear copyright notices, we have the website name and logo in the photos, and we have a Photo Licensing page which states the prices of licensing our photos. Despite all this, our photos are copied by personal and commercial websites alike. We really want to do something about this. We do not want them to take out the photos and leave it at that. We want them to pay for the usage, as we clearly state on our website. Now a few questions come to mind:Can we legally force them to pay right away? Or are we obligated to first write a Cease and Desist letter?Photos are used on websites throughout the world. Are there any worldwide rules for this? Has anybody experience with doing these things outside of their home country? Should we hire a lawyer in any country? Or could a local lawyer contact oversees companies directly?",
    "target": "copyright"
  },
  {
    "id": "_softwareengineering.133159",
    "source": "Entity-Component-System architecture: interaction between systems <eos> I am studying the Entity-Component-System architecture philosophy. As I have read about it, a typical entity system has:1) Entities - which are merely ID tags which have a number of components2) Components - which contain data on various aspects of an enity that the component is responsible for3) Systems - which update relevant components of every entity. Say, a rendering system updates the rendering component, or simply saying, draws a picture that is stored in the data of that component. A positional and movement system handles position and movement of each entity who has a corresponding component.These statements follow from this article which in my opition tries to be the most clear and pure in it's statements - But the author did not explain how the interaction between systems should be realized. For example, the rendering system must know the data from the positional component of an entity in order to draw it in a correct position. And so on.So the question is - how should I implement the interaction between the various systems?",
    "target": "architecture;concepts;entity;component;message passing"
  },
  {
    "id": "_unix.345452",
    "source": "Bridge eth0 and wlan0 <eos> I've a computer, C, a router R, and a raspberry pi, P. They are connected:Internet <--ethernet--> R <--wlan--> P <--ethernet--> CNow I want C to be able to access the internet.The P has wlan0 and eth0, my first thought was to bridge eth0 and wlan0 but that is not possible due to the nature of wifi I've learned.Next approach is to add a dhcp server to P and let C lease an IP number. It works fine and ip route on C gives:10.254.239.0/27 dev eth0  src 10.254.239.13 default via 10.254.239.10 dev eth0and ifconfig on P giveseth0      Link encap:Ethernet  HWaddr b8:27:eb:44:bb:71            inet addr:10.254.239.10  Bcast:10.254.239.31  Mask:255.255.255.224          inet6 addr: fe80::3206:e7e:fb7e:23d5/64 Scope:Link          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1          RX packets:569 errors:0 dropped:0 overruns:0 frame:0          TX packets:235 errors:0 dropped:0 overruns:0 carrier:0          collisions:0 txqueuelen:1000           RX bytes:142936 (139.5 KiB)  TX bytes:50384 (49.2 KiB)lo        Link encap:Local Loopback            inet addr:127.0.0.1  Mask:255.0.0.0          inet6 addr: ::1/128 Scope:Host          UP LOOPBACK RUNNING  MTU:65536  Metric:1          RX packets:19 errors:0 dropped:0 overruns:0 frame:0          TX packets:19 errors:0 dropped:0 overruns:0 carrier:0          collisions:0 txqueuelen:1           RX bytes:1444 (1.4 KiB)  TX bytes:1444 (1.4 KiB)wlan0     Link encap:Ethernet  HWaddr b8:27:eb:11:ee:24            inet addr:192.168.0.106  Bcast:192.168.0.255  Mask:255.255.255.0          inet6 addr: fe80::2501:6a8:8bcf:4a40/64 Scope:Link          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1          RX packets:5415 errors:0 dropped:4989 overruns:0 frame:0          TX packets:454 errors:0 dropped:0 overruns:0 carrier:0          collisions:0 txqueuelen:1000           RX bytes:815495 (796.3 KiB)  TX bytes:49230 (48.0 KiB)C can ping P but not R, leaving me to believe that P has some routing error.How can I configure P to pass traffic between R and C?ip route on P gives:default via 192.168.0.1 dev wlan0  metric 303 10.254.239.0/27 dev eth0  proto kernel  scope link  src 10.254.239.10 192.168.0.0/24 dev wlan0  proto kernel  scope link  src 192.168.0.106  metric 303 Also on P$ cat /proc/sys/net/ipv4/ip_forward1",
    "target": "routing;wlan;isc dhcpd"
  },
  {
    "id": "_unix.119021",
    "source": "Dual keyboard shortcuts in Gnome <eos> I would like to set multiple keyboard shortcuts doing the same thing. My particular example is Volume Up/Down, I would like to retain the standard settings I have (Sound/VolumeUp - XF86AudioRaiseVolume, my laptop dedicated button) and I would like to add a second set (Tux+Up). How can I do that? Thanks a lot.",
    "target": "gnome;keyboard shortcuts;volume"
  },
  {
    "id": "_softwareengineering.313078",
    "source": "Within an interface specified by a core component, should it request IReadOnlyCollection or IEnumerable? <eos> In thinking about the principle of be conservative in what you send and liberal in what you accept, I generally try to make my methods receive IEnumerable parameters, but emit a IReadOnlyCollection (except where deferred execution is truly valuable, then I do emit an IEnumerable).However, I just realized that when specifying methods in an interface, this may be reversed. Is that true?Should my interface specifications be telling any implementers I'll give you an IReadOnlyCollection, but you can just give me any old IEnumerable back? (Again, if deferred execution makes sense, I would provide an IEnumerable as a parameter type instead.) This makes those methods the reverse, accepting a narrow/conservative set but emitting a broad/liberal one. However, this seems right to me because with the dependency inversion, in reality the input arguments when the method is called are really the output arguments of the core system (specifying the interface).I'm just wondering if my thinking is right on this or not. It seems that making the implementer side as easy as possible is really where the benefit is.I'm realizing that part of the issue comes from my concern about not requiring implementers to think deeply about whether deferred execution makes sense or not. Knowing when an enumerable will be enumerated can be very important in a system, and with the separation of concerns that an interface can help bring to code, I wouldn't want to be so liberal in what the interface method outputs (which is ultimately an input to the core system) that improperly-deferred IEnumerables get thrown around...This is not about speed. Not sure why this was raised, but please do not even think for a second about performance implications here. That is not the question.",
    "target": "c#;interfaces;parameters;return type"
  },
  {
    "id": "_unix.333587",
    "source": "how to view certificate detail that contains more than one certificates <eos> In ubuntu 16.04 OS there is /etc/ssl/certs/ca-certificates.crt which has a lot of: -----BEGIN CERTIFICATE-----xxx-----END CERTIFICATE-----how can I view what certificates are in the file as individual certificate, one by one?I have tried:openssl x509 -noout  -issuer -subject -dates -in ca-certificates.crtbut it looks as there is only one cert in it: issuer= /CN=ACCVRAIZ1/OU=PKIACCV/O=ACCV/C=ESsubject= /CN=ACCVRAIZ1/OU=PKIACCV/O=ACCV/C=ESnotBefore=May  5 09:37:37 2011 GMTnotAfter=Dec 31 09:37:37 2030 GMTShouldnt there be more? How can I see all of them? ",
    "target": "openssl;ssl"
  },
  {
    "id": "_cs.6237",
    "source": "What units should Shannon entropy be measured in? <eos> The only examples I've seen use bits as a measurement of entropy, but all these examples happen to use binary code alphabets. If we wanted to see how well a coding with a code alphabet of length n works, would we measure entropy in units of n?Or would it make sense to stay using bits if we're comparing codings with binary and n-length code alphabets?",
    "target": "information theory;entropy"
  },
  {
    "id": "_scicomp.20276",
    "source": "Solving quasilinear/nonlinear equations obtained from the discretization of partial differential equations <eos> When you solve numerically a (system of) linear partial differential equation (PDE) as for example Lapace's equation $\\nabla^2\\varphi = 0$ or Poisson's equation $\\nabla^2\\varphi = f$ you obtain a linear system of equations that can be solve easily with the tools provided by the theory of linear algebra. Conversely, when you solve a quasilinear (system of) PDE, as for example a simple convection-difussion problem $\\nabla^2\\varphi - \\vec{v}\\cdot\\nabla\\varphi = f$, or a nonlinear (system of) PDE, as for example a general convection-difussion problem $\\nabla\\cdot(\\Gamma\\nabla\\varphi) - \\nabla(\\vec{v}\\varphi) = f$, you obtain a nonlinear system of equations that cannot be solved (directly) with the same tools.One possible solution is the use Newton or Quasi-Newton method, but you must evaluate full or approximate Jacobian, which increases the complexity of algorithm. Another solution is to use Jacobi/Gauss-Seidel/SOR methods, but they do not work unless the system is diagonally dominant and the nonlinearities are small. What methods are used in practice or more often to solve these problems?",
    "target": "pde;solver"
  },
  {
    "id": "_unix.239278",
    "source": "How to make files unmodifiable and undeletable without `chattr`? <eos> I (and my collaborators) have a directory tree containing ~160K files (most of them are automatically generated by data gathering instrumentation).These files reside in a system that gets backed up constantly, and therefore, we are not too worried about data loss or corruption, as long as we have the information required to restore from backup when needed.We're much more worried about inadvertent data loss or corruption resulting from user error (especially buggy user-written code), because this means, at best, wasted work until the problem is detected.Therefore, we want to make these files undeletable and unmodifiable.Unfortunately, neither of us has permission to use chattr on this system, which rules out applying chattr +i to these files.Is there some other way, not requiring special permissions, to approximate chattr +i?The rest of this post describes a couple of possibilities we've considered, along with their shortcomings.One possibility would be to apply chmod -R a-w DATA, where I've used DATA as shorthand for the root of the directory tree in question.This is fine as a first approximation, but it goes a bit too far, because it renders many operations that we may need to perform occasionally (e.g. consolidating several subdirectories into one)A second possibility would be something likefind DATA -type f -exec chmod a-w {} \\;This is a bit more flexible, and the files can no longer be modified, but they can still be deleted.",
    "target": "files;permissions"
  },
  {
    "id": "_unix.217262",
    "source": "rsyslogd taking up all my drive space, only when the service is started <eos> I have configured rsyslogd to write log files to an external drive.  When the service is not started, but the drive is mounted, my disk utilization (by df) is low.  As soon as I start rsyslogd, the disk utilization creeps up over a minute or so to very high utilization on the main drive (not the drive that it's logging to.)  Using du to try to find a cache file or something else that might be used by rsyslogd shows nothing.  What could be causing this?",
    "target": "rsyslog"
  },
  {
    "id": "_codereview.171904",
    "source": "Scraping the names of a whole category with a three-liner code <eos> I've written a script in python using BeautifulSoup to parse the name of different coffee shops spreading across 51 pages in yellowpage website. I'm thrilled to see that it works perfectly. Except for importing libraries, I used three lines of code to do this. I think this time I've done this errorlessly.Here is what I've tried with:import requestsfrom bs4 import BeautifulSoup for i in range(1, 52):    for title in BeautifulSoup(requests.get(https://www.yellowpages.com/search?search_terms=coffee&geo_location_terms=Los+Angeles%2C+CA&page={0}.format(i)).text, lxml).findAll(h2,{class:n},a):        print(title.text)",
    "target": "python;python 3.x;web scraping;beautifulsoup"
  },
  {
    "id": "_webmaster.90456",
    "source": "What is the recommended SEO procedure when moving to a site with several subdomains to a new domain? <eos> Is there any known SEO recommendation for migrating a domain with several subdomains to a new domain name?As Google can see subdomains as internal parts of root domains (link), what could be the SEO impact if we only migrate the root domain (www.old.com to www.new.com) and leave the subdomains unmodified (a.old.com, b.old.com, etc...)?Consider the subdomains indexed at Google, with moderated inbound links, and with links to root domain. Is it worth it to migrate all subdomains or by migrating the root domain (with the proper procedure) will be enough? The goal is to keep our website traffic, while risking as little as possible .I couldn't find any article describing this scenario. ",
    "target": "seo;google;301 redirect;subdomain;migration"
  },
  {
    "id": "_webmaster.108131",
    "source": "Does it matter if my meta description is truncated? <eos> So I'm programmatically generating meta descriptions from the first 160 characters of my site's product listing descriptions. (I'm putting a 160 character limit on it. Is that still best practice?) Does it matter if a word at the end of the description gets truncated? So if the word was, say, webmasters, it might get truncated to webmast. I can make it so only whole words are included by dropping the final truncated word, but some sentences will necessarily be chopped in half. Does that also matter?",
    "target": "seo;meta tags;meta description"
  },
  {
    "id": "_datascience.10015",
    "source": "Implement MLP in tensorflow <eos> There are many resources online about how to implement MLP in tensorflow, and most of the samples do work :) But I am interested in a particular one, that I learned from https://www.coursera.org/learn/machine-learning. In which, it uses a cost function defined as follow:$J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} \\sum_{k=1}^{K} \\left[ -y_k^{(i)} \\log((h_\\theta(x^{(i)}))_k - (1 - y_k^{(i)}) \\log(1 - (h_\\theta(x^{(i)}))_k \\right]$$h_\\theta$ is the sigmoid function.And there's my implementation:# one hidden layer MLPx = tf.placeholder(tf.float32, shape=[None, 784])y = tf.placeholder(tf.float32, shape=[None, 10])W_h1 = tf.Variable(tf.random_normal([784, 512]))h1 = tf.nn.sigmoid(tf.matmul(x, W_h1))W_out = tf.Variable(tf.random_normal([512, 10]))y_ = tf.matmul(h1, W_out)# cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(y_, y)cross_entropy = tf.reduce_sum(- y * tf.log(y_) - (1 - y) * tf.log(1 - y_), 1)loss = tf.reduce_mean(cross_entropy)train_step = tf.train.GradientDescentOptimizer(0.05).minimize(loss)correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))# trainwith tf.Session() as s:    s.run(tf.initialize_all_variables())    for i in range(10000):        batch_x, batch_y = mnist.train.next_batch(100)        s.run(train_step, feed_dict={x: batch_x, y: batch_y})        if i % 100 == 0:            train_accuracy = accuracy.eval(feed_dict={x: batch_x, y: batch_y})            print('step {0}, training accuracy {1}'.format(i, train_accuracy))I think the definition for the layers are correct, but the problem is in the cross_entropy. If I use the first one, the one got commented out, the model converges quickly; but if I use the 2nd one, which I think/hope is the translation of the previous equation, the model won't converge.",
    "target": "machine learning;tensorflow"
  },
  {
    "id": "_webmaster.35363",
    "source": "Can someone sue me/take my domain? <eos> I have found a great domain that isn't in use, but the .com and .net domains are already taken. There's nothing on the domains though, it just says they are registered with Network Solutions and are under construction.My question is: If i buy the .org version of the domain, and the .com guys later start a company on that domain, can they sue me or make me change name because it is too similar to their .com domain? Should i avoid using domains that have already been registered but with a different ending?",
    "target": "domains;legal;registration;purchase"
  },
  {
    "id": "_unix.228178",
    "source": "Sed: replace text keeping digit occurrence <eos> I have some text like:Blablabla <b>[intlink id=</b>2204<b> type=page] BlalalaI want replace it for remove the </b> and <b>, keeping the id=number. So it should result like:Blablabla <b>[intlink id=2204 type=page] BlalalaI try with:sed -i 's@id=</b>[[:digit:]]\\+<b>@id={1}@g' ~/edit.txtBlablabla <b>[intlink id={1} type=page] BlalalaAlso I try with:sed -i 's@id=</b>[[:digit:]]\\+<b>@id=\\\\1@g' ~/edit.txtBut I get:Blablabla <b>[intlink id=\\1 type=page] BlalalaSo, how I can keep the id number text in the regex digit?",
    "target": "sed;regular expression;replace;html;trim"
  },
  {
    "id": "_softwareengineering.200214",
    "source": "Cross Compile Arm Program to Intel <eos> I have searched around for a way to run a program meant for ARM processors on an Intel computer, but I can only find ways to do the reverse, to compile Intel programs for ARM. Are there any open-source cross-compilers that will allow me to do so? Thanks for your help.",
    "target": "compiler;arm;intel"
  },
  {
    "id": "_softwareengineering.212808",
    "source": "Treating a 1D data structure as 2D grid <eos> I am working with a native class that represents a 2D image as a 1D array. If you want to change one pixel, for example, you need to now how to derive the index from the x,y coordinates.So, let's say we have a 1D array array1d like this:array1d = [ a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y ]In the context of our program, array1d represents a 2D grid:a b c d ef g h i jk l m n op q r s tu v w x yAnd we want to perform operations on array1d such as:Get the value at x,y coordinates (in this example, 1,2 would give l)Get any sub-grid using x,y,width,height (1,2,2,2 would give [l, m, q, r])Set the value at any x,y coordinate (etc.)How do we do these?",
    "target": "data structures;math;graphics"
  },
  {
    "id": "_cs.44181",
    "source": "Regular expression of a language over {a,b,c} which does not contain substring bbb <eos> I'm trying to figure out how to build a regular expression for a language that doesn't contain substring bbb. The alphabet is {a,b,c}. I'm trying to construct a DFA and convert to help me get the Regular Expression but still stuck as I found the DFA a bit complicated. I appreciate any help. Thanks!!!Ok, here is the Regular Expression I've worked on to help me solve the above question.ac[(acb)* U (acbb)]ac*Test:aaaa ccccc acbacbacb aaaaaaa ccccc (OK)aa acbb acbb acbb acbb cccccccc (OK)But how about cab or cabb? I then modified the above expression to:ac[(acb)* U (acbb)* U (cab)* U (cabb)]ac*I'm I heading to the right direction?Thanks again!",
    "target": "regular languages;regular expressions"
  },
  {
    "id": "_codereview.24493",
    "source": "Optimizing Jquery Twitch TV Application <eos> I'm trying to get in the habit of writing better looking code and more efficient code blocks. I wrote this Twitch TV Application which allows you to add and edit channels and it lets you know when a channel is live. Is there anything I can work on to make my code work / look better? HTML<!DOCTYPE html PUBLIC -//W3C//DTD XHTML 1.0 Strict//EN http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd><html xmlns=http://www.w3.org/1999/xhtml><head>    <title>Streaming</title>    <link href=style.css rel=stylesheet type=text/css />    <script type=text/javascript src=//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js></script>    <script type=text/javascript src=streamer.js></script>    <script type=text/javascript src=dynamic.js></script></head><body>    <div id=container>        <div id=nav>            <ul id=mainNav>                <li id=streamInfo></li>            </ul>            <ul id=chatAnchor>                <li>                    <a onclick=$(this).addClass('activeChat');$('#streamChat').removeClass('activeChat') href=http://twitch.tv/chat/embed?popout_chat=true&amp;channel=mxgdichello target=chatFrame id=mainChat class=activeChat>                        Main Chat                    </a>                </li>                <li>                    <a href=javascript: void(0) class=tab id=streamChat onclick=changeChat()>                        Stream Chat                    </a>                </li>            </ul>        </div>        <div style=clear:both></div>        <div id=player>            <object type=application/x-shockwave-flash id=twitchTV width=780px             height=500px></object>        </div>        <div id=chat>            <iframe name=chatFrame frameborder=0 scrolling=no id=chatFrame src=http://twitch.tv/chat/embed?popout_chat=true&amp;channel=mxgdichello></iframe>        </div>         <div id=chanControls>            <div id=add>                <a href=javascript:void(0)>                    <img src=add.jpg />                </a>                <form id=addChan onSubmit=return addChannel()>                    Streamer Name:                         <input type=text name=title />                    Streamer Channel:                        <span style=color:#383838; font-style:italic>                            http://www.twitch.tv/                        </span>                        <input type=text name=url />                    <input type=submit id=submit value=Verify Channel />                    <span class=successMsg></span>                </form>            </div>            <div id=edit>                <a href=javascript:void(0)>                    <img src=edit.jpg />                </a>            </div>        </div>        <div id=list>            <ul></ul>        </div>    </div></body></html>Jqueryvar streams = new Array();var current = -1; // For viewers updatevar twitch = false;var youtube = false;var timer = 60000; // Milisecondsvar toggleEdit = [editList, addList];var toggleCounter = 0;         var youtubePlayer = '<iframe width=765 height=500 frameborder=0 allowfullscreen id=youtubePlayer></iframe>';var twitchPlayer = '<object type=application/x-shockwave-flash id=twitchTV width=780px height=500px></object>';var tubes = [zn7-fVtT16k, IVJVCoHDAXs, 1_hKLfTKU5Y, l3w2MTXBebg, UcTLJ692F70, zj2Zf9tlg2Y, mgVwv0ZuPhM,            7ZsKqbt3gQ0, YHRxv-40WMU, ZIMoQHpvFQQ, TAaE7sJahiw, xBzoBgfm55w, AeNYDwbm9qw, mhTd4_Ids80,            AFA-rOls8YA, CeLrlmV9A-s, 7rE0-ek6MZA, WA4tLCGcTG4, 0M0RbaPxq2k, vICX-6dMOuA, njos57IJf-0,            K5a_v0MP_Fk, dX_1B0w7Hzc, xDj7gvc_dsA, 17CLlZuiBkQ, 0kRAKXFrYQ4, gJ1Mz7kGVf0, -6G6CZT7h4,            liLU2tEz7KY, eHCyaJS4Cbs, uEIPCOwY4DE, V2XGp5ix8HE, DrQRS40OKNE, BBcYG_J3O2Q, upxzaVMhw8k,            0XcN12uVHeQ, itvJybdcYbI, l7iVsdRbhnc, 51V1VMkuyx0, aQQeg3jYgOA, XGK84Poeynk, MaCZN2N6Q_I,            9q5pZ49r9aU, DFM140rju4k, qHBVnMf2t7w, YtO-6Xg3g2M];var updateTimer = setInterval(getList, timer);          // Update the streams list every minute$(window).load(function(){    if(localStorage.length == 0)    {        var streamer1 = new Streamer(Gaurdsman Bob, guardsmanbob, null, null);        var streamer2 = new Streamer(Siv HD, sivhd, null, null);        var streamer3 = new Streamer(Day9 TV, day9tv, null, null);        localStorage.setItem(streamer1.url, JSON.stringify(streamer1));        localStorage.setItem(streamer2.url, JSON.stringify(streamer2));        localStorage.setItem(streamer3.url, JSON.stringify(streamer3));    }    getStorage();    getList();});$(document).ready(function(){    $('#add a').click(function() {        var lefty = $(this).next();        lefty.animate({          left: parseInt(lefty.css('left'),10) == 150 ?            -lefty.width() : 150         });    });    $('#addChan input[name=title]').click(function(){        var title = $('#addChan input[name=title]');        if(title.val() == Enter Streamer Name)        {            title.val('');            title.css(border-color, );        }    });    $('#addChan input[name=url]').click(function(){        var url = $('#addChan input[name=url]');        if(url.val() == Enter Streamer URL)        {            url.val('');            url.css(border-color, );        }    });    $('#edit a').click(function(){        if(toggleCounter % 2 == 1)        {            $(document).off('click', '#list li img');            $(document).off('focusout', '#list input.editTitle');        }        toggleEdit[toggleCounter++%2]();    });});function getList(){    $.post(        streams.php,        {streams : JSON.stringify(streams)},         function(data)         {            streams = $.parseJSON(data);            $.each(streams, function(index, obj){                 $.each(obj, function(key, value){                    if(current == -1 && value == 'online')                    {                        current = index;                        return false;                    }                });            });            if(current != -1 && !twitch)                build(current);            else if(current == -1 && !youtube)                randomTube();            if(twitch)                updateViewers();            addList();        }      );}function build(index){    var data = 'http://www.twitch.tv/widgets/live_embed_player.swf?channel=';   // Object Data    var src = 'hostname=www.twitch.tv&auto_play=false&start_volume=25&channel='; // Flashvars Param    var changeVars = '<param name=flashvars \\    value=hostname=www.twitch.tv&auto_play=false&start_volume=100&channel='+streams[index].url+'/>';    var params = '<param name=allowFullScreen value=true />' +                 '<param name=allowScriptAccess value=always />' +                 '<param name=allowNetworking value=all />' +                 '<param name=movie value=http://www.twitch.tv/widgets/live_embed_player.swf />' +                 changeVars;    $(#player).html(twitchPlayer);    $(#twitchTV).html(params);    $(#twitchTV).attr(data, data);    if(streams[index].status == 'online')        $('#streamInfo').html(<span id=\\streamTitle\\>Streamer:  + streams[index].title +             </span> - <span id=\\viewers\\> + streams[index].viewers + </span> Viewers);    else        $('#streamInfo').text(Streamer:  + streams[index].title +  - Offline);    current = index;    twitch = true;}function addList(){    var numOffline = 0;    var online = '';    var offline = '';    var curr = '';    for(var i = 0; i < streams.length; i++)    {        if(i == current && streams[i].status == 'online')         {                curr = '<li class=item><div class=online></div><a style=color:green href=javascript: void(0) \\                        title='+streams[i].title+' Stream \\                        onClick=changeStream($(this).text())>'+streams[i].title+'</a></li>';        }        else if(streams[i].status == 'online' && i != current)        {                online += '<li class=item><div class=online></div><a style=color:green href=javascript: void(0) \\                        title='+streams[i].title+' Stream \\                        onClick=changeStream($(this).text())>'+streams[i].title+'</a></li>';        }        else        {            offline += '<li class=item><div class=offline></div><a href=javascript: void(0) \\                       title='+streams[i].title+' Stream - Offline \\                       onClick=changeStream($(this).text())>'+streams[i].title+'</a></li>';            numOffline++;        }    }    if(numOffline == streams.length)    {        online += '<li class=item><div class=online></div><a style=color:green href=javascript: void(0) \\                        title=Random Youtube onClick=randomTube()>Random Youtube</a></li>';    }    $('#list ul').html(curr + online + offline);}function editList(){    clearInterval(updateTimer);    var online = '';    var offline = '';    var curr = '';    var previousText;    for(var i = 0; i < streams.length; i++)    {        if(i == current && streams[i].status == 'online')        {            curr = '<li class=item><div><img src=greenDelete.png /></div> \\                        <input type=text value='+streams[i].title+' class=editTitle /></li>';        }        else if(streams[i].status == 'online' && i != curr)        {                online += '<li class=item><div><img src=greenDelete.png /></div>\\                            <input type=text value='+streams[i].title+' class=editTitle /></li>';        }        else        {            offline += '<li class=item><div><img src=redDelete.png /></div>\\                            <input type=text value='+streams[i].title+' class=editTitle /></li>';        }    }    $('#list ul').html(curr + online + offline);    $(document).on('click', '#list li div img', function(){        var find = $(this).parent().next(input).val();        alert(find);        var index = findObjByTitle(streams, find);        var obj =  streams.splice(index, 1);        removeFromStorage(obj[0]);        $(this).parent().parent().remove();    });    $(document).on('focus', '#list input.editTitle', function(){        previousText = this.value;    });    $(document).off('focus', '#list input.editTitle', function(){});    $(document).on('focusout', '#list input.editTitle', function(){        var index = findObjByTitle(streams, previousText);        streams[index].title = this.value;        updateStorage(streams[index]);    });}function updateViewers(){    if(typeof(streams[current]) != 'undefined')        $('#viewers').text(streams[current].viewers);}function changeChat(){    var chatSrc = $('#chatFrame').attr('src');    var chat = chatSrc.split('channel=');    $('#chatFrame').attr('src', chat[0]+'channel='+streams[current].url);    $('#mainChat').removeClass('activeChat');    $('#streamChat').addClass('activeChat');}function changeStream(find){    var found = false    $.each(streams, function(index, obj){         $.each(obj, function(key, value){            if(!found && streams[index].title == find)            {                build(index);                current = index;                found = true;                return false;            }        });    });    if($('#streamChat').hasClass('activeChat'))        changeChat();}function randomTube(){    var video = tubes[Math.floor(Math.random()*tubes.length)];    $('#player').html(youtubePlayer);    $('#player iframe').attr(src, http://www.youtube.com/embed/+ video);    $.ajax({        url: http://gdata.youtube.com/feeds/api/videos/+video+?v=2&alt=json,        dataType: jsonp,        success: function (data){            $('#streamInfo').html('<a href=javascript: void(0) style=color:#ae0000 title=Random Video onClick=randomTube()>\\                Random Video</a> -- ' + data.entry.title.$t);        }    });    youtube = true;}function addChannel(){    var tempStreamer;    var title = $('#addChan input[name=title]');    var url = $('#addChan input[name=url]');    if(title.val() == '' && url.val() == '')    {        title.css(border-color, red);        title.val(Enter Streamer Name);        url.css(border-color, red);        url.val(Enter Streamer URL);        return false;    }    else if(title.val() == '')    {        title.css(border-color, red);        title.val(Enter Streamer Name);        return false;    }    else if(url.val() == '')    {        url.css(border-color, red);        url.val(Enter Streamer URL);        return false;    }    else    {        title = title.val();        url = (url.serialize()).split('=');    }    tempStreamer = new Streamer(title, url[1], null, null);    $.post(        chanExists.php,        {streams : tempStreamer},         function(data){            tempStreamer = $.parseJSON(data);            if(!(tempStreamer.status))            {                $('#addChan .successMsg').text(Channel Does Not Exist!);                $('#addChan .successMsg').css('color', 'red');            }            else            {                var objIndex = objExists(streams, tempStreamer);                if(objIndex == -1)                {                    $('#addChan .successMsg').text(Channel Added!);                    $('#addChan .successMsg').css('color', 'green');                    localStorage.setItem(tempStreamer.url, JSON.stringify(tempStreamer));                    streams.push(tempStreamer);                    clearInterval(updateTimer);                    getList();                }                else                {                    $('#addChan .successMsg').text(Channel  + streams[objIndex].title +  Already Added);                    $('#addChan .successMsg').css('color', 'red');                }            }    });    updateTimer = setInterval(getList, timer);    return false;}/*******************************/*  The Following are Storage/*  Manipulation Functions*******************************/function getStorage(){    var tempStream;    for(var i = 0; i < localStorage.length; i++)    {        tempStream = $.parseJSON(localStorage.getItem(localStorage.key(i)));        streams.push(tempStream);    }}function removeFromStorage(obj){    var found = false;    for(var i = 0; (i < localStorage.length && !found); i++)    {        tempStream = $.parseJSON(localStorage.getItem(localStorage.key(i)));        if(tempStream.url = obj.url)        {            localStorage.removeItem(obj.url);            found = true;        }    }}function updateStorage(obj){    var found = false;    for(var i = 0; (i < localStorage.length && !found); i++)    {        tempStream = $.parseJSON(localStorage.getItem(localStorage.key(i)));        if(tempStream.url = obj.url)        {            localStorage.removeItem(obj.url);            localStorage.setItem(obj.url, JSON.stringify(obj));            found = true;        }    }}/*******************/* Streamer Object/* And Member Functions*******************/function Streamer(title, url, status, viewers){    this.title=title;    this.url=url;    this.status=status;    this.viewers=viewers;}function objExists(arr, obj){    var i = arr.length;    while(i--)    {        if(arr[i].url == obj.url)            return i;    }    return -1;}function findObjByTitle(arr, title){    var found = false;    var i = 0;    while(!found)    {        if(arr[i].title == title)        {            return i;        }               i++;    }}",
    "target": "javascript;jquery;optimization"
  },
  {
    "id": "_codereview.122839",
    "source": "Recursion into git diff tree using nodegit <eos> I'm using nodegit to develop the backend for a nodejs app that uses a mix of mongodb and git for persistence. The app has to version documents and be able to present diffs between versions, thus the use of git in the backend.For one of the API endpoints, I needed to get the diff between two commits, so I've develop the express middleware getDiffBetweenCommits detailed below.AFAIK, Nodegit does not provide this natively. It just provides with commit.getDiff() which only compares a commit to its parent, but I needed to compare to arbitrary commits.Git model is as follows:commit -> patches -> hunks -> modified linesI need to traverse this tree, gather all the modified lines for all the hunks in all the patches, and return.The thing is, all the calls that go deeper into this tree (ie. commit.patches(), patch.hunks(), hunks.lines(), are all async (Promises), so instead of simply doing a forEach at each level, I had to recursively visit the patches tree.I created a context object to help me iterate it, maintain cursors and stack state, and call expressJS next() function to pass to the next middleware when all the tree has been traversed and there are no more patches to iterate.exports.getDiffBetweenCommits = function (req, res, next) {  var commitID1 = req.params.stageID1;  var commitID2 = req.params.stageID2;  var repo;  Git.Repository.open('/path/to/git/repo')    .then(function (repository) {      repo = repository;      return repo.getCommit(commitID1);    })    .then(function (firstCommit) {      req.commit1 = firstCommit;      return repo.getCommit(commitID2);    })    .then(function (commit2) {      req.commit2 = commit2;      req.gitOptions = null;      return;    })    .then(function () {      return req.commit1.getTree();    })    .then(function (commitTree) {      req.commit1Tree = commitTree;      return req.commit2.getTree();    })    .then(function (commitTree) {      req.commit2Tree = commitTree;      return;    })    .then(function () {      return req.commit1Tree.diff(req.commit2Tree);    })    .then(function (diffs) {      var diffResult = [];      req.diffResult = diffResult;      var context = {        next: next,        diffResult: diffResult,        modificationCount: 0,        pushPatches: function (patches) {          this.patches = patches;          this.currentPatch = -1;        },        nextPatch: function () {          this.currentPatch++;          if (this.currentPatch !== this.patches.length) {            this.patches[this.currentPatch].hunks().then(processHunks.bind(null, this));          } else {            this.next();          }        },        pushHunks: function (hunks) {          this.hunks = hunks;          this.currentHunk = -1;        },        nextHunk: function () {          this.currentHunk++;          if (this.currentHunk !== this.hunks.length) {            var hunkHeader = this.hunks[this.currentHunk].header().trim();            log(hunkHeader.substring(0, hunkHeader.length - 1));            this.hunks[this.currentHunk].lines().then(processLines.bind(null, this));          } else {            this.nextPatch();          }        },        increaseModificationCount: function () {          this.modificationCount++;          req.modificationCount = this.modificationCount;        }      };      diffs.patches().then(processPatches.bind(null, context));    });};function processPatches(context, patches) {  if (patches.length === 0) {    return context.next();  }  context.pushPatches(patches);  context.nextPatch();}function processHunks(context, hunks) {  if (hunks.length === 0) {    return context.next();  }  context.pushHunks(hunks);  context.nextHunk();}function processLines(context, lines) {  lines.forEach(function (line) {    var diffString = String.fromCharCode(line.origin()) + line.content().trim();    log(diffString);    var originChar = String.fromCharCode(line.origin());    var diffLine = {      contents: line.content().trim(),      isAddition: originChar === '+',      isDeletion: originChar === '-',      isContext: originChar === ' '    };    if (diffLine.isAddition || diffLine.isDeletion) {      context.increaseModificationCount();    }    context.diffResult.push(diffLine);  });  context.nextHunk();}I would like a review of this because although it works, it feels too complex and procedural, so perhaps I'm missing a simpler or more proper solution here.",
    "target": "javascript;recursion;node.js;promise;git"
  },
  {
    "id": "_softwareengineering.276266",
    "source": "More efficient alternative that checks if a list can be made a palindrome <eos> For my algorithms and data structures class, I have to write an algorithm that is more efficient in the worst case than the following algorithm:def algo_X(A):    i = 0    j = len(A)-1    while i < j:        if A[i] != A[j]:            k = i + 1            while k < j:                if A[i] == A[k]:                    A[k], A[j] = A[j], A[k]                    break                elif A[j] == A[k]:                    A[k], A[i] = A[i], A[k]                    break                else:                    k += 1            if k == j:                return False        i += 1        j -= 1    return TrueThis algorithm returns True if the elements of list passed as argument can be manipulated (swapped) in order to create a new list, which, if we read from the left or from the right, has the same order of elements (palindrome). Else returns False.For example, this list ['a', 'a', 'b', '2', 'b', 'b', 2] can be ordered so that we have a list with the same elements in the same positions, if we read at the same time from the left and from the right: ['a', 'b', '2', 'b', '2', 'b', a].Note that this is my interpretation of the algorithm, they did not tell us what this algorithm was supposed to do.If I am not wrong, this algorithm, in the worst case (and average case), is O(n2), and (n) in the best case.The exercise specifically states that I don't have necessarily to change the list (like in algo_X), but just to return True or False specifying respectively if the list can be made a palindrome or not. We cannot use libraries, but just built-in constructs. We cannot even use slice, for example. This is because we don't know exactly the time complexity of those functions. I will edit my questionTo make a better algorithm for the worst case, I thought I could use merge sort, whose time complexity is always n*log(n), plus a loop, which would not make the algorithm worse, asymptotically.This is my merge function for my merge sort function:def merge(A, B):    ls = []    a, b = 0, 0    while a < len(A) and b < len(B):        if A[a] <= B[b]:            ls.append(A[a])            a += 1        else:            ls.append(B[b])            b += 1    while a < len(A):        ls.append(A[a])        a += 1    while b < len(B):        ls.append(B[b])        b += 1    return lsThis is my merge sort function:def merge_sort(A):    if len(A) < 2:  # basic condition        return A    L = merge_sort(A[0:len(A)//2])    R = merge_sort(A[len(A)//2:])    return merge(L, R)Finally, here's my alternative, which returns True, if the list can be made a palindrome, False otherwise:def better_algo_x(A):    if len(A) < 2:        return True    sorted_A = merge_sort(A)    odd_groups = 0    current = sorted_A[0]    c = 1  # Used to count the number of characters that are equal between them    for i in range(1, len(sorted_A)):        if current == sorted_A[i]:            c += 1        else:            if c % 2 == 1:                odd_groups += 1            if odd_groups > 1:                return False            current = sorted_A[i]            c = 1    # for the last group of characters    if c % 2 == 1:        odd_groups += 1    if odd_groups > 1:        return False    return TrueI have a few questions:Are my functions correct?  Is my analysis of the time complexity of the algorithm algo_X correct?Does my better_algo_x do what it is supposed to do? Does it do it in n*log(n) in the worst case?Can I still improve it? How?Do you know (other) better alternatives for algo_X?Of course, some questions might seem silly, but I would like to hear the opinion of some experts. Of course, I have tried my algorithms.",
    "target": "algorithms;algorithm analysis;python 3.x"
  },
  {
    "id": "_unix.12918",
    "source": "GNU Emacs; Does the GUI version offer anything more than the ability to have a GUI menu? <eos> I've been looking at GNU Emacs for a few months now, on and off (mainly off), and I've really only gone as far as testing a few basic things which I especially want in an editor...  I'm slowly getting to realize its topography, and it is starting to make (good) sense.... The main thing I've noticed is that it seems to work exactly the same in the X-GUI version as it does in the X-Terminal version (and I suspect it would be pretty much the same in a non-GUI environment...  I originally thought that I would feel very uncomfortable working in a non-GUI editor, and that has been the case, but the more I dabble in the Emacs waters, the less significant that need becomes...  so I am now looking at it from the other end of the stick... I'm turning my focus to working primarily in the Terminal version..  My question is: Aside from the obvious GUI-menu (which has turned out to be quite unnecessary), is there any notable difference between the versions  (X-GUI, X-Terminal, and no-GUI) ?*    ",
    "target": "x11;emacs"
  },
  {
    "id": "_cs.32035",
    "source": "top k selection in fixed size priority queue with dynamically changing values <eos> My question is something of a scheduling problem. I'd like to know what algorithm to use to find the top k items in a fixed length queue in which the values of the items change dynamically.basically a long running online top k selectionI imagine that operating systems do this all the time, but not being a systems guy, I don't know what terms to search for. Thanks in advance.",
    "target": "scheduling"
  },
  {
    "id": "_codereview.124643",
    "source": "Eval is evil: Dynamic method calls from named regex groups in Python 3 <eos> I'm working on a simple dice roller for a Python IRC bot. The particular game this roller is for uses six different kinds of dice, which I've defined using a simple base class, and created six instances of it, passing a string array with the possible values of each dice.class DiceBag(object):    def __init__(self, dice: List[str]):        self.bag = dice    def draw(self, count: int) -> str:        return [random.choice(self.bag) for _ in range(0, count)]An example of the instances:proficiency_dice = DiceBag(['', 'S', 'S', 'SS', 'SS', 'A', 'AS', 'AS', 'AS', 'AA', 'AA', '!'])boost_dice = DiceBag(['', '', 'AA', 'A', 'SA', 'S'])Now for a user to actually access this function, they must write a textual dice expression in the IRC channel. An example usage:<user> ?roll 2p1b<bot>  Result:  P(A, AA)  B(S)So I need a way to quickly convert from the dice expression provided by the user, to call the draw method on the appropriate class.I'm using a regular expression to evaluate the dice expression, so named capture groups seem like the most straightforward way to handle this - at the possible cost of my immortal soul, since I'm eval-ing the group name to the proper instance of DiceBag.#User's input comes in as a string on the dice varrex = (r'(?P<setback>\\ds)?'       r'(?P<ability>\\da)?'       r'(?P<difficulty>\\dd)?'       r'(?P<proficiency>\\dp)?')to_roll = re.match(rex, dice).groups()    for group in to_roll:        if group:  # We don't care about the Nones            dicetype = group.split('')[1]            dicecnt = group.split('')[0] # handle the extra rolls later            eval(dicetype + _dice + .draw( + dicecnt + ))Is there a better, or saner, or more pythonic, or perhaps less evil way I could be handling this use case?",
    "target": "python;strings;regex;dynamic loading"
  },
  {
    "id": "_cs.11233",
    "source": "Looking for Rating Functions <eos> I'm looking for something i would call rating functions.I'm searching for some literature about this concept.I'm not really sure about the terminology, but what I mean should be pretty obvious.A type of function that returns a rating of some input.Lets have a function that gets some input and returns a number between 0 and 1 as a rating, where 0 is bad and 1 is great. Everything between is well between bad and great depending.Lets assume inputs are just numbers$f\\colon \\mathbb{N} \\longrightarrow [0,1]$I would like if I have several rating functions be able to compose them.For example if I have the rating functions $r_1$, $r_2$ I would like to compose both to a new rating function that returns a new rating in dependency to $r_1$ and $r_2$Now I'm looking for literature, but was unable to find any.Can somebody hint me into the correct direction?The correct name for the concept I'm looking for would be great.EditI want to implement various Rating Functions and want to combine themOne functions could bealwaysPerfect = (x) -> 1alwaysBad = (x) -> 0isOdd = (x) -> x%2distanceToOne = (x) ->  x = 2 if x is 0  1/abs(x)Anyone could implement this functions, but the contract for this functions would be to always return a value between 0 and 1I need to evaluate some data with various evaluation conditions. Writing these evaluation seperate small functions and combine them seems to be more clearer than writing one big function that does all the evalauting",
    "target": "machine learning;mathematical analysis;data mining"
  },
  {
    "id": "_cs.79507",
    "source": "Are there any hash functions/stateless RNGs that do not use XOR, but produce good quality visual randomness? <eos> I'm looking for a small function from integers to integers - in a language that only has floats - that can act as a visual RNG. Normally I would use a function such as the one described here:int cash(int x, int y){       int h = seed + x*374761393 + y*668265263; //all constants are prime    h = (h^(h >> 13))*1274126177;    return h^(h >> 16);}However, for the thing I'm working on, I have the added restriction of only using arithmetic operations. the operations I have available are: +, *, -, /, %, sign(), abs(), pow(base, exponent), ln(), floor(), as well as basic trig functions. I'm having difficulty finding anything that doesn't rely on having bitwise operations available. Does anyone know of a hash function that doesn't use xor, that produces reasonable visual randomness when fed a linear sequence of integers?",
    "target": "hash;graphics;pseudo random generators"
  },
  {
    "id": "_webmaster.33421",
    "source": "same blog post link appearing in different tag pages <eos> I have each blog post tagged with different terms. Each term page lists the tagged post link, so that the link may appear more than once. How does that affect my SEO?",
    "target": "seo;tags"
  },
  {
    "id": "_unix.242357",
    "source": "How to find the most frequent word of each file in a directory? <eos> I need to find the most frequent word of each file in a directory and print it like this :12 my /home/test/file1.txt5 you /home/test/file3.txt7 hello /home/test/file4.txtI tried:for tmp in <path>     do   tr -c '[:alnum:]' '[\\n*]' < $tmp | sort | uniq -c | sort -nr | head  -1    done   It doesn't work",
    "target": "bash;text processing;files"
  },
  {
    "id": "_codereview.148382",
    "source": "Add buffer to hash table <eos> RetrieveData is a 3rd party API that takes 3 parameters: a buffer, number of bytes to retrieve, and actual bytes required for the buffer.The buffer returned is a non-null terminated unicode string99% of the time, the buffer is less than 256 bytes, but may be larger and needs to handle this scenarioRetrieveData(data) is guaranteed to return The reason for using std::map is the ID must later be retrieved based on a stringstd:map<std::wstring, unsigned int> map_columns;unsigned int id;unsigned long pcbActual;char* data;do {    RetrieveID(&id);    // find out how large buffer we need to retrieve data    RetrieveData(NULL, 0, &pcbActual);    data = new char[pcbActual + 2];    // actually retrieve data    RetrieveData(data, pcbActual, &pcbActual);    data[pcbActual] = '\\0';    data[pcbActual + 1] = '\\0';    std::wstring str((wchar_t*)data);    map_columns[str] = id;} while (MoveNext());",
    "target": "c++;c++11"
  },
  {
    "id": "_cs.23802",
    "source": "If A is mapping-reducible to B and is not mapping-reducible to co-B, is A Turing-reducible to co-B? <eos> If $A \\leq_m B$ and $A$ is not mapping reducible to $co\\text{-}B$, then $A \\leq_T co\\text{-}B$.Is this true?My intuition is false even if we can find some special case to make it true such as $A=B=co\\text{-}A_{TM}$. However, I still can't find a counterexample. Could anyone give me a little hint?   ",
    "target": "computability;reductions"
  },
  {
    "id": "_unix.329537",
    "source": "help understanding the behaviour of at + x minutes <eos> When I run echo hello | at now + 7 minutesI get the following output - job 2 at 2016-12-11 05:06However when I use bash txt | at now + 7 minutesIt starts executing immediately. Can someone please explain this behaviour?",
    "target": "at"
  },
  {
    "id": "_unix.293202",
    "source": "run a command in subfolders <eos> I have a command rdseed -d -R -p -f filename which gives an output of response time and etc for each file in a subfolder. The problem is I want to run this command in all subfolders and the output (response time, pz) must be inside the subfolders. I've tried  using ls -1 */*.file type | awk -F '[/]' '{print rdseed -d -R -p -f }' but the result is just it do this in the file in the first subfolder and its was also placed in the parent folder. ",
    "target": "linux;awk"
  },
  {
    "id": "_codereview.153627",
    "source": "Modeling a control polygon for a piecewise spline curve <eos> AimI'm modeling a control polygon for a piecewise spline curve. Each sub-spline is defined by a location the spline must pass through, as well as a forward tangent, and a backwards tangent. The control points and their tangents can be freely manipulated.I aim at keeping this flexible, so the forward and backward tangents may or may not be colinear. If the user want to make them colinear, I want to be able to express this as a Constraint, that holds true even when the control points and/or its tangents are manipulated.Additionally, a control point can be reused in an other Piecewise spline, to make a network of them. Think Train Fever's free-form tracklaying system:Here is a usage scenario:Have a start point A with a forward tangent Afwd.Have an end point C with a backward tangent Cbwd.Build a spline out of that control polygon:  Awfd---->CbwdInsert a mid-point B with two tangents (Bfwd/Bbwd)Require B's tangents to be opposite.Build a spline out of that control polygon: Awfd---->[Bbwd|Bfwd]---->CbwdMove the tangent Bfwd.-> The tangent Bbwd is automatically altered to the oppositeBreak the constraint on B's tangents-> The tangent Bbwd and Bfwd are automatically freedHere's how I did itA ControlPoint class, which has location, and references two TangencyConstraint objectsA ControlPolygon class, is a collection of ControlPoints. Has a Builder, and can generate an immutable PiecewiseBezier splineA TangencyConstraint interface that provides a tangent vectorAn OppositeTangency which is a TangencyConstraint. Works in pair, one isthe opposite of the other. Is an inner (non-static) class of OppositeTangencyManagerAn OppositeTangencyManager class wich manages two OppositeTangency. Makessure both are opposite, and that if one side wishes to break the constraint, the other is informed and becomes a free tangent.Here's the codeControlPoint.java:public class ControlPoint {    private final Point2D location;    private final AtomicReference<TangencyConstraint> forwardTangency;    private final AtomicReference<TangencyConstraint> backwardTangency;    public ControlPoint(Point2D location, Point2D backwardTangent, Point2D forwardTangent) {        this.location = new Point2D.Double(location.getX(), location.getY());        this.backwardTangency = new AtomicReference<>(new AbsoluteTangency(forwardTangent));        this.forwardTangency = new AtomicReference<>(new AbsoluteTangency(forwardTangent));    }    public Point2D getLocation() {        return new Point2D.Double(location.getX(), location.getY());    }    public Point2D getForwardTangent() {        return forwardTangency.get().get();    }    public Point2D getBackwardTangent() {        return backwardTangency.get().get();    }    public void moveForwardTangency(Point2D dir) {        forwardTangency.get().move(dir);    }    public void imposeOppositeTangency(Point2D forwardDirection) {        OppositeTangencyManager.lock(forwardTangency, backwardTangency, forwardDirection);    }    public void imposeOppositeTangency(boolean keepForward) {        Point2D direction;        if (keepForward) {            direction = forwardTangency.get().get();        } else {            Point2D opp = backwardTangency.get().get();            direction = new Point2D.Double(-opp.getX(), -opp.getY());        }        OppositeTangencyManager.lock(forwardTangency, backwardTangency, direction);    }    public void freeTangency() {        forwardTangency.get().destroy();        backwardTangency.get().destroy();    }}ControlPolygon.java:/**  A ControlPolygon is a collection of {@link ControlPoint}s. Has a {@link Builder}, and can generate an immutable PiecewiseBezier spline */public class ControlPolygon {    /** Builds a {@link ControlPolygon} */    public static class Builder {        private final List<ControlPoint> controlPolygon = new ArrayList<>();        public Builder(Point2D begin) {            controlPolygon.add(new ControlPoint(begin, new Point2D.Double(), new Point2D.Double()));        }        public Builder(Point2D begin, Point2D forwardTangent) {            controlPolygon.add(new ControlPoint(begin, new Point2D.Double(), forwardTangent));        }        public Builder through(Point2D next, Point2D backwardTangent, Point2D forwardTangent) {            controlPolygon.add(new ControlPoint(next, backwardTangent, forwardTangent));            return this;        }        public Builder endAt(Point2D next, Point2D backwardTangent) {            controlPolygon.add(new ControlPoint(next, backwardTangent, new Point2D.Double()));            return this;        }        public ControlPolygon build() {            return new ControlPolygon(new ArrayList<>(controlPolygon));        }    }    private final List<ControlPoint> polygon;    private ControlPolygon(List<ControlPoint> poly) {        this.polygon = poly;    }    public ControlPoint getControlPoint(int i) {        return polygon.get(i);    }    /** Generates an immutable {@link PiecewiseBezier} curve using this ControlPolygon.     public PiecewiseBezier toBezier() {        Point2D p0 = polygon.get(0).getLocation();        PiecewiseBezier.Builder builder = new PiecewiseBezier.Builder(p0);        for (int i = 0; i < polygon.size() - 1; i++) {            ControlPoint cp1 = polygon.get(i);            ControlPoint cp2 = polygon.get(i + 1);            Point2D t1 = cp1.getForwardTangent();            Point2D t2 = cp2.getBackwardTangent();            Point2D p1 = new Point2D.Double(p0.getX() + t1.getX(), p0.getY() + t1.getY());            Point2D p3 = cp2.getLocation();            Point2D p2 = new Point2D.Double(p3.getX() - t2.getX(), p3.getY() - t2.getY());            builder.addBezier(p1, p2, p3);            p0 = p3; // loop        }        return builder.build();    }}TangencyConstraint.java interface :/** Provides a tangent vector which may or may not be externally constrained. An eventual constrain can be destroyed. */public interface TangencyConstraint {    Point2D get();    void destroy();    void move(Point2D dir);}OppositeTangencyManager.java:/** Manages two {@link OppositeTangency} objects so they are always opposite. Can be disabled, but never re-enabled. */public class OppositeTangencyManager {    /** A {@link TangencyConstraint} which is always the opposite of another one. */    public class OppositeTangency implements TangencyConstraint {        private final AtomicReference<TangencyConstraint> referenceToMe;        protected OppositeTangency(AtomicReference<TangencyConstraint> referenceToMe) {            super();            this.referenceToMe = referenceToMe;        }        @Override        public Point2D get() {            return OppositeTangencyManager.this.getTangencyForMe(this); // Don't know the current value, must ask the manager        }        @Override        public void destroy() {            OppositeTangencyManager.this.destroy(); // Can't do this myself, must ask the manager        }        @Override        public void move(Point2D dir) {            OppositeTangencyManager.this.move(this, dir); // Can't do this myself, must ask the manager        }    }    /** Creates a constraint on two references to Tangents so they stay opposite until it is disabled. */    public static void lock(AtomicReference<TangencyConstraint> forward, AtomicReference<TangencyConstraint> backward, Point2D direction) {        new OppositeTangencyManager(forward, backward, direction);    }    private final Point2D tangency; // The only place the shared tangent is stored    private boolean active = true; // Can only become false.    private final OppositeTangency forwardTangency;    private final OppositeTangency backwardTangency;    /** Displace the tangent, but keep the constraint. */    public void move(OppositeTangency oppositeTangency, Point2D dir) {        if (oppositeTangency == forwardTangency) {            tangency.setLocation(dir);        } else {            tangency.setLocation(-dir.getX(), -dir.getY());        }    }    private OppositeTangencyManager(AtomicReference<TangencyConstraint> forward, AtomicReference<TangencyConstraint> backward, Point2D direction) {        super();        this.tangency = direction;        this.forwardTangency = new OppositeTangency(forward);        this.backwardTangency = new OppositeTangency(backward);        forward.get().destroy(); // Must destroy the old ones before!        backward.get().destroy(); // Must destroy the old ones before!        forward.set(forwardTangency);        backward.set(backwardTangency);    }    public void destroy() {        if (!active) {            return;        }        active = false;        forwardTangency.referenceToMe.set(new AbsoluteTangency(new Point2D.Double(tangency.getX(), tangency.getY())));        backwardTangency.referenceToMe.set(new AbsoluteTangency(new Point2D.Double(-tangency.getX(), -tangency.getY())));    }    protected Point2D getTangencyForMe(OppositeTangency requestingTangency) {        if (!active) {            return null; // Should be handled better        }        if (requestingTangency == forwardTangency) {            return new Point2D.Double(tangency.getX(), tangency.getY());        } else {            return new Point2D.Double(-tangency.getX(), -tangency.getY());        }    }}PiecewiseBezier.java is way outside the scope. Any usual library works.Example usage (complies with the scenario above):public static void main(String[] argc) {    // 1. Have a start point `A` with a forward tangent `Afwd`.    Point2D A = new Point2D.Double(0, 0);    Point2D Afwd = new Point2D.Double(0, 1.0);    // 2. Have an end point `C` with a backward tangent `Cbwd`.    Point2D C = new Point2D.Double(10, 0);    Point2D Cbwd = new Point2D.Double(-0.5, -0.5);    // 3. Build a spline out of that control polygon:  `Awfd---->Cbwd`    Builder builder = new ControlPolygon.Builder(A, Afwd);    builder.endAt(C, Cbwd,);    ControlPolygon polyAC = builder.build();    PiecewiseBezier curveAC = polyAC.toBezier();    // 4. Insert a mid-point `B` with two tangents (`Bfwd`/`Bbwd`)    Point2D B = new Point2D.Double(5, 5);    Point2D Bbwd = new Point2D.Double(-1, 0);    Point2D Bfwd = new Point2D.Double(-1, 0.5);    builder.insert(1, B, Bbwd, Bfwd);    // 5. Require B's tangents to be opposite.    ControlPolygon polyABC = builder.build();    polyABC.getControlPoint(1).imposeOppositeTangency(true);    // 6. Build a spline out of that control polygon: `Awfd---->[Bbwd|Bfwd]---->Cbwd`    PiecewiseBezier bezierABC = polyABC.toBezier();    // 7. Move the tangent `Bwfd`.      //    -> The tangent `Bbwd` is automatically altered to the opposite    polyABC.getControlPoint(1).moveForwardTangency(new Point2D.Double(2,3));    // 9. Break the  constraint on `B`'s tangents      //    -> The tangent `Bbwd` and `Bfwd` are automatically freed    polyABC.getControlPoint(1).freeTangency();}What I'm looking forI'm looking for a simpler, more elegant way to activate/deactivate/maintain those constraints than a Manager. I feel like this framework is a sledgehammer to crack a nut.The builder is annoying. Should I not have made one? How to change the definition of the control polygon easily?My control points are directed (have a forward, and a backward). This prevents me from defining a polygon as Abwd--->Bbwd at the moment. How can I remedy this? A ControlPointReverser?I intend to allow making constraints between two distinct control point's tangents (like ctrlA.forceParallel(ctrlB)). I also might introduce constraints on location (like ctrlA.sitOnTopOf(ctrlB)) or even curvature. How do you feel about applying the same manager mechanic throughout all these constraints?Any complaints on style?",
    "target": "java;algorithm;graph;computational geometry"
  },
  {
    "id": "_unix.289758",
    "source": "How to open a new terminal from my working folder in Solaris 10? <eos> In Solaris 8, I could to ctrl+t to open a terminal from the file manager. But in Solaris 10, I can't seem to be able to.I try to create a shortcut key by gnome-terminal, but the pwd is always my home directory. I want a way to set up a keyboard shortcuts to be able to use in file browser to open up a terminal that has pwd of the directory I am currently on. ",
    "target": "gnome;keyboard shortcuts;gnome terminal;working directory"
  },
  {
    "id": "_webmaster.43534",
    "source": "Is there a way to know if apache receives a request from a public IP not local to your country? <eos> I'm looking for ways to know if an apache server receives a request , from another country (e.g germany) considering its a fair request (no spam , or proxies). I want it either to appear this as a separate entry(using dns request) in apache logs? or some kind of alert . Can this be possible.",
    "target": "apache;logging;geolocation;geotargeting;apache log files"
  },
  {
    "id": "_cstheory.20035",
    "source": "Does Second X is NP-complete imply X is NP-complete? <eos> Second $X$ problem is the problem of deciding the existence of another solution different from some given solution for problem instance. For some $NP$-complete problems, the second solution version is $NP$-complete (deciding the existence of another solution for the partial Latin square completion problem) while for others it is either trivial (Second NAE SAT) or it can not be $NP$-complete (Second Hamiltonian cycle in cubic graphs) under widely believed complexity conjecture. I am interested in the opposite direction. We assume a natural $NP$ problem $X$ where there is natural efficient verifier that verifies a natural interesting relation $(x, c)$ where $x$ is an input instance and $c$ is a short witness of membership of $x$ in $X$. All witnesses are indistinguishable to the verifier. The validity of witnesses must be decided by running the natural verifier and it does not have any knowledge of any correct witness ( both examples in the comments are solutions by definition).  Does Second $X$ is NP-complete imply $X$ is NP-complete for all natural problems $X$?In other words, Are there any natural problem $X$ where this implication fails?. Or equivalently,Is there any natural problem $X$ in $NP$ and not known to be $NP$-complete but its Second $X$ problem is $NP$-complete?EDIT: Thanks to Marzio's comments, I am not interested in contrived counter-examples. I am only interested in natural and interesting counter-examples for NP-complete problems $X$ similar to the ones above. An acceptable answer is either a proof of the above implication or a counter-example Second X problem which is defined for natural, interesting, and well known $NP$ problem $X$.EDIT 2: Thanks to the fruitful discussion with David Richerby, I have edited the question to emphasis that my interest is only in natural problems $X$.EDIT 3: Motivation: First, the existence of such implication may simplify the $NP$-completeness proofs of many $NP$ problems. Secondly, the existence of the implication links the complexity of deciding the uniqueness of solution to the problem of deciding existence of a solution for $NP$ problems.",
    "target": "cc.complexity theory;unique solution"
  },
  {
    "id": "_codereview.160113",
    "source": "Checking whether one string is a permutation of another <eos> I solved the standard write a method to determine if one string is a permutation of the other question with the following code, using xor, map, and reduce:from functools import reducefrom operator import xordef checkPermutation(str1, str2):    return not bool(reduce(xor, map(ord, str1 + str2)))The idea is that if the two strings are permutations, the xor sum of the int value of every character of the concatenation of the two strings must be 0.If I write the algorithm out by hand it seems come down to O(n) time and space:def checkPermutation(str1, str2):    # map every character in the strings to its integer value    map = []    str = str1 + str2    for char in str:        map.append(ord(char))    # xor every number that was mapped into a sum    sum = map[0]    for i in range(1, len(map)):        sum ^= map[i]    return not bool(sum)Essentially I think that's what reduce and map are doing but depending on how they're actually implemented in python, the time and space complexity of two solutions may differ.",
    "target": "python;algorithm;strings;comparative review;complexity"
  },
  {
    "id": "_webmaster.14178",
    "source": "How do keywords in Google Webmaster Tools affect search results? <eos> I've checked the keywords list on the Google Webmaster Tools account for my website (which is a message board), and I noticed that the top keywords are things such as topic and forum. I'm guessing that is because those are the words which appear the most within the homepage.The question is, will this impact search results? I'm guessing yes. If so, can this be solved, and how? I already searched on Google and on SEO forums without any luck. (When it comes to SEO, most info looks like bogus to me. I hope I'm wrong, but meanwhile I'll ask here since it seems a reliable place.) ",
    "target": "seo;google search console;keywords"
  },
  {
    "id": "_webmaster.77692",
    "source": "Is it true that Google will effectively penalise mobile-unfriendly sites from April 21, 2015? <eos> I have heard that Google will boost mobile-friendly websites in search results.  My website is not mobile-friendly.Will my website penalised in the Google search results if I have not made the  website mobile friendly before April 21st?",
    "target": "seo;google search;mobile;penalty"
  },
  {
    "id": "_unix.252023",
    "source": "How do I list all lines after two subsequent patterns are matched up to when they don't <eos> I have files that are used to install files with specific owner:group and permissions.  I'll ignore permissions for clarity and the details of installing files.  Once an owner & group are set to a specific pair, then I want to print a separator line followed by all subsequent lines until either the owner or group changes.  If I could print the line numbers with the lines, that would be great too.  The pair I'm searching for is owner, group as ownerX, groupY respectively.Example (I don't need line numbers, so I'll leave them off)type = d  owner = root  group = staff      mode = 0750 <-Ignore.  owner & group aren't ownerX & groupY      ...  <- Ignore  group = groupY <- owner=root, not ownerX, so still not ownerX & groupY      ...  <- Ignore  owner = ownerX <-Now, owner=ownerX and group=groupY      <- Print -----------------      mode = 0750             <- Print      target = /app_dir/conf  <- Print       target = /app_dir/data  <- Print  owner = dilbert          <- Stop printing since not ownerX & groupY      ...  <- Ignore  group = Dogbert      ...  <- Ignore  group = groupY      ...  <- Ignore  owner = ownerX      <- Print a separator line      type = f                                                       <- Print      mode = 0540                                                    <- Print      source = [path to compiled binary file in source environment]/file1_ver2  <- Print      target = [path to a bin directory in the install environment]/file  <- Print  owner = oracle <- stop printing  ...  <End of File, EOF>  So, the desired output would be:  ---------  mode = 0750  target = /app_dir/conf  target = /app_dir/data  ---------  type = f  mode = 0540  source = [path to compiled binary file in source environment]/file1_ver2  target = [path to a bin directory in the install environment]/file1  That would help me apply the following fixes:Change the 1st mode from 0750 (group is read-only) to 0770.Change the 2nd mode from 0540 (group can't execute) to 0550.  ",
    "target": "text processing;sed;awk"
  },
  {
    "id": "_softwareengineering.121587",
    "source": "How many tiers should my models have in a DB driven web app? <eos> In my experience, the Model in MVC is often not really a single layer. I would regularly have backend models and frontend models, where the backend ones would have properties that I want to hide from the UI code, and the frontend ones have derived or composite properties which are more meaningful in the context of the UI.Recently, I have started to introduce a third layer in between when database normalization created tables that did not really match the conceptual domain objects anymore. In those projects I have model classes that are equivalent with the DB structure, these become components of objects that represent the domain model, and finally these are filtered and amended for displaying information to the user.Are there patterns or guidelines for how, when and why to organize the data model across application layers?",
    "target": "design"
  },
  {
    "id": "_unix.330915",
    "source": "understanding this DOS partition table and cloning to a new drive <eos> I have a piece of equipment that has a motherboard in it which boots to a linux based operating system.  I am interested in being able to clone this one hard drive so that in the case it fails i have a backup plan to keep the equipment working.  So far I have been able to mount the hard disk to a different PC running linux, and was able to tar the data off the partitions.  However I don't know what to make of two of the partitions- sdb2 and sdb13 which do not show up as EXT3 file systems; sdb2 is 0x05 extended, and while sdb13 is 0x83 it does not show it has any file system and I cannot mount it.And I am not sure yet how to handle GRUB if I use a new hard drive of a different size.  I'm looking to find out if what I want to do is even possible... if i have enough information from the followingoutput from fdisk -lDisk /dev/sdb: 500.1 GB, 500107862016 bytes255 heads, 63 sectors/track, 60801 cylinders, total 976773168 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 4096 bytesI/O size (minimum/optimal): 4096 bytes / 4096 bytesDisk identifier: 0x00066c45   Device Boot      Start         End      Blocks   Id  System/dev/sdb1              63      208844      104391   83  LinuxPartition 1 does not start on physical sector boundary./dev/sdb2          208845    31262489    15526822+   5  ExtendedPartition 2 does not start on physical sector boundary./dev/sdb5          208908     6650909     3221001   83  LinuxPartition 5 does not start on physical sector boundary./dev/sdb6         6650973     7052534      200781   83  LinuxPartition 6 does not start on physical sector boundary./dev/sdb7         7052598     7646939      297171   83  LinuxPartition 7 does not start on physical sector boundary./dev/sdb8         7647003     7855784      104391   83  LinuxPartition 8 does not start on physical sector boundary./dev/sdb9         7855848    15679439     3911796   83  Linux/dev/sdb10       15679503    23503094     3911796   83  LinuxPartition 10 does not start on physical sector boundary./dev/sdb11       23503158    24097499      297171   83  LinuxPartition 11 does not start on physical sector boundary./dev/sdb12       24097563    24691904      297171   83  LinuxPartition 12 does not start on physical sector boundary./dev/sdb13       24691968    31262489     3285261   83  Linuxoutput from sfdisk -d# partition table of /dev/sdbunit: sectors/dev/sdb1 : start=       63, size=   208782, Id=83/dev/sdb2 : start=   208845, size= 31053645, Id= 5/dev/sdb3 : start=        0, size=        0, Id= 0/dev/sdb4 : start=        0, size=        0, Id= 0/dev/sdb5 : start=   208908, size=  6442002, Id=83/dev/sdb6 : start=  6650973, size=   401562, Id=83/dev/sdb7 : start=  7052598, size=   594342, Id=83/dev/sdb8 : start=  7647003, size=   208782, Id=83/dev/sdb9 : start=  7855848, size=  7823592, Id=83/dev/sdb10: start= 15679503, size=  7823592, Id=83/dev/sdb11: start= 23503158, size=   594342, Id=83/dev/sdb12: start= 24097563, size=   594342, Id=83/dev/sdb13: start= 24691968, size=  6570522, Id=83I was able to mount the EXT3 file systems of sdb 1, 5, 7, 8, 9, 10, 11, 12, and save the contents of each to sdb1.tar, sdb5.tar, and so on.I have also done dd if=/dev/sdb of=./sdb_dd bs=512 count=1 to save the MBR of the drive to a file called sdb_dd.",
    "target": "partition;mbr"
  },
  {
    "id": "_unix.348123",
    "source": "Find all videos by codec (and not by container formats or MIME type) <eos> How can I get the list of all my videos with the used video codec?I found some intersting commands like mediainfo, ffmpeg or exiftool but they giving a lot of informations only by one video.The most intersting command I found is file and give me this output:$ file *8 Mile (2002).avi:        RIFF (little-endian) data, AVI, 640 x 272, 23.98 fps, video: XviD, audio: MPEG-1 Layer 3 (stereo, 48000 Hz)1984 (1984).avi:          RIFF (little-endian) data, AVI, 960 x 540, ~24 fps, video: H.264 X.264 or H.264, audio: MPEG-1 Layer 3 (stereo, 48000 Hz)And I would like an output something like this (to convert next, for sample, only videos with XviD codec):~/Movies/8 Mile (2002).avi     XviD~/Movies/1984 (1984).avi       H.264NB : I'm on MacOS Sierra (10.12) but I can translate Linux commands too",
    "target": "command line;video;video encoding;codec"
  },
  {
    "id": "_webmaster.18310",
    "source": "Running a program that extracts data from websites <eos> I have created a program that searches through every player of a particular online game, visits their information webpage and extracts pieces of information about them (ie. their stats).The problem is that there are several millions of players. By my initial calculations, it may take over 10 days to complete, and will use up over 30gbs of data traffic. This is less than ideal when you have a 40gb monthly allowance and you want to run the program weekly.My question is this. How can I run my program quickly and cheaply. For instance, is it possible to buy some webspace with a webhosting company and run my java program somehow from there? I have seen some webhosting for around $2 per month, which seems pretty reasonable.Or is it a webserver I would be after. Although they seem rather expensive. I am only doing this for my own interest and wouldn't want to spent more than a few dollars.Thanks",
    "target": "web hosting;webserver;java"
  },
  {
    "id": "_webapps.3964",
    "source": "How do I remove 1 item from an Amazon order? <eos> How can I remove just one item from my Amazon order? I accidentally ordered 2 copies of a book. I find where I can remove the item, but it completely deletes the item. I just want to remove one of the two. How can I do this?",
    "target": "amazon"
  },
  {
    "id": "_cstheory.17411",
    "source": "#P-Completeness of the Hosoya Index <eos> The description from Wikipedia mentions that it is #P-Complete to compute, but there are methods.  What is a layman's explanation to this?",
    "target": "time complexity;counting complexity"
  },
  {
    "id": "_unix.179639",
    "source": "Missing kernel headers, but need them to install the Wifi driver <eos> I am trying to install Kali on my Lenovo Yoga13, but after formatting the disk the setup failed to install grub because of no internet access (no Ethernet, need driver to get Wifi to work).So, I decided to compile the Wifi driver to complete the setup just to realize I am missing kernel headers. I cannot apt-get install because I do not have net access. Is there a way to manually install kernel headers to compile the driver?",
    "target": "kernel;drivers;compiling;kali linux"
  },
  {
    "id": "_unix.213860",
    "source": "Linux server as a target for my C code <eos> How to use a linux server as a target for my C code written on a different (Windows) machine. Including step by step debugging and etc... All that with Eclipse Env.",
    "target": "remote;c;debugging;eclipse"
  },
  {
    "id": "_datascience.15512",
    "source": "Calculating RMSE AND R-squared from the confusion matrix <eos> I have my confusion matrix as C.mat8263    20    392       3826  1443       7    4431 My predicted class labels are Ypred and actual labels are Ytest. Ypred size is 16000*1 and Ytest 16000*1.I am trying to calculate the R-squared and RMSE. Is there a way to directly calculate RMSE and R-squared from the confusion matrix?I tried this:RMSE = sqrt(immse(Ypred, Ytest))However, it didn't work.I can use  either R or Matlab.Any advice will be appreciated!",
    "target": "multiclass classification;confusion matrix"
  },
  {
    "id": "_softwareengineering.274760",
    "source": "Two dimensional matrix-like data type using lists and/or mutable lists <eos> I am trying to think of an implementation of a two dimensional matrix-like data type.Normally I would take an array of arrays but I'm bound to a relatively low language level which only provides lists and mutable lists, because this is part of (but not an exercise itself, I could simply use an inefficient solution) a software project at university. In this, we are only allowed to use a specific language level.So of cause I could take a list of mutable lists and, in search of an item in row n and column m, get the m-th mutable list and go throught it until position n. But isn't there a better solution than going through the whole list?",
    "target": "array;scheme;matrices;racket"
  },
  {
    "id": "_webapps.75925",
    "source": "Calculate difference between numbers in 2 columns row-by-row in a spreadsheet <eos> I have 3 columns in a Google Docs spreadsheet: A) Inventory purchased price, B) Inventory sold price, C) Difference between A and B (i.e. profit or loss)Data is going to be entered manually into columns A and B. How do I make column C to 1) display the calculated amount for each row, and 2) color profitable sales in green and unprofitable in red?",
    "target": "google spreadsheets;worksheet function"
  },
  {
    "id": "_unix.258381",
    "source": "MX Record Question <eos> Is there a way to bypass the DNS's MX record?  My company uses Barracuda for spam filtering and our company's MX record points to Barracuda.  A product we're trying to build needs to talk TLS to the mail server, but to test this I have to create a subdomain that bypasses Barracuda and then having to deal with the SSL certs for that.  Not necessarily a show stopper.  But if I could fool something to use our mail server's actual IP address as opposed to the MX, that'd help a lot.Any thought, cantor, ideas or anecdotes?",
    "target": "email;dns"
  },
  {
    "id": "_softwareengineering.110135",
    "source": "Ubiquitous Language - conflict between correctness and usability <eos> A core part of Domain Driven Design is the consistent use of a ubiquitous language across the system - in conversations, code, database schema, UI, tests, etc.I'm involved in a project in which there is a well-established domain language already, defined by an international standards organisation.However, the work we're doing is for a public web site, and the 'correct' terms for the domain aren't necessarily how the public typically use and understand them.The compromise we're using at the moment is to use the 'official' terms everywhere, except for in our acceptance criteria which refer to UI components, where we use the informal names.Does this seem like a reasonable approach?",
    "target": "documentation;domain specific languages"
  },
  {
    "id": "_unix.139744",
    "source": "How to enable Control key combinations for GNU screen on putty? <eos> I am accessing a linux box via ssh using putty.Key combinations work fine when I'm not running screen.However, Ctrl key combinations do not work under a screen session.In fact, a Ctrl-any key is registered the same as the same key without the Ctrl combination.I know this by typing Ctrl-V and then a Ctrl-key combination to figure out what characters are sent to my terminal. For example, Ctrl- (left arrow) gives me ^[[D on screen (screen256-color term).  gives me the same result.Weird thing is that Alt-key combinations work fine.In particular, I would like to get the 'forward-word' and 'backward-word' key bindings working under screen.I have tried modifying .inputrc to work with various terminals. As such, my .inputrc looks something like this:$if term=xterm    'xxx' : forward-word # xxx key gotten from Ctrl-V    'xxx' : backward-word$endif$if term=screen-256color......I have also tried various terminals by setting the TERM of my bash profile, setting TERM on .screenrc, and setting the Putty keyboard terminal mappings. The obvious ones, linux and xterm, don't work. However, I haven't tried every permutation of settings for obvious reasons.Additional info:I stand corrected, arrow key combinations are the only combinations that do not work.The distro is RHEL 6. .screenrc:term xterm # tried other terms as wellshell -$SHELL # login shell to reload configscaption string %whardstatus alwayslastline %{b kw}%H %{r}%1` %{w}| %{g}%c %{w}| %{y}%d.%m.%Y %{w}| %{g}%l %{w}| %{-b kw}%u %-Lw%{= rW}%50> %n%f %t %{-}%+Lw%<vbell offdefscrollback 5000Putty's default keyboard mode ESC [n~. Taken from the putty manual:In the default mode, labelled ESC [n~, the function keys generate sequences like ESC [11~, ESC [12~ and so on. This matches the general behaviour of Digital's terminals.Interestingly, what's actually sent by Putty (by following the first answer on https://superuser.com/questions/342848/cant-get-keyboard-to-work-correctly-in-putty), is ^[0D : left-arrow^[[D : Ctrl-{left-arrow}Since the they are different, I guess putty isn't the issue then?FWIW, I tried changing the Application Cursor key mode settings on Putty, but to no avail. I also tried using tmux, only to encounter the same issue.",
    "target": "terminal;gnu screen;putty"
  },
  {
    "id": "_cogsci.8857",
    "source": "Does your voice pitch affect your perceived authority? <eos> I heard a claim that people with lower voice pitch are perceived as more credible than people with higher pitch.Is there any research on this?",
    "target": "social psychology;perception;audition;trust"
  },
  {
    "id": "_unix.368067",
    "source": "splitting a single row command to two parts so it would be more structured aesthetically <eos> I have the following command which I run from a script. In the script file it is written in this somewhat long row:sudo zip -r /var/www/html/html-$(date +\\%F-\\%T-).zip /var/www/html -x /var/www/html/wp-content/cacheSo far so good, but I want to split this command into a few pieces horizontally, like:sudo zip -r /var/www/html/html-$(date +\\%F-\\%T-).zip /var/www/html || -x /var/www/html/wp-content/cacheWhere || should come non-executed characters that will use just for aeshtetic splitting of the command to two parts.Or maybe even vertically like:sudo zip -r /var/www/html/html-$(date +\\%F-\\%T-).zip /var/www/html -x /var/www/html/wp-content/cacheWhat will you say is the best way to achieve that?",
    "target": "shell"
  },
  {
    "id": "_unix.60872",
    "source": "HP Deskjet 3050A scanner not working in Debian <eos> I have an HP Deskjet All-in-one 3050A.In Debian Testing I installed it through CUPS and the printer works fine. However I can't say the same about the scanner. I've tried install it using HPLIP, but it's the same. SANE or Simple Scan detect the scanner but at the time of use it, both say that there was a problem with I/O.The weird part is that I've tried the scanner in two virtual machines (W7 and Linux Mint 14) hosted in the Debian Testing, and works fine in both VM's.",
    "target": "debian;scanner"
  },
  {
    "id": "_scicomp.11554",
    "source": "Why does my Finite Difference approximation not work? <eos> I am trying to find out the magnitude of the acceleration of my object based on non-uniformly sampled 3D position data. I'm using the standard approximation of the 2nd order derivative on a non-uniform grid (see e.g. here, page 121):$$ f'' \\approx 2 \\cdot\\frac{h^+ f_0 - (h^- + h^+) f_1 + h^- f_2}{h^+ h^- (h^+ + h^-)}$$where $h^-$ is the first sample interval, $h^+$ is the second sample interval, and $f_n$ are the sampled points.I'm trying to implement it in the following way:class ComputeAcceleration{    Vector3D prevPosition;    Vector3D prevPrevPosition;    float prevTimeStep;    float acceleration;    // This function gets called every time step with the time step    // since the last data input as argument.    void Update(const float timeStep)    {        float doubleTimeStep = prevTimeStep + timeStep;        Vector3D currentPosition = getCurrentPosition();        Vector3D accelerationVector = prevTimeStep * currentPosition -                                       doubleTimeStep * prevPosition +                                       timeStep * prevPrevPosition;              accelerationVector  *= 2 / (doubleTimeStep * prevTimeStep * timeStep);        acceleration = sqrt(accelerationVector.X * accelerationVector.X +                            accelerationVector.Y * accelerationVector.Y+                            accelerationVector.Z * accelerationVector.Z);        prevPrevPosition = prevPosition;        prevPosition = currentPosition;    }}I can't find the error in this, but when I plot this in real-time, I get a curve that doesn't resemble acceleration at all, but rather speed, in some jerky way. I plotted it against the speed (which I know to be correct), and it looks roughly like this:Am I doing something fundamentally wrong here?",
    "target": "finite difference;computational physics"
  },
  {
    "id": "_unix.375606",
    "source": "understand the order of operations for bash parameter expansion <eos> I read a similar example from bash programming book:$ cat indirection #!/usr/bin/env bashset -xnum=1eval ${!num#*:}$ When I execute the script with bash indirection test:echo blah, then how is the last line of the script processed? I guess first the indirection happens so that eval ${!num#*:} becomes eval ${1#*:}? Then substring removal takes place and eval ${1#*:} becomes eval echo blah? If yes, then why is eval needed, i.e ${!num#*:} instead of eval ${!num#*:} would provide the same results?",
    "target": "bash"
  },
  {
    "id": "_codereview.154188",
    "source": "ActiveRoomModel <eos> Could someone tell me how I can improve this please? It's similar to my other question just another version of it.using System;using System.Collections.Generic;using System.Globalization;using System.Linq;using System.Text;using System.Threading.Tasks;namespace Sahara.Base.Game.Rooms{    internal class ActiveRoomModel : IDisposable    {        private readonly bool _clubOnly;        private readonly int _doorX;        private readonly int _doorY;        private readonly double _doorZ;        private readonly int _doorDirection;        private string _modelHeightmap;        private int _modelSizeX;        private int _modelSizeY;        private short[,] _squareFloorHeight;        private byte[,] _squareSeatRotation;        private SquareState[,] _squareState;        private RoomModel _staticModel;        private readonly string _dependantHeightmap;        public ActiveRoomModel(RoomModel staticModel)        {            _staticModel = staticModel;            _doorX = staticModel.DoorX;            _doorY = staticModel.DoorY;            _doorZ = staticModel.DoorZ;            _doorDirection = staticModel.DoorDirection;            _modelHeightmap = staticModel.Heightmap;            _modelSizeX = staticModel.ModelSizeX;            _modelSizeY = staticModel.ModelSizeY;            _clubOnly = staticModel.ClubOnly;            _dependantHeightmap = string.Empty;            _squareState = new SquareState[_modelSizeX, _modelSizeY];            _squareFloorHeight = new short[_modelSizeX, _modelSizeY];            _squareSeatRotation = new byte[_modelSizeX, _modelSizeY];            for (var y = 0; y < _modelSizeY; y++)            {                for (var x = 0; x < _modelSizeX; x++)                {                    if (x > (staticModel.ModelSizeX - 1) || y > (staticModel.ModelSizeY - 1))                    {                        _squareState[x, y] = SquareState.Blocked;                    }                    else                    {                        _squareState[x, y] = staticModel.SquareState[x, y];                        _squareFloorHeight[x, y] = staticModel.SquareFloorHeight[x, y];                        _squareSeatRotation[x, y] = staticModel.SquareSeatRotation[x, y];                    }                }            }            var floorMap = new StringBuilder();            for (var y = 0; y < _modelSizeY; y++)            {                for (var x = 0; x < _modelSizeX; x++)                {                    if (x == _doorX && y == _doorY)                    {                        floorMap.Append(_doorZ > 9 ? ((char)(87 + _doorZ)).ToString() : _doorZ.ToString());                        continue;                    }                    if (_squareState[x, y] == SquareState.Blocked)                    {                        floorMap.Append('x');                        continue;                    }                    double height = _squareFloorHeight[x, y];                    floorMap.Append(height > 9 ? ((char)(87 + height)).ToString() : height.ToString());                }                floorMap.Append(Convert.ToChar(13));            }            _dependantHeightmap = floorMap.ToString();        }        public string DependantHeightmap => _dependantHeightmap;        public bool DoorCorrect => _doorX <= _squareFloorHeight.GetUpperBound(0) && _doorY <= _squareFloorHeight.GetUpperBound(1);        public void AppendXCordinate()        {            _modelSizeX++;            UpdateSquareArrays();        }        public void AppendYCordinate()        {            _modelSizeY++;            UpdateSquareArrays();        }        public void CreateMap(int x, int y)        {            _modelSizeX = x;            _modelSizeY = y;            UpdateSquareArrays();        }        private void UpdateSquareArrays()        {            var newSqState = new SquareState[_modelSizeX + 1, _modelSizeY + 1];            var newSqFloorHeight = new short[_modelSizeX + 1, _modelSizeY + 1];            var newSqSeatRot = new byte[_modelSizeX + 1, _modelSizeY + 1];            for (var y = 0; y < _modelSizeY; y++)            {                for (var x = 0; x < _modelSizeX; x++)                {                    if (x > (_staticModel.ModelSizeX - 1) || y > (_staticModel.ModelSizeY - 1))                    {                        newSqState[x, y] = SquareState.Blocked;                    }                    else                    {                        newSqState[x, y] = _squareState[x, y];                        newSqFloorHeight[x, y] = _squareFloorHeight[x, y];                        newSqSeatRot[x, y] = _squareSeatRotation[x, y];                    }                }            }            _squareState = newSqState;            _squareFloorHeight = newSqFloorHeight;            _squareSeatRotation = newSqSeatRot;        }        public void Dispose()        {            Array.Clear(_squareState, 0, _squareState.Length);            _squareState = null;            Array.Clear(_squareFloorHeight, 0, _squareFloorHeight.Length);            _squareFloorHeight = null;            Array.Clear(_squareSeatRotation, 0, _squareSeatRotation.Length);            _squareSeatRotation = null;            _staticModel = null;            _modelHeightmap = null;        }    }}RoomModel:using System;namespace Sahara.Base.Game.Rooms{    internal sealed class RoomModel    {        private readonly bool _clubOnly;        private readonly int _doorX;        private readonly int _doorY;        private readonly double _doorZ;        private readonly int _doorDirection;        private readonly string _modelHeightmap;        private readonly int _modelSizeX;        private readonly int _modelSizeY;        private readonly int _wallHeight;        private readonly short[,] _squareFloorHeight;        private readonly byte[,] _squareSeatRotation;        private readonly SquareState[,] _squareState;        private readonly string _modelFurniMap;        private readonly bool _publicPool;        private readonly byte[,] _roomModelEffects;        public RoomModel(bool clubOnly, int doorPositionX, int doorPositionY, int wallHeight, double doorPositionZ, int doorDirection, string modelHeightMap, string modelFurniMap, string poolMap)        {            _doorX = doorPositionX;            _doorY = doorPositionY;            _doorZ = doorPositionZ;            _doorDirection = doorDirection;            _wallHeight = wallHeight;            _modelHeightmap = modelHeightMap.ToLower();            _modelFurniMap = modelFurniMap;            if (poolMap != string.Empty)            {                _publicPool = true;                _roomModelEffects = new byte[_modelSizeX, _modelSizeY];            }            var temporaryHeightmap = _modelHeightmap.Split(Convert.ToChar(13));            _modelSizeX = temporaryHeightmap[0].Length;            _modelSizeY = temporaryHeightmap.Length;            _clubOnly = clubOnly;            _squareState = new SquareState[_modelSizeX, _modelSizeY];            _squareFloorHeight = new short[_modelSizeX, _modelSizeY];            _squareSeatRotation = new byte[_modelSizeX, _modelSizeY];            for (var y = _modelSizeY - 1; y >= 0; y--)            {                var line = temporaryHeightmap[y].Replace(Environment.NewLine, string.Empty);                var x = 0;                foreach (var modelSquare in line)                {                    if (modelSquare == 'x')                    {                        _squareState[x, y] = Rooms.SquareState.Blocked;                    }                    else                    {                        _squareState[x, y] = Rooms.SquareState.Open;                        _squareFloorHeight[x, y] = Sahara.GetServer().GetUtility().ParseModelSquare(modelSquare);                    }                    x++;                }            }        }        public int DoorX => _doorX;        public int DoorY => _doorY;        public double DoorZ => _doorZ;        public int DoorDirection => _doorDirection;        public string Heightmap => _modelHeightmap;        public int ModelSizeX => _modelSizeX;        public int ModelSizeY => _modelSizeY;        public bool ClubOnly => _clubOnly;        public SquareState[,] SquareState => _squareState;        public short[,] SquareFloorHeight => _squareFloorHeight;        public byte[,] SquareSeatRotation => _squareSeatRotation;        public bool PublicPool => _publicPool;    }}SquareState:using System;using System.Collections.Generic;using System.Linq;using System.Text;using System.Threading.Tasks;namespace Sahara.Base.Game.Rooms{    public enum SquareState    {        Open = 0,        Blocked = 1,        Seat = 2,        Pool = 3,        Vip = 4    }}",
    "target": "c#"
  },
  {
    "id": "_webapps.91052",
    "source": "Using Cognito Form Creator to create Order Forms with Multiple Available Options <eos> Using the Cognito Form creator there does not seem to be a very straightford way of creating an Order  form with multiple available items for possible selection; where each available items has different possible options such as sizes and colors. Here is an example of my order form that have created using JotForm: https://form.jotform.com/omillbro/CalAfrica_Online_OrderForm . I would like to create this same form using Cognito including the images. Does anyone know how to do it?",
    "target": "cognito forms"
  },
  {
    "id": "_unix.250100",
    "source": "logrotate fails to rotate logs: error setting owner <eos> Recently I've noticed that logrotate does not rotate my logs.user1@host:~$ /usr/sbin/logrotate /home/user1/logrotate.conf -v gives me an error:error: error setting owner of /home/logs/mylog.log.1 to uid 10111 and gid 10111: Operation not permittederror: error creating output file /var/lib/logrotate/status.tmp: Permission denied That gid confuses me, as user1 is only a member of a group with different gid:user1@host:~$ iduid=10111(user1) gid=1001(mygroup) groups=1001(mygroup) However, there's another group called user1, but, as I mentioned, actual user user1 is not its member:user1@host:~$ cat /etc/group | grep user1user1:x:10111It's something simple here, but I can't see it.UPDATE:here's what logrotate.conf looks like:/home/logs/*.log {    rotate 7    daily    copytruncate    compress    notifempty }logrotate 3.8.7UPDATE 2:user1@host:~$ ls -la /home/logs/-rw-r--r-- 1 user1 mygroup 1358383344 Dec 19 00:58 mylog.log",
    "target": "ubuntu;permissions;users;group;logrotate"
  },
  {
    "id": "_codereview.5725",
    "source": "Singleton wrapper <eos> Feel free to critique this database wrapper which is written as a code example for employers or clients.<?php     class Database {        static function getInstance()        {            if (self::$instance == NULL) {                self::$instance = new Database();            }            return self::$instance;        }        public function connect()        {            /*             if dbConnection already exists, do not             make another one.             */            if (is_resource($this->dbConnection))            {                return true;            }            $conn = $this->createDbConnection();            if (!$conn){                trigger_error(Error Connecting to Database, E_USER_NOTICE);            }            $this->dbConnection = $conn;            $result = mysql_select_db($this->database_name, $conn);            if (!$result){                trigger_error(Error Selecting Database, E_USER_NOTICE);            }        }//endfunction        public function closeConnection()        {            /*             mysql documentation says closing a connection             isn't nessesary since the connection is closed             at the end of the script.             */            mysql_close($this->dbConnection);        }        public function executeQuery($query)        {            $this->query_result = mysql_query($query);            if (!$this->query_result){                trigger_error(Error Executing Database Query, E_USER_NOTICE);            }        }        public function getRow(){            return mysql_fetch_array($this->query_result);        }        private function createDbConnection()        {            if ($_SERVER[SERVER_NAME] == website.com) {                $this->database_name = 'databasename';                return mysql_connect('localhost', 'username', 'password');                //$msdb = mysql_connect(localhost, root, );                //mysql_select_db(test, $msdb) or die(mysql_error());            }        }        private $dbConnection;        private $query_result;        private $database_name;        static private $instance = NULL;    }?>",
    "target": "php;singleton"
  },
  {
    "id": "_unix.192363",
    "source": "Understanding ext4/jbd2 transactions <eos> I'm trying to debug a bit of trouble I'm having with I/O latency on a system using ext4, but I'm a bit stumped in that I don't understand its journalling as well as I'd like to.What I'm wondering in particular is at what point disk blocks are actually written, both into the journal and for real. My assumption thus far is that, when some metadata operation like, say, a rename(), is done by a user process, the filesystem will ensure that the disk blocks that the operation needs to touch are in the buffer cache, carry out the necessary changes in memory on the cached pages, while creating a jbd2 transaction that records the changed pages, and then, at some later point, write those pages into the journal, and then, only when that is done and at some further arbitrarily later point, write them into the filesystem proper. Please do correct me if I'm wrong somewhere in here.Assuming I'm somewhat correct, I'm wondering what might trigger the write to the journal to be carried out. Is it when some more general FS/VM part of the kernel decides that it's time to flush the dirty pages? Is it when there is no more space in the journal to allocate for more transactions? What happens if the kernel needs to reclaim some of the dirty pages from the buffer cache? Would that trigger the journal-write and main-write in forced succession?Also, what is the standard terminology? When I see a transaction being referred to being committed, what does that mean, more precisely?",
    "target": "linux;ext4"
  },
  {
    "id": "_unix.134165",
    "source": "Hidden password is being displayed when invoking the su command? <eos> This is the first time it has happened to me where I am using the su command and it actually displays the password on the terminal and doesn't stay hidden. Here is my code snippet:sshpass -p password ssh -q username@74.11.11.11 su -lc 'mkdir temp/'Code explanation: I am accessing a remote server and trying be root on that server to create a folder. In doing so I have to use the su command and it prompts me for the password. When I enter the password, it gets displayed and doesn't stay hidden. ",
    "target": "bash"
  },
  {
    "id": "_unix.374605",
    "source": "Make rsync print unicode filenames correctly <eos> I'm using rsync on Mac, during file syncing, unicode filenames are not correctly displayed, e.gAny ideas?",
    "target": "rsync;macintosh"
  },
  {
    "id": "_webmaster.91735",
    "source": "Why has my Google Analytics Goal stopped tracking visits? <eos> I created a goal on Google Analytics which was working just fine all this time. It looked like this:My URLs are dynamic so I chose the Begins with. It was working fine until recently. I wanted to see full page URLs in my reports. So I created a filter to show the complete page URL following this link - https:// support.google.com/analytics/answer/1012243?hl=enSince then, the goal won't track any visits. In the Goal funnel page, should I use the complete page URL now like http:// sub.example.com/itineraryBooking instead of /itineraryBooking?EDITHere's how the new Goal details screen looks with the hostname included as part of the URL.EDIT after user nyuen's recommendation of using RegEx in Goal DetailsPlease find the screenshot below. I have used RegEx while creating these steps but 3 of the 5 page links will be dynamic in nature. 2 links will be an exact match.Actual URL -> http://pickyourtrail.com/itinerary/details/56e3f99b0956b30dd4eba428RegEx Step -> .*veho.pickyourtrail.com/itinerary/detailsActual URL -> http://veho.pickyourtrail.com/itineraryCost?itineraryId=56e3f99b0956b30dd4eba428RegEx Step -> .*veho.pickyourtrail.com/itineraryCostActual URL -> http://veho.pickyourtrail.com/itineraryBooking?itineraryId=56e3f99b0956b30dd4eba428RegEx Step -> .*veho.pickyourtrail.com/itineraryBookingGoal Step -> ",
    "target": "google analytics"
  },
  {
    "id": "_unix.303157",
    "source": "Is there something wrong with my script or is Bash much slower than Python? <eos> I was testing the speed of Bash and Python by running a loop 1 billion times.$ cat python.py#!/bin/python# python v3.5i=0;while i<=1000000000:    i=i+1;Bash code:$ cat bash2.sh#!/bin/bash# bash v4.3i=0while [[ $i -le 1000000000 ]]dolet i++doneUsing the time command I found out that the Python code takes just 48 seconds to finish while the Bash code took over 1 hour before I killed the script.Why is this so? I expected that Bash would be faster. Is there something wrong with my script or is Bash really much slower with this script?",
    "target": "bash;python3"
  },
  {
    "id": "_softwareengineering.310773",
    "source": "VMs are not created on the same physical server to balance load? <eos> When load reaches a certain level in IaaS environemnt, new VM instances are created to reduce load (scalability).My Questions that these VMs are not created on the same physical server, right?I mean one VM with like 10 users will give the same performance as 2 VMs on the same physical server with each VM has 5 users.If VMs are created on the same physical server, then how can this balance load?For background, I'm just new to cloud computing programming and I'm trying to understand some of the concepts involved. ",
    "target": "scalability;cloud computing;concepts;cloud;load balancing"
  },
  {
    "id": "_unix.317593",
    "source": "Trying to open grub configuration file during boot process <eos> I am trying to access GRUB configuration file at boot process (boot load). but unable to do it. I am able to go to grub terminal but when i give below command, it is throwing an error file not foundCommand: configfile (hd0,0)/boot/grub/grub.cfgIs there any any command to open grub configuration file during boot?",
    "target": "grub2"
  },
  {
    "id": "_opensource.886",
    "source": "Copyright and Contributing to an Open Source Project <eos> I'm a little confused by copyright notices on open source projects.Let's say that a particular project is covered by a very permissive license, such as MIT or BSD.  A copyright notice appears from the company that originated the source code.But let's say that the project leader leaves the company, but continues to contribute to the project.  Should s/he add a new copyright notice, to indicate that portions are copyright from the original company and portions from the author no longer employed by that company?It seems to me that anyone who touches a file essentially invalidates the copyright claims of anyone prior, because the file becomes a new creative expression based on those modifications.  How is the copyright supposed to be managed in a legally (and morally) robust manner as more and more people contribute?",
    "target": "licensing;contributor;copyright;collaboration"
  },
  {
    "id": "_unix.256306",
    "source": "The equivalent of a live-CD for a smartphone <eos> Is there any way of running an OS in a smartphone without installing it on the device? That would be the equivalent of a live-CD for a PC. I intend to test several BSD distributions on a phone, that could be an Android or Windows.",
    "target": "livecd"
  },
  {
    "id": "_unix.241753",
    "source": "Remove headers and contents from a flat file if they are below a specific line count <eos> I've a flat file containing about 10 million lines:    query    ID1    content1    content2    query    ID2    content3    content4    ...    content21    query    ID3    content22    content23    ...    content81Any block in the file less than 10 lines should be removed. For example, the first block contains 4 lines (query to content2) and it should be removed. This step need to be done before splitting the blocks into individual files. Any suggestion?",
    "target": "sed;awk"
  },
  {
    "id": "_webapps.13325",
    "source": "Can one use any search engine in order to find a set of keywords on a site (not page)? <eos> The problem I'm trying to solve is that I'd like to buy a set of products online (FYI: Topeak F25, F66, F55, iPhone DryBag, and ProPack Small).For convenience, and to save on shipping costs, I'd like to buy all products from one retailer.I can find each and every aforementioned product at different retailers in the EU, but not all of them at a single one.",
    "target": "search engine;shopping"
  },
  {
    "id": "_codereview.114050",
    "source": "You are Promoted, You are Promoted, We All are Promoted! <eos> My latest refactoring for Rubberduck is called Introduce Field - it promotes a local variable to a private field.The three overridden Refactor() methods are the members of IRefactoring, and are used to start the refactoring sequence.  The other methods are the worker methods.Overall, I am pretty happy with it, but there are a few things that bother me.  The first of these is that Refactor(Declaration) has a strict requirement for the declaration type, but accepts any declaration, regardless of the type.  Is there a way to enforce this other than throwing?  Should I even be throwing here?  Should I just return instead?RemoveVariable() and RemoveExtraComma() both seem somewhat clunky.  Is there a cleaner way to do this?public class IntroduceField : IRefactoring{    private readonly IList<Declaration> _declarations;    private readonly IActiveCodePaneEditor _editor;    private Declaration _targetDeclaration;    private readonly IMessageBox _messageBox;    public IntroduceField(RubberduckParserState parseResult, IActiveCodePaneEditor editor, IMessageBox messageBox)    {        _declarations = parseResult.AllDeclarations.ToList();        _editor = editor;        _messageBox = messageBox;    }    public void Refactor()    {        if (_targetDeclaration == null)        {            _messageBox.Show(RubberduckUI.PromoteVariable_InvalidSelection);            return;        }        RemoveVariable();        AddField();    }    public void Refactor(QualifiedSelection selection)    {        _targetDeclaration = FindSelection(selection);        Refactor();    }    public void Refactor(Declaration target)    {        if (target.DeclarationType != DeclarationType.Variable)        {            throw new ArgumentException(Invalid declaration type);        }        _targetDeclaration = target;        Refactor();    }    private void AddField()    {        var module = _targetDeclaration.QualifiedName.QualifiedModuleName.Component.CodeModule;        module.InsertLines(module.CountOfDeclarationLines + 1, GetFieldDefinition());    }    private void RemoveVariable()    {        Selection selection;        var declarationText = _targetDeclaration.Context.GetText();        var multipleDeclarations = HasMultipleDeclarationsInStatement(_targetDeclaration);        var variableStmtContext = GetVariableStmtContext(_targetDeclaration);        if (!multipleDeclarations)        {            declarationText = variableStmtContext.GetText();            selection = GetVariableStmtContextSelection(_targetDeclaration);        }        else        {            selection = new Selection(_targetDeclaration.Context.Start.Line, _targetDeclaration.Context.Start.Column,                _targetDeclaration.Context.Stop.Line, _targetDeclaration.Context.Stop.Column);        }        var oldLines = _editor.GetLines(selection);        var newLines = oldLines.Replace( _ + Environment.NewLine, string.Empty)            .Remove(selection.StartColumn, declarationText.Length);        if (multipleDeclarations)        {            selection = GetVariableStmtContextSelection(_targetDeclaration);            newLines = RemoveExtraComma(_editor.GetLines(selection).Replace(oldLines, newLines));        }        _editor.DeleteLines(selection);        _editor.InsertLines(selection.StartLine, newLines);    }    private Selection GetVariableStmtContextSelection(Declaration target)    {        var statement = GetVariableStmtContext(target);        return new Selection(statement.Start.Line, statement.Start.Column,                statement.Stop.Line, statement.Stop.Column);    }    private VBAParser.VariableStmtContext GetVariableStmtContext(Declaration target)    {        var statement = target.Context.Parent.Parent as VBAParser.VariableStmtContext;        if (statement == null)        {            throw new MissingMemberException(Statement not found);        }        return statement;    }    private string RemoveExtraComma(string str)    {        if (str.Count(c => c == ',') == 1)        {            return str.Remove(str.IndexOf(','), 1);        }        var significantCharacterAfterComma = false;        for (var index = 0; index < str.Length; index++)        {            if (!char.IsWhiteSpace(str[index]) && str[index] != '_' && str[index] != ',')            {                significantCharacterAfterComma = true;            }            if (str[index] == ',')            {                significantCharacterAfterComma = false;            }            if (!significantCharacterAfterComma && str[index] == ',')            {                return str.Remove(index, 1);            }        }        return str;    }    private bool HasMultipleDeclarationsInStatement(Declaration target)    {        var statement = target.Context.Parent as VBAParser.VariableListStmtContext;        if (statement == null) { return false; }        return statement.children.Count(i => i is VBAParser.VariableSubStmtContext) > 1;    }    private string GetFieldDefinition()    {        if (_targetDeclaration == null) { return null; }        return Private  + _targetDeclaration.IdentifierName +  As  + _targetDeclaration.AsTypeName;    }    private Declaration FindSelection(QualifiedSelection selection)    {        var target = _declarations            .Where(item => !item.IsBuiltIn)            .FirstOrDefault(item => item.IsSelected(selection) && item.DeclarationType == DeclarationType.Variable                                 || item.References.Any(r => r.IsSelected(selection) &&                                    r.Declaration.DeclarationType == DeclarationType.Variable));        if (target != null) { return target; }        var targets = _declarations            .Where(item => !item.IsBuiltIn                           && item.ComponentName == selection.QualifiedName.ComponentName                           && item.DeclarationType == DeclarationType.Variable);        foreach (var declaration in targets)        {            var declarationSelection = new Selection(declaration.Context.Start.Line,                                                declaration.Context.Start.Column,                                                declaration.Context.Stop.Line,                                                declaration.Context.Stop.Column + declaration.Context.Stop.Text.Length);            if (declarationSelection.Contains(selection.Selection) ||                !HasMultipleDeclarationsInStatement(declaration) && GetVariableStmtContextSelection(declaration).Contains(selection.Selection))            {                return declaration;            }            var reference =                declaration.References.FirstOrDefault(r => r.Selection.Contains(selection.Selection));            if (reference != null)            {                return reference.Declaration;            }        }        return null;    }}",
    "target": "c#;meta programming;rubberduck"
  },
  {
    "id": "_softwareengineering.309720",
    "source": "Repositories, Gateways, Models and Architecture Questions <eos> I am working with a Laravel project and I am looking for a way to solve the issue of bloated models and cross referencing between them.I had started extracting higher level methods to a repository but this doesn't solve the issue of one method needing to know about another method.For example a task lookup method needs to lookup a slug in another table first. I don't believe I should be placing this code into either model or repository but i'd like a single method to achieve this lookup./Models/Slug/Models/Task/Repositories/SlugRepository/Repositories/TaskRepositoryI have now started experimenting with adding a gateway/service layer with a higher level methods which can access both of the underlying repositories to complete the task.The task service would depend on the two repositories above./Service/TaskfindBySlug()I think this will work but I am not sure if I should now let the controllers still access the repository directly or force everything through the service/gateway layer.Or perhaps do away with the repositories entirely and let the services access the models directly, (Laravel abstracts db access anyway).And on top of it all I want to keep this as simple as possible!Can anyone confirm this method as a good choice or not or perhaps suggest an alternative?",
    "target": "design patterns;architecture;repository;services;laravel"
  },
  {
    "id": "_cs.72655",
    "source": "Help with this FSA please :( <eos> I have to convert this fsa to regular expression but these are too different than i learned... Can you guys help with converting these? Plz! ",
    "target": "finite automata;regular expressions"
  },
  {
    "id": "_cstheory.5803",
    "source": "Looking for papers and articles on higher-order sequent systems <eos> I am looking for work on systems that are similar to K. Dosen's higher-order sequents (Sequent Systems for Modal Logic, JSL 50).  The only work that I am aware of is recent work by Iemhoff and Metcalfe (Proof theory for admissible rules, Annals of Pure and Applied Logic 159 (1-2), 2009).Are there other papers on such systems?",
    "target": "reference request;lo.logic;proof theory"
  },
  {
    "id": "_codereview.25994",
    "source": "Is there a method to add multiple properties to HtmlTextWriterStyle? <eos> I am creating new elements for a webpage at run-time and I have code like this:      var dynDiv = new System.Web.UI.HtmlControls.HtmlGenericControl(Div) {ID = dynDiv};      dynDiv.Style.Add(HtmlTextWriterStyle.BackgroundColor, Red);      dynDiv.Style.Add(HtmlTextWriterStyle.Position, absolute; left: 500px; top: 500px);      dynDiv.Style.Add(HtmlTextWriterStyle.Height, 30px);      dynDiv.Style.Add(HtmlTextWriterStyle.Width, 300px);      dynDiv.InnerHtml = New Object;      PlaceHolder1.Controls.Add(dynDiv);Is there a shorthand method to adding these value? I.e. something like:dynDiv.Style.Add(HtmlTextWriterStyle {BackgroundColor = Red, Position = absolute; left: 500px; top: 500px, Height = 30px, Width=300px});Or any other easier way that anyone can suggest?",
    "target": "c#;html;asp.net"
  },
  {
    "id": "_softwareengineering.37673",
    "source": "Are your projects completed on time or past the deadline? <eos> Are your projects completed on time? If not, what problems cause you to miss deadlines? How can they be overcome? Do your clients understand them?",
    "target": "productivity;project management;time management"
  },
  {
    "id": "_unix.317190",
    "source": "lxc unable to apply profile to container <eos> I'm using LXC on Ubuntu Ubuntu 14.04.4 LTS, and I'm performing the following operations as unprivileged user. $lxc config profile create privileged$lxc config profile set privileged security.privileged trueI'm attempting to apply this profile to my container   $ lxc profile apply my-lxc-ct privileged    error: not foundAny idea on why I'm unable to apply this profile? ",
    "target": "lxc"
  },
  {
    "id": "_cs.75558",
    "source": "circuit for finding the index of first zero entry in a binary string <eos> finding the index of first zero entry in a binary string:Input: binary string ($0$'s and $1$'s)Output: index of first zero entryCan you give a circuit for finding the index of first zero entry in a binary string with minimum depth and polynomial many processors? 1) Is this problem in $AC_0$?2) Is this problem in $NC_1$?Can point me at references?  ",
    "target": "circuits;digital circuits;sequential circuit"
  },
  {
    "id": "_codereview.42893",
    "source": "Async Queue Processing <eos> I have a Queue that needs to try to process when anything updates in it (add, remove or update).However, I don't want any of the callers to wait while the processing is happening (either for the processing to happen or while the processing is happening).This is what I came up with:private static readonly SemaphoreSlim asyncLock = new SemaphoreSlim(1);private async void ProcessQueue(){    // Lock this up so that one thread at a time can get through here.      // Others will do an async await until it is their turn.    await asyncLock.WaitAsync();    try    {        // Offload this to a background thread (so that the UI is not affected)        var queueProcessingTask = Task.Run( () =>        {            var processingStuck = false;            while (myQueue.Count >= 1 && !processingStuck)            {                // Get the next item                var queueItem = myQueue.Peek();                // Try to process this one. (ie DoStuff)                processingStuck = ProcessQueueItem(queueItem);                // If we processed successfully, then we can dequeue the item                if (!processingStuck)                    myQueue.Dequeue();            }                        });        Task.WaitAll(queueProcessingTask);    }    finally    {        asyncLock.Release();    }    }Is my Thread and async handling going to ensure that only 1 queueItem at a time can ever be in the works?And will this avoid using resources from the UI thread?",
    "target": "c#;task parallel library;async await"
  },
  {
    "id": "_cs.55760",
    "source": "Can we always reduce the weights of a weighted graph to rationals and preserve equality relationships? <eos> Let $G = (Q, \\Delta, W)$ be a finite weighted graph with $\\Delta: Q \\times Q$ and $W: Q \\times Q \\to \\mathbb{R}^{+}$. Is it the case that there always exist a function $W': Q \\times Q \\to \\mathbb{Q}^{+}$ such that $\\forall S, S' \\subseteq Q, \\forall s, s' \\in S$:$$\\sum_{s'' \\in S'}{W(s, s'')} = \\sum_{s'' \\in S'}{W(s', s'')} \\Leftrightarrow \\sum_{s'' \\in S'}{W'(s, s'')} = \\sum_{s'' \\in S'}{W'(s', s'')}$$?I believe, at least for the finite case, this should be possible and I'm trying to prove this constructively by finding $W'$.So let $\\epsilon \\in \\mathbb{Q}^{+}$ be a rational such that $\\forall s_0,s_1,s_2,s_3 \\in Q, \\epsilon < |W(s_0, s_1) - W(s_2, s_3)|$ whenever that difference isn't $0$.Obviously if we just round every non-rational weight in a grid with spacing $\\epsilon$ we will not preserve equalities and I believe it'll be quite difficult to restore the exact relations.So my idea is to round one weight at a time, and then fix the equalities that get broken by modifying only non-rational weights and repeating the process until there are only rational weights.So start by taking two subsets $S, S' \\subseteq Q$ and take $s \\in S$ and $s'' \\in S'$ such that $W(s, s'') \\notin \\mathbb{Q}$.Now we can round this number to the nearest rational of the form $k\\cdot \\epsilon$.Let $e = W(s, s'') - W'(s, s'')$ is the error we introduced.Now if there was an $s' \\in S$ and an $s'''$ such that $W(s', s''') = W(s, s'')$ then we modify that weight in the same manner, and thus the iff condition still holds for $s$ and $s'$.Otherwise for $s' \\in S$ we must have that some (more than one) weight $W(s', s''') \\notin \\mathbb{Q}$ and we can subtract $e$ from it and preserve the condition for $s$ and $s'$ with respect to $S$ and $S'$.However we have now changed some other weight, and thus while we may have preserved the equality between $S$ and $S'$, we may have broken it for other subsets. So we have to consider every subset that is either a subset or superset of $S$ and $S'$, verify if we have broken that iff condition, and if so we must find an other weight and change it, and repeat the process until it we find an equilibrium. But does this actually happen?My question is:Does there exist such $W'$ or am I trying to build a non-existent function?If $W'$ exists, is the above approach feasible in some way, or should I completely change strategy in order to find $W'$? Do you know any particular trick that can help in devising $W'$?",
    "target": "graph theory;simulation;weighted graphs"
  },
  {
    "id": "_softwareengineering.209550",
    "source": "What does it mean for the JSON interchange format to have a license? <eos> A recent flurry of comments on a JSHint issue alerted me to the fact that the JSON data-interchange format has a license.The content of this license can be debated elsewhere.What I'm unclear on is what it means for JSON (or any other data-interchance format) to have a license.If an a library simply consumes and parses JSON, does it have to include this license? I understand that using a library that contains this license would require a user to include it. I'm talking about writing a library from scratch.What if I have to use JSON because a third party service only communicates via JSON. If I'm serializing and deserializing data according to the RFC, do I still need to refer to the license?",
    "target": "licensing;legal;json"
  },
  {
    "id": "_softwareengineering.238253",
    "source": "Mimicking a bluetooth disconnection <eos> I've written a program to control a bluetooth device. I'm trying to test cases when the bluetooth disconnects, i.e. if its out of range.Physically taking the device out of range is one possibility, but its quite cumbersome and I have to go outside my office to achieve this.What can I do to trigger a disconnection? Is there, for example, an interferer I can setup, say with an Android phone, that would make the connection drop? Or limit the Bluetooth transmit power? Any other possibilities?",
    "target": "testing"
  },
  {
    "id": "_softwareengineering.206963",
    "source": "Which child process will inherit threads of parent process? <eos> What happens when one process has child threads and a child process, will child process inherit all child threads of parent process?Assume OS is Linux. Let it be Java Threading model.",
    "target": "multithreading;operating systems"
  },
  {
    "id": "_unix.233446",
    "source": "Put command result in variable within makefile target <eos> I am trying to install something in tomcat webapp. This is beginning of my install target:tomcat=`locate --regex ^(/var/lib/tomcat[0-9]{1,2}/webapps/[^/]+/)AppName\\.html$ -l 1 | tr -d \\n`echo Tomcat: $tomcat# If the string is empty (no path matched) or the path does not exists (that should never really happen)# terminateif [ -z $tomcat ] || [ ! -f $tomcat ]; then   echo Application not found on filesystem.  exit 404fiHowever this is the output:tomcat=`locate --regex ^(/var/lib/tomcat[0-9]{1,2}/webapps/[^/]+/)AppName\\.html -l 1 | tr -d \\n`/bin/sh: 1: Syntax error: Unterminated quoted stringmakefile:77: recipe for target 'install' failedmake: *** [install] Error 2Everyone else claims that you can use ` (backtick) to assign command stdout output into variable. I even used tr -d \\n to delete all newline characters, may they appear. And the code works flawlessly in shell:XXXXX@debianvirtualbox:~$ tomcat=`locate --regex ^(/var/lib/tomcat[0-9]{1,2}/webapps/[^/]+/)AppName\\.html$ -l 1 | tr -d \\n`XXXXX@debianvirtualbox:~$ echo $tomcat/var/lib/tomcat8/webapps/websight/AppName.htmlWhat else is there to fix?",
    "target": "bash;make"
  },
  {
    "id": "_datascience.2269",
    "source": "Any Online R console? <eos> I am looking for an online console for the language R. Like I write the code and the server should execute and provide me with the output.Similar to the website Datacamp.",
    "target": "r;statistics"
  },
  {
    "id": "_unix.225450",
    "source": "nfc-list not showing device <eos> I have plugged in my Nexus 4 via USB and I'm running nfc-list on Kali Linux 2.0.But when running the command I only receive 'no device found'. Is the Nexus 4 not compatible with nfc-list??",
    "target": "kali linux"
  },
  {
    "id": "_webapps.104362",
    "source": "I accidentally removed my ufw allow rules (ssh and ftp rules) and then logged out of my server, am now locked out <eos> My environment: aws ec2 (VMware Workstation 11) for use as development sandbox environment. it's not crucial, i just have some work i don't want to re do for a client. Is there anyway to change those rules from the outside?",
    "target": "amazon web services;amazon ec2"
  },
  {
    "id": "_webmaster.93069",
    "source": "Any idea what nt referrer means? <eos> I'm getting a lot of referrer headers that are just nt. There's no other information (it's just that string, not a URL). Has anyone come across this referrer string before? Does it correspond to a known user agent or spider?",
    "target": "referrer"
  },
  {
    "id": "_webapps.30446",
    "source": "Getting insights data from LinkedIn and Twitter <eos> Is there any way to get insights data from Twitter and LinkedIn company/brand pages as Facebook provides?Data like:negative feedback;comment/wall posts;likes, shares, follows, re-tweets etcAnd insights like:Monthly active users;Page views;User demographics etc",
    "target": "linkedin;data;twitter api"
  },
  {
    "id": "_softwareengineering.342572",
    "source": "Why doesn't greedy approach work for following problem but the solution provided in the editorial does? <eos> Problem Statement:Alexa has two stacks of nonnegative integers, stack A = [a0,a1, . . . ,an_1] and stackB = [b0, b1, . . . ,bm_1] where index 0 denotes the top of the stack. Alexa challenges Nick to play thefollowing game:In each move, Nick can remove one integer from the top of either stack A or stack B. Nick keeps a running sum of the integers he removes from the two stacks. Nick is disqualified from the game if, at any point, his running sum becomes greater than some integer given at the beginning of the game.Nick's fine/score is the total number of integers he has removed from the two stacks.Given A, B, and m for g games, find the maximum possible score Nick can achieve (i.e., the maximumnumber of integers he can remove without being disqualified)Link to the problem:  https://www.hackerrank.com/contests/university-codesprint-2/challenges/game-of-two-stacksMy solution(greedy approach):Pick(pop) the smallest element between the one present on top of the stack A and the other present on top of the stack B. Increment sum by the value of popped element and total(number of ints) by 1.Repeat 1 until either sum becomes greater than asked or one of the two stacks get empty.If one of the two stacks get empty then pop ints from the other stack until the current sum exceeds the asked limit.Editorial solution:This problem can be solved in linear time. We'll begin by taking as many integers as possible from stack A without exceeding the sum. Once we've done this we'll start taking integers from B, but whenever the sum becomes larger than the limit, we'll put integers back into stack A. Make sure to update the answer (the number of integers) as the traversal through stack B takes place. Break the loop when you have put back all integers that was taken from A and it's not possible to take any more integers from B.Please explain where am I getting wrong and what is the intuition behind the editorial solution?",
    "target": "algorithms;data structures;stack"
  },
  {
    "id": "_unix.76292",
    "source": "Can iptables be used to convert a single-homed host into a NAT server? <eos> Given: I have a machine (HostA) with only one NIC which has Internet connectivity. I have another machine (HostB) with one NIC on the same switch. HostB is not configured for Internet access yet. HostA has its default gateway and DNS servers appropriately configured. IPv4 is being used. OSes on the hosts are Ubuntu 13 and Fedora17.What I want: Now, I would like HostB to have Internet connectivity, too. Is this possible using 'some' combination of iptables, virtual tun/tap devices, or a VPN setup between HostA and HostB, etc? What I already know and can do: Currently, I can use an ssh-based SOCKS proxy on HostB (ssh -D 9050 UserA@HostA) and route traffic of select 'socksifiable' applications on HostB via this proxy to HostA and beyond. However, sadly, not all applications are socksifiable. Now, I know very well that if HostA had 2 NICs, I could have used some iptables rules to convert HostA into a gateway that would then route traffic between its NIC-1 and NIC-2 (where NIC-1 would be connected to HostB and NIC-2 to Internet). But installing another NIC in HostA is not feasible for me.PS: I had posted this earlier on superuser.com but got no useful information.edit 1:network informationHost A::> ip addr[...]2: p4p1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP qlen 1000link/ether d4:be:d9:d5:46:05 brd ff:ff:ff:ff:ff:ffinet 192.168.22.9/24 brd 192.168.22.255 scope global p4p1 :> ip routedefault via 192.168.22.254 dev p4p1 proto static192.168.22.0/24 dev p4p1 proto kernel scope link src 192.168.22.9Host B::> ip addr[...]2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP qlen 1000link/ether 30:f9:ed:d9:2e:20 brd ff:ff:ff:ff:ff:ffinet 192.168.22.234/24 brd 192.168.22.255 scope global eth0 :> ip route169.254.0.0/16 dev eth0 scope link metric 1000192.168.22.0/24 dev eth0 proto kernel scope link src 192.168.22.234 metric 1",
    "target": "linux;networking;iptables;nat"
  },
  {
    "id": "_unix.250585",
    "source": "using printf function for repeated patterns <eos> I have codes which append the patterns into text file w.r.t. the user's input as follows;echo -n WHICH STATIONS?read stationawk -v input=$station ' BEGIN {        n = split(tolower(input), user)              pattern=  force %-4s npos 0. .0001\\n           }    {print}    /<< write after this line >>/ {        for (i=1; i<=n; i++)             printf pattern, user[i]        exit    }' ./data > data_2let assume user's input abcd ab12 then commands append below lines;force abcd npos 0. .0001force ab12 npos 0. .0001I need to add epos and upos strings for each input for separate lines as follows (for same inputs as above example);force abcd npos 0. .0001force abcd epos 0. .0001force abcd upos 0. .0001force ab12 npos 0. .0001force ab12 epos 0. .0001force ab12 upos 0. .0001How can I modify the pattern option to append these lines into the data file?",
    "target": "awk;printf"
  },
  {
    "id": "_codereview.159700",
    "source": "Decorator Pattern in PHP Simple implementation <eos> I am learning decorator design pattern in PHP. Please see what i am doing is correct or wrong, would appreciate your review, feedback, comments, suggestions.<?php/** * NotifierService interface is used as abstraction for Notification Mechanism * * It can be later implemented as EmailNotifierService, PushNotifierService, or * any other Notification SErvice */interface NotifierService {    public function Notify();}/** *  EmailNotifierService - is Email Decorator *  here the EmailSending is Implemented, and it can be used wherever it is *  required, Different Unique services that doesn not have common behaviours *   are utilised using decorator patterns */class EmailNotifierService implements NotifierService {    public function __construct(){        $this->to = 'Praveen@gmail.com' ;//$toarr;        $this->from  = 'Napoleon@gmail.com' ;//$from;        $this->msg   = 'This is a test message';//$msg    }    /**     * [sendMail Actual Implementation of Sending Email is put here]     * Kept simple for demo purposes     */    private function sendMail(){        echo Sending Email To .PHP_EOL;        print_r($this->to);        echo From:  .PHP_EOL;        print_r($this->from);        echo Msg:  .PHP_EOL;        print_r($this->msg);    }    /**     * [Notify - Implementation of the interface method - Notify]     */    public function Notify(){        echo Notify function called .PHP_EOL;        $this->SendMail();    }}class User implements NotifierService{    var $users = [];    var $notifierservice;    //Passing NotifierService Object, So that we can utilise its service    public function __construct(NotifierService $notifierservice){        echo New User constructed;        $this->notifierservice = $notifierservice;    }    /**     * [adduser This function creates a new user, like new user signup,     * Whenever a new user signup, a Email is sent to the Website Admin]     * @param  [Username] $u Username     */    public function adduser($u){        $this->users[]=$u;        $this->Notify();// Calls the Notification    }    public function Notify(){        $this->notifierservice->Notify();    }}// New User is created, EmailNotificationService is wrapped in it// So that whenever a new user is created, Admin gets an Email$u1 = new User(new EmailNotifierService());$u1->adduser('Ramkumar');",
    "target": "php;design patterns"
  },
  {
    "id": "_codereview.122185",
    "source": "Uploading .dll files to a local computer <eos> I have created a simple application that has grown a little bit. Though most likely it won't grow anymore, I have looked back and I realized that it has become a little monster in terms of how many almost identical properties and methods I have created. Please let me know how this could be made more manageable etc.Purpose of the application**Upload dll files to a remote computer. There are three types of files - workflow plugin, archive plugin, processing plugin. After some time, I have extended the app so that for each file type it can also have a config xml file.StructureUser controlsTo keep things simpler and more reusable, I have created a user control for uploader section, as this will repeat three times.It has:Two path boxes (for paths of .dll and XML files) - these are smaller usercontrols with browse/open selected file/display previous files' functionalitiesTwo upload buttons - one for .dll and one for XMLTwo sets of two labels - to display modified date of local and server file for .dll and XML files - labels can change colorsOne 'open folder' button - to open a server folder where a .dll file isA fold/unfold button so that it could be collapsedA checkbox for autouploadAs a result, this user control has got 17 dependency properties and 4 events:Four dependency properties for paths (current path and list of previous paths for two types of files)Four dependency properties for labelsFour dependency properties for label brushesA couple of miscellaneous DPs for 'auto-uplad' checkbox, visibility, groupbox header etcFour routed events - for all buttons clicksFull XAML on dotnetfiddle, click on the View tabMainWindow.xamlNow, in my MainWindow.xaml file, apart from crap like status bar and menu bar, I need to define three UploaderControls. And this is where it starts being pretty monstrous (especially if I were to have e.g. 10 types of files to upload)For each of the controls I need a separate set of properties to be bound.Four properties for paths, connected with application settingsFour properties for XML file labels and brushes Four properties for .dll file labels and brushes Apart from that there's a bunch of miscellaneous props for visbility, auto-uplad and event handlers. I am not really concerned about those.     <controls:UploaderControl ControlHeader=Workflow plugin                              ContentVisibility={Binding ElementName=ThisUc, Path=WorkflowUploaderVisibility}                              HideButtonClick=OnHideButtonClick                                       CurrentProvidedPath={Binding ElementName=ThisUc, Path=CurrentWorkflowPluginPath, UpdateSourceTrigger=PropertyChanged, Mode=TwoWay}                                       PreviousPathsCollection={Binding ElementName=ThisUc, Path=PreviousWorkflowPluginPathsCollection}                                       CurrentProvidedConfigPath={Binding ElementName=ThisUc, Path=CurrentWorkflowPluginConfigPath, UpdateSourceTrigger=PropertyChanged, Mode=TwoWay}                                       PreviousConfigPathsCollection={Binding ElementName=ThisUc, Path=PreviousWorkflowPluginConfigPathsCollection}                                       DockPanel.Dock=Top                                       OpenServerFolder=UploaderControl_OnOpenServerFolder                                       AutoUploadAfterBuild={Binding ElementName=ThisUc,Path=WorkflowAutoUpload,Mode=TwoWay}                                       LocalLastModified={Binding ElementName=ThisUc, Path=LocalWorkflowPluginLastModified}                                       LocalLastModifiedBrush={Binding ElementName=ThisUc, Path=LocalWorkflowPluginLastModifiedBrush}                                       ServerLastModified={Binding ElementName=ThisUc, Path=ServerWorkflowPluginLastModified}                                       ServerLastModifiedBrush={Binding ElementName=ThisUc, Path=ServerWorkflowPluginLastModifiedBrush}                                 LocalConfigLastModified={Binding ElementName=ThisUc, Path=LocalWorkflowPluginConfigLastModified}                                       LocalConfigLastModifiedBrush={Binding ElementName=ThisUc, Path=LocalWorkflowConfigLastModifiedBrush}                                       ServerConfigLastModified={Binding ElementName=ThisUc, Path=ServerWorkflowPluginConfigLastModified}                                       ServerConfigLastModifiedBrush={Binding ElementName=ThisUc, Path=ServerWorkflowConfigLastModifiedBrush}                                       UploadPluginClick=UploadButton_Click                              UploadConfigClick=UploaderControl_OnUploadConfigClick                                       UploaderName={Binding Source={x:Static tmsObjectsNames:TmsServiceNames.Workflow}} />    <controls:UploaderControl ControlHeader=Archiver plugin                              ContentVisibility={Binding ElementName=ThisUc, Path=ArchiverUploaderVisibility}                              HideButtonClick=OnHideButtonClick                              CurrentProvidedConfigPath={Binding ElementName=ThisUc, Path=CurrentArchiverPluginConfigPath, UpdateSourceTrigger=PropertyChanged, Mode=TwoWay}                                       PreviousConfigPathsCollection={Binding ElementName=ThisUc, Path=PreviousArchiverPluginConfigPathsCollection}                                       AutoUploadAfterBuild={Binding ElementName=ThisUc,Path=ArchiverAutoUpload, Mode=TwoWay}                                       CurrentProvidedPath={Binding ElementName=ThisUc, Path=CurrentArchiverPluginPath, UpdateSourceTrigger=PropertyChanged, Mode=TwoWay}                                       OpenServerFolder=UploaderControl_OnOpenServerFolder                                       DockPanel.Dock=Top                                       PreviousPathsCollection={Binding ElementName=ThisUc, Path=PreviousArchiverPluginPathsCollection}                                       LocalLastModified={Binding ElementName=ThisUc, Path=LocalArchiverPluginLastModified}                                       LocalLastModifiedBrush={Binding ElementName=ThisUc, Path=LocalArchiverPluginLastModifiedBrush}                                       ServerLastModified={Binding ElementName=ThisUc, Path=ServerArchiverPluginLastModified}                                       ServerLastModifiedBrush={Binding ElementName=ThisUc, Path=ServerArchiverPluginLastModifiedBrush}                                       LocalConfigLastModified={Binding ElementName=ThisUc, Path=LocalArchiverPluginConfigLastModified}                                       LocalConfigLastModifiedBrush={Binding ElementName=ThisUc, Path=LocalArchiverConfigLastModifiedBrush}                                       ServerConfigLastModified={Binding ElementName=ThisUc, Path=ServerArchiverPluginConfigLastModified}                                       ServerConfigLastModifiedBrush={Binding ElementName=ThisUc, Path=ServerArchiverConfigLastModifiedBrush}                                        UploadPluginClick=UploadButton_Click                                        UploadConfigClick=UploaderControl_OnUploadConfigClick                                       UploaderName={Binding Source={x:Static tmsObjectsNames:TmsServiceNames.Archiver}} />C#For all the dependency properties above I have separate properties that are almost identical, except they are for different uploader type (workflow, archive, processing). Do I really need it like that? I suppose not, but I don't know how to handle this better.Sample properties    #region Wokrlfow plugin ConfigPathBox //this one will be 'repeated' six times - 3x for different file types and 2x for dll and xmlprivate string _currentWorkflowPluginConfigPath = Settings.Default.CurrentWorkflowPluginConfigPath;public string CurrentWorkflowPluginConfigPath{    get    {        return _currentWorkflowPluginConfigPath;    }    set    {        _currentWorkflowPluginConfigPath = value;        Settings.Default.CurrentWorkflowPluginConfigPath = value;        RaisePropertyChanged(nameof(CurrentWorkflowPluginConfigPath));        InitializeWorkflowPluginUploader();    }}private bool _prevWorkflowConfigPathsEventSubscribed;private ObservableCollection<string> _previousWorkflowPluginConfigPathsCollection = Settings.Default.PreviousWorkflowPluginConfigPathsCollection ?? new ObservableCollection<string>();public ObservableCollection<string> PreviousWorkflowPluginConfigPathsCollection{    get    {        if (!_prevWorkflowConfigPathsEventSubscribed)        {            _previousWorkflowPluginConfigPathsCollection.CollectionChanged += _previousWorkflowConfigPathsList_CollectionChanged;            _prevWorkflowConfigPathsEventSubscribed = true;        }        return _previousWorkflowPluginConfigPathsCollection;    }    set { }}void _previousWorkflowConfigPathsList_CollectionChanged(object sender, NotifyCollectionChangedEventArgs e){    RaisePropertyChanged(nameof(PreviousWorkflowPluginConfigPathsCollection));    Settings.Default.PreviousWorkflowPluginConfigPathsCollection = PreviousWorkflowPluginConfigPathsCollection;}#endregion   #region Workflow // this is a section for last modified info along with brushes for coloring. Again, these will be 'repeated' six times.private string _localWorkflowPluginLastModified;public string LocalWorkflowPluginLastModified{    get    {        return _localWorkflowPluginLastModified;    }    set    {        _localWorkflowPluginLastModified = value;        RaisePropertyChanged(nameof(LocalWorkflowPluginLastModified));        Brush local;        Brush server;        ColorizeLabels(LocalWorkflowPluginLastModified, out local, ServerWorkflowPluginLastModified, out server);        LocalWorkflowPluginLastModifiedBrush = local;        ServerWorkflowPluginLastModifiedBrush = server;    }}private string _serverWorkflowPluginLastModified;public string ServerWorkflowPluginLastModified{    get    {        return _serverWorkflowPluginLastModified;    }    set    {        _serverWorkflowPluginLastModified = value;        RaisePropertyChanged(nameof(ServerWorkflowPluginLastModified));        Brush local;        Brush server;        ColorizeLabels(LocalWorkflowPluginLastModified, out local, ServerWorkflowPluginLastModified, out server);        LocalWorkflowPluginLastModifiedBrush = local;        ServerWorkflowPluginLastModifiedBrush = server;    }}private Brush _localWorkflowPluginLastModifiedBrush;public Brush LocalWorkflowPluginLastModifiedBrush{    get    {        return _localWorkflowPluginLastModifiedBrush;    }    set    {        _localWorkflowPluginLastModifiedBrush = value;        RaisePropertyChanged(nameof(LocalWorkflowPluginLastModifiedBrush));    }}private Brush _serverWorkflowPluginLastModifiedBrush;public Brush ServerWorkflowPluginLastModifiedBrush{    get    {        return _serverWorkflowPluginLastModifiedBrush;    }    set    {        _serverWorkflowPluginLastModifiedBrush = value;        RaisePropertyChanged(nameof(ServerWorkflowPluginLastModifiedBrush));    }}#endregionI think I am handling button click events pretty well with switches, so that all uploaders point to the same handler and then proper object is launched: private async void UploaderControl_OnUploadConfigClick(object sender, RoutedEventArgs e)        {            FileUploadInfo = Preparing upload...;            Application.Current.MainWindow.Cursor = Cursors.Wait;            string pluginName = (sender as Controls.UploaderControl).UploaderName;            switch (pluginName)            {                case TmsServiceNames.Workflow:                    await WorkflowFileUploader?.UploadConfig(false);                    break;                case TmsServiceNames.Archiver:                    await ArchiverFileUploader?.UploadConfig(false);                    break;                case TmsServiceNames.PptService:                    await PptFileUploader?.UploadConfig(false);                    break;            }            Application.Current.MainWindow.Cursor = Cursors.Arrow;        }I have a big problem with initialization of each of the FileUploader classes.For each of the three types I had to create a separate method: private void InitializeWorkflowPluginUploader()        {            if (CurrentWorkflowPluginPath.IsExistingFilePath() && ServicesManager.Services.ContainsKey(TmsServiceNames.Workflow))            {                IProgress<FileWatcherProgress> p = new Progress<FileWatcherProgress>(x =>                {                    LocalWorkflowPluginLastModified = x.LocalFileVersion ?? LocalWorkflowPluginLastModified;                    ServerWorkflowPluginLastModified = x.ServerFileVersion ?? ServerWorkflowPluginLastModified;                    LocalWorkflowPluginConfigLastModified = x.LocalConfigFileVersion ?? LocalWorkflowPluginConfigLastModified;                    ServerWorkflowPluginConfigLastModified = x.ServerConfigFileVersion ?? ServerWorkflowPluginConfigLastModified;                    FileUploadInfo = x.OverallInfo ?? FileUploadInfo;                    if (x.PopupText != null)                    {                        LaunchUploaderPopup(x.PopupTitle, x.PopupText);                    }                });                WorkflowFileUploader = new RemoteFileUploader(CurrentWorkflowPluginPath, CurrentWorkflowPluginConfigPath, new TmsFolderPaths().Workflow, WorkflowAutoUpload, ShowPopupAfterAutoUpload, ServicesManager.Services[TmsServiceNames.Workflow], p);            }        }I would like to create all these in a single method, where I could pass a bunch of properties as parameters - in this case for example file paths and properties for status labels (LocalWorkflowPluginLastModified) etc, which are different for each file type.So, summing up, while this is finished and will not grow any further, I would like to do a better structure next time, reduce the number of properties if possible. What would I do if I had to add 5 more file types, and then add 2 more labels to each of them?",
    "target": "c#;wpf;xaml"
  },
  {
    "id": "_unix.132604",
    "source": "br0 causes to drop multicast connection after 5 minutes <eos> I have these interfaces set up on the router (Linux machine):br0: flags=4419<UP,BROADCAST,RUNNING,PROMISC,MULTICAST>  mtu 1500        inet 192.168.0.3  netmask 255.255.255.0  broadcast 192.168.0.255bridge name bridge id       STP enabled interfacesbr0     8000.00156d8591ec   no      eth0                            wlan0eth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500        inet6 fe80::7271:bcff:feb1:d9cf  prefixlen 64  scopeid 0x20<link>eth1: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500        inet 10.200.44.147  netmask 255.255.255.128  broadcast 10.200.44.255wlan0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500        inet6 fe80::215:6dff:fe85:91ec  prefixlen 64  scopeid 0x20<link>In br0 there are two interfaces (eth0 - local home network and wlan0 - wireless home network). eth1 is internet connection interface and is not part of the br0. I use mumudvb for sending multicast IPTV with IP group 239.100.0.1 (udp/1234) and receiving this multicast traffic on a different machine on LAN using VLC player. When I configure it to send multicast over eth0 all works well on home LAN but I can't join the multicast group from the router itself. That's why I configured it to send multicast over br0 (makes more sense - then I can join the multicast group from the LAN eth0 as well as router itself) but after about 5 minutes since join, LAN multicast connection drops (without sending any IGMP message). But I can join again and it will work for next 5 minutes again, then drop.Why is it dropping when sending multicast over br0 and not dropping when sending directly through eth0? Am I missing some configuration on the bridge? What can expire during this period? For example STP is disabled for the bridge but it shouldn't affect this?When I join the br0 multicast group from the router itself, it won't drop. Only when subscribed from a machine connected to the br0 through eth0.",
    "target": "linux;bridge;multicast"
  },
  {
    "id": "_webapps.45039",
    "source": "google spreadsheets timesheet calculations <eos> I have a timesheet that I use to log my time. It works fine if I log in and log out. It works at the end of the day but doesn't work in all configurations. For example, I want it to work if I only arrive then leave at the end of the day but also show total of hours for the day if I am logging back in after a break.My example shows the configurations that don't work.EDITUpdated Example sheet so anyone can use it. What I do is hide all but the current week. Then go to the html view and copy+paste that to my payroll person.",
    "target": "google spreadsheets"
  },
  {
    "id": "_vi.2627",
    "source": "How to add a string to cursor point of gvim through a shell script <eos> When gvim is opened it saves the cursor position whether it is minimized or not. So I'm curious whether it is possible to add a string starting from the cursor blinking position by running a shell script or through a terminal.",
    "target": "cursor movement;terminal;invocation;gvim;persistent state"
  },
  {
    "id": "_softwareengineering.303887",
    "source": "Can I use Qt open-source for my web-scraping website? <eos> I apologize if I should be understanding this more readily but I'm a little new to this and dont understand the LGPL license.  Here is the FAQ for it: http://www.qt.io/qt-licensing-terms/I am making a website that scrapes data from other websites and organizes it in a nice manner.  I plan to try and make money off this website through advertising and also by getting commissions from linking to certain sites.  I plan on using server-side code that scrapes the website using PyQt4 (which uses Qt).  The code scrapes the website and stores the data in a sql database.  I then use the sql database to display the webpage.I think it's fine to use the open source version of Qt right?  I'm not selling or really giving any application away.  The Qt is being used on server-side code to generate the sql database.And if it is fine to use the open source, do I have to display a link on the website to the source code of the Qt I'm using?  Just trying to fully understand.",
    "target": "web development;licensing;python;lgpl;qt"
  },
  {
    "id": "_codereview.44821",
    "source": "Print out table with start/end temperatures and step size <eos> I am trying to learn C++ by myself. I looked up a sample question after going through some text. Though I would like someone to review my code.  I'm basically asking you to break it to show some flaws or some thing I missed.  As a beginner I tried exhaustively to improve it and now hit a wall to analyse robustness of the code.Problem statement:In this challenge, write a program that takes in three arguments, a  start temperature (in Celsius), an end temperature (in Celsius) and a  step size. Print out a table that goes from the start temperature to  the end temperature, in steps of the step size; you do not actually  need to print the final end temperature if the step size does not  exactly match. You should perform input validation: do not accept  start temperatures less than a lower limit (which your code should  specify as a constant) or higher than an upper limit (which your code  should also specify). You should not allow a step size greater than  the difference in temperatures.#include <iostream>#include <cstdlib>#include <string>#define LOWER_LIMIT 23.3#define UPPER_LIMIT 256.3using namespace std;bool isnum(string s){    //check if the string is a number    //48 & 57    int len = s.length();    for(int i = 0; i < len; i++)        {        //cout << s[i] << \\t << int(s[i])<< endl;        if(int(s[i])>=48 && int(s[i])<=57)            return true;        else        {            return false;            break;        }    }}int main(int argc, char** argv)//The int argc holds the argument count and the argv is a 2-D array4// of characters{    double start,end,step_size;    if(argc!=4)    {        cout<<Please enter three intigers<<endl;        cout<<celcius <start_temprature> <end_temprature> <step_size><<endl;        cout<<Last step may not be printed<<endl;    }    else    {        //check if all the arguments are intigers        if(isnum(argv[1]) && isnum(argv[2]) && isnum(argv[3]))        {               cout<<argv[1]<<endl;            cout<<argv[2]<<endl;            cout<<argv[2]<<endl;            start = atof(argv[1]);            end = atof(argv[2]);            step_size = atof(argv[3]);            //calculate the table and print.            if(start < LOWER_LIMIT || start >UPPER_LIMIT)            {                cout<<The <start_temprature> does not meet the limit requirement (<<LOWER_LIMIT<<\\u00B0<<C - <<UPPER_LIMIT<<\\u00B0<<C)<<endl;                // The degree symbol to be printed on command line requires UTF-8 characters which has the degree symbol and the location is \\u00B0                return -1;            }            if(end >UPPER_LIMIT || end <LOWER_LIMIT)            {                cout<<The <end_temprature> does not meet the requirement (<<LOWER_LIMIT<<\\u00B0<<C - <<UPPER_LIMIT<<\\u00B0<<C) <endl;                             return -1;            }            if (step_size  <1 || step_size >=(UPPER_LIMIT - LOWER_LIMIT))            {   //zero or negetive stepsize checking                cout<<The step_size cannot be negetive, zero or greater than or equal to step_size<<endl;                return -1;            }            if(end<start) //swapping variables if start is greater than end            {                cout <<Swapped! end and start values for simplicity <<endl;                double tmp = start;                start = end;                end = tmp;            }            cout << start <<start<<endl;            cout << end <<end<<endl;            cout << step_size <<step_size<<endl;            int nend = (int)((end-start)/step_size);            cout << nend <<number of iterations<<endl;            for(int i = 0; i < nend ;i++)            {                cout << start << \\u00B0<<C  =   << ((start*(9/5))+32) << \\u00B0<<F <<endl;                start += (double)step_size;            }        }        else        cout <<All three input arguments must be positive numbers! <<endl;    }}",
    "target": "c++;beginner"
  },
  {
    "id": "_unix.218198",
    "source": "load balancing multiplie services linux <eos> I have setup multiple servers,One of them is a windows server running team speak.The other is a game server with csgo(counter strike global offensive) and lastly, one running an apache server.I will use my vserver as load balancer.I want to load balance all traffic over the vserver but without redirects, so that clients can connect to my vserver using multiple games and gaming services.It has been suggested to use something like vpn or iptables but didn't get a good answer so I'm asking here..I am already using pound for web services and now I will do the same things for my games and services...How I can do this?Another thing that I  would like to do is white-list on every server only the vserver, so no client can do an direct connection to the serversHERE IS THE ACTUAL SYSTEM:[CLIENT]-(ts3)--[ts3 Server](different ip)[CLIENT]-(apache)--[apache Server](different ip)[CLIENT]-(game)--[game Server](different ip)HERE IS MY PLANNED SYSTEM:                              (one IP)[CLIENT]-(ts3/apache/game)--[vserver]-(apache via pound)-[apache Server]                                                                    |-(Ts3 traffic)-[ts3 Server]                                  |-(game traffic)-[game Server]",
    "target": "linux;load balancing"
  },
  {
    "id": "_unix.115566",
    "source": "What is the kernel syntax when booting from ZFS? <eos> I'm trying to write a grub.cfg completely from scratch that will boot one of several FreeBSD systems off of a single ZFS pool named tank with a set of root file systems named root1, root2, root3.When I look at the official GRUB2 docs, there is one example in 5.3 menuentry FreeBSD {          insmod zfs          search --set=root --label freepool --hint hd0,msdos7          kfreebsd /freebsd@/boot/kernel/kernel          kfreebsd_module_elf /freebsd@/boot/kernel/opensolaris.ko          kfreebsd_module_elf /freebsd@/boot/kernel/zfs.ko          kfreebsd_module /freebsd@/boot/zfs/zpool.cache type=/boot/zfs/zpool.cache          set kFreeBSD.vfs.root.mountfrom=zfs:freepool/freebsd          set kFreeBSD.hw.psm.synaptics_support=1}I figured that freepool is likely the ZFS pool name which I would replace with tank. I suspect that the x@y syntax is the way to refer to a file y on the file system x of the pool selected by the search. Then I would replace this with /root1@/boot/kernel/kernel. Sadly, the x@y syntax is undocumented and I don't want to just try with fingers crossed, but rather understand and know what I'm doing. Can anyone shed light on this?",
    "target": "freebsd;grub2;zfs"
  },
  {
    "id": "_softwareengineering.283432",
    "source": "Are there constraints for functions in structured programming? <eos> I just talking with a colleague (University instructor) who teaches C (Fundamental of programming Course). He said I won't give score to a student, if he uses I/O (scanf or printf or cin count) in a function (it shows he hasn't understood it well) or if he writes a function which does two things (for example to return the maximum of an array, he shouldn't sort the array and return the first element, however he can use two functions, one for sorting and another for returning the first element ...)... I thought these are related to his teaching method but he claimed they are the principles of functions in structured programming.Are there really such constraints and definitions for functions? What are those?If yes, in which topic are they discussed?  Should they be discussed in a C or C++ teaching course?",
    "target": "functions;definition"
  },
  {
    "id": "_webapps.92218",
    "source": "How does Facebook know my credit card number? <eos> I just looked at boosting a post on one of my Facebook pages. And they already had a credit card number for me. I'm pretty sure I haven't given them my credit card details before, is there another reason they could have my credit card number? For example, I do use Gmail to log in to it, and Gmail has my credit card number. ",
    "target": "facebook"
  },
  {
    "id": "_codereview.98051",
    "source": "Using logic to compare absolute values <eos> Is there a way to make my code simpler/more Pythonic?Given three int values (a, b, c), return True if one of b or c is close  (differing from a by at most 1), while the other is far, differing  from both other values by 2 or more. Note: abs(num) computes the  absolute value of a number. close_far(1, 2, 10)  Trueclose_far(1, 2, 3)  Falseclose_far(4, 1, 3)  Truedef close_far(a, b, c):    if abs(a - b) <= 1 or abs(a - c) <= 1:        if abs(c - a) >= 2 <= abs(c - b) or abs(b - a) >= 2 <= abs(b - c):            return True           return False",
    "target": "python"
  },
  {
    "id": "_unix.175180",
    "source": "How do I make an alias to substitute single word in a piped command? <eos> I use aliases a lot but right now only for use cases like alias i='sudo apt-get install -y'. I often would like to add an alias in the following form:alias cmd='echo [something] >> /path/to/file' where I would like to substitute [something] with what I enter after the cmd.I can obviously create a one-line script,save it somewhere and make an alias to that command but since I only want to substitute only 1 word in a pipe, is there a simpler way to do this?",
    "target": "command line;pipe;alias;arguments"
  },
  {
    "id": "_cstheory.16864",
    "source": "A game of positioning overlapping circles to maximize travel time between them <eos> I encountered the following game. I'll migrate this as requested.A bug is visiting circles, and an adversary wishes to maximize his travel time.The adversary places a circle on every turn. The bug walks from it's current position directly toward the center of the newest circle, then stops when it encounters the interior of the circle (thus: it doesn't walk if a circle is played covering its location). This is the bug's turn.There are $N$ circles available to the adversary. Each subsequent circle has radius less than the previous circle. Each circle must intersect the intersection of all previously played circles. That is, all circles must have a common intersection once all are played.EDIT:  The adversary is free to choose the radii of the circles, subject to the constraint that the radii monotonically decrease.Questions and Answers:Is the distance as $N\\to\\infty$ bounded? A: No, an example of an adversary strategy is given by this AnswerWhat is the maximum distance the bug must travel over the playing of $N$ circles. A: it grows at $\\Theta(\\log(N))$, by the same answer.Variant 2: The bug walks directly toward the intersection of the two most recently played circles.UPDATE: This variant was addressed, under the assumption that the bug can only remember the last 2 circles played here. The result was again an unbounded distance. What impact does unliminted memory have? i.e., the bug goes to the intersection of all previously played circles. This produced a loose bound of $O(d)$, where $d$ is the diameter of the first circle. Obviously it cannot be less than this. See here. The current upper bound was $1000\\times d$. This was obtained by approximating the worst-case path as a tour around progressively smaller circles. It was shown that the bug always makes progress towards the final intersection, thus reducing the next-step distance it must travel.I suspect the distance traveled is a small constant times the circumference of the first circle, but I'm not currently able to provide a good proof.",
    "target": "gt.game theory"
  },
  {
    "id": "_unix.381395",
    "source": "How to find which package required another package? <eos> I am looking for which no-longer-installed package depended on rsync. An apt-get autoremove now wants to remove rsync so I'm guessing that it was installed as part of a dependency rather than manually, and I'm curious which package depended on it.Can I search back in logs for something like X requires Y, so I will install Y as well? Or does it even store which reverse dependency required it, just like it stores that it was not installed by the user?",
    "target": "dpkg;dependencies"
  },
  {
    "id": "_softwareengineering.46084",
    "source": "How to make people new to programming stop asking me questions and distracting me? <eos> I am at secondary school right now and I'm the only one in my class who is experienced with programming. Because of that, people are constantly distracting me while I'm writing code to ask me to solve a problem. Usually I reply with something like 'I don't know, I never use that' but I don't want to lie to people.Another problem is that I became so well known for this that even students from other classes are asking me questions. I find this damn annoying.Thirdly, if I solve a problem for them they don't learn anything from it.How can I stop people from asking me programming-related questions in a kind way? ",
    "target": "productivity;knowledge transfer"
  },
  {
    "id": "_webmaster.108169",
    "source": "Preventing/blocking from crawling a specific user control of a page <eos> Currently, google access/crawls a user control from the page given below-http://articles.mercola.com/sites/articles/archive/2017/07/20/do-fidget-spinners-help-anxiety-adhd.aspxResult of Google crawl - LinkAs per the above link, we can see that the comment section [i.e. user control] is accessed and crawled and we have to prevent/Disallow and block the same.Any ideas or suggestion on how to block the same.",
    "target": "seo;web crawlers;robots.txt;meta tags"
  },
  {
    "id": "_cs.24232",
    "source": "Minimum weighted arithmetic mean partion? <eos> Assume I have some positive numbers $a_1,\\ldots,a_n$ and a number $k \\in \\mathbb{N}$. I want to partition these numbers into exactly $k$ sets $A_1,\\ldots,A_k$ such that the weighted arithmetic mean$$\\text{cost}(A_i,\\ldots,A_k)=\\sum_{i=1}^{k}\\frac{|A_i|}{n}c(A_i)$$is minimal, where $c(A_i)=\\sum_{a \\in A_i}a$ is simply the sum of all numbers in $A_i$.Is there actually a (polynomial) algorithm to do this or is this a (NP) hard problem? I tried to reduce it to some NP-hard problems but didn't get anywhere, especially because the numbers are nonnegative and thus in an optimal partition big sets need to have smaller weight which seems to be some kind of balancing problem instead of a packing problem (which I am more familiar with).",
    "target": "optimization;np hard;np;partitions"
  },
  {
    "id": "_unix.359441",
    "source": "update linux centos 6.6 <eos> I've tried to update my Linux server centos6.6 using these command, yum clean all and then yum update, but unfortunately I got these errors.please help me. according to these errors if I use this command yum update --skip-broken, it will be dangerous to my server??? how can I solve these errors.thank you in advance Error: Package: xine-lib-extras-1.1.21-10.el6.x86_64 (@epel)           Requires: libMagickCore.so.2()(64bit)           Removing: ImageMagick-6.5.4.7-7.el6_5.x86_64 (@base)               libMagickCore.so.2()(64bit)           Updated By: ImageMagick-6.7.2.7-6.el6.x86_64 (base)               Not foundError: Package: php-pecl-igbinary-1.2.1-1.el6.x86_64 (epel)           Requires: php(zend-abi) = 20090626           Installed: php-common-5.5.14-2.el6.remi.x86_64 (@remi-php55)               php(zend-abi) = 20121212-64           Available: php-common-5.3.3-49.el6.x86_64 (base)               php(zend-abi) = 20090626           Available: php55w-common-5.5.38-1.w6.x86_64 (webtatic)               php(zend-abi) = 20121212-64           Available: php56w-common-5.6.30-1.w6.x86_64 (webtatic)               php(zend-abi) = 20131226-64           Available: php70w-common-7.0.15-1.w6.x86_64 (webtatic)               php(zend-abi) = 20151012-64           Available: php70w-common-7.0.16-1.w6.x86_64 (webtatic)               php(zend-abi) = 20151012-64           Available: php70w-common-7.0.17-1.w6.x86_64 (webtatic)               php(zend-abi) = 20151012-64           Available: php71w-common-7.1.1-1.w6.x86_64 (webtatic)               php(zend-abi) = 20160303-64           Available: php71w-common-7.1.2-1.w6.x86_64 (webtatic)               php(zend-abi) = 20160303-64           Available: php71w-common-7.1.3-1.w6.x86_64 (webtatic)               php(zend-abi) = 20160303-64Error: Package: xine-lib-extras-1.1.21-10.el6.x86_64 (@epel)           Requires: libMagickWand.so.2()(64bit)           Removing: ImageMagick-6.5.4.7-7.el6_5.x86_64 (@base)               libMagickWand.so.2()(64bit)           Updated By: ImageMagick-6.7.2.7-6.el6.x86_64 (base)               Not foundError: Package: php-pecl-apcu-4.0.11-2.el6.x86_64 (epel)           Requires: php(api) = 20090626           Installed: php-common-5.5.14-2.el6.remi.x86_64 (@remi-php55)               php(api) = 20121113-64           Available: php-common-5.3.3-49.el6.x86_64 (base)               php(api) = 20090626           Available: php55w-common-5.5.38-1.w6.x86_64 (webtatic)               php(api) = 20121113-64           Available: php56w-common-5.6.30-1.w6.x86_64 (webtatic)               php(api) = 20131106-64           Available: php70w-common-7.0.15-1.w6.x86_64 (webtatic)               php(api) = 20151012-64           Available: php70w-common-7.0.16-1.w6.x86_64 (webtatic)               php(api) = 20151012-64           Available: php70w-common-7.0.17-1.w6.x86_64 (webtatic)               php(api) = 20151012-64           Available: php71w-common-7.1.1-1.w6.x86_64 (webtatic)               php(api) = 20160303-64           Available: php71w-common-7.1.2-1.w6.x86_64 (webtatic)               php(api) = 20160303-64           Available: php71w-common-7.1.3-1.w6.x86_64 (webtatic)               php(api) = 20160303-64Error: Package: php-pecl-igbinary-1.2.1-1.el6.x86_64 (epel)           Requires: php(api) = 20090626           Installed: php-common-5.5.14-2.el6.remi.x86_64 (@remi-php55)               php(api) = 20121113-64           Available: php-common-5.3.3-49.el6.x86_64 (base)               php(api) = 20090626           Available: php55w-common-5.5.38-1.w6.x86_64 (webtatic)               php(api) = 20121113-64           Available: php56w-common-5.6.30-1.w6.x86_64 (webtatic)               php(api) = 20131106-64           Available: php70w-common-7.0.15-1.w6.x86_64 (webtatic)               php(api) = 20151012-64           Available: php70w-common-7.0.16-1.w6.x86_64 (webtatic)               php(api) = 20151012-64           Available: php70w-common-7.0.17-1.w6.x86_64 (webtatic)               php(api) = 20151012-64           Available: php71w-common-7.1.1-1.w6.x86_64 (webtatic)               php(api) = 20160303-64           Available: php71w-common-7.1.2-1.w6.x86_64 (webtatic)               php(api) = 20160303-64           Available: php71w-common-7.1.3-1.w6.x86_64 (webtatic)               php(api) = 20160303-64Error: Package: php-pecl-apcu-4.0.11-2.el6.x86_64 (epel)           Requires: php(zend-abi) = 20090626           Installed: php-common-5.5.14-2.el6.remi.x86_64 (@remi-php55)               php(zend-abi) = 20121212-64           Available: php-common-5.3.3-49.el6.x86_64 (base)               php(zend-abi) = 20090626           Available: php55w-common-5.5.38-1.w6.x86_64 (webtatic)               php(zend-abi) = 20121212-64           Available: php56w-common-5.6.30-1.w6.x86_64 (webtatic)               php(zend-abi) = 20131226-64           Available: php70w-common-7.0.15-1.w6.x86_64 (webtatic)               php(zend-abi) = 20151012-64           Available: php70w-common-7.0.16-1.w6.x86_64 (webtatic)               php(zend-abi) = 20151012-64           Available: php70w-common-7.0.17-1.w6.x86_64 (webtatic)               php(zend-abi) = 20151012-64           Available: php71w-common-7.1.1-1.w6.x86_64 (webtatic)               php(zend-abi) = 20160303-64           Available: php71w-common-7.1.2-1.w6.x86_64 (webtatic)               php(zend-abi) = 20160303-64           Available: php71w-common-7.1.3-1.w6.x86_64 (webtatic)               php(zend-abi) = 20160303-64 You could try using --skip-broken to work around the problem You could try running: rpm -Va --nofiles --nodigest",
    "target": "centos;yum"
  },
  {
    "id": "_reverseengineering.15671",
    "source": "What makes CDMs such as Widevine hard to reverse engineer? <eos> According to this PDF, Widevine has three security levels. The least secure one, and the one used by Chrome on desktops is level 3 in which all decryption is done outside of a Trusted Execution Environment.But in that case, what stops someone from opening the Widevine Chrome plugin in IDA and following the video data until they get to whatever function that decrypts it and then write their own implementation of Widevine that just saves the output to a file instead of rendering it?The PDF does say that appropriate measures may be taken to protect the cryptographic information and decrypted content on host operating system, but things like video games also use various protection systems, but these still get cracked with some effort.So, why hasn't Widevine been cracked yet?",
    "target": "ida;disassembly"
  },
  {
    "id": "_webapps.58899",
    "source": "Add another accout in Gmail interface <eos> Q: what's the work around way to use gmail interface with email handle by MS exchange server?The company I worked for use MS exchange server for the emails, but my workstation is iMac and they installed me entourage 2007 which is very poor designed for work flow.I have add my work email account (ex: me@mycompany.com) to the gmail succesfully, got verify..etc. but it only work half way,Scenerio: (works) when I create a new message from gmail interface with me@mycompany.com and send to me@mycompany.com, I can recieve it in entourage from my local computer. (not works) But if I create a new message from entourage or MS exchange web server, the message just don't get to the gmail interface.(works) if I create new message from gmail interface and send to my colleuage, she can recieve it and reply, and I can get her replies in  gmail interface as well.I believe there is firewall or sort of thing, the challengs I face is without IT guy turn off anything for me ( a wanna-be super user), what's the work around way? of coz no forwarding method, coz it will create a mess....Thanks.",
    "target": "email;gmail"
  },
  {
    "id": "_unix.39268",
    "source": "Chkconfig on Linux Mint 12 giving tons of errors <eos> I'm trying to disable some services from starting at boot time on my Linux Mint 12 laptop.So I installed chkconfig, which has worked great for me before on Fedora.However, on Linux Mint 12, it gives me tons of errors. Here is an example, trying to disable the rsync service:$ sudo chkconfig rsync offinsserv: warning: script 'K01acpi-support' missing LSB tags and overridesThe script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'cryptdisks-udev' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `cryptdisks-udev'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `cryptdisks-udev'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'acpid' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `acpid'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `acpid'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'plymouth-upstart-bridge' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `plymouth-upstart-bridge'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `plymouth-upstart-bridge'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'rsyslog' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `rsyslog'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `rsyslog'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'friendly-recovery' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `friendly-recovery'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `friendly-recovery'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'udevtrigger' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `udevtrigger'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `udevtrigger'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'udev-finish' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `udev-finish'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `udev-finish'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'plymouth-stop' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `plymouth-stop'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `plymouth-stop'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'apport' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `apport'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `apport'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'dbus' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `dbus'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `dbus'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'cryptdisks-enable' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `cryptdisks-enable'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `cryptdisks-enable'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'hwclock' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `hwclock'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `hwclock'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'lightdm' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `lightdm'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `lightdm'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'udevmonitor' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `udevmonitor'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `udevmonitor'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'ufw' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `ufw'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `ufw'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'binfmt-support' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `binfmt-support'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `binfmt-support'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'udev' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `udev'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `udev'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'irqbalance' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `irqbalance'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `irqbalance'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'cron' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `cron'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `cron'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'nmbd' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `nmbd'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `nmbd'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'plymouth-splash' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `plymouth-splash'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `plymouth-splash'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'procps' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `procps'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `procps'insserv: warning: script 'acpi-support' missing LSB tags and overridesThe script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'network-manager' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `network-manager'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `network-manager'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'smbd' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `smbd'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `smbd'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'dmesg' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `dmesg'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `dmesg'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'module-init-tools' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `module-init-tools'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `module-init-tools'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'network-interface' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `network-interface'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `network-interface'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'console-setup' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `console-setup'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `console-setup'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'anacron' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `anacron'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `anacron'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'modemmanager' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `modemmanager'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `modemmanager'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'udev-fallback-graphics' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `udev-fallback-graphics'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `udev-fallback-graphics'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'plymouth' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `plymouth'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `plymouth'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'network-interface-security' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `network-interface-security'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `network-interface-security'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'alsa-store' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `alsa-store'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `alsa-store'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'alsa-restore' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `alsa-restore'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `alsa-restore'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'avahi-daemon' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `avahi-daemon'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `avahi-daemon'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'plymouth-log' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `plymouth-log'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `plymouth-log'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'mysql' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `mysql'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `mysql'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'atd' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `atd'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `atd'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'hostname' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `hostname'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `hostname'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'cups' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `cups'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `cups'The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'hwclock-save' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `hwclock-save'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `hwclock-save'insserv: script virtualbox: service vboxdrv already provided!insserv: script virtualbox: service virtualbox already provided!The script you are attempting to invoke has been converted to an Upstartjob, but lsb-header is not supported for Upstart jobs.insserv: warning: script 'setvtrgb' missing LSB tags and overridesinsserv: Default-Start undefined, assuming empty start runlevel(s) for script `setvtrgb'insserv: Default-Stop  undefined, assuming empty stop  runlevel(s) for script `setvtrgb'It seems to have worked when I run:# chkconfig rsync  rsync  offIs it bad to continue to use chkconfig? Can anyone suggest an alternate service-managing program, or a way to fix the errors when running chkconfig?",
    "target": "command line;linux mint;upstart;chkconfig"
  },
  {
    "id": "_softwareengineering.353029",
    "source": "Should TDD be done top-down, bottom-up, or a combination of the two? <eos> When doing Test-Driven Development, should you start at the lowest possible level of abstraction, writing your classes bottom-up, to ensure that you can run unit tests in a timely manner? Or should you start somewhat above that level, coding several classes top-down, and afterward, using those classes, code bottom-up?",
    "target": "tdd"
  },
  {
    "id": "_softwareengineering.195601",
    "source": "Are Python sockets suitable for file synchronization? <eos> I'm working in an organisation with limited funds. They can't afford a business account on Dropbox. However, they would find it useful to have all their files synchronized on local machines. I've recently looked at Python Sockets and it looks as though a custom script could achieve what they're looking for. I'm concerned that it may be too low-level  because a library may exist that provides a lot of functionality and it would be a waste of resources to start from scratch. Is there a Python library/module that would provide what I'm looking for? ",
    "target": "python;networking;sockets;file storage"
  },
  {
    "id": "_webmaster.22783",
    "source": "jquery ui minify <eos> I have a series of web pages that link to the following:jquery-ui-1.8.4.custom.min.jsjquery.ui.widget.jsjquery.ui.core.jsjquery.ui.accordion.jsjquery.ui.selectmenu.jsjquery.ui.button.jsNot every page uses each .js (for example, not every pages uses jquery.ui.button) however I was wondering if it would make more sense to combine all of these files and minify them into a single.js file and include it on every page?",
    "target": "javascript;jquery"
  },
  {
    "id": "_codereview.125723",
    "source": "Design Patterns in Swift: Chain of Responsibility <eos> I'm solving the following problem using the Chain Of Responsibility design pattern in Swift:Not all mechanics are created equally. Some mechanics are more  experienced and can do more than others. We need a system where every  job is propagated from the least experienced mechanic to the most.  This way  experienced mechanics that can perform more jobs are not  busy with jobs that more junior mechanics can take care of.I would love some feedback on how I can improve this. If it remains true to the definition of Chain Of Responsibility or if there are any swift standard coding convention that I should be following. Here is the code, the full repo can be found here: Design Patterns in Swift: Chain of Responsibility import Foundationenum Skill: Int{  case OilChangeOnly = 1, Junior, Apprentice, MasterMechanic}class Job{  let minimumSkillSet: Skill  let name: String  var completed: Bool = false  init(minimumSkillSet: Skill, name: String){    self.minimumSkillSet = minimumSkillSet    self.name = name  }}class Mechanic{  let skill: Skill  var name: String  var isBusy: Bool = false  init(skill: Skill, name: String){    self.skill = skill    self.name = name  }  func performJob(job: Job) -> Bool{    if job.minimumSkillSet > self.skill || isBusy{      assert(false, This mechanic is either busy or insufficiently skilled for this job, he should have never been asked to perform it, there is something wrong in the chain of responsibility);    }else    {      isBusy = true      print(\\(name) with skill set \\(skill) has started to do \\(job.name))      job.completed = true      return true    }  }}class MechanicSkillGroup{  var mechanics: [Mechanic]  var nextLevel: MechanicSkillGroup?  var skill: Skill  init(skill: Skill, mechanics: [Mechanic], nextLevel: MechanicSkillGroup?){    self.mechanics = mechanics    self.skill = skill    self.nextLevel = nextLevel  }  func performJobOrPassItUp(job: Job) -> Bool{    if (job.minimumSkillSet > skill || mechanics.filter({$0.isBusy == false}).count == 0){      if let nextLevel = nextLevel{        return nextLevel.performJobOrPassItUp(job)      }else{        print(No one is available to do this job)        return false      }    }else{      if let firstAvailableMechanic = mechanics.filter({$0.isBusy == false}).first{        return firstAvailableMechanic.performJob(job)      }      assert(false, This should never be reached since our if-else statement is fully exhaustive. You cannot have both all mechanics busy and an available mechanic within one skill group);    }  }}class Shop{  private var firstMechanics: MechanicSkillGroup  init(firstMechanics: MechanicSkillGroup){      self.firstMechanics = firstMechanics  }  func performJob(job: Job) -> Bool{    return firstMechanics.performJobOrPassItUp(job)  }}Here is main with setup and some test casesimport Foundationvar steve = Mechanic(skill: .MasterMechanic, name: Steve Frank)var joe = Mechanic(skill: .MasterMechanic, name: Joe Alison)var jack = Mechanic(skill: .MasterMechanic, name: Jack Ryan)var brian = Mechanic(skill: .MasterMechanic, name: Drake Jin)var masterMechanics = MechanicSkillGroup(skill: .MasterMechanic, mechanics: [steve, joe, jack, brian], nextLevel: nil)var tyson = Mechanic(skill: .Apprentice, name: Tyson Trump)var tina = Mechanic(skill: .Apprentice, name: Tina Bernard)var bryan = Mechanic(skill: .Apprentice, name: Bryan Tram)var lin = Mechanic(skill: .Apprentice, name: Lin Young)var apprenticeMechanics = MechanicSkillGroup(skill: .Apprentice, mechanics: [tyson, tina, bryan, lin], nextLevel: masterMechanics)var ken = Mechanic(skill: .Junior, name: Ken Hudson)var matt = Mechanic(skill: .Junior, name: Matt Lowes)var sandeep = Mechanic(skill: .Junior, name: Sandeep Shenoy)var tom = Mechanic(skill: .Junior, name: Tom Berry)var juniorMechanics = MechanicSkillGroup(skill: .Junior, mechanics: [ken, matt, sandeep, tom], nextLevel: apprenticeMechanics)var grant = Mechanic(skill: .OilChangeOnly, name: Grant Hughes)var larry = Mechanic(skill: .OilChangeOnly, name: Larry White)var bryant = Mechanic(skill: .OilChangeOnly, name: Bryant Newman)var reza = Mechanic(skill: .OilChangeOnly, name: Reza Shirazian)var laura = Mechanic(skill: .OilChangeOnly, name: Laura Lee)var arnold = Mechanic(skill: .OilChangeOnly, name: Arnold Shummer)var oilChangeOnlyes = MechanicSkillGroup(skill: .OilChangeOnly, mechanics: [grant], nextLevel: juniorMechanics)var shop = Shop(firstMechanics: oilChangeOnlyes)var jobs = [Job(minimumSkillSet: .Junior, name: Windshield Viper),            Job(minimumSkillSet: .Apprentice, name: Light Bulb Change),            Job(minimumSkillSet: .Apprentice, name: Battery Replacement),            Job(minimumSkillSet: .OilChangeOnly, name: General Oil Change),            Job(minimumSkillSet: .OilChangeOnly, name: General Oil Change),            Job(minimumSkillSet: .OilChangeOnly, name: General Oil Change),            Job(minimumSkillSet: .OilChangeOnly, name: General Oil Change),            Job(minimumSkillSet: .MasterMechanic, name: Timing Belt Replacement),            Job(minimumSkillSet: .Junior, name: Brake Pads Replacement)]for job in jobs{  shop.performJob(job)}Here is output you'd get with this setup:Ken Hudson with skill set Junior has started to do Windshield WiperTyson Trump with skill set Apprentice has started to do Light Bulb ChangeTina Bernard with skill set Apprentice has started to do Battery ReplacementGrant Hughes with skill set OilChangeOnly has started to do General Oil ChangeMatt Lowes with skill set Junior has started to do General Oil ChangeSandeep Shenoy with skill set Junior has started to do General Oil ChangeTom Berry with skill set Junior has started to do General Oil ChangeSteve Frank with skill set MasterMechanic has started to do Timing Belt ReplacementBryan Tram with skill set Apprentice has started to do Brake Pads ReplacementProgram ended with exit code: 9   ",
    "target": "design patterns;swift"
  },
  {
    "id": "_webapps.36073",
    "source": "Personalizing Trello invitation message <eos> I'm a member of an IRL ONG and I invited several to a Trello board. But as they don't know what's this trello they put their invitation in the trash.Can I change the invitation message to write a personalized message?",
    "target": "trello"
  },
  {
    "id": "_cstheory.24941",
    "source": "What can we say about all cycles in graphs (connected undirected graph) <eos> I am considering one optimization problem who is known to be NP hard in the general setting. But there is application of this problem on the cylces of graph. This problem involves several sets and in this setting each set is the set of nodes of cycle in connected unidrected graph. And all cycles of connected unidrected graphs are the all sets for this problem. This is quite specific setting for the problem and I wonder whether there can be improvements in this specific setting.I would like to work out all the details myself but the question is - is there the general theory of all cycles in grpahs (connected undirected). Like - what is the number of cycles, what is the minimum and maximum lenght of them, how much common nodes they can have and so on? Mybe there are connections with group theory - e.g. cycle could be some kind of orbit for a group element (in rude language). Any such information provides the constraint on the initial problem and therefore - the complexity improvements can be possible to achieve in this specific setting.Google gives a lot about Hamiltonian and similar specific cycles. My question is about all possible cycles in graph.Any references could be helpful. Any names for the problems and keywords in this are could be appreciated as well. Thanks.",
    "target": "cc.complexity theory;graph theory;graph algorithms"
  },
  {
    "id": "_webmaster.8372",
    "source": "The Joomla 'create a template' tutorial <eos> I've recently downloaded Joomla using an instant download option, and now I'm looking to create my own templates. I went to http://www.siteground.com/tutorials/joomla15/joomla_create_template.htm and am trying to follow the tutorial but I've failed at the first hurdle... where it says:First, open the templates directory in your Joomla installation. Then create a subfolder in it named tutorial_template. All the files of your template will reside in it.The problem is I have no clue how to do this, where is the directory to start with? The only thing I know how to get up is the administrator's screen, in which I have to choose one of the stock templates, which would be great if I didn't care about my own designs...but obviously I'm looking to have my own HTML and CSS coding used instead.How do I find where the folders are and how do I open them?",
    "target": "html;css;joomla"
  },
  {
    "id": "_unix.367699",
    "source": "File containing directory structure <eos> I'm currently doing a CTF challenge and have extracted what I assume is the flag by injecting a relative path into the $filename parameter of a call to the PHP functionfile_get_contents($filename)that is executed by an Apache server on the target system.I got the name of the file the flag was hidden in through a hint at some other point but I was wondering:Is there a file that's commonly present on a Linux system that holds information about the directory structure and files contained in these directories?I've tried searching through several log files in order to find references to interesting files but I've yet to find a detailed list of file names. I also do not have permission to read entire device files. I do have full control over the $filename parameter but from I gathered, I can only insert absolute or relative paths without wildcards in there.",
    "target": "files;php;directory structure"
  },
  {
    "id": "_cs.55929",
    "source": "PDA for all non-palindromic strings of even length <eos> I had a homework assignment where I had to build a PDA over the alphabet $\\{a,b\\}^*$, accepting $L = \\{x \\mid x \\text{ is even but not a palindrome}\\}$.I already turned it in, but I know I had it wrong and it's driving me insane that I can't figure out this construction. I tried a Cartesian product construction of the following languages and then deselected the accepting states of $L_2$, but I obviously did it wrong:$L_1 = \\{x \\mid x \\text{ is even}\\}$$L_2 = \\{xx^R\\}$, where $x^R$ denotes $x$ reversed.I kept running into a problem where it would still accept because Palindromes are even and I was basically accepting all even numbers.",
    "target": "finite automata;pushdown automata;nondeterminism"
  },
  {
    "id": "_codereview.80686",
    "source": "Binding events in constructor <eos> I am trying to get familiar with OOP JavaScript, in particular working with the prototype pattern and would love some pointers/suggestions on how to improve my code.I think I have understood the basics well, and have been able create class instances successfully.I am however, a little unsure on how to work with events when it comes to representing these instances with a UI. Until now, I have been binding my events in the constructor before the element gets added to the DOM, but am sure this could be improved:function Person(data) {    var self = this;    self.data = data;    self.$element = $('<div class=person>' +                          '<p class=name>' + data.name + '</p>' +                          '<p class=age>' + data.age + '</p>' +                      '</div>');    // bind events    self.$element.find('.name').click(function () {        self.speakName();    });    self.$element.find('.age').click(function () {        self.speakAge();    });    // render element    $('.person-container').append(self.$element);}Person.prototype.speakName = function () {    alert(this.data.name);};Person.prototype.speakAge = function () {    alert(this.data.age);};Ideally, I'd like to be able to build up a relatively complex UI of 'people', with various controls on each person to perform actions related to that person only. Apologies for the contrived example, I'm just trying to get the concept right in my head before doing anything more real-world.I've also included a working jsfiddle incase this is easier to work with: http://jsfiddle.net/z59q2rab/.",
    "target": "javascript;beginner;jquery;object oriented;prototypal class design"
  },
  {
    "id": "_softwareengineering.167627",
    "source": "How show Attributes which appear In Many To Many association <eos> As we know a many to many association are shown by two asterisks in both end of association. Now I have a association between two entities Good and Invoice so Good and Invoice have a many to many association but I want to show the count of each good in each invoice on class diagram. How can I show it?",
    "target": "uml;modeling;class diagram"
  },
  {
    "id": "_datascience.398",
    "source": "What to consider before learning a new language for data analysis <eos> I'm currently in the very early stages of preparing a new research-project (still at the funding-application stage), and expect that data-analysis and especially visualisation tools will play a role in this project.In view of this I face the following dilemma: Should I learn Python to be able to use its extensive scientific libraries (Pandas, Numpy, Scipy, ...), or should I just dive into similar packages of a language I'm already acquainted with (Racket, or to a lesser extent Scala)?(Ideally I would learn Python in parallel with using statistical libraries in Racket, but I'm not sure I'll have time for both)I'm not looking for an answer to this dilemma, but rather for feedback on my different considerations:My current position is as follows:In favour of Python:Extensively used librariesWidely used (may be decisive in case of collaboration with others)A lot of online material to start learning itConferences that are specifically dedicated to Scientific Computing with PythonLearning Python won't be a waste of time anywayIn favour of a language I already know:It's a way to deepen my knowledge of one language rather than getting superficial knowledge of one more language (under the motto: you should at least know one language really well)It is feasible. Both Racket and Scala have good mathematics and statistics librariesI can start right away with learning what I need to know rather than first having to learn the basicsTwo concrete questions:What am I forgetting?How big of a nuisance could the Python 2 vs 3 issue be?",
    "target": "python;visualization"
  },
  {
    "id": "_unix.108009",
    "source": "Weird escape sequence <eos> I need help identifying what this escape sequences represents. I see this sequence is autogenerating on my server's console, but I'm not sure what is the reason for that.Escape sequence:^[[[DI've checked this chart of escape sequences as reference: http://ascii-table.com/ansi-escape-sequences-vt-100.php , but haven't found anything matching.",
    "target": "console;tty;escape characters"
  },
  {
    "id": "_cs.10468",
    "source": "The importance of normal forms like Chomsky normal form for CFGs <eos> I understand that context-free grammars can be used to represent context-free languages.It might have ambiguities. We also have normal forms like Chomsky and Greibach normal form. I couldn't understand the need of that. Why they are important in the theory of languages? All the textbooks I referred to tell about these normal forms but not telling anything about their importance. ",
    "target": "formal languages;context free;formal grammars;normal forms"
  },
  {
    "id": "_unix.151723",
    "source": "Unable to mount root fs over NFS <eos> I am attempting to set up the first (of many) Raspberry Pis running Pidora (a Fedora Remix) to boot from an NFS share. It is my goal to eventually place a dozen or more Raspberry Pis in the datacenter I use to power several different services for my infrastructure and clients and hopefully replace some of the smaller VPS nodes that I am currently using. My configuration in cmdline.txt is: dwc_otg.lpm_enable=0 console=ttyAMA0,115200 console=tty1 root=/dev/nfs nfsroot=<serverip>:/fake/path,nolock ip=dhcp elevator=deadline rootwaitOn the Pi, the output I see is:IP-Config: Got DHCP answer from <router>, my address is <clientip>IP-Config: Complete:device=eth0, hwaddr=<macaddress>, ipaddr=<clientip>, mask=255.255.255.0, gw=<routerip>host=<clientip>, domain=, nis-domain=(none)bootserver=<routerip>, rootserver=<serverip>, rootpath=nameserver0=<routerip>(It pauses for a bit here)VFS: Unable to mount root fs via NFS, trying floppyVFS: Cannot open root device nfs or unknown-block(2,0); error -6Please append a correct root= boot option; here are the available partitions:.....The export configuration is:/fake/path        <clientip>(rw,no_root_squash,insecure,no_subtree_check)On the NFS Server (an OpenVZ Container), the output I see in the /var/log/messages is:Aug 22 23:24:01 vps-4178 rpc.mountd[928]: authenticated mount request from <clientip>:783 for /fake/path (/fake/path)Aug 22 23:24:38 vps-4178 rpc.mountd[928]: authenticated mount request from <clientip>:741 for /fake/path (/fake/path)Aug 22 23:25:25 vps-4178 rpc.mountd[928]: authenticated mount request from <clientip>:752 for /fake/path (/fake/path)Aug 22 23:26:12 vps-4178 rpc.mountd[928]: authenticated mount request from <clientip>:876 for /fake/path (/fake/path)To test, I've made sure I can mount (non-root) from both the Pi and another machine and it worked. Does anyone have an idea on what could be wrong or how to narrow it down? UPDATE:The process has gotten slightly further. The server is still showing the same message, however the client is now saying  is not responding, still trying.Here is the tcpdump (tcdump -vv 'port not 22') during the process:tcpdump: listening on venet0, link-type LINUX_SLL (Linux cooked), capture size 65535 bytes02:27:49.396600 IP (tos 0x0, ttl 50, id 56458, offset 0, flags [DF], proto UDP (17), length 144)    <clienthostname>.3541049940 > <serverhostname>.nfs: 116 read fh Unknown/01000401D2255200F6209D570C172001AA2F2645000000000000000000000000 4096 bytes @ 51609602:27:49.396694 IP (tos 0x0, ttl 64, id 22318, offset 0, flags [+], proto UDP (17), length 1500)    <serverhostname>.nfs > <clienthostname>.3541049940: reply ok 1472 read REG 100755 ids 0/0 sz 1630184 nlink 1 rdev ffffffff fsid 579d20f6 nodeid 120170c a/m/ctime 1408774668.892909 1404929018.000000 1408747025.20258902:27:49.396700 IP (tos 0x0, ttl 64, id 22318, offset 1480, flags [+], proto UDP (17), length 1500)    <serverhostname> > <clienthostname>: udp02:27:49.396701 IP (tos 0x0, ttl 64, id 22318, offset 2960, flags [none], proto UDP (17), length 1264)    <serverhostname> > <clienthostname>: udp02:27:49.396963 IP (tos 0x0, ttl 64, id 34369, offset 0, flags [DF], proto UDP (17), length 72)    <serverhostname>.57067 > <redacted2>.domain: [udp sum ok] 45505+ PTR? <redacted>.in-addr.arpa. (44)02:27:49.400054 IP (tos 0x0, ttl 60, id 0, offset 0, flags [DF], proto UDP (17), length 121)    <redacted2>.domain > <serverhostname>.57067: [udp sum ok] 45505 q: PTR? <redacted>.in-addr.arpa. 1/0/0 <redacted>.in-addr.arpa. PTR <clienthostname>. (93)02:27:49.400289 IP (tos 0x0, ttl 64, id 34372, offset 0, flags [DF], proto UDP (17), length 73)    <serverhostname>.51421 > <redacted2>.domain: [udp sum ok] 15808+ PTR? <redacted3>.in-addr.arpa. (45)02:27:49.401603 IP (tos 0x0, ttl 60, id 0, offset 0, flags [DF], proto UDP (17), length 115)    <redacted2>.domain > <serverhostname>.51421: [udp sum ok] 15808 q: PTR? <redacted3>.in-addr.arpa. 1/0/0 <redacted3>.in-addr.arpa. PTR <redacted2>. (87)02:27:50.496543 IP (tos 0x0, ttl 50, id 56459, offset 0, flags [DF], proto UDP (17), length 144)    <clienthostname>.3541049940 > <serverhostname>.nfs: 116 read fh Unknown/01000401D2255200F6209D570C172001AA2F2645000000000000000000000000 4096 bytes @ 51609602:27:50.496627 IP (tos 0x0, ttl 64, id 22319, offset 0, flags [+], proto UDP (17), length 1500)    <serverhostname>.nfs > <clienthostname>.3541049940: reply ok 1472 read REG 100755 ids 0/0 sz 1630184 nlink 1 rdev ffffffff fsid 579d20f6 nodeid 120170c a/m/ctime 1408774668.892909 1404929018.000000 1408747025.20258902:27:50.496634 IP (tos 0x0, ttl 64, id 22319, offset 1480, flags [+], proto UDP (17), length 1500)    <serverhostname> > <clienthostname>: udp02:27:50.496636 IP (tos 0x0, ttl 64, id 22319, offset 2960, flags [none], proto UDP (17), length 1264)    <serverhostname> > <clienthostname>: udp02:27:52.694985 IP (tos 0x0, ttl 50, id 56460, offset 0, flags [DF], proto UDP (17), length 144)    <clienthostname>.3541049940 > <serverhostname>.nfs: 116 read fh Unknown/01000401D2255200F6209D570C172001AA2F2645000000000000000000000000 4096 bytes @ 51609602:27:52.695058 IP (tos 0x0, ttl 64, id 22320, offset 0, flags [+], proto UDP (17), length 1500)    <serverhostname>.nfs > <clienthostname>.3541049940: reply ok 1472 read REG 100755 ids 0/0 sz 1630184 nlink 1 rdev ffffffff fsid 579d20f6 nodeid 120170c a/m/ctime 1408774668.892909 1404929018.000000 1408747025.20258902:27:52.695064 IP (tos 0x0, ttl 64, id 22320, offset 1480, flags [+], proto UDP (17), length 1500)    <serverhostname> > <clienthostname>: udp02:27:52.695066 IP (tos 0x0, ttl 64, id 22320, offset 2960, flags [none], proto UDP (17), length 1264)    <serverhostname> > <clienthostname>: udp02:27:57.105354 IP (tos 0x0, ttl 50, id 56461, offset 0, flags [DF], proto UDP (17), length 144)    <clienthostname>.3541049940 > <serverhostname>.nfs: 116 read fh Unknown/01000401D2255200F6209D570C172001AA2F2645000000000000000000000000 4096 bytes @ 51609602:27:57.105451 IP (tos 0x0, ttl 64, id 22321, offset 0, flags [+], proto UDP (17), length 1500)    <serverhostname>.nfs > <clienthostname>.3541049940: reply ok 1472 read REG 100755 ids 0/0 sz 1630184 nlink 1 rdev ffffffff fsid 579d20f6 nodeid 120170c a/m/ctime 1408774668.892909 1404929018.000000 1408747025.20258902:27:57.105456 IP (tos 0x0, ttl 64, id 22321, offset 1480, flags [+], proto UDP (17), length 1500)    <serverhostname> > <clienthostname>: udp02:27:57.105458 IP (tos 0x0, ttl 64, id 22321, offset 2960, flags [none], proto UDP (17), length 1264)    <serverhostname> > <clienthostname>: udp02:28:05.914058 IP (tos 0x0, ttl 50, id 56462, offset 0, flags [DF], proto UDP (17), length 144)    <clienthostname>.3541049940 > <serverhostname>.nfs: 116 read fh Unknown/01000401D2255200F6209D570C172001AA2F2645000000000000000000000000 4096 bytes @ 51609602:28:05.914130 IP (tos 0x0, ttl 64, id 22322, offset 0, flags [+], proto UDP (17), length 1500)    <serverhostname>.nfs > <clienthostname>.3541049940: reply ok 1472 read REG 100755 ids 0/0 sz 1630184 nlink 1 rdev ffffffff fsid 579d20f6 nodeid 120170c a/m/ctime 1408774668.892909 1404929018.000000 1408747025.20258902:28:05.914137 IP (tos 0x0, ttl 64, id 22322, offset 1480, flags [+], proto UDP (17), length 1500)    <serverhostname> > <clienthostname>: udp02:28:05.914138 IP (tos 0x0, ttl 64, id 22322, offset 2960, flags [none], proto UDP (17), length 1264)    <serverhostname> > <clienthostname>: udp02:28:07.014579 IP (tos 0x0, ttl 50, id 56463, offset 0, flags [DF], proto UDP (17), length 144)    <clienthostname>.3541049940 > <serverhostname>.nfs: 116 read fh Unknown/01000401D2255200F6209D570C172001AA2F2645000000000000000000000000 4096 bytes @ 51609602:28:07.014665 IP (tos 0x0, ttl 64, id 22323, offset 0, flags [+], proto UDP (17), length 1500)    <serverhostname>.nfs > <clienthostname>.3541049940: reply ok 1472 read REG 100755 ids 0/0 sz 1630184 nlink 1 rdev ffffffff fsid 579d20f6 nodeid 120170c a/m/ctime 1408774668.892909 1404929018.000000 1408747025.20258902:28:07.014672 IP (tos 0x0, ttl 64, id 22323, offset 1480, flags [+], proto UDP (17), length 1500)    <serverhostname> > <clienthostname>: udp02:28:07.014674 IP (tos 0x0, ttl 64, id 22323, offset 2960, flags [none], proto UDP (17), length 1264)    <serverhostname> > <clienthostname>: udp02:28:09.216009 IP (tos 0x0, ttl 50, id 56464, offset 0, flags [DF], proto UDP (17), length 144)    <clienthostname>.3541049940 > <serverhostname>.nfs: 116 read fh Unknown/01000401D2255200F6209D570C172001AA2F2645000000000000000000000000 4096 bytes @ 51609602:28:09.216102 IP (tos 0x0, ttl 64, id 22324, offset 0, flags [+], proto UDP (17), length 1500)    <serverhostname>.nfs > <clienthostname>.3541049940: reply ok 1472 read REG 100755 ids 0/0 sz 1630184 nlink 1 rdev ffffffff fsid 579d20f6 nodeid 120170c a/m/ctime 1408774668.892909 1404929018.000000 1408747025.20258902:28:09.216107 IP (tos 0x0, ttl 64, id 22324, offset 1480, flags [+], proto UDP (17), length 1500)    <serverhostname> > <clienthostname>: udp02:28:09.216109 IP (tos 0x0, ttl 64, id 22324, offset 2960, flags [none], proto UDP (17), length 1264)    <serverhostname> > <clienthostname>: udp",
    "target": "linux;mount;nfs;startup;root filesystem"
  },
  {
    "id": "_unix.275732",
    "source": "building a uefi-secure boot debian-USB <eos> I assume that there already is something where exactly my problem was discussed years ago, but after spending too much time searching I try my luck here, I hope you can help me or atleast show me the right links to get my information from.Target: Debian with secure boot on USBSome Links I base my progress onrodsbooks efi-bootloaders installationrodsbooks efi-bootloaders secureboothttps://wiki.ubuntu.com/SecurityTeam/SecureBootSteps so far:# download debian8.4-netinstall (official link)wget http://cdimage.debian.org/debian-cd/8.4.0/amd64/iso-cd/debian-8.3.0-amd64-netinst.isomkdir debNet   # extract isobsdtar -C debNet -xf debian-8.4.0-amd64-netinst.isols debNet>autorun.inf  doc        install      pool                 README.txt>boot         efi        install.amd  README.html          setup.exe>css          firmware   isolinux     README.mirrors.html  tools>debian       g2ldr      md5sum.txt   README.mirrors.txt   win32-loader.ini>dists        g2ldr.mbr  pics         README.sourceAs described by rodsbooks,I should now rename EFI/BOOT/bootx64.efi to EFI/BOOT/grubx64.efimove shim.efi to EFI/BOOT/bootx64.efimove MokManager.efi to EFI/BOOT/make some nice magic with keys and signing, tadaa, you're done.To make an bootable USB, I take the following stepssources=debNetoutISO=debian8.4.0.modified.isorelative_isolinuxbin=isolinux/isolinux.binxorriso -as mkisofs \\    -isohybrid-mbr /usr/lib/syslinux/isohdpfx.bin   \\    -c boot.cat \\    -b $relative_isolinuxbin \\    -no-emul-boot -boot-load-size 4 -boot-info-table -eltorito-alt-boot \\    -e boot/grub/efi.img -no-emul-boot -isohybrid-gpt-basdat \\    -o $outISO $sourcessudo dd if=debian8.4.0.modified.iso of=/dev/sdbIf I had any idea what I was doing before (just getting uefi to run), I would have seen that I use efi.img. So it took some time experimenting with  debNet/efi/boot to find that adding or changing of even deleting this directory does not change booting at all. (maybe deleting the directory corrupts the installation - didnt try - but not the booting)So, I finally understood I have to change debNet/boot/grub/efi.img. So here's my main question so far - how do I create this efi.img for my needs?dd if=/dev/zero of=efi.img bs=1k count=3000mkfs.vfat efi.imgsudo mount efi.img img_mountpoint/and copying the bootloaders as described in rodsbooks does not seem to work.If have information for me would be quite nice.",
    "target": "debian;uefi;secure boot"
  },
  {
    "id": "_unix.333350",
    "source": "Can't delete file on MTP device <eos> Using libmtp and mtp-tools to copy files from an MTP device(camera) over usb.I can copy files but when I try and delete using the following commandsudo mtp-delfile -n <File ID>I get the following errorFailed to delete file:3 Error 2: PTP Layer error 200e:  LIBMTP_Delete_Object(): could not delete object. Error 2: Error 200e:  PTP: Store Read Only",
    "target": "usb;mtp;delete"
  },
  {
    "id": "_cogsci.5068",
    "source": "Psychology behind repeated viewing of certain pictures and songs <eos> Often it happens that we like to frequently listen to a particular tune or song or view some pictures or images repeatedly time after time. What are the reasons and psychology behind this?",
    "target": "cognitive psychology;perception;music;aesthetics"
  },
  {
    "id": "_unix.85700",
    "source": "How to set what field names are displayed in listings? <eos> When I execute a command in Ubuntu, which results in a listing, I get results without the field names. Example is ls -l or ps l. I am not very experienced and always need to go digging through man pages and online documentation. And the names are quite crypcit already.Is there a way to turn on field name listing globally i.e. for all commands?Note: actually ps l shows field names, while ls -l does not. It is true that the second is very trivial. However, the question stands - is there a way to overwrite this behaviour?",
    "target": "command line;configuration;ls;ps"
  },
  {
    "id": "_webapps.42234",
    "source": "Is it possible to get a PayPal Sandbox account without creating a PayPal account? <eos> Recently PayPal changed their Sandbox account section. Now it asks for a real PayPal account to get into the Sandbox account. As I don't have a PayPal account, is there any way to get back into my Sandbox account without creating a PayPal account? Or are there any demo accounts available?",
    "target": "paypal"
  },
  {
    "id": "_unix.200477",
    "source": "how to install a src .rpm <eos> I downloaded a source rmp src.rpm file of audacity when i run [root@09PC148B Downloads]# rpmbuild --rebuild audacity-2.1.0-2.fc23.src.rpmthis is the response i am getting flac-devel is needed by audacity-2.1.0-2.el6.i686    jack-audio-connection-kit-devel is needed by audacity-2.1.0-2.el6.i686    ladspa-devel is needed by audacity-2.1.0-2.el6.i686    libid3tag-devel is needed by audacity-2.1.0-2.el6.i686    taglib-devel is needed by audacity-2.1.0-2.el6.i686    libogg-devel is needed by audacity-2.1.0-2.el6.i686    libsndfile-devel is needed by audacity-2.1.0-2.el6.i686    libvorbis-devel is needed by audacity-2.1.0-2.el6.i686    portaudio-devel >= 19-16 is needed by audacity-2.1.0-2.el6.i686    soundtouch-devel is needed by audacity-2.1.0-2.el6.i686    soxr-devel is needed by audacity-2.1.0-2.el6.i686    vamp-plugin-sdk-devel >= 2.0 is needed by audacity-2.1.0-2.el6.i686    wxGTK-devel is needed by audacity-2.1.0-2.el6.i686    libappstream-glib is needed by audacity-2.1.0-2.el6.i686when i run this command [root@09PC148B Downloads]# rpm -ivv audacity-2.1.0-2.fc23.src.rpmmy resonse is D: ============== audacity-2.1.0-2.fc23.src.rpmD: loading keyring from pubkeys in /var/lib/rpm/pubkeys/*.keyD: couldn't find any keys in /var/lib/rpm/pubkeys/*.keyD: loading keyring from rpmdbD: opening  db environment /var/lib/rpm cdb:mpool:joinenvD: opening  db index       /var/lib/rpm/Packages rdonly mode=0x0D: locked   db index       /var/lib/rpm/PackagesD: opening  db index       /var/lib/rpm/Name rdonly mode=0x0D:  read h#    1438 Header sanity check: OKD: added key gpg-pubkey-6b8d79e6-3f49313d to keyringD: Using legacy gpg-pubkey(s) from rpmdbD: Expected size:     24389466 = lead(96)+sigs(4292)+pad(4)+data(24385074)D:   Actual size:     24389466D: audacity-2.1.0-2.fc23.src.rpm: Header SHA1 digest: OK (6b5705fc00764be7bc14578e1976d33d86ac2a3d)D:  added source package [0]D: found 1 source and 0 binary packagesD: Expected size:     24389466 = lead(96)+sigs(4292)+pad(4)+data(24385074)D:   Actual size:     24389466D: InstallSourcePackage at: psm.c:244: Header SHA1 digest: OK (6b5705fc00764be7bc14578e1976d33d86ac2a3d)audacity-2.1.0-2.fc23D: ========== Directories not explicitly included in package:D:          0 /root/rpmbuild/SOURCES/D:          1 /root/rpmbuild/SPECS/D: ==========D: fini      100664  1 ( 501, 501)  19390331 /root/rpmbuild/SOURCES/audacity-manual-2.1.0.zip;55486cb6 unknownD: fini      100664  1 ( 501, 501)   5104924 /root/rpmbuild/SOURCES/audacity-minsrc-2.1.0.tar.xz;55486cb6 unknownD: fini      100644  1 ( 501, 501)     23062 /root/rpmbuild/SPECS/audacity.spec;55486cb6 unknownGZDIO:    2994 reads, 24518844 total bytes in 0.074680 secsD: closed   db index       /var/lib/rpm/NameD: closed   db index       /var/lib/rpm/PackagesD: closed   db environment /var/lib/rpmwhat is the error how to fix this regardsAGXIN.J",
    "target": "software installation"
  },
  {
    "id": "_webmaster.10488",
    "source": "Information about links disappeared from Webmaster Tools <eos> I discovered that all information about links to my site disappeared from Google Webmaster Tools. Last time I checked the Links to your site page in GWT there was nice list of linking domains and all. But now there is only No data available. There were no changes to the site contents.Why could it be? And what can I do to fix this?About a month earlier I found that PR of all my pages dropped by 2 points. May these changes be related? ",
    "target": "pagerank;google search console;backlinks"
  },
  {
    "id": "_webapps.84227",
    "source": "IMPORTDATA Google Sheet CSV on Google Drive <eos> So I'm starting to really get into utilizing Google Drive to streamline my many personal projects.  One of the things I'd love to do is figure out how to download CSV files onto my Google Drive, and have Google Sheets automatically do an =IMPORTDATA on any new .csv files in a specific directory.I've come across a number of problems trying to figure this out, but the biggest issue is that putting any kind of file on the Google Drive doesn't give you a link to the file itself, but rather something like such:https://drive.google.com/a/xxxx/file/x/xxxxxxxxxxxxxxxx/view?usp=sharing=IMPORTDATA doesn't recognize this as a .csv file.  How can I go about doing this?",
    "target": "google spreadsheets;google drive;csv"
  },
  {
    "id": "_unix.125009",
    "source": "Need to run su command If I am a user with sudo access <eos> I am a user in Oracle Linux server with sudo access. If I run su command, system prompts for password. When I input my account password, system gives message Incorrect password while I login successfully with the same password. Why is it happening? Need to execute su or sudo command after login if I have sudo access? Need to prefix sudo with every command?",
    "target": "sudo;oracle linux"
  },
  {
    "id": "_unix.118211",
    "source": "if/then/else man page <eos> I would like to know if there is any man page documenting the construction of the most basic script commands like if/then/else, while, for each, and all the relative switches, like -eq, -e, -ge, and so on.",
    "target": "shell;scripting;man;documentation"
  },
  {
    "id": "_unix.22367",
    "source": "Where are NetworkManager's WiFi settings stored? <eos> I remember the days of playing with /etc/$WE/wpa_supplicant.conf to try and force a semi-secure network on a debian based system, but now on to xubuntu, I haven't needed to do any *.conf-ing in a while (in terms of networking)As such, I'm interested to know; How do the nm gui's store network information? Can this be backed up or exported as a wpa_supplicant.conf file?",
    "target": "ubuntu;networking;wifi;networkmanager;xubuntu"
  },
  {
    "id": "_unix.72279",
    "source": "How do I recover files from a single degraded mdadm raid1 drive? not enough to start the array <eos> Given a single raid1 drive in degraded/rebuilding state, can it be force mounted?  I'd like to recover all the files before undertaking the dangerous operation of pairing it and rebuilding.  As far as I can tell the drive is in perfectly good shape, fully intact. The pair drive is partly failed.If the drive was not in rebuilding state I'd know exactly what to do. Here is what I have tried:# mdadm --verbose --assemble /dev/md8 /dev/sdb1  --forcemdadm: looking for devices for /dev/md8mdadm: /dev/sdb1 is identified as a member of /dev/md8, slot 1.mdadm: no uptodate device for slot 0 of /dev/md8mdadm: added /dev/sdb1 to /dev/md8 as 1mdadm: /dev/md8 assembled from 0 drives and  1 rebuilding - not enough to start the array.# cat /proc/mdstat                       md8 : inactive sdb1[1](S)      976759808 blocks super 1.2          md0 : active raid1 sdc1[0]      976759672 blocks super 1.2 [2/1] [U_]# mdadm --stop /dev/md8mdadm: stopped /dev/md8# mount /dev/sdb1 /mnt/temp2mount: unknown filesystem type 'linux_raid_member'# mount -o ro -t ext3 -b 2048 /dev/sdb1 /mnt/temp1mount: wrong fs type, bad option, bad superblock on /dev/sdb1.# foremost -i /dev/sdb -o /tmp/foo    (this results in perfectly good files)In this particular case the foremost command recovers files, so something is definitely on the drive, if I could only get the superblock offset correct.And in this particular case assembling both halves of the array crashes the kernel(!), so that's not a real option anyway (aside from the safety issues).UPDATE: added output of mdadm# mdadm --examine /dev/sdb1/dev/sdb1:          Magic : a92b4efc        Version : 1.2    Feature Map : 0x2     Array UUID : e00a291e:016bbe47:09526c90:3be48df3           Name : ubuntu:0  Creation Time : Wed May 11 12:26:39 2011     Raid Level : raid1   Raid Devices : 2 Avail Dev Size : 1953519616 (931.51 GiB 1000.20 GB)     Array Size : 1953519344 (931.51 GiB 1000.20 GB)  Used Dev Size : 1953519344 (931.51 GiB 1000.20 GB)    Data Offset : 2048 sectors   Super Offset : 8 sectorsRecovery Offset : 0 sectors          State : clean    Device UUID : 41346f44:ccacbbf7:0c17c133:eb7b341f    Update Time : Sat Apr 13 00:02:08 2013       Checksum : 483a0a44 - correct         Events : 402833   Device Role : Active device 1   Array State : AA ('A' == active, '.' == missing)",
    "target": "data recovery;software raid;mdadm"
  },
  {
    "id": "_cstheory.2681",
    "source": "Algorithm for finding similar images <eos> If you go to FFFFOUND! and click on some image you will notice that on the new page, under the image, there is a section called You may like these images. which suggests 10 images that look similar to the original.What would be a good algorithm to achieve this functionality for a collection of images?Any documentation, books, etc. related to such algorithms is very appreciated. Also algorithms for finding similar images that yield better results than those seen on FFFFOUND! website are also welcome.",
    "target": "ds.algorithms;reference request"
  },
  {
    "id": "_codereview.144900",
    "source": "Object-oriented Brainfuck interpreter <eos> Inspired by this question, I decided to give it a try and implemented a brainfuck interpreter myself. It includes various improvements:It's object-oriented and modularUnlimited tape sizeIt includes a call stack (no seeking for opening parenthesis)It allows stepping and debuggingIt throws exceptions on errorsTape/// <summary>/// One-sided, infinite, default-initialized Tape. </summary>public class Tape<T>{    List<T> _tape;    int _pos;    public Tape()    {        _tape = new List<T>();        _tape.Add(default(T));        _pos = 0;    }    /// <summary>    /// Currently selected cell's value. </summary>    public T Value    {        get        {            return _tape[_pos];        }        set        {            _tape[_pos] = value;        }    }    /// <summary>    /// Step one cell to the left. </summary>    public void StepLeft()    {        if (_pos == 0)            throw new InvalidOperationException();        else            _pos--;    }    /// <summary>    /// Step one cell to the right. </summary>    public void StepRight()    {        _pos++;        if (_pos == _tape.Count)            _tape.Add(default(T));    }    /// <summary>    /// Return a full snapshot of the tape without altering anything. </summary>    public T[] ToArray()    {        return _tape.ToArray();    }}Interpreterpublic class BrainfuckInterpreter{        Stream _program;    Stream _input;    Stream _output;    Tape<byte> _tape;    Stack<long> _callStack;    /// <summary>    /// Create a new BrainfuckInterpreter. </summary>    /// <param name=program>    /// Program to be executed. Must be readable and seekable.    /// <param name=input>    /// Must be readable. Can be null if the program doesn't take any input. </param>    /// <param name=output>    /// Must be writable. Can be null if the program doesn't produce output. </param>    public BrainfuckInterpreter(Stream program, Stream input, Stream output)    {        _program = program;        _input = input;        _output = output;        _tape = new Tape<byte>();        _callStack = new Stack<long>();    }    /// <summary>    /// Run the program until it terminates. </summary>    public void Run()    {        while (Step());    }    /// <summary>    /// Execute the next command. </summary>    /// <returns>    /// False if the program terminated. True otherwise. </returns>    public bool Step()    {        int command = _program.ReadByte();        switch (command)        {            default: throw new ArgumentException(); // Invalid command            case -1: return false; // End reached            case '+': _tape.Value++; break;            case '-': _tape.Value--; break;            case ',':                int input = _input.ReadByte();                if (input == -1) // Null-termination instead of error status                    _tape.Value = 0;                else                    _tape.Value = (byte)input;                break;            case '.': _output.WriteByte(_tape.Value); break;            case '>': _tape.StepRight(); break;            case '<': _tape.StepLeft(); break;            case '[': _callStack.Push(_program.Position); break;            case ']':                if (_tape.Value == 0)                    _callStack.Pop();                else                    _program.Position = _callStack.Peek();                break;        }        return true;    }    /// <summary>    /// Print the tape for debug purposes.    /// Format (hex): |XX|XX|XX|...|XX| </summary>    public string Print()    {        string result = |;        foreach (var n in _tape.ToArray())        {            result += String.Format({0:X2}|, n);        }        return result;    }}Main routine (for testing)Takes the program directly (not a filename) as first command line argument. Prints the tape's contents to stderr after each step.public static class Program{    public static void Main(string[] args)    {        Stream program = new MemoryStream(args[0].Select(c => (byte)c).ToArray());        var bf = new BrainfuckInterpreter(            program,            Console.OpenStandardInput(),            Console.OpenStandardOutput()        );        while (bf.Step())        {            Console.Error.WriteLine(bf.Print());        }    }}",
    "target": "c#;interpreter;brainfuck"
  },
  {
    "id": "_webapps.43193",
    "source": "My work profile changed <eos> My work profile changed to being formerly employed as an employee health nurse at Metro health hospital. I never changed this. Could facebook have changed their format and just added this?It usually reads worked at Metro health hospital.",
    "target": "facebook;privacy"
  },
  {
    "id": "_softwareengineering.93107",
    "source": "How to decide maintenance cost/terms for freelance work? <eos> I am a JavaScript programmer and am planning to take Freelance projects related to JavaScript effects for the web. Recently a potential client approached me to create a JavaScript effect for his website. The effect was quite complex and it was not generic. That is, every time the design of the website would change the JavaScript code would have to be modified.Due to this nature of the code, I told the client that I will not be able to provide maintenance for this project. I will be happy to modify the code in the future but I will be doing the cost estimation each time there is a modification. The client was not happy with this. I thought of calculating the probability of the modifications the client may ask per year and multiply the initial estimate by that so that the maintenance becomes free. For example, if the cost of the initial project is $100 and I assume that the client will ask me to modify the code 4 times a year I would charge him $ (100 + 4*100). But I think this would be way too much and the client would deny to pay such a high amount.I have just started freelancing and the cost estimation part related to maintenance confuses me a lot. What is a good way to estimate maintenance cost. Also suggestions on maintenance terms like what should be the scope would be useful.",
    "target": "freelancing;maintenance;pricing"
  },
  {
    "id": "_codereview.61712",
    "source": "Using large amounts of if-else statements for playing card numbers <eos> I have a method that uses a bunch of if-else statements, and I am thinking how I could simplify it.public static CardNumber decode(String s) {    if(s == null) {        return null;    } else if(s.equalsIgnoreCase(ACE.toString())) {        return ACE;    } else if(s.equalsIgnoreCase(TWO.toString())) {        return TWO;    } else if(s.equalsIgnoreCase(THREE.toString())) {        return THREE;    } else if(s.equalsIgnoreCase(FOUR.toString())) {        return FOUR;    } else if(s.equalsIgnoreCase(FIVE.toString())) {        return FIVE;    } else if(s.equalsIgnoreCase(SIX.toString())) {        return SIX;    } else if(s.equalsIgnoreCase(SEVEN.toString())) {        return SEVEN;    } else if(s.equalsIgnoreCase(EIGHT.toString())) {        return EIGHT;    } else if(s.equalsIgnoreCase(NINE.toString())) {        return NINE;    } else if(s.equalsIgnoreCase(TEN.toString())) {        return TEN;    } else if(s.equalsIgnoreCase(JACK.toString())) {        return JACK;    } else if(s.equalsIgnoreCase(QUEEN.toString())) {        return QUEEN;    } else if(s.equalsIgnoreCase(KING.toString())) {        return KING;    } else {        return null;    }}The whole class is here:public class CardNumber {    private final String name;    private final int value;    public static final CardNumber ACE_AS_ONE = new CardNumber(A, 1);    public static final CardNumber TWO = new CardNumber(2, 2);    public static final CardNumber THREE = new CardNumber(3, 3);    public static final CardNumber FOUR = new CardNumber(4, 4);    public static final CardNumber FIVE = new CardNumber(5, 5);    public static final CardNumber SIX = new CardNumber(6, 6);    public static final CardNumber SEVEN = new CardNumber(7, 7);    public static final CardNumber EIGHT = new CardNumber(8, 8);    public static final CardNumber NINE = new CardNumber(9, 9);    public static final CardNumber TEN = new CardNumber(10, 10);    public static final CardNumber JACK = new CardNumber(J, 11);    public static final CardNumber QUEEN = new CardNumber(Q, 12);    public static final CardNumber KING = new CardNumber(K, 13);    public static final CardNumber ACE = new CardNumber(A, 14);    private CardNumber(String name, int value) {        this.name = name;        this.value = value;    }    @Override    public String toString() {        return name;    }    public static CardNumber decode(String s) {        if(s == null) {            return null;        } else if(s.equalsIgnoreCase(ACE.toString())) {            return ACE;        } else if(s.equalsIgnoreCase(TWO.toString())) {            return TWO;        } else if(s.equalsIgnoreCase(THREE.toString())) {            return THREE;        } else if(s.equalsIgnoreCase(FOUR.toString())) {            return FOUR;        } else if(s.equalsIgnoreCase(FIVE.toString())) {            return FIVE;        } else if(s.equalsIgnoreCase(SIX.toString())) {            return SIX;        } else if(s.equalsIgnoreCase(SEVEN.toString())) {            return SEVEN;        } else if(s.equalsIgnoreCase(EIGHT.toString())) {            return EIGHT;        } else if(s.equalsIgnoreCase(NINE.toString())) {            return NINE;        } else if(s.equalsIgnoreCase(TEN.toString())) {            return TEN;        } else if(s.equalsIgnoreCase(JACK.toString())) {            return JACK;        } else if(s.equalsIgnoreCase(QUEEN.toString())) {            return QUEEN;        } else if(s.equalsIgnoreCase(KING.toString())) {            return KING;        } else {            return null;        }    }    public int getValue() {        return value;    }}",
    "target": "java;strings;playing cards"
  },
  {
    "id": "_codereview.25123",
    "source": "Extracting data from a Word document is too slow <eos> I have a 100page long .docx format document. I'm using a macro written in VBS to extract some information and then just generate a table from them.  I iterate through the paragraphs and store the found strings in 3 separate arrays.However, the loop is unreasonably slow. It takes 3 min to complete on a relatively fast computer. Can you take a look at it and tell me what causes this slowness?'TODO : Add checks, exception handling, dynamic user options, probes, style checks, and fix slowness.Sub genTable()Dim objDoc'''''''''''''''''''''Modify these''''''''''''''''Dim ColumnName1, ColumnName2, ColumnName3, magicStringColumnName1 = foo1ColumnName2 = foo2ColumnName3 = foo3magicString = ASD321:  ' we search for this stringSet objDoc = ActiveDocument ' Because we run inside of word as macro''''''''''''''''''''''''''''''''''''''''''''''''''Const MAX = 200 ' using fixed sized arrays, mod this if you'll have more than 200 entries.Dim vulnerabilityArr(MAX) ' initializing the arraysDim severityArr(MAX)Dim paragraphArr(MAX)Dim counter ' will count the processed entries in thiscounter = 0Dim currParagraph ' will be set in loopDim tmpArray() As String ' for splitting    For pIndex = 1 To objDoc.Paragraphs.Count ' THIS LOOP IS SLOW        currParagraph = objDoc.Paragraphs(pIndex)        currParagraph = Left(currParagraph, Len(currParagraph) - 1) 'remove junk character        If InStr(1, currParagraph, magicString) > 0 Then ' assuming this string is always present and the other two target data is near it            tmpArray = Split(currParagraph) ' extract level            currParagraph = objDoc.Paragraphs(pIndex - 1) 'assuming the previous paragraph is the vuln. name            'Storing the 3 extracted data            vulnerabilityArr(counter) = currParagraph            severityArr(counter) = tmpArray(1)            paragraphArr(counter) = objDoc.Paragraphs(pIndex - 1).Range.ListFormat.ListString ' for some weird reason I cant use currParagraph here            counter = counter + 1 ' adjusting index        End If    Next pIndexobjDoc.Tables.Add objDoc.Paragraphs(objDoc.Paragraphs.Count).Range, counter, 3, True, TrueSet objTable = objDoc.Tables(objDoc.Tables.Count) 'select last tableobjTable.Cell(1, 1).Range.Text = ColumnName1objTable.Cell(1, 2).Range.Text = ColumnName2objTable.Cell(1, 3).Range.Text = ColumnName3For RowIndex = 0 To counter    objTable.Cell(RowIndex, 1).Range.Text = paragraphArr(RowIndex)    objTable.Cell(RowIndex, 2).Range.Text = vulnerabilityArr(RowIndex)    objTable.Cell(RowIndex, 3).Range.Text = severityArr(RowIndex)    Next    RowIndexy = RowIndex + 1objTable.AutoFormat (25)End Sub",
    "target": "performance;vba;vbscript;ms word"
  },
  {
    "id": "_cs.64511",
    "source": "Relation between Lattice and Boolean Algebra <eos> In discrete math, I have read that lattice is a generalized form of boolean lattice. But those places where boolean algebra is mentioned, they don't tell about lattices (digital logic, binary,...). Whether the meet and join is same as and and or in boolean logic? If we are thinking in terms of lattices how you define 1 and 0 = 0? We consider only a two element lattice?",
    "target": "discrete mathematics;boolean algebra;lattices"
  },
  {
    "id": "_softwareengineering.274143",
    "source": "How to efficiently determine when changes occur in event lists <eos> We have a system that stores event information.There is a primary list of events as well as a secondary list, these may overlap.Secondary lists are combined with the primary based on 3 main rules.Default - only displayed when no events are currentEvents - only displayed when primary events are currentOverride - displayed in stead of eventsA new 3rd party system we have to integrate with means we need to get each of the different states throughout the days of what events/secondary events should be showing.Eg, from 9-5 these events are current based on the timings/ rules, but then after 5 these events are current based on the timings and rules.A simple examplePrimary EventsEvent alpha | 10:30 - 14:30Event bravo | 14:00 - 16:00Event charlie | 18:30 - 20:00Secondary EventsEvent zulu | 00:00 - 23:59 | defaultEvent yankee | 09:00 - 11:00 | defaultEvent xray | 09:00 - 11:30 | eventsEvent whiskey | 19:00 - 19:15 | overrideJust on this very small example this would result as the following lists that we would need to generate00:00-09:00Event zulu09:00-10:30Event zuluEvent yankee10:30-11:30Event alphaEvent xray11:30-14:00Event alpha14:00-14:30Event alphaEvent bravo14:30-16:00Event bravo16:00-18:30Event zulu18:30-19:00Event charlie19:00-19:15Event whiskey19:15-20:00Event charlie20:00-23:59Event zuluThis is a tiny example in production there is usually hundreds to thousands of events over many days. At present the only end points deal with this problem dynamically on the fly, this third party system requires we provide the data in this way.It's all written in php, and we have the primary and secondary event lists in an array each.What is the most efficient way of making these lists ?We have considered doing a minute by minute check, but this seems horribly inefficient and I'm hoping there is a better way. ",
    "target": "php;sorting"
  },
  {
    "id": "_softwareengineering.293702",
    "source": "C# - design to parse and write csv and manipulating data <eos> I've designed the below code for one of the requirement. I have to write different tests for the code and I would need feedback on where I can improve the design. Requirement: Read the customer details from csv, calculate his average expenses on different items on yearly and write to csv again. Read the customer details from csv, calculate his total expenses on faimly and write to csv again.As both the ExpenseCalculator uses CsvReaderWriter function, is it better to create the abstract class which implements csvReaderWriter functionality and derive from abstract class or is it better to use Interface?      public class Customer{    public string FirstName { get; set; }    public string LastName { get; set; }    public int Expenses { get; set; }    // other details}public interface ICsvReaderWriter<T>{    IEnumerable<T> ParseCsv(string filePath);    void WriteCsv(string filePath, IEnumerable<Customer> customers);}public class ReaderWriter : ICsvReaderWriter<Customer>{    public IEnumerable<Customer> ParseCsv(string filePath)    {        throw new NotImplementedException();    }    public void WriteCsv(string filePath, IEnumerable<Customer> customers )    {        throw new NotImplementedException();    }}public interface IExpenseCalculator{    void CalculateExpenses(string filePath);}public class ItemExpenseCalculator : IExpenseCalculator{    private readonly ICsvReaderWriter<Customer> _csvReaderWriter;    public ItemExpenseCalculator(ICsvReaderWriter<Customer> csvReaderWriter)    {        this._csvReaderWriter = csvReaderWriter;    }    public void CalculateExpenses(string filePath)    {        var customers = _csvReaderWriter.ParseCsv(filePath);        // do manipulation        _csvReaderWriter.WriteCsv(filePath, customers);    }}public class FamilyExpenseCalculator: IExpenseCalculator{    private readonly ICsvReaderWriter<Customer> _csvReaderWriter;    public FamilyExpenseCalculator(ICsvReaderWriter<Customer> csvReaderWriter)    {        this._csvReaderWriter = csvReaderWriter;    }    public void CalculateExpenses(string filePath)    {        var customers = _csvReaderWriter.ParseCsv(filePath);        // do manipulation        _csvReaderWriter.WriteCsv(filePath, customers);    }}public class Program{    private void Main()    {        IExpenseCalculator itemExpenseCalculator = new ItemExpenseCalculator(new ReaderWriter());        itemExpenseCalculator.CalculateExpenses(@D:\\);        IExpenseCalculator familyExpenseCalculator = new FamilyExpenseCalculator(new ReaderWriter());        familyExpenseCalculator.CalculateExpenses(@D:\\);    }}",
    "target": "c#"
  },
  {
    "id": "_unix.220229",
    "source": "Set CPU affinity for the specific program? <eos> How can I set CPU affinity for the specific program (say gzip) to always run on specific core or cores (core 1, for example)?I read about taskset, but can it be used before program is actually used and creates a process?",
    "target": "cpu;cpu frequency;cpu usage"
  },
  {
    "id": "_cstheory.18556",
    "source": "maximize MST(G[S]) over all induced subgraphs G[S] in a metric graph <eos> Has this problem been studied before?Given a metric undirected graph G (edge lengths satisfy triangle inequality), find a set S of vertices such that MST(G[S]) is maximized, where MST(G[S]) is the minimum spanning tree of the subgraph induced by S. Has this problem been studied before? Is it NP-hard? Thanks a lot.",
    "target": "ds.algorithms;graph algorithms;np hardness;approximation algorithms"
  },
  {
    "id": "_unix.180853",
    "source": "How to upload to a unix server? <eos> Im a part of a project group, and one of our tasks is to upload some content to a server. I am completely new to this and have some questions.There are content on different servers(distributed on several servers). My task is to get all the content, and upload them on a single server, and make them available for others, e.g everybody that visits that server(by website) should be able to download the content.How does one do that in a UNIX server? And how do I make them available for others?I have no experience with servers, but I have experience with Java(also Java EE). What do I need to learn to be able to do these tasks?Ill be getting an account for the server soon, which will give me access to it.Please, if the question is in wrong place, or it violates any rules, let me know.Thanks.",
    "target": "linux;files;webserver;file server"
  },
  {
    "id": "_cs.71992",
    "source": "Using Induction to prove that $n^3log^4n=O(n^4)$ <eos> I need to prove the following asymptotic relation for the purpose of cacluating a recurrence relation:$$n^3log^4n=O(n^4)$$I tried and failed to do it with induction, which, if possible using basic Calculus 1 level math, I would like you to help me with.I am not required to do it with induciton or anything, I just wondered if I can do it.I was able to prove it though, in a differet manner:$$f \\in o(g) \\Rightarrow f \\in O(g)$$$$lim_{n\\to \\infty} \\frac{n^3log^4n}{n^4}=0$$Using L'Hpital's rule 4 times, which proves that:$$n^3log^4n=o(n^4)$$By the definitino of $o$.Therefore it also follows that $$n^3log^4n=O(n^4)$$For the basis of the induction let $n=1$ and with $c=1$:$$f(1) = 1^3log^4(1) = 0 \\leq 1=1^4 \\cdot 1=c \\cdot g(1)$$From here I think that it would be enough to show that:$$log^4(n) \\leq n$$Although I am not sure how to continue from here.",
    "target": "asymptotics;recurrence relation;induction"
  },
  {
    "id": "_cs.16716",
    "source": "Determining Length of a walk in Nondeterministic Finite Automata with Lambda Transitions <eos> I am learning about CS Theory and specifically Nondeterministic Finite Automata (NFA) right now. In my book I came across a section of text that discussed a way to determine the length of a walk stating specifically that :If a transition graph has a walk labeled $w$, then there is a walk w of length no more than $\\Lambda + (1 + \\Lambda)|w|$ where $\\Lambda$ is the number of $\\lambda$ transitions in the graph.The book does not define $|w|$ which is causing part of my confusion. I'm assuming $|w|$ is the length of the label of the walk. So in this case it would be 1 when going from $q_1 \\to q_0 \\to q1$ because $a$ is the only labeled edge.I am trying to understand this concept and how it works because when I have tested out this claim it has not held true.Here is the test I did with this NFA$q_1$ is the final state. So assuming you were trying to find the length of the walk $a$, the label would indicate that the length is 1 (e.g. $\\delta^* (q_1, a)$) . However due to the lambdas you actually have $\\lambda \\lambda a$ to go from $q_1 \\to q_0 \\to q_1$.This theorem doesn't hold with my math though because it is defined as  + (1 + )|w| where  is the number of -edges in the graph.Since there are two -edges (and it doesn't state whether it means -edges in the walk itself or in the graph in total...) this would then be 2 + (1 + 2)|w|. So thats 2 + 3|w|. This clearly is more than 3, which is the length of q1 -> q1 of a.What am I missing here? Any help is greatly appreciated.This comes from Peter Linz An Introduction to Formal Languages and Automata 5th edition.Some more information about the argument for this claim:While -edges may be repeated, there is always a walk in which every repeated -edge is separated by an edge labeled with a nonempty symbol. Otherwise, the walk contains a cycle labeled , which can be replaced by a simple path without changing the label of the walk.Also the book never names this as a theorem or lemma or anything of the sort so it has been very difficult to find online resources about this topic.",
    "target": "graph theory;finite automata;nondeterminism"
  },
  {
    "id": "_softwareengineering.314129",
    "source": "Node.js dependencies weigh too much <eos> Recently I started playing with node.js.Now, every node tutorial out there states that you should start withnpm initand then, say you want some standard server framework, say you choose express:npm install expressbut then you'll want many more things you are used to from worlds like ASP.NET.I talk about template engines (jade) and stylesheet pre-processors (SASS).And then they tell you install gulp/grunt! so you can minify and uglify and run the server and so many other things automatically!And that means installing gulp, node-sass, and gulp-sass, and gulp-uglify, and maybe some more really cool stuff (tsd or babel, markdown etc)...But all of those are heavy on your disk and project. Don't look for a moment and you can easily find yourself with 100MB+ disk size for that project (which hasn't even started yet!) not to mention 10000+ files since every node module brings its own dependencies, no matter that the same dependency is used by another module. And this is a very hard thing to move anywhere, let alone a web server.Am I missing something? I don't think it's possible that so much praise is given to the node environment while such a clear flaw exists. Do I expect too much (after all I did try to use many tools at once), is there something trivial known to Node veterans to bypass this?",
    "target": "node.js;dependency management"
  },
  {
    "id": "_webapps.98578",
    "source": "Share Google Drive Folder with submitters of Google Form <eos> I have a Google Form that is used as a sign up form. This form has a question requesting emails. It uses the email validation. I have a Google Drive folder that I want everyone who signs up to be able to view. Some of these files, I want to be able to easily set it up so they can edit it. How can I do this?",
    "target": "google spreadsheets;google drive;google forms"
  },
  {
    "id": "_softwareengineering.174770",
    "source": "What is the way to understand someone else's giant uncommented spaghetti code? <eos> Possible Duplicate:Ive inherited 200K lines of spaghetti code  what now? I have been recently handled a giant multithreaded program with no comments and have been asked to understand what it does, and then to improve it (if possible). Are there some techniques which should be followed when we need to understand someone else's code? OR do we straightaway start from the first function call and go on tracking next function calls?C++ (with multi-threading) on Linux",
    "target": "c++;productivity;linux;code reviews;maintenance"
  },
  {
    "id": "_unix.160172",
    "source": "Does gzip add integrity/crc check to a .tar? <eos> I run commands:tar -cf myArchive.tar myDirectory/gzip myArchive.tarthen I copy the file over a lot of unreliable mediums, and later I unpack it using:tar -xzf myArchive.tar.gzThe fact that I compressed the tar-ball, will that in any way guarantee the integrity, or at least a CRC of the unpacked content?",
    "target": "tar;gzip;checksum;integrity"
  },
  {
    "id": "_unix.366069",
    "source": "What does 01:00.0 mean with respect to graphics? <eos> When I typed $ lspci -nn | grep VGA01:00.0 VGA compatible controller [0300]: NVIDIA Corporation G80 [GeForce 8800 GTS] [10de:0193] (rev a2)I was reminded of this strange string, 01:00.0, which I have seen occasionaly without ever knowing what it wants to tell me. Especially the 00.0 part of it. How would you explain to a Layman what this string mean?",
    "target": "graphics;monitors"
  },
  {
    "id": "_softwareengineering.273842",
    "source": "Design Pattern for Removing Default Listeners <eos> We have a standard GUI control with a bunch of default listeners like that:class OurControl extends Control {    OurControl() {         addMouseWheelListener(new DefaultMouseWheelListener());    }}The defaults are good for the standard use-cases, but now the customer wants to use their own listeners in some cases. I'm searching for the most elegant way to achieve that.Idea 1: (it just feels weird to me, and I don't like to maintain a list of listeners that might be removed)class OurControl extends Control {    MouseWheelListener defaultListener = new DefaultMouseWheelListener();    OurControl() {         addMouseWheelListener(defaultListener);    }    void removeDefaultMouseWheelListener() {         removeMouseWheelListener(defaultListener);    }}Idea 2: (I like this one, even though technically speaking the listener stays where it is; it at least follows the standard bean pattern)class OurControl extends Control {    public boolean enableMouseWheel = true;    OurControl() {         addMouseWheelListener(new MouseWheelListener() {             void mouseWheelMoved(final MouseWheelEvent e) {                 if (enableMouseWheel)                     doMagic();             }         });    }}What is a good way to achieve this goal?",
    "target": "design patterns"
  },
  {
    "id": "_cs.40807",
    "source": "Understanding terms related to 2SAT algorithm <eos> Recently I am learning about solution of the 2-satiability problem using strongly connected components. There is a theorem related to this problem given below:Let $F = Q_lx_1 Q_2x_2\\ldots Q_nx_n C$ be a quantified Boolean formula with no free variables, where each $Q_i$ is either universal or existential, and $C$ is in conjunctive normal form. That is, $C$ is a conjunction of clauses, each clause is a disjunction of literals, and each literal is either a variable, $x_i$, or the negation of a variable, $x_i$ ($1 \\leq i \\leq n$). Theorem 2: The formula $F$ is true if and only if none of the following three conditions holds: 3(i) An existential vertex $u$ is in the same strong component as its complement $u$.3(ii) A universal vertex $u_i$ is in the same strong component as an existential vertex $u_j$ such that $j < i$ (i.e., $x_i$ is not quantified within the scope of $Q_i$).3(iii) There is a path from a universal vertex $u$ to another universal vertex $v$. (This condition includes the case that $v = u$.)In the proof they use this definition:We call a vertex universal if the corresponding variable is universally quantified and existential otherwise.But I am not familiar with the terms universal vertex and existential vertex. Can any one please explain these terms to me?",
    "target": "algorithms;graphs;satisfiability"
  },
  {
    "id": "_webapps.63012",
    "source": "Is there a way to set today as default due date in Trello? <eos> I am using a Trello board for my daily plan. I would like all newly added cards to be added with current date as due date. I know I can add cards and afterward I can set the date, I am even using the d shortcut to speed things up. I was wondering if there is a way to automate it even more.",
    "target": "trello;trello cards"
  },
  {
    "id": "_softwareengineering.175996",
    "source": ".NET - refactoring code <eos> I have inherited and now further develop a large application consisting of an ASP.NET application, VB6 and VB.NET application.The software was poorly written.  I am trying to refactor the code as I go along.  The changes I am making are not live (they are contained in a folder on my development machine).  This is proving to be time consuming and I am doing this along side other work which is the prioritiy.My question is: is this a practical approach or is there a better methodology for refactoring code? I don't have any experience with version control software or source control software and I am wandering if this is what I am missing.  I am a sole developer.",
    "target": "design patterns;asp.net"
  },
  {
    "id": "_codereview.13080",
    "source": "Getting prices and volume <eos> I'm learning F# and have a couple of routines much of whose functionality looks common so I am looking to refactor them together.Here are the routines (which for the record I lifted from elsewhere:let Prices time ID (polling:float) =   let sync = System.Threading.SynchronizationContext.Current  let obs = new Event<int>()   let raiseEvent (value:int) = sync.Post((fun _ -> obs.Trigger(value)), null)    let interval = TimeSpan.FromSeconds(polling)  let rec loop nextTime= async {     // Generate next value (on the GUI thread)        do getPrices nextTime      |> List.filter (fun price -> price.ID = ID)      |> List.iter (fun price -> raiseEvent price.Price)                            // Wait some short time    do! Async.Sleep(1000)    // Continue looping    do! loop (nextTime.Add(interval)) }    loop time |> Async.Start    obs.Publishand let Volumes time ID (polling:float) =   let sync = System.Threading.SynchronizationContext.Current  let obs = new Event<VolumeDTO>()   let raiseEvent (value:VolumeDTO) = sync.Post((fun _ -> obs.Trigger(value)),  null)    let interval = TimeSpan.FromSeconds(polling)  let rec loop nextTime= async {     // Generate next value (on the GUI thread)        do getVolumes nextTime      |> List.filter (fun volume -> volume.ID = ID)      |> List.iter (fun volume -> raiseEvent volume)                            // Wait some short time    do! Async.Sleep(1000)    // Continue looping    do! loop (nextTime.Add(interval)) }    loop time |> Async.Start     obs.PublishThe external function calls are hopefully reasonable self explanatory retrieving data from a dblet getPrices lastTime =  createList<PriceDTO>((getPriceSql lastTime), priceReader)let getVolumes lastTime =  createList<VolumeDTO>((getVolumeSql lastTime), volumeReader)The types are very simple, but I'm not sure I've got this 'right':type IID =  abstract member ID : int64type PriceDTO(ID:int64, Price:int) =   interface IID with    member this.ID = ID  member x.ID = ID  member x.Price = Pricetype VolumeDTO(ID:int64, Amount:decimal, Price:int32) =   interface IID with    member this.ID = ID  member x.ID = ID  member x.Amount = Amount  member x.Price = PriceI've played around with something but I'm not at all there as yet:let publish<'a> time ID (polling:float) dataRetriever =   let sync = System.Threading.SynchronizationContext.Current  let obs = new Event<'a>()   let raiseEvent (value:'a) = sync.Post((fun _ -> obs.Trigger(value)), null)    let interval = TimeSpan.FromSeconds(polling)  let rec loop (nextTime:DateTime)= async {     // Generate next value (on the GUI thread)        do dataRetriever nextTime      |> List.filter (fun item -> item.ID = ID)      |> List.iter (fun item -> raiseEvent item)                            // Wait some short time    do! Async.Sleep(1000)    // Continue looping    do! loop (nextTime.Add(interval)) }    loop time |> Async.Start     obs.PublishI may well have not quite implemented this correctly. I'm obviously getting a list of prices or volumes filtering them and publishing them. In order to achieve the filtering I've created an interface, but I'm not really happy with this since I'd prefer to keep the DTOs as simple as possible. Intellisense is telling me that my dataRetriever function takes a DateTime and returns an 'a list, but I'm not sure I quite want that since I need to cast it to an IID interface for filtering and then back to the underlying DTO for publishing.Is there a more 'functional' (or perhaps just better) way to do this?",
    "target": "f#"
  },
  {
    "id": "_codereview.133980",
    "source": "Fibonacci sequence methods <eos> Decided to get a little JDK 8 practice in today, so I built two methods to print out the golden ratio, one uses the Stream API the other does not. Wanted to request general feedback on how well I implemented these methods (mainly the stream generator,) considering the given task and if there is anything I could have done better.import java.util.ArrayList;import java.util.Arrays;import java.util.List;import java.util.function.Supplier;import java.util.stream.Collectors;import java.util.stream.Stream;/** * Created on 7/5/2016. *  */public class Fibonacci {    public static void main(String[] args) {        System.out.printf(Fibonacci Old: %s%n, String.join(,  , Fibonacci.calculateFib(10).stream()                .map(Object::toString)                .collect(Collectors.toList())));        System.out.printf(Fibonacci New: %s%n, String.join(,  , Fibonacci.generateFib()                .limit(10)                .map(Object::toString)                .collect(Collectors.toList())));    }    private static List<Integer> calculateFib(int fibCount){        List<Integer> fibSequence = new ArrayList<>();        fibSequence.add(0);        fibSequence.add(1);        for(int i = 2; i < fibCount; i++){            fibSequence.add(fibSequence.get(i-1) + fibSequence.get(i-2));        }        return fibSequence;    }    private static Stream<Integer> generateFib() {        return Stream.generate(new Supplier<Integer>() {            List<Integer> list = new ArrayList<>(Arrays.asList(0, 1));            int i = 0;            @Override            public Integer get() {                list.add(list.get(i) + list.get(i+1));                return list.get(i++);            }        });    }}",
    "target": "java;fibonacci sequence;generator"
  },
  {
    "id": "_softwareengineering.316411",
    "source": "Event driven programming in Haskell <eos> I'm new to Haskell, so this is more a high-level conceptual question. I've read this: https://wiki.haskell.org/Real_World_Applications/Event_Driven_Applications and it has this:run :: Domain -> [Event] -> IO ()run dm [] = do  events <- uiUpdate dm  run dm eventsrun _ (EventExit:_) =  return ()run dm (e:es) =  run (dmUpdate dm e) esSo uiUpdate would generate events in this case.I am trying to understand how this works in an application where you need to push events. An example - say you have a GUI where you have a single int counter and three types of event sources:FilesystemNetworkHuman interactionFor simplicity, say the counter needs to be increased or decreased whenever any kind of event happens (e.g. new file added or deleted, HTTP call succeeded or failed, human typed on a keyboard or clicked with a mouse).How do you push these events into the event loop? Most importantly, I'm not asking for here's how you can do it, but here's how real world Haskell applications work. Especially if there are different options that are used in practice.",
    "target": "haskell;event programming"
  },
  {
    "id": "_cs.2031",
    "source": "Can constraint satisfaction problems be solved with Prolog? <eos> Is party attendance type of problems solvable in Prolog? For example:Burdock Muldoon and Carlotta Pinkstone both said they would come if Albus Dumbledore came. Albus Dumbledore and Daisy Dodderidge both said they would come if Carlotta Pinkstone came. Albus Dumbledore, Burdock Muldoon, and Carlotta Pinkstone all said they would come if Elfrida Clagg came. Carlotta Pinkstone and Daisy Dodderidge both said they would come if Falco Aesalon came. Burdock Muldoon, Elfrida Clagg, and Falco Aesalon all said they would come if Carlotta Pinkstone and Daisy Dodderidge both came. Daisy Dodderidge said she would come if Albus Dumbledore and Burdock Muldoon both came.  Whom is needs to be persuaded to attend the party in order to ensure that all her invitees attend?I have tried to express this in GNU Prolog:attend(BM) :- attend(AD).attend(CP) :- attend(AD).attend(AD) :- attend(CP).attend(DD) :- attend(CP). attend(AD) :- attend(EC).attend(BM) :- attend(EC).attend(CP) :- attend(EC). attend(CP) :- attend(FA).attend(DD) :- attend(FA).attend(BM) :- attend(CP),attend(DD).attend(EC) :- attend(CP),attend(DD).attend(FA) :- attend(CP),attend(DD).attend(DD) :- attend(AD),attend(BM).attend(FA). /* try different seed invitees in order to see if all would attend*//* input:write('invited:'),nl,  attend(X),write(X),nl,  fail.*/I'm experiencing stack overflow (no pun), and have no knowledge of prolog evaluation, this is why I'm asking.Generally speaking, this problem can be cast into Boolean CNF satisfaction formula (with 6 boolean variables). Therefore, does the prolog perspective have any merit?",
    "target": "logic;constraint programming;prolog;logic programming"
  },
  {
    "id": "_scicomp.1644",
    "source": "High-resolution finite volume schemes for two phase flow (fields with jumps) literature sources <eos> what other recent sources of literature on this topic would you recommend? This is where I'm starting from: Leveque's article: HRIC schemeBut the related articles seem to be a bit dated (some up to 20 years). Can anyone with experience with such higher order schemes suggest a direction in which I could search?",
    "target": "numerics;reference request;finite volume"
  },
  {
    "id": "_cs.77400",
    "source": "Stroke Extraction to recreate Chinese characters <eos> I was going through the project lists of Andrew NG from his Stanford machine learning course and I found a project based on recreation of calligraphic characters. To do so firstly we need to extract strokes from characters and I can only understand it in bits and pieces and I cannot understand at all how to implement it in matlab.I also read the research paper that the stroke extraction method is based on. But I did not understand that too like there were some terms that I could not understand. And not to mention I can't understand just how to implement all the pixel related operations mentioned. I am a beginner in image processing. Ss please any help is appreciated. Quoting some lines from the paper:We use the direction contribution of the segments to estimate the degree for each pixel on the thick-line image. Given a binary image, for each black pixel $p(r,c)$, let $D_k(r,c)$ denote the orientation distance between the pixel and the boundary point along the $k$th quantized orientation, where $k = 1, 2, \\dots, M$, and $M$ is an integer that denotes the quantization number from $0^\\circ$ to $360^\\circ$ . The orientation distance is called point-to-boundary orientation distance (PBOD). The distribution of the PBODs contains information   about the degree of each pixel. We can easily tell that the PBODs along the quantized orientations of the branches are much larger than that along other quantized orientation. So, to estimate the degree of each pixel, we need only calculate the number of the crests of the distribution of all the PBODs of the pixel. Figure 2 shows some cases of the distribution. The resolution of quantization is $3^\\circ$. What is quantisation and orientation distance, and how to implement these in matlab?",
    "target": "image processing"
  },
  {
    "id": "_unix.158279",
    "source": "Unix: What happens if I enter ls -d [2-q]* <eos> Would it just ignore the bit after the -d option since you cant arrange characters lexically between 2 and q?",
    "target": "shell;wildcards"
  },
  {
    "id": "_webmaster.105084",
    "source": "Do crawlers add page views on a forum? <eos> I have a MyBB forum and I get multiple page views on new threads within 3-5 minutes of posting. I manually submit new URLs through Google Webmaster Tools which should if anything account for 1 page view, but not multiple. I don't have active members at the moment. Research leads me to believe my 100+ members who never post or respond to Admin emails are actually registration bots. So are these page views on my new content from real people or from web crawlers? ",
    "target": "forum;spam bots"
  },
  {
    "id": "_softwareengineering.141019",
    "source": "Should cookies be used in a RESTful API? <eos> I'm specifically interested in how users perform authorized / authenticated operations on a web API.Are authentication cookies compatible with the REST philosophy, and why?",
    "target": "web applications;web services;rest"
  },
  {
    "id": "_datascience.22212",
    "source": "What is Policy Collapse and what are the causes? <eos> I saw the term policy collapse on the comments of a tutorial for  reinforcement learning. I'm guessing that it's referred to as a policy collapse when the policy worsens over training due to a bad hyper-parameter, be it the learning rate, batch size, etc., but I couldn't find anything explaining it in clearly and in detail. ",
    "target": "reinforcement learning"
  },
  {
    "id": "_unix.218246",
    "source": "Properties of cat command <eos> a simple question, can I create a file at a location I want & using cat command & without using pipes & and the location is some other place than I where I am currently. (I would appreciate an edit)",
    "target": "cat"
  },
  {
    "id": "_unix.322150",
    "source": "gvfs-mount won't mount a ssh host specified in config <eos> I am struggling with configuring gvfs-mount to work with a host that is being connected to through a proxy. My config looks like this:Host proxyhost  User [username]  HostName [domain]  Port [non-standard port]Host destination  HostName [ip]  User [other username]  Port 22  IdentityFile [path to private key]  ForwardAgent yes  ProxyCommand ssh proxyhost nc %h %p 2> /dev/nullI am able to connect to it through the terminal - ssh destination works perfectly fine. The first server just asks for password and I'm logged in.But when I try to connect through gvfs-mount (I would like to work using Thunar) it prompts for username and password and I have completely no idea what should I provide there. I tried credentials to the proxyhost and it does not work. I just keep being asked 3 times for passoword and then returnedError mounting location: Permission deniederror. Is there any way that I can make it work?",
    "target": "ssh;mount;thunar;gvfs"
  },
  {
    "id": "_unix.182602",
    "source": "Trim audio file using start and stop times <eos> I have an FFmpeg command to trim audio:ffmpeg -ss 01:43:46 -t 00:00:44.30 -i input.mp3 output.mp3The problem I have with this command is that option -t requires a duration (in seconds) from 01:43:46. I want to trim audio using start/stop times, e.g. between 01:43:46 and 00:01:45.02.Is this possible?",
    "target": "audio;ffmpeg;trim"
  },
  {
    "id": "_unix.63081",
    "source": "What are ./ and ../ directories? <eos> Simple question, but I'm not sure where to look and google doesn't respond to periods and slashes.I'm just trying to count the # of files & directories in the current directory (not including subfolders/files) and was trying to differentiate ls -1 | wc -l and ls | wc -l since they seem identical.  A site I was looking at said Keep in mind that this is also counting the ./ and ../ directories. regarding the one with ls -1, and I'm not sure if that means it includes the directories before or something (which I don't want), but it didn't seem to do that from testing.Could someone confirm which one of those would be most adequate for counting # of files & directories in the current directory only (not sub) and what they mean by ./ and ../ directories?",
    "target": "directory;filenames"
  },
  {
    "id": "_webapps.108177",
    "source": "Create a pie chart with a formula <eos> I'm using google's monthly budget sheet to track my expenses.I need to have a pie chart but I don't want it to be floating around in the sheet and be in a specific cell(s). So I thought a formula like Sparkline might be the answer. But is there such a formula? how can I achieve this?  ",
    "target": "worksheet function;google spreadsheets"
  },
  {
    "id": "_codereview.140769",
    "source": "2d game enemy entities factories, probably in need of refactoring <eos> So I'm making a 2d shoot'em up game as a way of learning canvas, and larger-scale programming than what I'm accustomed to. I'm a purely front-end web dev, I can't say I'm very experienced in this.Anyway the way I spawn my enemies is like this : at xyz gameTime, a spawner object is pushed into the game. This spawner object add various enemies in various configurations, using that type of interface, I hope the code is self explanatory:state.enemies.push(enemies[this.enemyType].add({  pos: [this.pos[0], this.pos[1]],  angle: this.angle,  rotation: this.enemyRotation,  path: this.path}));But I'm not here for game design review so let me talk about what I want advice on.basically you can see my enemy module here: https://github.com/acezard/aceforceone/blob/develop/src/entities/enemies.jsLet me explain it bit by bit.This is the global config object that manages only the default settings of every enemy type. That is, it doesn't contain any vector/rotation/position infos, because these settings are injected at enemy creation. // Config Objectvar enemyConfig = {  redBomber: {    url: 'assets/images/enemy-xs-1.svg',    pos: [0, 0],    size: [75, 53],    speed: 100,    hitpoints: 10,    ROF: 100,    score: 100,    burst: {      amount: 3,      delay: 1000,      counter: 3    },  },  scout: {    url: 'assets/images/scout.png',    pos: [0, 0],    size: [50, 44],    speed: 500,    hitpoints: 2,    score: 50  },  rotatingPlat: {    url: 'assets/images/platpart.png',    pos: [0, 0],    size: [150, 44],    speed: 30,    hitpoints: 100,    ROF: 200,    score: 250,    burst: {      amount: 1000,      delay: 1000,      counter: 1000    },  },  rogueLeader: {    url: 'assets/images/rogueleader.svg',    pos: [0, 0],    size: [200, 89],    speed: 100,    hitpoints: 60,    score: 300,    ROF: 500,  },  drone: {    url: 'assets/images/drone.svg',    pos: [0, 0],    size: [50, 62],    speed: 300,    hitpoints: 5,    score: 75  },};Next we have a global enemy constructor, managing every enemy type as a base. It contains a mix of the default settings shown above, and the what I call active settings, that is, arguments different for every enemy entity even if they are of the same type (like position). This constructor also have the basic methods and a blank shoot method, because each enemy type has his own implementation (doesn't seem right?).// Base enemy constructorvar EnemyEntity = function(settingsDefault, settingsActive) {  // Default  this.active = true;  this.speed = settingsDefault.speed;  this.hitpoints = settingsDefault.hitpoints;  this.lastFire = Date.now();  this.score = settingsDefault.score;  this.ROF = settingsDefault.ROF || null;  this.maxHitpoints = settingsDefault.hitpoints;  this.rotating = settingsDefault.rotating || null;  if (settingsDefault.burst) {    this.burst = {      amount: settingsDefault.burst.amount,      delay: settingsDefault.burst.delay,      counter: settingsDefault.burst.counter    };  }  this.sprite = new Sprite({    url: settingsDefault.url,    pos: settingsDefault.pos,    size: settingsDefault.size,    rotated: true  });  // Active  this.angle = settingsActive.angle;  this.pos = settingsActive.pos;  this.radians = settingsActive.angle * Math.PI / 180;  this.vector = [Math.cos(this.radians) * this.speed, Math.sin(this.radians) * this.speed];  this.rotation = settingsActive.rotation || 0;  this.path = settingsActive.path || null;};// Update methodEnemyEntity.prototype.shoot = function() {};EnemyEntity.prototype.update = function(dt) {  if (this.outOfBounds()) {    this.active = false;    return;  }  if (this.path == angular) {    paths.angular(this);  }  this.pos[0] += this.vector[0] * dt;  this.pos[1] += this.vector[1] * dt;};EnemyEntity.prototype.outOfBounds = function() {  return this.pos[1] > canvas.height || this.pos[0] < 0 || this.pos[0] > canvas.width;};// Draw methodEnemyEntity.prototype.render = function() {    canvas.ctx.save();    canvas.ctx.translate(this.pos[0], this.pos[1]);    canvas.ctx.translate(this.sprite.size[0] / 2, this.sprite.size[1] / 2);    canvas.ctx.rotate(Math.PI / 180 * this.rotation);    this.sprite.render(canvas.ctx);    canvas.ctx.restore();};This part is another constructor, used to create enemy factories. Basically its only role is to share an ADD method, used by every enemy factory.// Factory constructorvar EnemyFactory = function() {};EnemyFactory.prototype.add = function(settings) {   return new this.type(settings);};Now this is an example of what a specific enemy factory looks like. I put two so you can see how much WET code this is. Basically, we first create a constructor, by calling the EnemyEntity constructor with this, and with the active settings. We also get enemyentity methods with calling it as a prototype. The shoot function is different for each enemy.Then we have the enemy factory per se, basically it's constructed from the EnemyFactory constructor, and giving the specific Enemy constructor as a type, so we then can use myEnemy.add(activeSettings);// RedBombervar RedBomber = function(settings) {  EnemyEntity.call(this, enemyConfig.redBomber, settings);};RedBomber.prototype = Object.create(EnemyEntity.prototype);RedBomber.prototype.shoot = function() {  var now = Date.now();  // If the enemy can shoot  if (this.pos[1] > 0 && this.burst.counter && now - this.lastFire > this.ROF) {    var x = this.pos[0] + this.sprite.size[0] / 2;    var y = this.pos[1] + this.sprite.size[1] / 2;    state.ebullets.push(weapons.red.addMissile({x: x, y: y, angle: 90}));    state.ebullets.push(weapons.red.addMissile({x: x, y: y, angle: 80}));    state.ebullets.push(weapons.red.addMissile({x: x, y: y, angle: 100}));    this.burst.counter--;    this.lastFire = now;    return;  } else  if (!this.burst.counter && now - this.lastFire > this.burst.delay) {    this.burst.counter = this.burst.amount;  }};function RedBomberFactory () {};RedBomberFactory.prototype = new EnemyFactory();RedBomberFactory.prototype.type = RedBomber;var redBomber = new RedBomberFactory();// Rogue Leadervar RogueLeader = function(settings) {  EnemyEntity.call(this, enemyConfig.rogueLeader, settings);};RogueLeader.prototype = Object.create(EnemyEntity.prototype);RogueLeader.prototype.shoot = function() {  var now = Date.now();  // If the enemy can shoot  if (this.pos[1] > 0 && now - this.lastFire > this.ROF) {    var x = this.pos[0];    var y = this.pos[1];    state.ebullets.push(weapons.redRay.addMissile({x: x + this.sprite.size[0] * 0.3, y: y + this.sprite.size[1] * 0.6, angle: this.rotation - 90}));    state.ebullets.push(weapons.redRay.addMissile({x: x + this.sprite.size[0] * 0.7, y: y + this.sprite.size[1] * 0.6, angle: this.rotation - 90}));    this.lastFire = now;  }};function RogueLeaderFactory () {};RogueLeaderFactory.prototype = new EnemyFactory();RogueLeaderFactory.prototype.type = RogueLeader;var rogueLeader = new RogueLeaderFactory();Then we exports our factory functionsmodule.exports = {  redBomber: redBomber,  scout: scout,  rotatingPlat: rotatingPlat,  rogueLeader: rogueLeader,  drone: drone};What's the problem then ? As you can see there is a lot of repetition in my code, every new enemy type adds a LOT of code, but I only really need the shoot method. Though I'm not sure right now how I could manage that better and ask for your advice. Any other consideration of the code is of course much appreciated",
    "target": "javascript;object oriented;game;constructor;factory method"
  },
  {
    "id": "_reverseengineering.9435",
    "source": "How can I find the implementation/source code of an interface in .NET? <eos> So I'm disassembling the Winnov.Amalga.Core.Session.Common.dll, and trying to figure out how the WriteScriptCommand works.I'm absolutely new to .NET, so go easy on me, please.You can find the dll yourself here: Link under the Binary folder.Below is pretty much the only reference I found. EDIT: From searching through the decompiled dll.using System;namespace winnov.Amalga.core{  public interface ISession  {     string Configuration { get; set; }     SessionState { get; }     TimeSpan Duration { get; }     string ArchiveBasePath { get; set; }     string ArchivePath { get; }     void Start();     void Stop();     void ApplyPreset(string presetxml);     void writeScriptCommand(string name, string value);   }}",
    "target": "decompilation;dll;.net"
  },
  {
    "id": "_codereview.78834",
    "source": "Salesforce Report that searches long text fields, has customizable view, easy to update, etc <eos> I got really tired of how ugly and inflexible Salesforce Reports are. So I made this Apex/Visualforce combo that searches long text fields, makes adding and removing fields a snap, has a customizable view, and is generally easy(er) to work with.This basically does everything by shuttling JSON strings back and forth between the view and the controller. If your browser doesn't have Javascript enabled, you're going to have a bad time.Other cool things:Works for any custom record type, and any custom field. You specify which in the view; theoretically, there's no need to touch any Apex, just good ol' HTML/Visualforce.Detects whether or not one of the fields by which you want to search is a picklist. If it is, it gets all the values for the picklist and prints them out in the DOM as a multi-select picklist. Ditto for checkboxes.It's super-easy to reference fields and make them appear in the view however you want.You can sort results just by clicking on column headers.Salesforce has two methods of searching for records: SOSL and SOQL. One's great for searching for text strings; the other one's great for everything else. This Apex class figures out automatically which one to use.<apex:page    controller  =SFReportsPlus    sidebar     =false    showHeader  =true    standardStyleSheets=true><!--Contact hello@robertakarobin.com with any questions!-->    <apex:form>        <apex:actionFunction            name            =  lookUpFields            action          ={!lookUpFields}            oncomplete      =renderFields(),                             $('#loading').slideUp(),                             $('#wrapper').slideDown()            reRender        =fieldsBlock, messageBlock        ><!--Specify the Salesforce Name of the record type you want to search. I use Leads here, but custom record types (and custom fields) are peachy.-->            <apex:param                name        =  recordName                assignTo    ={!recordName}                value       =Lead            /><!--Specify all the fields you want to involve here -- the fields by which you want people to search, and the fields you want to otherwise show in the view.--><!--This is clearly just a JSON map. The values are the actual Salesforce Names of the fields. The keys are easier-to-read headers that you create, and that you use to refer to the fields from now on.--><!--If you're getting a ton of null pointer exceptions, it's because you spelled field's Name wrong, or referenced a field that doesn't exist. Pardon my crappy error handling.-->            <apex:param                name        =  fieldsHeadersWithNamesJSONIn                assignTo    ={!fieldsHeadersWithNamesJSONIn}                value       ={                    'id'                        :'Id',                    'name'                        :'Name',                    'description'                        :'Description',                    'where_it_came_from'                        :'LeadSource'                }            /><!--Using the headers you specified above, specify the fields by which you want people to be able to search.-->            <apex:param                name        =  fieldsToSearchJSONIn                assignTo    ={!fieldsToSearchJSONIn}                value       =[                    'name',                    'where_it_came_from'                ]            /><!--Using the headers you specified above, specify the fields you want to show in the view.-->            <apex:param                name        =  fieldsToShowJSONIn                assignTo    ={!fieldsToShowJSONIn}                value       =[                    'id',                    'name',                    'where_it_came_from',                    'description'                ]            />        </apex:actionFunction>    </apex:form><!--You'll need to tweak this to reference jQuery properly.-->      <apex:includeScript value={!URLFOR($Resource.SLCA2__jQuery, 'jquery.min.js')} />    <script type=text/javascript>        window.onload = new function(){            lookUpFields();        }        var fieldsToShow;        var fieldsToSearch;        var fieldsWithOptions;        function prettify(input){            var output = ;                output += input.charAt(0).toUpperCase();                output += input.substr(1).replace(/_/g, );            return output;        }//This takes the values from multi-select picklists and concats them into a comma-separated string in hidden text inputs.        function selectedToCsv(select){            var values = [];            $(select).find(:selected).each(function(index, element){                values.push($(element).val());            });            $(select).prev(input).val(values.join(,));        }        function toggleFields(){            if($(#and).val().trim() == ){                $(#or, #not).prop(disabled,disabled);            }else{                $(#or, #not).prop(disabled,);            }        }               function renderFields(){            window.fieldsWithOptions                    = $.parseJSON($(#fieldsWithOptionsJSONOut).val());            window.fieldsToSearch                    = $.parseJSON($(#fieldsToSearchJSONOut).val());            window.fieldsToShow                    = $.parseJSON($(#fieldsToShowJSONOut).val());            window.results;            var fieldsInputs        = [],                fieldsHeaders       = [],                fieldsInputsHTML    = ,                fieldsHeadersHTML   = ,                fieldsToSearchHTML  = ,                numCols             = 5;            for(var x in fieldsToSearch){                var fieldHeader = fieldsToSearch[x],                    field       = fieldsWithOptions[fieldHeader],                    output      = ;                switch(field.type){                    case checkbox:                        output  = <input type=\\checkbox\\ id=\\ + field.name                                + \\ name=\\ + field.name + \\/>;                        break;                    case picklist:                        output  = <input type=\\hidden\\ name=\\ + field.name + \\>                                + <select multiple=\\true\\ id=\\ + field.name                                + \\ onchange=\\selectedToCsv(this)\\>;                        for(var optionValue in field.options){                            var optionLabel = field.options[optionValue];                            output  += <option value=\\ + optionValue + \\>                                    + optionLabel + </option>;                        }                        output  += </select>;                        break;                    default:                        output  =                            <input type=\\text\\ name=\\ + field.name + \\ />;                        break;                }                fieldsInputs.push(<td> + output + </td>);                fieldsHeaders.push(<th> + prettify(fieldHeader) + </th>);            }            for(var x in fieldsHeaders){                var counter = Number(x) + 1;                fieldsHeadersHTML   += fieldsHeaders[x];                fieldsInputsHTML    += fieldsInputs[x];                if(counter % numCols == 0 || counter >= fieldsHeaders.length){                    fieldsToSearchHTML  +=                         <tr> + fieldsHeadersHTML + </tr> +                        <tr> + fieldsInputsHTML + </tr>;                    fieldsHeadersHTML   = ;                    fieldsInputsHTML    = ;                }            }            $(#fieldsToSearch).html(fieldsToSearchHTML);        }        function getNewResults(){            window.results = $.parseJSON($(#resultsJSON).val());            renderResults();        }        function renderResults(){            var output = ;            $(#results).html();            for(x in window.results){                var result  = window.results[x],                    template = $(#resultTemplate).html();                output += template.replace(/\\{([a-zA-Z_])+\\}/g, function(substring){                    var varName = substring.substring(1, substring.length - 1);                    if(varName.indexOf(date) > -1){                        return result[varName].substring(0, 10);                    }else if(result[varName] == null){                        return ;                    }else{                        return result[varName];                    }                });            }            $(#results).html(output);            $('#loading').slideUp();            $('#resultsWrapper').slideDown();        }        var ascOrDesc = asc;        function orderBy(orderByThis){            window.results.sort(function(a,b){                if(a[orderByThis] > b[orderByThis]){                    return (window.ascOrDesc == asc? 1 : -1);                }else{                    return (window.ascOrDesc == asc? -1 : 1);                }            });            if(window.ascOrDesc == asc){                window.ascOrDesc = desc;            }else{                window.ascOrDesc = asc;            }            renderResults();        }    </script>    <style type=text/css>        .errors        {            color:red;          }        #wrapper *        {            box-sizing:border-box;          }        #wrapper table        {        width:100%;        }        #wrapper tr>*        {            vertical-align:top;        }        #wrapper th        {            background-color:#fda;            white-space:normal;        }        #fields select,        #fields input,        #fields textarea        {            width:100%;         }        #fields *[colspan]        {            max-width:none;         }        #fields td        {            padding-bottom:30px;        }        #resultsWrapper th[onclick]        {            cursor:pointer;            text-decoration:underline;        }        .hide{            display:none;        }        #loading span        {            display:inline-block;            vertical-align:bottom;            overflow:hidden;            animation: loading 1s ease-in-out 0s infinite alternate;            -webkit-animation: loading 1s ease-in-out 0s infinite alternate;        }        @keyframes loading        {            0% { width:5px;}            100% { width:30px; }        }        @-webkit-keyframes loading        {            0% { width:5px; }            100% { width:30px; }        }    </style>    <apex:sectionHeader title=SFReportsPlus />    <apex:outputPanel id=messageBlock>            <p class=errors>{!messageOut}</p>    </apex:outputPanel>    <div id=wrapper class=hide>        <apex:pageBlock id=fieldsBlock>            <apex:form>            <input                id      =  fieldsToSearchJSONOut                value   ={!fieldsToSearchJSONOut}                type    =hidden            />            <input                id      =  fieldsToShowJSONOut                value   ={!fieldsToShowJSONOut}                type    =hidden            />            <input                id      =  fieldsWithOptionsJSONOut                value   ={!fieldsWithOptionsJSONOut}                type    =hidden            />            <table id=fields>            <tbody id=fieldsToSearch></tbody>            <tr>                <th colspan=2>Search for records that contain...</th>                <th>ANY of these words:</th>                <th>OR any of these:</th>                <th>but NOT any of these:</th>            </tr>            <tr>                <td colspan=2><em>(Separate terms with commas, e.g. <kbd>John Smith, Graphic design, Graduate</kbd>)</em></td>                <td>                    <input                        name        =and                        id          =and                        type        =text                        onkeyup     =toggleFields()                    />                </td>                <td>                    <input                        name        =or                        id          =or                        type        =text                        disabled    =disabled                    />                </td>                <td>                    <input                        name        =not                        id          =not                        type        =text                        disabled    =disabled                    />                </td>            </tr>            <tr>                <td>                    <apex:commandButton                        value       =Search                        action      ={!doTheSearch}                        onclick     =$('#loading').slideDown()                        oncomplete  =getNewResults()                        reRender    =messageBlock, resultsJSONBlock                    />                </td>            </tr>            </table>            </apex:form>        </apex:pageBlock>        <apex:outputPanel id=resultsJSONBlock>            <input                id      =  resultsJSON                value   ={!resultsJSON}                type    =hidden            />        </apex:outputPanel>        <div id=resultsWrapper class=hide>            <apex:pageBlock>                <table>                    <thead>                        <tr>                            <th></th>                            <th onclick=orderBy('name')>Name</th>                            <th onclick=orderBy('where_it_came_from')>Lead source</th>                        </tr>                    </thead><!--This is where the results actually show up. This <tbody> is a template. For each result, Javascript repeats this template in the DOM. It expects everything inside curly brackets {blah} to correspond to one of the headers of the record you're looking up.--><!--Stuff in curly brackets with an exclamation mark {!blah} still refers to an actual Salesforce variable.-->                    <tbody id=resultTemplate class=hide>                        <tr>                            <td>                                <button onclick=$('#longText{id}').toggle() type=button>View</button>                            </td>                            <td><a href={!$Site.BaseUrl}/{id} target=_blank>{name}</a></td>                            <td>{where_it_came_from}</td>                        </tr>                        <tr id=longText{id} class=hide>                            <td colspan=8>{description}</td>                        </tr>                    </tbody>                    <tbody id=results>                    </tbody>                </table>            </apex:pageBlock>        </div>    </div>    <p id=loading>Loading<span>..........</span></p></apex:page>...and the Apex class:public with sharing class SFReportsPlus{    public String        messageOut      = '';    public String        recordName {get; set;}    public Schema.SObjectType        recordType;    public Map<String, Schema.SObjectField>        recordFields;    public SObject         record;    public String        fieldsHeadersWithNamesJSONIn {get; set;}    public Map<String, String>        fieldsHeadersWithNames;    public Map<String, Map<String, Object>>         fieldsWithOptions   = new Map<String, Map<String, Object>>();    public String        fieldsToSearchJSONIn {get; set;}    public List<String>        fieldsToSearch;    public String        fieldsToShowJSONIn {get; set;}    public List<String>        fieldsToShow;    public String getMessageOut(){        return      messageOut;    }    public String getFieldsHeadersWithNamesJSONOut(){        return      JSON.serializePretty(fieldsHeadersWithNames);    }    public String getFieldsToSearchJSONOut(){        return      JSON.serializePretty(fieldsToSearch);    }    public String getFieldsToShowJSONOut(){        return      JSON.serializePretty(fieldsToShow);    }    public String getFieldsWithOptionsJSONOut(){        return      JSON.serializePretty(fieldsWithOptions);    }    public PageReference lookUpFields(){        try{            recordType  = Schema.getGlobalDescribe().get(recordName);            record      = recordType.newSObject();            recordFields                        = recordType.getDescribe().fields.getMap();            fieldsHeadersWithNames  = (Map<String, String>)                    JSON.deserialize(                        fieldsHeadersWithNamesJSONIn.replaceAll('\\'', ''),                        Map<String, String>.class                    );            fieldsToSearch = (List<String>)                    JSON.deserialize(                        fieldsToSearchJSONIn.replaceAll('\\'', ''),                        List<String>.class                    );            fieldsToShow = (List<String>)                    JSON.deserialize(                        fieldsToShowJSONIn.replaceAll('\\'', ''),                        List<String>.class                    );            for(String fieldLabel : fieldsHeadersWithNames.keySet()){                fieldsWithOptions.put(fieldLabel, returnFieldOptions(fieldLabel));            }        }catch(Exception e){            messageOut += 'Something went wrong getting the search fields: ' + e + '; ';        }        return null;    }    public Map<String, Object> returnFieldOptions(String fieldLabel){        String            fieldName   = fieldsHeadersWithNames.get(fieldLabel);        Schema.DescribeFieldResult            field       = recordFields.get(fieldName).getDescribe();        String            fieldType   = String.valueOf(field.getType());        Map<String, String>            fieldOptions                        = new Map<String, String>();        Map<String, Object>            output      = new Map<String, Object>();        if(            fieldType == 'PICKLIST'          ||fieldType == 'MULTIPICKIST'        ){                fieldType = 'picklist';                for(Schema.PicklistEntry option : field.getPicklistValues()){                    fieldOptions.put(option.getValue(), option.getLabel());                }        }else if(            fieldType == 'DATE'          ||fieldType == 'TIME'        ){                fieldType = 'time';        }else if(            fieldType == 'BOOLEAN'        ){                fieldType = 'checkbox';        }else{                fieldType = 'string';        }        output.put('name', fieldName);        output.put('type', fieldType);        output.put('options', fieldOptions);        return output;    }    public Map<String, String>        fieldsWithInputs {get; set;}    public String        logicString = '';    public String        conditionalString   = '';    public String        fieldsToShowString  = '';    public String        queryString;    public List<SObject>        results = new List<SObject>();    public List<Object>        resultsOut;    public String getResultsJSON(){        return JSON.serializePretty(resultsOut);        }    public String getQueryString(){        return queryString;    }    public PageReference doTheSearch(){        messageOut  = '';        resultsOut  = new List<Object>();        try{            fieldsWithInputs = ApexPages.currentPage().getParameters();            buildLogicString();            buildFieldsToShowString();            buildConditionalString();            if(fieldsWithInputs.get('and') == ''){                results = doSOQLSearch();            }else{                results = doSOSLSearch();            }            for(Integer x = 0; x < results.size(); x++){                SObject                    result      = results.get(x);                Map<String, Object>                    resultOut   = new Map<String, Object>();                for(String fieldHeader : fieldsToShow){                    String fieldName = fieldsHeadersWithNames.get(fieldHeader);                    resultOut.put(fieldHeader, result.get(fieldName));                }                resultsOut.add(resultOut);            }        }catch(Exception e){            messageOut += 'Something went wrong looking up records: ' + e + '; ';           }        return null;    }    public List<SObject> doSOQLSearch(){        queryString = 'SELECT ' + fieldsToShowString                    + ' FROM ' + recordName;        if(conditionalString != ''){            queryString                    +=' WHERE (' + conditionalString + ')';        }        List<SObject> SOQL = Database.query(queryString);        return SOQL;    }    public List<SObject> doSOSLSearch(){        queryString = 'FIND \\'(' + logicString + ')\\''                    + ' RETURNING ' + recordName                    + ' (' + fieldsToShowString;        if(conditionalString != ''){            queryString                    +=' WHERE (' + conditionalString + ')';        }            queryString                    +=')';        List<List<SObject>> SOSL = Search.query(queryString);        return SOSL[0];    }    public void buildLogicString(){        logicString = '(';        logicString += '(' + fieldsWithInputs.get('and').replaceAll(',',' AND ') + ')';        if(String.isNotBlank(fieldsWithInputs.get('or'))){            logicString += ' OR (' + fieldsWithInputs.get('or').replaceAll(',',' OR ') + ')';        }        logicString += ')';        if(String.isNotBlank(fieldsWithInputs.get('not'))){            logicString += ' AND NOT (' + fieldsWithInputs.get('not').replaceAll(',',' OR ') + ')';        }    }    public void buildFieldsToShowString(){        List<String> output = new List<String>();        for(String fieldHeader : fieldsToShow){            output.add(fieldsHeadersWithNames.get(fieldHeader));            }        fieldsToShowString = join(output, ', ');    }    public void buildConditionalString(){        List<String> outputsList    = new List<String>();        for(String fieldHeader : fieldsToSearch){            String fieldName = fieldsHeadersWithNames.get(fieldHeader);            if(fieldsWithInputs.get(fieldName) == null             ||fieldsWithInputs.get(fieldName) == ''            ){                continue;            }            String  outputString;            String  inputString = fieldsWithInputs.get(fieldName);            List<String>                    inputList   = inputString.split(',', 0);            if(inputList.size() == 1){                outputString =                     fieldName + ' = \\'' + inputString + '\\'';            }else{                outputString =                    fieldName + ' IN (\\'' + join(inputList,'\\',\\'') + '\\')';            }            outputsList.add('(' + outputString + ')');        }        conditionalString = join(outputsList, ' AND ');    }    public String join(List<String> values, String delimeter){        String output = '';        for(Integer x = 0; x < values.size(); x++){            output += values.get(x);            if(x < values.size() - 1){                output += delimeter;            }        }        return output;    }}On GitHub",
    "target": "salesforce apex"
  },
  {
    "id": "_unix.159286",
    "source": "Prevent Mint from suspending while playing music in Spotify <eos> In Linux Mint 17 I have Suspend when inactive for under Power Management set to 10 minutes.The problem is that the system suspends even when I'm listening to music using Spotify.Is there any way to prevent this?",
    "target": "linux mint;power management"
  },
  {
    "id": "_cstheory.31933",
    "source": "The Complexity of Properly Learning Decision Trees <eos> Where does this paper prove the middle bullet point of its abstract?I have looked through that paper fairly thoroughly.There are three things I want to read how they're getting around.Reductions from NP problems to SAT may have the effectof applying arbitrarily large polynomials to the input size.Theorems 2 and 3 and 20 restrict the runtime of their learning algorithms.Theorems 2 and 3 and 20 consider randomized algorithms.",
    "target": "decision trees;pac learning"
  },
  {
    "id": "_unix.126000",
    "source": "Floating panel over fullscreen windows in tile WM <eos> I want to create kiosk using GNU/Linux. I need to show GUI one application full screen.I've found that ratpoison suits my needs. But I also want to allow user to see and change keyboard layout and display digital clock on a panel. It's clear that I don't need all 1280 horizontal pixels to display this information. My fullscreen application has main menu and it would be great to use empty space on the right to overlay it with the panel.I've achieved that with those lines in tint2 config:```panel_position = top right horizontalpanel_size = 150 24strut_policy = nonepanel_layer = top```It works well with a normal WM (like kwin), but I cannot get the same result with a tile WM (I suppose it's easier to strengthen simple tile WM than a normal one). I've already tried ratpoison, awesome and i3.How can I achieve my goal? I can easily change WM or panel to a different one.",
    "target": "tiling wm;panel;kiosk;fullscreen"
  },
  {
    "id": "_unix.75821",
    "source": "Installing Ossec on an existing centos 6.4 machine <eos> I have an existing machine running centos 6.4. Is it ok to install now the Ossec or it's not worth any more as the machine is already running for few months. Which is the best mechanism to install because I saw one is from the source and some recommend atomicorp repo? Any recommendation please?",
    "target": "centos;security"
  },
  {
    "id": "_unix.227081",
    "source": "How to make modprobe nf_conntrack_ftp persist a reboot on CentOS 7 and firewalld? <eos> I'm stumped. I've seen the related questions about editing /etc/sysconfig/iptables-config, but I'm running CentOS 7 (and webmin/virtualmin), which uses firewalld instead of iptables.How do I get modprobe nf_conntrack_ftp to persist after a reboot? I tried setting up a cron on reboot to issue the command, but that didn't work (and is probably the wrong way to go about it anyway).Right now after every reboot I have to login and type in the command manually in order to get FTP connections to work correctly.Thanks.",
    "target": "centos;modprobe;firewalld;proftpd"
  },
  {
    "id": "_softwareengineering.336669",
    "source": "Recommended way to organize and build multiple services for App Engine Flexible Environment with custom runtime <eos> When deploying to Flexible Environment using the default runtime (e.g. python), we just need to specify different app.yaml files with different entrypoint: values.But what would the 'best practice' for custom runtimes be for this case? Multiple Dockerfile's with different CMD values?But that would mean that each service needs to be built individually. Maybe have a 'base' Dockerfile and image to speed up the build?",
    "target": "python;google app engine;docker"
  },
  {
    "id": "_codereview.65031",
    "source": "Creating a list containing the rank of the elements in the original list <eos> I don't really know how to explain what I'm looking for in a way that makes sense, but here goes:Say I have a list $$L=(4,7,9,10,6,11,3)$$What I want to produce is a corresponding list$$ K = (1,3,4,5,2,6,0)$$where element K[i] has the value of the 'rank' of the element for the corresponding location in L. So the higher the number the higher the rank, starting from rank 0 for the smallest number in LThe code I have written for this is:x = [4,7,9,10,6,11,3]index = [0]*len(x)for i in range(len(x)):    index[x.index(min(x))] = i    x[x.index(min(x))] = max(x)+1and it works, but I just feel it looks horrible, and was wondering if there might exist a more aesthetic way.",
    "target": "python;sorting"
  },
  {
    "id": "_datascience.18641",
    "source": "Why predicted proababilities from this binary classifier does not sum up to 1? <eos> I have a C5.0 model that is trained to predict binary class (C1/C2) on a dataset with 20 features. The model is configured to perform boosting (10 trials) and it has a miss-classification cost function (100:1 where 100 is the cost for miss-classifying a Negative sample as Positive and 1 is the cost for miss-classifying Negative as Positive).Looking at predicted probabilities generated by the model, I can see that it ranges from 0 to 1 for each class. i.e, I have instances where the predicted class (C1) has a probability lower than 0.5 ( for example: predicted class=C1 and predicted probability=0.1 ) - This is where the question arises: if P(C1) < 50% why is it classified as C1 (there are only two classes, C1 and C2)Based on my understanding of decision trees, the predicted probabilities are often generated based on the percentage of test cases on the leaf node that were labeled in each class divided by the total number of instances hitting that leaf node. This method will dictate the probability for two classes must sum up to 1.My question is why does the model classify an instance in class C1 if it has only got 0.1 confidence in it. Does a predicted probability of 0.1 on class C1 mean that there is a 0.9 confidence in it belonging to class C2? If so, why does it classify an instance in class C1 is it has less than 0.5 confidence in it?My own theory is that this might be due to boosting and miss-classification cost and the way they are influencing the predicted class.",
    "target": "classification;predictive modeling;probability;binary"
  },
  {
    "id": "_webapps.20203",
    "source": "How do I send a link to a shared Trello board? <eos> Possible Duplicate:Bookmarking in Trello Is it possible to give or share a direct link to a particular Trello board? There's no direct link that I can see to either the list of boards, or to one board that I share with others.  Where might this simple functionality be hiding?",
    "target": "trello;sharing;links"
  },
  {
    "id": "_unix.318699",
    "source": "How to reduce the boot time of a beaglebone using systemd <eos> I'm currently trying to reduce the time it takes to boot my beaglebone green and start a python script. My simple python script just turns on a relay on a cape.I'm using the time it takes for the relay to turn as the time it takes to boot and do something useful.Previously the relay would take 18 secs and I've gotten it down to 14 secs messing around with systemd.I've created a simple unit file that will start my python program[Unit]Description=Relaycheck run on startupDefaultDependencies=noAfter=systemd-system.slice[Service]WorkingDirectory=/home/ExecStart=/home/relaycheck2.pyStandardOutput=null[Install]Alias=relaycheck2.serviceAnd here's a cropped picture of the current boot chart:BootchartTo my understanding, my service is being run quite early and the time consuming services like networking, don't impact my relay service. Is this correct?Is there anything else I can do reduce the time to boot using systemd? ",
    "target": "linux;debian;boot;systemd;beagleboneblack"
  },
  {
    "id": "_softwareengineering.229925",
    "source": "Member functions vs. Non-member functions for math operators <eos> I'm writing a linear algebra library (long story short, it's a school assignment) that involves matrices, vectors, etc.  In the process of creating this library, I'm going to be creating functions that perform mathematical operations on objects.  For example, transpose matrix, invert matrix, normalize vector, etc.I was curious as to what is the best practice for this sort of function...  That is, should I make the function a member function, or non-member?  (For clarity/library use sake)Example://Member function way:B = A.transpose();C = A.inverse();//Non-member function way:B = linalg::transpose(A); //Non-member transpose function in linear algebra namespaceC = linalg::inverse(A);Is there some standard regarding these sorts of operations?  Or, at least, is there a common way people do this?  I'm leaning towards the first option, but I'd like to know if this is recommended.",
    "target": "c++;libraries;methods"
  },
  {
    "id": "_codereview.48396",
    "source": "Router for MVC framework <eos> The class routes URLs based on the domain.com/class/method/param/.. format. It also checks the request type (GET or POST) and calls the method name GET or POST from the identified class.class Router {    private $_routes,            $_path,            $_method,            $_found;    public function __construct(Array $routes, $path, $method) {        krsort($routes);        $this->_routes = $routes;        $this->_path   = $path;        $this->_method = strtoupper($method);    }    public function load() {        foreach($this->_routes as $regex => $class) {            $regex = str_replace('/', '\\/', $regex);            $regex = '^' . $regex . '\\/?$';            if(preg_match('/' . $regex . '/i', $this->_path, $params)) {                $this->_found = true;                $this->_classInstantiate($class, $params);                break;            }        }        if(!$this->_found) {            throw new Exception('URL location not found: ' . $this->_path);        }    }    private function _classInstantiate($class, $params) {        if(class_exists($class)) {            $obj = new $class($params);            if(method_exists($obj, $this->_method)) {                $method = $this->_method;                $obj->$method();            } else {                throw new BadMethodCallException('Method not found: ' . $this->_method);            }        } else {            throw new Exception('Class not found: ' . $class);        }    }}I load it up in my entry file like so://url to class router$routes = (Array) $config->routes;$path   = $_SERVER['REQUEST_URI'];$method = $_SERVER['REQUEST_METHOD'];$router = new Router($routes, $path, $method);$router->load();Am I utilizing dependency injection correctly?Are there any parts of my class that I should decouple?Is there anything I could improve in my code when it comes to OO PHP (and MVC)?",
    "target": "php;object oriented;mvc;url routing"
  },
  {
    "id": "_unix.90043",
    "source": "Wrong root shell in /etc/passwd <eos> I wanted to change the standard shell for my root user to bash but I got the path wrong. i typed /bin/bash instead of /opt/bin/bash. Now my /etc/passwd looks like this:root:x:0:0:root:/root:/bin/bashThe problem is that I can no longer login via ssh. Additionally I can't su to root from an other user because of: >su rootsu: must be suid to work properly Any suggestions?",
    "target": "linux;shell;ssh"
  },
  {
    "id": "_unix.172639",
    "source": "Disable root password caching <eos> How can I disable root password caching? I looked at This Question, but I didn't really understand how to do it, is not the same as my question but it is indirectly related.I tried adding this to /etc/sudoers:timestamp_timeout=0But it gave me:>>> /etc/sudoers: syntax error near line 46 <<<So I just pressed x. 46 is the line where I added it, so there isn't a problem with anything else.",
    "target": "sudo;password;root"
  },
  {
    "id": "_codereview.44690",
    "source": "Proper action when a Java program fails <eos> I have a program that has to initialize a few big things (connect to a few databases, parse some XML) and without the initialization being successful the program would not be able to continue.Right now I have my main method throwing just a general Exceptionpublic static void main(String[] args) throws Exception{    //Throws numerous types of Exceptions    WhateverObject we = WhateverObject.getInstance();    we.doSomething();}My question is, is there a better way to handle this? Should I catch the exception and then print out that it failed an exit? Something else maybe? Note, there's no hope of program recovery at this point.",
    "target": "java;exception handling"
  },
  {
    "id": "_datascience.13815",
    "source": "How to deal with item belonging to more than one category <eos> So I'm training a classification task which takes as input some description of the state of a 2x2x2 rubix cube and outputs the optimal move to take. And a potential problem I noticed is that in many states more than one move is optimal. In particular, only about 46% of states have only one optimal move, and 24% have 2, 12% have three, etc. So I have a few choices.The options I thought of werehave each data point choose an optimal move at randomDo cross-entropy minimization with the data point containing the same probability for each optimal move. i.e (0.5,0.5,0,0,0,0,0,0,0) if the first two are optimalDiscard states with more than one optimal move (this seems really bad)What is the standard practice? Also, is there a difference between 1 and 2?If necessary you may assume that I'm using a neural network model",
    "target": "classification;neural network"
  },
  {
    "id": "_cs.43757",
    "source": "Multiple sequence Progressive alignment example using five sequences <eos> I tried to find sources that explain multiple sequence alignment with an example using progressive alignment, but I couldn't find one.I actually know till creating a guide tree, after creating a guide tree we use guide tree to arrange sequences. This is the critical part. Can some please help me in explaining how to align sequences that are already aligned with a new sequence.For Example there are 5 sequences S1, S2, S3,S4 and S5. After aligning S1 and S3, suppose the aligned sequence is A1. Now the problem is I don't know how to align A1 with S2 or S4 or S5.Please help me by explaining that with an example. Your help is much appreciated.Thanks, Ravi",
    "target": "algorithms;bioinformatics"
  },
  {
    "id": "_softwareengineering.34547",
    "source": "Adding complexity by generalising: how far should you go? <eos> Reference question: https://stackoverflow.com/questions/4303813/help-with-interview-questionThe above question asked to solve a problem for an NxN matrix. While there was an easy solution, I gave a more general solution to solve the more general problem for an NxM matrix. A handful of people commented that this generalisation was bad because it made the solution more complex. One such comment is voted +8.Putting aside the hard-to-explain voting effects on SO, there are two types of complexity to be considered here:Runtime complexity, i.e. how fast does the code runCode complexity, i.e. how difficult is the code to read and understandThe question of runtime complexity is something that requires a better understanding of the input data today and what it might look like in the future, taking the various growth factors into account where necessary.The question of code complexity is the one I'm interested in here. By generalising the solution, we avoid having to rewrite it in the event that the constraints change. However, at the same time it can often result in complicating the code. In the reference question, the code for NxN is easy to understand for any competent programmer, but the NxM case (unless documented well) could easily confuse someone coming across the code for the first time.So, my question is this: Where should you draw the line between generalising and keeping the code easy to understand?",
    "target": "complexity"
  },
  {
    "id": "_softwareengineering.339568",
    "source": "Which should be done first: use cases or user stories? <eos> I've heard both about use cases (I'm talking about the description, not the diagram) and user stories being used to gather requirements and organize them better.I work alone, so I'm just trying to find the best way to organize requirements, to understand what has to be done in the development. I don't have, nor need, any formal methodologies with huge documents and so forth.User stories I've seem being used to build the product backlog, which contains everything that needs to be done in the development.Use cases, on the other hand, provide a description of how things are done in the system, the flow of interaction between external actors and the system.It seems to me that for one use case there are several user stories.This leads me to the following question: when discovering requirements, what should I do first? Find and write user stories or find and write use cases? Or they should be done at the same time somehow?I'm actually quite confused. Regarding use cases and user stories, for a developer who works alone, what is a good workflow, to use these methodologies correctly in order to have a better development?",
    "target": "agile;requirements;user story;use case"
  },
  {
    "id": "_unix.239413",
    "source": "Issues Installing Ruby without sudo <eos> I am migrating a website to a server that is running Ubuntu 14.04.2 LTS, the website is managed through git and built using Jekyll. Jekyll is installed as ruby gem and unfortunately the server does not have ruby installed.I attempted to install ruby to my user folder (I am not a sudoer)./configure --prefix=$HOME/bin/ruby && make && make installand it appears to install fine, with the one warning:skip installing bundle gems because of lacking zlibWhen I execute the ruby executable, I get the following errors: $./ruby system --upgrade    ./ruby: No such file or directory -- system (LoadError)$./tmp/ruby-2.2.3/bin/gem install jekyll/usr/bin/env: ruby: Permission denied$ ./bin/ruby/bin/gem install jekyllERROR:  Loading command: install (LoadError)    cannot load such file -- zlibERROR:  While executing gem ... (NoMethodError)    undefined method `invoke_with_build_args' for nil:NilClassI looked into the zlib, but could not find how to install it locally and set ruby to point to it.When trying rvm, I found I was missing the following packages:libreadline6-dev zlib1g-dev libssl-dev libyaml-dev libsqlite3-dev sqlite3 autoconf libgdbm-dev libncurses5-dev automake libtool bison pkg-config libffi-devAnyone have some build experience that may help?",
    "target": "ubuntu;ruby"
  },
  {
    "id": "_cs.75588",
    "source": "Asynchronous Encryption with wordlists <eos> As I understand it encrypted emails have a high profile (detectable through pgp header / attachment). Would it be possible to match the encrypted data with a wordlist to hide the fact that the email contains a encrypted message? I know that the other person would need the same list of words for decrypting and the message would be only a bunch of random words, but the fact that its encrypted world be not as obvious for automated scanning.EDIT: As pointed out I am referring to steganography to hide from traffic analysis. ",
    "target": "encryption"
  },
  {
    "id": "_unix.254276",
    "source": "How to delete, without rm/unlink <eos> Related to another question I asked here [https://unix.stackexchange.com/questions/253932/rename-folder-with-odd-characters]I'm wondering if it's possible to bypass the normal rm/rmdir/unlink binaries and delete a file using another method.  Maybe say by finding out exactly where on the disk a file or folder resides, and writing different data to that location, wiping out the folder or file.  How would one go about doing that, and would it cause problems for the OS or filesystem?Or, is there a .. I hesitate to call it a file but an area of the disk that can be viewed and edited with a hex editor, say, to find and unlink the exact reference to this folder/file?  And then, is there a different way of doing that specific to HFS+ and/or OS X?EDIT1: I'm interested not in deleting the contents of a file here, I'm interested in removing a file and/or folder using methods outside of rm/unlink.  I'm not trying to get rid of data in a forensic sense, I'm trying to remove a folder that refuses to be removed (see question I linked to above).",
    "target": "filesystems;osx"
  },
  {
    "id": "_codereview.127168",
    "source": "Rails create create default database records <eos> In my application I have an accounts model:class Account < ActiveRecord::Base  belongs_to :user  has_many :invoicesendThe Account model belongs to the User model. After the user is created, some default accounts must be created:class User < ActiveRecord::Base  has_many :accounts  after_create do    Account.create(name: Repairs,user: self)    Account.create(name: Supplies, user: self)  endendInvoices can then be assigned to one of these initial accounts:class Invoice < ActiveRecord::Base  belongs_to :accountsendIs this the proper way to to create the default accounts?",
    "target": "ruby;ruby on rails;database"
  },
  {
    "id": "_softwareengineering.107733",
    "source": "Removing elements of an 'at least one' association <eos> let's assume - regardless from technology and programming languages - you have a type and the type has an association to another type. This association has the complexity of 'at least one' (1..n). How would you specify the behavior, when removing elements from this association based on a predicate? Say, the predicate fits to all elements, thus the removal would violate the 1..n constraint, would you remove all elements but one or would you rather not remove any element in this case (and have a transactional-like behavior)?",
    "target": "language agnostic"
  },
  {
    "id": "_unix.351451",
    "source": "List directories, then files - with single command? <eos> I really don't like how Linux ls -al mixes files and directories. Is it possible to list directories, then files, with single command? dirAdirBdirCfileAfileBfileC",
    "target": "linux;shell script;ls"
  },
  {
    "id": "_softwareengineering.240668",
    "source": "How does a search functionality fit in DDD with CQRS? <eos> In Vaughn Vernon's book Implementing domain driven design and the accompanying sample application I found that he implemented a CQRS approach to the  iddd_collaboration bounded context.He presents the following classes in the application service layer:CalendarApplicationService.java     CalendarEntryApplicationService.javaCalendarEntryQueryService.javaCalendarQueryService.javaI'm interested to know if an application will have a search page that feature numerous drop downs and check boxes with a smart text box to match different search patterns; How will you structure all that search logic?In a command service or a query service?Taking a look at the CalendarQueryService.java I can see that it has 2 methods for a huge query, but no logic at all to mix and match any search filters for example.I've heard that the application layer shouldn't have any business logic, so where will I construct my dynamic query? or maybe just clutter everything in the Query service?",
    "target": "design;object oriented;architecture;domain driven design;cqrs"
  },
  {
    "id": "_codereview.86856",
    "source": "Return true if the elements of an array do not contain one or the other <eos> I am gradually completing the CodingBat exercises for Java. Here is the one I just did:Given an array of ints, return true if it contains no 1's or it contains no 4's. Here is my code:public boolean no14(int[] nums) {    int oneCount = 0;    int fourCount = 0;    for (int i = 0; i < nums.length; i++) {        if (nums[i] == 1) {            oneCount++;        }        if (nums[i] == 4) {            fourCount++;        }    }    if (oneCount > 0 && fourCount > 0) {        return false;    }    return true;}Now, I am pretty unfamiliar with arrays, so I would just like to know if there is a simpler/shorter way of finding such information without setting a count for each number? Perhaps using a regular expression?",
    "target": "java;beginner;array"
  },
  {
    "id": "_codereview.45793",
    "source": "Knapsack 01 solution <eos> Solution to bounded knapsack 01 problem. Once again comprehensive description is difficult in this space, refer here. Looking for code review. optimizations and best practices.final class Item {    private final int value;    private final int weight;    public Item (int value, int weight) {        if (value == 0) {            throw new IllegalArgumentException(The value  + value +  should be positive.);        }        if (weight == 0) {            throw new IllegalArgumentException(The weight  + weight +  should be positive.);        }        this.value = value;        this.weight = weight;    }    public int getValue() {        return value;    }    public int getWeight() {        return weight;    }}public final class Knapsack01 {    private Knapsack01() {  }    /**     * Returns the maximum value, given set of items and maxweight     *      * @param items         the set of items.     * @param maxWeight     the max weight     * @return              the max value obeying the constraints     */    public static int getMaxValue (Item[] items, int maxWeight) {        if (maxWeight <= 0) {            throw new IllegalArgumentException(the maxweight:  + maxWeight +  should be positive);        }        int[][] knapsack = new int[items.length + 1][maxWeight + 1];        for (int item = 0; item <=items.length; item++) {             for (int weight = 0;  weight <= maxWeight; weight++) {                if (item == 0 || weight == 0) {                     continue;                }                int itemWeight = items[item - 1].getWeight();                if (weight >= itemWeight) {                    int remainingWeight = weight -  itemWeight;                    // check the max value upto remainingWieght, the we might have computed before.                    int valueUptoRemainingWeight = knapsack[item - 1][remainingWeight];                    // how about trying currentItem + remainingItem ?                     int tentativeValue = items[item - 1].getValue() + valueUptoRemainingWeight;                    // compare this against previously calculated max-value                    int previousMaxValue = knapsack[item - 1][weight];                    knapsack[item][weight] = Math.max(tentativeValue, previousMaxValue);                } else {                    knapsack[item][weight] = knapsack[item - 1][weight];                 }            }        }        return knapsack[items.length][maxWeight];    }    public static void main(String[] args) {        Item i1 = new Item( 60, 10);        Item i2 = new Item(100, 20);        Item i3 = new Item(120, 30);        Item[] items = new Item[3];        items[0] = i1;        items[1] = i2;        items[2] = i3;        assertEquals(180, getMaxValue(items, 40));        assertEquals(220, getMaxValue(items, 50));        assertEquals(280, getMaxValue(items, 60));        assertEquals(280, getMaxValue(items, 60));    }}",
    "target": "java;algorithm;dynamic programming;knapsack problem"
  },
  {
    "id": "_softwareengineering.54612",
    "source": "How to capitalize maximally on location-independence  my personal #1-incentive for working as a developer <eos> To me the ultimate beauty in working as a developer is the fact that given a nice CV, your are going to find a new job, everywhere at any time.So I would like to ask if somebody here as experience in working while travelling for example. Or job-hopping from metropolis to metropolis every, say, six months.For example I have been investigating for how to get to Brazil. But it seems like that working as an employee in Brazil would be no option, b/c it takes a lot of time/money/effort to get the proper visas and permissions. So the only practical solution would be to freelance and the just travel, while getting your job done wherever you are.I bet my ass that there are loads of IT-guys out there and on here who know exactly what I am talking about.I'm looking forward to interesting ideas and stories.EDIT for the BOUNTY:I am not so much intersted in general wisdoms but rather in concrete accounts of personal experiences addressing the subject from people who can relate to my question and do have actual personal experiences to share. I am not asking for opinions and accounts of second-degree nature.EDIT for EVERYBODY (concrete questions):Where do you work while travelling? (office pooling? libraries? cafs?)Where do you sleep? I guess hotels are somewhat to expensive. (hostels? couchsurfing?)EDITI accepted Andy's reply as the answer mainly b/c of its romantic and positive undertone. Though of course there is not THE answer to that question. I was hoping for an intriguing discussion and given 11 vote ups and 5 bookmarks I seem to be not the only one who is interested in some input.So I hope some more people chime in and share their experiences.",
    "target": "freelancing"
  },
  {
    "id": "_webmaster.15719",
    "source": "User generated articles, how to do meta description? <eos> If users submit a lot of good quality articles on the site, what is the best way to approach the meta description tag?I see two options:Have a description box and rely on them to fill it sensibly and in a good quality wayJust exclude the meta descriptionMethod 1 is bad initially, but I'm willing to put time in going through and editing/checking all of them on a permanent basis.Method 2 is employed by the stack exchange site, and lets the search bots extract the best part of the page in the SERP.Thoughts?  Ideas?  I'm thinking a badly formed description tag is more damaging than not having one at all at the end of the day.I don't expect content to ever become unwieldy and too much to manage.",
    "target": "meta description;user engagement;articles;user generated content"
  },
  {
    "id": "_unix.352743",
    "source": "Get to command line from arch cinnamon <eos> I have a new arch install with Gnome Window Manager and Cinnamon. I created ~/.xinitrc with the command start cinnamon, and restarted the computer. Now the system boots into the login screen for Gnome and Cinnamon, but there is no command line shell available in the GUIs, and I'm unable to boot the computer into command line mode either.",
    "target": "command line;arch linux;gnome;cinnamon"
  },
  {
    "id": "_softwareengineering.141495",
    "source": "What is a microframework? <eos> Why are some frameworks (e.g. Flask for Python, Sinatra for Ruby) called microframeworks?What differentiates them from full-fledged frameworks, like Django or Rails?",
    "target": "terminology;frameworks"
  },
  {
    "id": "_softwareengineering.149037",
    "source": "Why is the folder name bin used in some frameworks and languages? <eos> I have been learning Java. And still after a prolonged time I don't know why the name of the folder is bin where one find all the tools for java?Is there is any logical reason behind that?I have also noticed the same in .Net framework also.",
    "target": "java;terminology"
  },
  {
    "id": "_unix.347001",
    "source": "Is the [PID] of Kernel Panic the killer of Kernel Panic? <eos> The following Kernel Panic occurred on my embedded board.I am using 3.10 Kernel.I am analyzing the cause of the Kernel Panic.The Kernel Panic message shows the PID(735).Feb 22 19:40:28 TEST kenel: CPU: 0 `PID: 735` Comm: cat Not tainted 3.10.73 #2Feb 22 19:40:28 TEST kernel: Process cat `(pid: 735`, stack limit = 0xee46c238)Does the PID mean the killer of the Kernel Panic?Below is my entire Kernel Panic message.Kernel Panic seems to be a really hard friend.... :(Feb 22 19:40:28 TEST kernel: Unable to handle kernel NULL pointer dereference at virtual address 0000000cFeb 22 19:40:28 TEST kernel: pgd = c0004000Feb 22 19:40:28 TEST kernel: [0000000c] *pgd=00000000Feb 22 19:40:28 TEST kernel: Internal error: Oops: 17 [#1] PREEMPT SMP ARMFeb 22 19:40:28 TEST kernel: Modules linked in: m2i_trn g_m2i libcomposite iptable_filter ip_tables smsc95xx usbnet mousedev rh_special_switches pn5xx_i2c mram tsc2007 spicc buzzer cover backlight device_info [last unloaded: spi_fieldbus]Feb 22 19:40:28 TEST kernel: CPU: 0 PID: 735 Comm: cat Not tainted 3.10.73 #2Feb 22 19:40:28 TEST kernel: task: ee404000 ti: ee46c000 task.ti: ee46c000Feb 22 19:40:28 TEST kernel: PC is at set_page_dirty+0x20/0x68Feb 22 19:40:28 TEST kernel: LR is at set_page_dirty+0xc/0x68Feb 22 19:40:28 TEST kernel: pc : [<c00a3c50>]    lr : [<c00a3c3c>]    psr: a0000013Feb 22 19:40:28 TEST kernel: sp : ee46de48  ip : 0002f9f9  fp : b6ffa000Feb 22 19:40:28 TEST kernel: r10: ee46dee0  r9 : ee46de84  r8 : b6ffc000Feb 22 19:40:28 TEST kernel: r7 : c0fd3860  r6 : 00000000  r5 : c0fd3860  r4 : ee3d87ecFeb 22 19:40:28 TEST kernel: r3 : 00000000  r2 : 40080068  r1 : c0fd3860  r0 : 00000012Feb 22 19:40:28 TEST kernel: Flags: NzCv  IRQs on  FIQs on  Mode SVC_32  ISA ARM  Segment userFeb 22 19:40:28 TEST kernel: Control: 10c5387d  Table: 2eb3c04a  DAC: 00000015Feb 22 19:40:28 TEST kernel: Feb 22 19:40:28 TEST kernel: PC: 0xc00a3bd0:Feb 22 19:40:28 TEST kernel: 3bd0  e2505000 1a000001 e1a00005 e8bd8038 e375001c e2841048 03a0001a 13a00019Feb 22 19:40:28 TEST kernel: 3bf0  eb0456e6 eafffff7 e92d4010 e1a04000 eb002f48 e590304c e5933010 e3130c02Feb 22 19:40:28 TEST kernel: 3c10  08bd8010 e5943000 e3130a02 08bd8010 e1a00004 e3a0100d e8bd4010 eaffdee6Feb 22 19:40:28 TEST kernel: 3c30  e92d4038 e1a05000 eb002f3a e3500000 0a00000a e5903044 e1a01005 e3a00012Feb 22 19:40:28 TEST kernel: 3c50  e593400c eb044d0a e59f3034 e1a00005 e3540000 01a04003 e12fff34 e8bd8038Feb 22 19:40:28 TEST kernel: 3c70  e5953000 e3130010 18bd8038 e1a01005 e3a00004 eb045711 e2700001 33a00000Feb 22 19:40:28 TEST kernel: 3c90  e8bd8038 c00fd924 e92d4030 e1a04000 e24dd00c eb002f1f e5943000 e1a05000Feb 22 19:40:28 TEST kernel: 3cb0  e3130001 0a00002b e3500000 0a000003 e590304c e5933010 e3130001 0a000004Feb 22 19:40:28 TEST kernel: Feb 22 19:40:28 TEST kernel: LR: 0xc00a3bbc:Feb 22 19:40:28 TEST kernel: 3bbc  e92d4038 e1a04002 e5923044 e5933000 e12fff33 e2505000 1a000001 e1a00005Feb 22 19:40:28 TEST kernel: 3bdc  e8bd8038 e375001c e2841048 03a0001a 13a00019 eb0456e6 eafffff7 e92d4010Feb 22 19:40:28 TEST kernel: 3bfc  e1a04000 eb002f48 e590304c e5933010 e3130c02 08bd8010 e5943000 e3130a02Feb 22 19:40:28 TEST kernel: 3c1c  08bd8010 e1a00004 e3a0100d e8bd4010 eaffdee6 e92d4038 e1a05000 eb002f3aFeb 22 19:40:28 TEST kernel: 3c3c  e3500000 0a00000a e5903044 e1a01005 e3a00012 e593400c eb044d0a e59f3034Feb 22 19:40:28 TEST kernel: 3c5c  e1a00005 e3540000 01a04003 e12fff34 e8bd8038 e5953000 e3130010 18bd8038Feb 22 19:40:28 TEST kernel: 3c7c  e1a01005 e3a00004 eb045711 e2700001 33a00000 e8bd8038 c00fd924 e92d4030Feb 22 19:40:28 TEST kernel: 3c9c  e1a04000 e24dd00c eb002f1f e5943000 e1a05000 e3130001 0a00002b e3500000Feb 22 19:40:28 TEST kernel: Feb 22 19:40:28 TEST kernel: SP: 0xee46ddc8:Feb 22 19:40:28 TEST kernel: ddc8  000000a8 0000006d b6f6a000 c105ace0 00000000 ffffffff 0000006d c06c8f40Feb 22 19:40:28 TEST kernel: dde8  c00a3c50 a0000013 ffffffff ee46de34 b6ffc000 c000dd98 00000012 c0fd3860Feb 22 19:40:28 TEST kernel: de08  40080068 00000000 ee3d87ec c0fd3860 00000000 c0fd3860 b6ffc000 ee46de84Feb 22 19:40:28 TEST kernel: de28  ee46dee0 b6ffa000 0002f9f9 ee46de48 c00a3c3c c00a3c50 a0000013 ffffffffFeb 22 19:40:28 TEST kernel: de48  326c375f ee3d87ec ee3d87e8 c00b8db0 ee46de58 ee785c00 c0f51b1c edef6f60Feb 22 19:40:28 TEST kernel: de68  ee93edb8 326c375f ee46c000 ee93edb8 b6ffc000 b6ffbfff 60000013 00000000Feb 22 19:40:28 TEST kernel: de88  fffffffe 00000000 ee46c000 edef6f60 ffffffff ee46dee0 00000000 00000000Feb 22 19:40:28 TEST kernel: dea8  ee46c000 ee785c40 00000000 c00b98c0 00000000 ee46c000 edef6c60 ee46df08Feb 22 19:40:28 TEST kernel: Feb 22 19:40:28 TEST kernel: R1: 0xc0fd37e0:Feb 22 19:40:28 TEST kernel: 37e0  40080068 ee913501 000010ea 00000000 00000001 c0fd37d4 c0fd3a34 00000000Feb 22 19:40:28 TEST kernel: 3800  40080068 ee913501 000010e2 00000000 00000001 c0f94cf4 c0fd3754 00000000Feb 22 19:40:28 TEST kernel: 3820  40080068 ee913501 000010da 00000000 00000001 c0fd3694 c0fd3734 00000000Feb 22 19:40:28 TEST kernel: 3840  4002002c ef074d64 00000038 ffffffff 00000001 c0f92af4 c0f8ed94 00000000Feb 22 19:40:28 TEST kernel: 3860  40080068 ee97a400 000b6ffa 00000000 00000001 c0fbbeb4 c0f91674 00000000Feb 22 19:40:28 TEST kernel: 3880  4002002c ef074d64 00000033 ffffffff 00000001 c0fa6034 c0f94574 00000000Feb 22 19:40:28 TEST kernel: 38a0  40000000 00000000 00000002 ffffffff 00000000 c0fc8a14 c0f91514 00000000Feb 22 19:40:28 TEST kernel: 38c0  40080068 ee913501 00001146 00000000 00000001 c0fd8d54 c0f92d34 00000000Feb 22 19:40:28 TEST kernel: Feb 22 19:40:28 TEST kernel: R4: 0xee3d876c:Feb 22 19:40:28 TEST kernel: 876c  00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000Feb 22 19:40:28 TEST kernel: 878c  00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000Feb 22 19:40:28 TEST kernel: 87ac  00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000Feb 22 19:40:28 TEST kernel: 87cc  00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000Feb 22 19:40:28 TEST kernel: 87ec  305b375f 00000000 31af57df 305d375f 00000000 00000000 00000000 00000000Feb 22 19:40:28 TEST kernel: 880c  00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000Feb 22 19:40:28 TEST kernel: 882c  00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000Feb 22 19:40:28 TEST kernel: 884c  00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000Feb 22 19:40:28 TEST kernel: Feb 22 19:40:28 TEST kernel: R5: 0xc0fd37e0:Feb 22 19:40:28 TEST kernel: 37e0  40080068 ee913501 000010ea 00000000 00000001 c0fd37d4 c0fd3a34 00000000Feb 22 19:40:28 TEST kernel: 3800  40080068 ee913501 000010e2 00000000 00000001 c0f94cf4 c0fd3754 00000000Feb 22 19:40:28 TEST kernel: 3820  40080068 ee913501 000010da 00000000 00000001 c0fd3694 c0fd3734 00000000Feb 22 19:40:28 TEST kernel: 3840  4002002c ef074d64 00000038 ffffffff 00000001 c0f92af4 c0f8ed94 00000000Feb 22 19:40:28 TEST kernel: 3860  40080068 ee97a400 000b6ffa 00000000 00000001 c0fbbeb4 c0f91674 00000000Feb 22 19:40:28 TEST kernel: 3880  4002002c ef074d64 00000033 ffffffff 00000001 c0fa6034 c0f94574 00000000Feb 22 19:40:28 TEST kernel: 38a0  40000000 00000000 00000002 ffffffff 00000000 c0fc8a14 c0f91514 00000000Feb 22 19:40:28 TEST kernel: 38c0  40080068 ee913501 00001146 00000000 00000001 c0fd8d54 c0f92d34 00000000Feb 22 19:40:28 TEST kernel: Feb 22 19:40:28 TEST kernel: R7: 0xc0fd37e0:Feb 22 19:40:28 TEST kernel: 37e0  40080068 ee913501 000010ea 00000000 00000001 c0fd37d4 c0fd3a34 00000000Feb 22 19:40:28 TEST kernel: 3800  40080068 ee913501 000010e2 00000000 00000001 c0f94cf4 c0fd3754 00000000Feb 22 19:40:28 TEST kernel: 3820  40080068 ee913501 000010da 00000000 00000001 c0fd3694 c0fd3734 00000000Feb 22 19:40:28 TEST kernel: 3840  4002002c ef074d64 00000038 ffffffff 00000001 c0f92af4 c0f8ed94 00000000Feb 22 19:40:28 TEST kernel: 3860  40080068 ee97a400 000b6ffa 00000000 00000001 c0fbbeb4 c0f91674 00000000Feb 22 19:40:28 TEST kernel: 3880  4002002c ef074d64 00000033 ffffffff 00000001 c0fa6034 c0f94574 00000000Feb 22 19:40:28 TEST kernel: 38a0  40000000 00000000 00000002 ffffffff 00000000 c0fc8a14 c0f91514 00000000Feb 22 19:40:28 TEST kernel: 38c0  40080068 ee913501 00001146 00000000 00000001 c0fd8d54 c0f92d34 00000000Feb 22 19:40:28 TEST kernel: Feb 22 19:40:28 TEST kernel: R9: 0xee46de04:Feb 22 19:40:28 TEST kernel: de04  c0fd3860 40080068 00000000 ee3d87ec c0fd3860 00000000 c0fd3860 b6ffc000Feb 22 19:40:28 TEST kernel: de24  ee46de84 ee46dee0 b6ffa000 0002f9f9 ee46de48 c00a3c3c c00a3c50 a0000013Feb 22 19:40:28 TEST kernel: de44  ffffffff 326c375f ee3d87ec ee3d87e8 c00b8db0 ee46de58 ee785c00 c0f51b1cFeb 22 19:40:28 TEST kernel: de64  edef6f60 ee93edb8 326c375f ee46c000 ee93edb8 b6ffc000 b6ffbfff 60000013Feb 22 19:40:28 TEST kernel: de84  00000000 fffffffe 00000000 ee46c000 edef6f60 ffffffff ee46dee0 00000000Feb 22 19:40:28 TEST kernel: dea4  00000000 ee46c000 ee785c40 00000000 c00b98c0 00000000 ee46c000 edef6c60Feb 22 19:40:28 TEST kernel: dec4  ee46df08 ee785c00 ee785c00 ee46c000 c00bf4ec c0f696e0 0025ceb0 ee785c00Feb 22 19:40:28 TEST kernel: dee4  00000001 00000000 00000000 ffffffff c045ec74 00000000 00000072 00000400Feb 22 19:40:28 TEST kernel: Feb 22 19:40:28 TEST kernel: R10: 0xee46de60:Feb 22 19:40:28 TEST kernel: de60  c0f51b1c edef6f60 ee93edb8 326c375f ee46c000 ee93edb8 b6ffc000 b6ffbfffFeb 22 19:40:28 TEST kernel: de80  60000013 00000000 fffffffe 00000000 ee46c000 edef6f60 ffffffff ee46dee0Feb 22 19:40:28 TEST kernel: dea0  00000000 00000000 ee46c000 ee785c40 00000000 c00b98c0 00000000 ee46c000Feb 22 19:40:28 TEST kernel: dec0  edef6c60 ee46df08 ee785c00 ee785c00 ee46c000 c00bf4ec c0f696e0 0025ceb0Feb 22 19:40:28 TEST kernel: dee0  ee785c00 00000001 00000000 00000000 ffffffff c045ec74 00000000 00000072Feb 22 19:40:28 TEST kernel: df00  00000400 ee912000 00000000 c045ec74 00000000 c045e9dc 00000001 c045e7f8Feb 22 19:40:28 TEST kernel: df20  00000000 c045ec74 ee785c30 ee785c00 00000000 ee404000 ee785c00 c0029360Feb 22 19:40:28 TEST kernel: df40  ee4042fc c00302a0 00000020 00000001 c0680eb4 00000000 00060006 c004fa88Feb 22 19:40:28 TEST kernel: Process cat (pid: 735, stack limit = 0xee46c238)Feb 22 19:40:28 TEST kernel: Stack: (0xee46de48 to 0xee46e000)Feb 22 19:40:28 TEST kernel: de40:                   326c375f ee3d87ec ee3d87e8 c00b8db0 ee46de58 ee785c00Feb 22 19:40:28 TEST kernel: de60: c0f51b1c edef6f60 ee93edb8 326c375f ee46c000 ee93edb8 b6ffc000 b6ffbfffFeb 22 19:40:28 TEST kernel: de80: 60000013 00000000 fffffffe 00000000 ee46c000 edef6f60 ffffffff ee46dee0Feb 22 19:40:28 TEST kernel: dea0: 00000000 00000000 ee46c000 ee785c40 00000000 c00b98c0 00000000 ee46c000Feb 22 19:40:28 TEST kernel: dec0: edef6c60 ee46df08 ee785c00 ee785c00 ee46c000 c00bf4ec c0f696e0 0025ceb0Feb 22 19:40:28 TEST kernel: dee0: ee785c00 00000001 00000000 00000000 ffffffff c045ec74 00000000 00000072Feb 22 19:40:28 TEST kernel: df00: 00000400 ee912000 00000000 c045ec74 00000000 c045e9dc 00000001 c045e7f8Feb 22 19:40:28 TEST kernel: df20: 00000000 c045ec74 ee785c30 ee785c00 00000000 ee404000 ee785c00 c0029360Feb 22 19:40:28 TEST kernel: df40: ee4042fc c00302a0 00000020 00000001 c0680eb4 00000000 00060006 c004fa88Feb 22 19:40:28 TEST kernel: df60: c0680eb4 ef391d40 00000000 ee46c000 000000f8 c000e3e8 ee46c000 00000000Feb 22 19:40:28 TEST kernel: df80: 00000000 c0030a20 00000000 000700de b6fd9760 b6fd9760 000000f8 c0030aa4Feb 22 19:40:28 TEST kernel: dfa0: 00000000 c000e240 000700de b6fd9760 00000000 000700ca b6ff84c0 00000000Feb 22 19:40:28 TEST kernel: dfc0: 000700de b6fd9760 b6fd9760 000000f8 00000002 00000000 00010000 00000000Feb 22 19:40:28 TEST kernel: dfe0: 000000f8 be8b5474 b6f6afc3 b6f14276 60000030 00000000 00000000 00000000Feb 22 19:40:28 TEST kernel: [<c00a3c50>] (set_page_dirty+0x20/0x68) from [<c00b8db0>] (unmap_single_vma+0x4d0/0x63c)Feb 22 19:40:28 TEST kernel: [<c00b8db0>] (unmap_single_vma+0x4d0/0x63c) from [<c00b98c0>] (unmap_vmas+0x54/0x68)Feb 22 19:40:28 TEST kernel: [<c00b98c0>] (unmap_vmas+0x54/0x68) from [<c00bf4ec>] (exit_mmap+0xd8/0x1f8)Feb 22 19:40:28 TEST kernel: [<c00bf4ec>] (exit_mmap+0xd8/0x1f8) from [<c0029360>] (mmput+0x48/0xf4)Feb 22 19:40:28 TEST kernel: [<c0029360>] (mmput+0x48/0xf4) from [<c00302a0>] (do_exit+0x244/0x878)Feb 22 19:40:28 TEST kernel: [<c00302a0>] (do_exit+0x244/0x878) from [<c0030a20>] (do_group_exit+0x3c/0xb0)Feb 22 19:40:28 TEST kernel: [<c0030a20>] (do_group_exit+0x3c/0xb0) from [<c0030aa4>] (__wake_up_parent+0x0/0x18)Feb 22 19:40:28 TEST kernel: Code: 0a00000a e5903044 e1a01005 e3a00012 (e593400c) Feb 22 19:40:28 TEST kernel: ---[ end trace 28aa0afec355b4f9 ]---Feb 22 19:40:28 TEST kernel: Fixing recursive fault but reboot is needed!",
    "target": "kernel;kernel panic"
  },
  {
    "id": "_softwareengineering.196882",
    "source": "Assertions vs Exceptions - is my understanding of the differences between the two correct? <eos> Design By Contract uses preconditions and postconditions of the public  methods in a class together to form a contract between the class and  its clients.a) In code we implement preconditions and postconditions either as assertions or as exceptions? b) We implement preconditions and postconditions in code as exceptions if not fulfilling preconditions or postconditions doesn't indicate logically impossible situations or programming errors?c) we implement them in code as assertions when not fulfilling preconditions or postconditions does indicate logically impossible situations or programming errors?d) Should preconditions and postconditions only be defined on public methods?EDIT:Aren't the following checks considered to be part of a normal operation ( and as I already mentioned, I've seen plenty of articles on DbC using similar examples for preconditions, where checks were made against arguments supplied by the user ), since if the user enters bad data, then without checks operation won't be rejected and as such system will stop working according to specs:Link:public User GetUserWithIdOf(int id,        UserRepository userRepository) {  // Pre-conditions  if (userRepository == null)      throw new ArgumentNullException(          userRepository);  if (id <= 0)      throw new ArgumentOutOfRangeException(          id must be > 0);  User foundUser = userRepository.GetById(id);  // Post-conditions  if (foundUser == null)      throw new KeyNotFoundException(No user with  +          an ID of  + id.ToString() +           could be located.);  return foundUser;}",
    "target": "exceptions;assertions"
  },
  {
    "id": "_webmaster.16038",
    "source": "Website Access...DNS, ISP, issue? <eos> This isn't so much a code issue as it might be an issue with my ISP.  For some reason when I visit a site very often, like one I manage or write stories on, it will just stop pulling data down after a while.  It's very random when it happens, but probably happens once a week. If effects everyone who is accessing the site from this connection, and I can access other sites no problem.  Also, if I go outside the office back home, which is right down the street, and access the site it is fine.  I'm using Comcast in both locations.It's almost as if I have a limit on requests to each site and have hit my limit so it blocks the site for a while.Anybody have any clue what this might be?",
    "target": "dns;isp"
  },
  {
    "id": "_unix.55448",
    "source": "NetworkManager tries to connect to previous network after suspend, even if the network isn't there <eos> At home I am connected to network 'A' and can see WLANs 'B' and 'C' from my neighbours. I suspend my computer and when I get to work the next day, the system still thinks it's connected to the same network 'A' and that it still can see the 'B' and 'C' networks, even though they aren't there. It will stay there forever trying to connect to the 'A' network, until it's stopped and I select the correct network.It is not a major problem (I can just open the list of networks and connect to the correct one), but is quite annoying.It is like (but is different) this bug: https://bugs.launchpad.net/ubuntu/+source/network-manager/+bug/893316 (in the bug, the system connects to a different WLAN even though the previous one is still available; with my case it's the opposite).I think it's a NetworkManager problem, because I never saw it when I used wicd. What can it be?I'm using x86-64 Arch Linux, NM 0.9.6.4, Intel Wireless 1030 card (iwlagn module).",
    "target": "wifi;networkmanager"
  },
  {
    "id": "_softwareengineering.139187",
    "source": "Web development: no local server workflow <eos> I'm considering the reengineering of my web development ecosystem. We use Git very successfully to deploy new changes to our Production, Staging, and Development servers. Traditionally, I've always had a copy of Apache on my local machine - in the interest of keeping my local machine as lean as possible, I'm considering running Apache in a non-local VM and syncing changes somehow.My initial thought was to run something like rsync and cron (Mac development system) to monitor the directory for file changes and then sync them up. I have been tempted to use a separate branch in Git and writing a hook to have the Apache server pull in the changes, but versioning all of my changes may be unproductive, particularly on very experimental additions.My question is, is there something I'm not considering in this workflow? This particular project requires ColdFusion, so am I going to realize significant benefits over not having Apache/CFIDE locally?  ",
    "target": "web development;workflows"
  },
  {
    "id": "_cs.44828",
    "source": "Bringing images into alignment <eos> I observe a scene with two cameras, c1 and c2, that produce two images i1 and i2, respectively. What I now want is to bring i1 and i2 into alignment, that is I want to know where pixel (x,y) in i1 is in i2. This alignment-matrix should be valid in general, that is not only for i1 and i2, but also for further images of the cameras c1 and c2 as long as they haven't been moved. I believe this problem is called correspondence problem. I have now read quite a bit about camera calibration, image rectification, essential and fundamental matrix. But there are still open questions and I would not know how to achieve my task.So, the question basically is:The essential matrix E and the fundamental matrix F both only give constraints for the correspondence problem (point p in i1 must lie on line l in i2). How do I actually solve the problem?Thanks a lot for your time and answers!",
    "target": "computational geometry;image processing;computer vision"
  },
  {
    "id": "_unix.384337",
    "source": "S.gpg-agent.browser not found in debian strech while adding ppa <eos> I do not know about S.gpg-agent.browser error while adding ppa repository.Can I get more information for solve this?add-apt-repository ppa:webupd8team/java (or another repository)gpg: keybox '/tmp/tmph1zsbhtw/pubring.gpg' createdgpg: /tmp/tmph1zsbhtw/trustdb.gpg: trustdb createdgpg: key C2518248EEA14886: public key Launchpad VLC importedgpg: no ultimately trusted keys foundgpg: Total number processed: 1gpg:               imported: 1gpg: no valid OpenPGP data found.Exception in thread Thread-1:Traceback (most recent call last):  File /usr/lib/python3.5/threading.py, line 914, in _bootstrap_inner    self.run()  File /usr/lib/python3.5/threading.py, line 862, in run    self._target(*self._args, **self._kwargs)  File /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py, line 688, in addkey_func    func(**kwargs)  File /usr/lib/python3/dist-packages/softwareproperties/ppa.py, line 386, in add_key    return apsk.add_ppa_signing_key()  File /usr/lib/python3/dist-packages/softwareproperties/ppa.py, line 273, in add_ppa_signing_key    cleanup(tmp_keyring_dir)  File /usr/lib/python3/dist-packages/softwareproperties/ppa.py, line 234, in cleanup    shutil.rmtree(tmp_keyring_dir)  File /usr/lib/python3.5/shutil.py, line 480, in rmtree    _rmtree_safe_fd(fd, path, onerror)  File /usr/lib/python3.5/shutil.py, line 438, in _rmtree_safe_fd    onerror(os.unlink, fullname, sys.exc_info())  File /usr/lib/python3.5/shutil.py, line 436, in _rmtree_safe_fd    os.unlink(name, dir_fd=topfd)FileNotFoundError: [Errno 2] No such file or directory: 'S.gpg-agent.browser'",
    "target": "debian;ppa"
  },
  {
    "id": "_softwareengineering.99548",
    "source": "What factors influence you to try out a new framework or tool? <eos> I'm in the process of putting the final touches on an open-source framework that I hope to release in the next few months. It's something that I'd like to develop a community for and so I'm curious about what factors influence your decision to use a new framework or tool and why. Some of the specific things I'd like to know more about (feel free to add to this):Types of documentation/tutorials/instructionCommunity support (comments/forum)Updates (blog/social media/feeds)Look and feel of the project website designWhite papers/testimonialsA big feature listCommunity sizeToolsAbility to contributeProject test coverage (stability/security)Level of buzz (recommended by friends or around the web)Convincing marketing copyIdeally, I'd like to have all of the above, but what specific features/qualities will carry greater weight in getting programmers to adopt something new? What says, 'This is a professional-grade project,' and what are red flags that keep you from trying it out?",
    "target": "open source;frameworks"
  },
  {
    "id": "_unix.205962",
    "source": "Fedora 21 wired internet problem <eos> Booted up Fedora on my desktop (previously was running w8.1, with also some network problems on restart/wake but usually a reset of the adapter solved them.) No internet on the Fedora. Here are the outputs of  ping 192.168.1.1 (i.e. the router), ifconfig, ping www.google.com, ping a google IP and netstatNotice the extremely high packet loss on the pings. What could be wrong, what to try?",
    "target": "networking;fedora"
  },
  {
    "id": "_webapps.45054",
    "source": "How to have a discussion in Trello similar to the ones in Teambox <eos> One cool thing about Teambox is that you have a dedicated discussion page. Whats the best way to have a discussion in Trello?",
    "target": "trello"
  },
  {
    "id": "_cs.11069",
    "source": "Prize collecting steiner tree <eos> I'm reading about the prize collecting steiner tree problem and an approximation algorithm that uses randomization to set a lower bound on the optimal solution (see Chapter 5.7 in  The Design of Approximation Algorithms  by Williamson and Shmoys). I don't understand the second line in the proof for Lemma 5.16: .It seems to me that $V-V(T)$ is a much larger set than $U$. So, how can the total penalty for this set be upper bounded by the total penalty of a set that is much smaller?",
    "target": "algorithm analysis;optimization;approximation;trees"
  },
  {
    "id": "_datascience.16756",
    "source": "Can I test actions on a decision tree (or other classification model)? <eos> Disclaimer: I created this question on Cross-Validated where it is well on the way to earning me the Tumbleweed badge, but then I found this site and thought it might be more at home here.I'm using Azure ML, and I've produced a basic PoC model of student success using a Two-class Boosted Decision Tree. One of the features I've included is whether the student has received a particular kind of support. What I'd like to do is test whether providing that support to a particular student will result in an improved success rate.In order to test this, I thought I would run through the details of students who haven't received that support to get the baseline score from the model, then run through the same information but flipping the feature indicating that they've received support, and record the new score.Assuming that the support feature is reasonably independent (i.e. it's causing the label, not caused by it - one that I tried to test initially was a contact type that only happened when the students had been absent, so it wasn't appropriate to apply it to other students), is this a valid tactic for evaluating whether we should provide that support to other students in the future? Are there any pit-falls I can run in to when performing these kinds of tests?",
    "target": "predictive modeling;decision trees;azure ml"
  },
  {
    "id": "_unix.46231",
    "source": "rsync hardlink attempt copies <eos> I've tried setting up a script to hardlink my files to my box.com account (as it's a backup of my music library). As I want to run it automatically to sync my music across several devices, I wanted to use rsync as I'm on Mac OS X 10.7.4 (if anyone cares).The script I came up with however only copies the files instead of hardlinking them (the available disc space lowers when I start the script). What I'm trying to achieve is the box.com app syncing something outside its actual folder.I already RTFMed and googled but I can't come up with a proper solution so I hope you guys could help me.This is the script I use:rsync -azluPhmt --progress --link-dest=./iTunes ./iTunes/Users/admin/Box.com/iTunes --delete-during --exclude=*Album Artwork*",
    "target": "rsync;synchronization;hard link"
  },
  {
    "id": "_unix.371049",
    "source": "Changing Active Directory password for service account in Linux <eos> I am really new to but I am trying to use Kerberos to authenticate my active directory service account from my own CentOS 7 box, after which I then proceed to run queries in a remote database using sqlcmd.To give more context, a snippet of my working Python code is below:import subprocesskinit = ['kinit', 'serviceaccount@DIRECTORY.COM', '-k', '-t', '/usr/local/var/krb5kdc/serviceaccount.keytab']kinit_cl = subprocess.Popen(kinit, stdout=subprocess.PIPE)kinit_output = kinit_cl.stdout.read()klist = ['klist','-l']klist_cl = subprocess.Popen(klist, stdout=subprocess.PIPE)klist_output = klist_cl.stdout.read()print klist_outputif 'KEYRING:persistent' in klist_output:    print Service Account Authenticated    #proceed to run sqlcmd queriesMy question relates more to the management of the keytab where my credential is stored, which is great because my password is not stored in the clear. The password expires every 30 days though, and I've noticed that if I use kpasswd to change my password from the command line, it will ask for my old password. This would mean I would have to store it in the clear somewhere and pass it, whereas I am happy not knowing my password and letting a script manage this for me.To generate a new strong password in Python wont be an issue, my question is what command can I use to change a password without being prompted for the old password. A command from kadmin.local says the password is changed, but the password accepted is still the old password. kadmin gives me the error below even though I added the service account in as an admin to the local file:[root@osboxes krb5kdc]# kadmin.local -q addprinc serviceaccount/adminAuthenticating as principal serviceaccount/admin@DIRECTORY.COM with password.WARNING: no policy specified for serviceaccount/admin@DIRECTORY.COM; defaulting to no policyEnter password for principal serviceaccount/admin@DIRECTORY.COM: Re-enter password for principal serviceaccount/admin@DIRECTORY.COM: Principal serviceaccount/admin@DIRECTORY.COM created.[root@osboxes krb5kdc]# kinit serviceaccount/adminkinit: Client 'serviceaccount/admin@DIRECTORY.COM' not found in Kerberos database while getting initial credentials[root@osboxes krb5kdc]# kadmin serviceaccountkadmin: Client 'serviceaccount/admin@DIRECTORY.COM' not found in Kerberos database while initializing kadmin interfaceDo I need to do this only through kadmin? Or else how would I script this?",
    "target": "centos;python;password;active directory;kerberos"
  },
  {
    "id": "_cs.9250",
    "source": "Is there a name for this relation on CFGs? <eos> I'm looking for the name (or a name if there isn't one already) of this relation between $G_1=\\left<\\Sigma_1,\\mathcal{N}_1,\\mathcal{R}_1,S_1\\right>$ and $G_2=\\left<\\Sigma_2,\\mathcal{N}_2,\\mathcal{R}_2,S_2\\right>$:$$\\exists f_\\Sigma\\in\\Sigma_1\\times\\Sigma_2,f_\\mathcal{N}\\in\\mathcal{N_1}\\times\\mathcal{N}_2 \\text{ surjective functions s.t. }\\\\ \\mathcal{R}_2=\\left\\{f_\\mathcal{N}(N)\\rightarrow f(\\alpha)\\mid N\\rightarrow\\alpha\\in R_1\\right\\}\\text{ and } S_2=f_\\mathcal{N}(S_1) $$where $f$ is the extension of $f_\\Sigma$ and $f_\\mathcal{N}$ to words ($f\\in(\\Sigma_1\\cup\\mathcal{N}_1)^*\\times(\\Sigma_2\\cup\\mathcal{N}_2)^*$).In other words, you can map $G_1$ to $G_2$ (but not necessarily $G_2$ to $G_1$).If the mapping function were bijective, this would be an isomorphism, but they're not.What about if only $f_\\mathcal{N}$ is  surjective, i.e. $f_\\Sigma$ is bijective, or even the identity function?",
    "target": "terminology;formal grammars;context free"
  },
  {
    "id": "_unix.191048",
    "source": "How to make svn save credentials when --non-interactive <eos> I'm trying to get svn to save my https username+password to ~/.subversion from within an automated script. I can pass creds on the command-line but I do not want to be prompted about whether to save the password unencrypted. Unfortunately this does not create ~/.subversion/:svn --non-interactive --trust-server-cert --username myusername --password secret co https://private.example.com/src/repo/FYI I'm trying to do this for a Dockerfile that invokes a bower install with a bower.json that references a password-protected svn repo. Unfortunately there's no way to pass the svn credentials to bower via command-line or environment. I am currently working around it by running svn interactively and letting it create ~/.subversion, then zipping up that entire directory and ADDing it in the Dockerfile. I guess I could look at the file formats in ~/.subversion and create it with a script, but would rather let svn do it.",
    "target": "shell script;subversion"
  },
  {
    "id": "_cogsci.12291",
    "source": "Are Free Will and Motivation related? <eos> I'm aware of numerous experiments, like Stanford prison experiment, Milgram experiment which indicate that humans can act in ways opposite to their best intentions. For the purposes of this question, let's define Free Will as ability to act and strive without external coercion. Ability to accomplish my goals and ambitions. In this context Free Will suddenly seems a lot like motivation. Found these quotes:Likewise, compatibilists define free will as freedom to act according  to one's determined motives without hindrance from other individualsThis makes me ask - Is Free Will related or is just another word for a more modern concept of motivation?",
    "target": "cognitive psychology;motivation;cognitive modeling;behavior;free will"
  },
  {
    "id": "_codereview.115953",
    "source": "Secure custom password hashing <eos> My team and I have ended up creating this class, which is called directly from ASP.NET Identity as a custom password hasher. I'd like to know whether this would be overkill/use a lot of CPU, specially because the site is going to be hosted in Azure.To take into account:  HashPassword is called when a new user is being created by IdentityVerifyHashedPassword is called when a user logs inprivate const int SaltByteLength = 16;private const int DerivedKeyLength = 20;private const int minIterationCount = 44000;private const int maxIterationCount = 50000;public string HashPassword(string password){    return CreateSecurePasswordHash(password);}public PasswordVerificationResult VerifyHashedPassword(string hashedPassword, string providedPassword){    providedPassword = Convert.ToBase64String(ComputeHash(providedPassword));    bool result = ComparePasswordHashes(providedPassword, hashedPassword);    return result ? PasswordVerificationResult.Success : PasswordVerificationResult.Failed;}private static byte[] ComputeHash(string password){    using (MemoryStream ms = new MemoryStream())    using (StreamWriter sw = new StreamWriter(ms))    {        sw.Write(password);        sw.Flush();        ms.Position = 0;        using (SHA512CryptoServiceProvider provider = new SHA512CryptoServiceProvider())            return provider.ComputeHash(ms);    }}private static string CreateSecurePasswordHash(string password){    byte[] hashedPassword = ComputeHash(password);    byte[] salt = GenerateSecureSalt();    Random rand = new Random();    int iterationCount = rand.Next(minIterationCount, maxIterationCount);    byte[] hashValue = GenerateSecureHashValue(hashedPassword, salt, iterationCount);    byte[] iterationCountBtyeArr = BitConverter.GetBytes(iterationCount);    byte[] valueToSave = new byte[SaltByteLength + DerivedKeyLength + iterationCountBtyeArr.Length];    Buffer.BlockCopy(salt, 0, valueToSave, 0, SaltByteLength);    Buffer.BlockCopy(hashValue, 0, valueToSave, SaltByteLength, DerivedKeyLength);    Buffer.BlockCopy(iterationCountBtyeArr, 0, valueToSave, salt.Length + hashValue.Length, iterationCountBtyeArr.Length);    return Convert.ToBase64String(valueToSave);}private static byte[] GenerateSecureSalt(){    using (RNGCryptoServiceProvider rngCSP = new RNGCryptoServiceProvider())    {        byte[] salt = new byte[SaltByteLength];        rngCSP.GetBytes(salt);        return salt;    }}private static byte[] GenerateSecureHashValue(byte[] password, byte[] salt, int iterationCount){    using (var pbkdf2 = new Rfc2898DeriveBytes(password, salt, iterationCount))    {        return pbkdf2.GetBytes(DerivedKeyLength);    }}private static bool ComparePasswordHashes(string guess, string saved){    if (string.IsNullOrEmpty(guess) || string.IsNullOrEmpty(saved))        return false;    byte[] passwordGuess = Convert.FromBase64String(guess);    byte[] savedPassword = Convert.FromBase64String(saved);    byte[] salt = new byte[SaltByteLength];    byte[] actualPasswordByteArr = new byte[DerivedKeyLength];    int iterationCount = savedPassword.Length - (salt.Length + actualPasswordByteArr.Length);    byte[] iterationCountByteArr = new byte[iterationCount];    Buffer.BlockCopy(savedPassword, 0, salt, 0, SaltByteLength);    Buffer.BlockCopy(savedPassword, SaltByteLength, actualPasswordByteArr, 0, actualPasswordByteArr.Length);    Buffer.BlockCopy(savedPassword, (salt.Length + actualPasswordByteArr.Length), iterationCountByteArr, 0, iterationCount);    byte[] passwordGuessByteArr = GenerateSecureHashValue(passwordGuess, salt, BitConverter.ToInt32(iterationCountByteArr, 0));    return ConstantTimeComparison(passwordGuessByteArr, actualPasswordByteArr);}private static bool ConstantTimeComparison(byte[] passwordGuessHash, byte[] savedHash){    uint difference = (uint)passwordGuessHash.Length ^ (uint)savedHash.Length;    for (var i = 0; i < passwordGuessHash.Length && i < savedHash.Length; i++)    {        difference |= (uint)(passwordGuessHash[i] ^ savedHash[i]);    }    return difference == 0;}All connections to my website are done strictly through TLS 1.2. Also, in the application where this code is used, absolutely no information about the user is stored, other than username, password and email. All other information is temporary and is deleted upon the user logging out.",
    "target": "c#;authentication"
  },
  {
    "id": "_unix.320085",
    "source": "ctrl+c on login <eos> when I ssh using mobaXterm to a RHEL7 server (with uname and pwd saved) I just get a blinking cursor that will take input but not execute anything.  I can press ctrl+c and then appears bash-4.2$ and all is well however this is annoying and adding ctrl+c to mobaXterm execute command on log in does not solve the issue here.Using other ssh/telnet tools such as putty,secureFX yields same results (ctrl+c to get interactive shell)",
    "target": "bash;login"
  },
  {
    "id": "_softwareengineering.283705",
    "source": "At what point can I call GPL code my code? <eos> I need some legal advice if possible.So I'm going to be implementing some code under OSS license. I realize that even if I rewrote the implementation, I need to include the license.However a lot of sources that I use to learn are under GPL Licenses. So even if I take what I learned and implemented it in my own way and heavily modified the code, with the only similarities being logic flow, I still can't claim the work as my own?What about algorithms that are extremely proficient? (Like binary Heaps)Do I need to include the inventor of the binary heap into my code?Also, as I understand it from GPL, if I use the code, even modified, does this mean I need to release the all of my code that even associates with it? So if I make a whole application in a closed system and I plan to sell it, I still have to release all my code via OSS license?Let me know if I need to provide more information about my question, thanks.",
    "target": "legal"
  },
  {
    "id": "_codereview.154869",
    "source": "Quarantine implementation <eos> I have an assignment to implemented a Quarantine project where I was left with the some unit tests and a skeleton of the implementation. I provided the solution below and get rejected from the interview. The feedbacks I get (I feel lucky that they provided, usually, they have legal issues) are, NO indicator of design (DDD, or design patterns) The code is not scalable (extendable)Overall, this is C code written in Java (bit harsh and made me sad). Is there any better way to do that? I mainly looking suggestions from the very experienced engineers. public class QuarantineTest {    private Quarantine quarantine;    @Before    public void setUp() {        // The responsibility of the Quarantine object is to simulate diseases on a group of patients.        // It is initialized with a list of patients' health status, separated by a comma.        // Each health status is described by one or more characters        // (in the test below, we will always have only one disease / patient)        // The characters mean:        // H : Healthy        // F : Fever        // D : Diabetes        // T : Tuberculosis        quarantine = new Quarantine(F,H,D,D,D,H,T);        // Quarantine provides medicines to the patients, but can not target a specific group of patient.        // The same medicines are always given to all the patients.        // Then Quarantine can provide a report with this format:        // F:1 H:2 D:0 T:1 X:3        // Report give the number of patients that have the given disease.        // X means Dead    }    @Test    public void beforeTreatment() throws Exception {        assertEquals(F:1 H:2 D:3 T:1 X:0, quarantine.report());    }    // people died in the Diabetes    @Test    public void noTreatment() throws Exception {        quarantine.wait40Days();        // diabetics die without insulin        assertEquals(F:1 H:2 D:0 T:1 X:3, quarantine.report());    }    // feaver is cured    //  people died in the Diabetes    @Test    public void aspirin() throws Exception {        quarantine.aspirin();        quarantine.wait40Days();        // aspirin cure Fever        assertEquals(F:0 H:3 D:0 T:1 X:3, quarantine.report());    }    @Test    public void antibiotic() throws Exception {        quarantine.antibiotic();        quarantine.wait40Days();        // antibiotic cure Tuberculosis        // but healthy people catch Fever if mixed with insulin.        assertEquals(F:1 H:3 D:0 T:0 X:3, quarantine.report());    }    @Test    public void insulin() throws Exception {        quarantine.insulin();        quarantine.wait40Days();        // insulin prevent diabetic subject from dying, does not cure Diabetes,        assertEquals(F:1 H:2 D:3 T:1 X:0, quarantine.report());    }    @Test    public void antibioticPlusInsulin() throws Exception {        quarantine.antibiotic();        quarantine.insulin();        quarantine.wait40Days();        // if insulin is mixed with antibiotic, healthy people catch Fever        assertEquals(F:3 H:1 D:3 T:0 X:0, quarantine.report());    }    @Test    public void paracetamol() throws Exception {        quarantine.paracetamol();        quarantine.wait40Days();        // paracetamol heals fever        assertEquals(F:0 H:3 D:0 T:1 X:3, quarantine.report());    }    @Test    public void paracetamolAndAspirin() throws Exception {        quarantine.paracetamol();        quarantine.aspirin();        quarantine.wait40Days();        // paracetamol kills subject if mixed with aspirin        assertEquals(F:0 H:0 D:0 T:0 X:7, quarantine.report());    }}import java.util.LinkedHashMap;import java.util.Map;import java.util.regex.Pattern;import java.util.stream.Collectors;public class Quarantine {    private Map<Character, Integer> map;    boolean insuline;    boolean wait40Days;    boolean antibiotic;    boolean aspirin;    boolean paracetamol;    public Quarantine(String subjects) {        try {            map = Pattern.compile(,)                    .splitAsStream(subjects)                    .collect(Collectors.groupingBy(                            s -> s.charAt(0),                            LinkedHashMap::new,                            Collectors.collectingAndThen(Collectors.counting(), Long::intValue)                    ));            map.put('X', 0);        } catch (Exception e) {            e.printStackTrace();        }    }    // aspirin cures fever    public void aspirin() {        aspirin = true;    }    public void antibiotic() {        antibiotic = true;    }    public void insulin() {        insuline = true;    }    public void paracetamol() {        paracetamol = true;    }    public void wait40Days() {        if (antibiotic) {            // antobiotic is mixed with the insuline            if (insuline) {                map.put('F', map.get('F') + map.get('H'));                map.put('H', map.get('T'));                map.put('T', 0);                return;            }            // only the antibiotic            else {                map.put('H', map.get('H') + map.get('T'));                map.put('T', 0);                wait40Days = true;            }        } else if (paracetamol) {            // paracetamol mixed with the aspirin kills everyone            if (aspirin) {                map.put('X', map.get('X') + map.get('F') + map.get('H') + map.get('D') + map.get('T'));                map.put('F', 0);                map.put('H', 0);                map.put('D', 0);                map.put('T', 0);                return;            } else { // only provides the paracetamol as medication                map.put('H', map.get('H') + map.get('F'));                map.put('F', 0);                wait40Days = true;            }        } else if(aspirin) { // only provides aspirin as medication            map.put('H', map.get('H') + map.get('F'));            map.put('F', 0);            wait40Days = true;        } else if (insuline) {            // only provision of insuline prevents death from the diabetes            return;        } else {         // no medicine was provided, just waited for the 40 days            wait40Days = true;        }        /*        check if we will needs to wait for 40 days        after the medication to see the affect        * */        if (wait40Days) {            map.put('X', map.get('D'));            map.put('D', 0);            wait40Days = false;        }    }    // get the Quarantine report    public String report() {        try {            final String[] result = {};            map.forEach((k, v) -> result[0] += k.toString() + : + v.toString() +  );            return result[0].trim();        } catch (Exception e) {            e.printStackTrace();        }        return null;    }}",
    "target": "java;object oriented;design patterns;junit"
  },
  {
    "id": "_codereview.19386",
    "source": "Resilient Wrapper for Robocopy in C# <eos> I was being troubled a lot by Robocopy (or maybe anti-virus or maybe Network Hardware). I copy files from the Dynamic View of Clearcase to the local machine for a fresh build. The copy would frequently fail due to:2012/12/06 15:35:07 ERROR 64 (0x00000040)... The specified network name is no longer available.The server and all network hardware resides in another geographical location, so there is no way to ascertain the hardware issues. The anti-virus can never be disabled as per some policy. The Snapshot View cannot be used as per another weird policy or prejudice.I am left with just one option: to make Robocopy resilient. The following is what I have come up with, which is a wrapper for Robocopy. Please review this.Summary: Call Robocopy with parametersGive it some time and certain number of tries for proper executionFirst try is allowed 10 minutes. The subsequent tries will have an increment of 5 minutes. Maximum 5 tries and 30 minutes are allowed.Catch all Robocopy error codes(0, 1 and 2 are success codes) and re-try.namespace ResilientRobocopy    {        class Program        {            static int Main(string[] args)            {                string commandLine = string.Empty;                int count = 0;                foreach (string str in args)                {                    string temp = string.Empty;                    if ((count == 0) || (count == 1))                    {                        temp = \\ + str + \\ +  ;                    }                    else                    {                        temp = str +  ;                    }                    commandLine = commandLine + temp;                    count += 1;                }                Console.WriteLine(--------------------------------------------------------------------);                Console.WriteLine(Robocopy Command Line:  + commandLine);                int returnCode = -1;                int tries = 0;                while (((returnCode == -1) || (returnCode == -2)) && (tries != 5))                {                    Console.WriteLine(Calling Robocopy);                    returnCode = StartCopy(commandLine, tries);                    tries += 1;                }                Console.WriteLine(--------------------------------------------------------------------);                return returnCode;            }            static int StartCopy(string commandLine, int tries)            {                Process robocopy = new Process();                try                {                    robocopy = Process.Start(C:\\\\Windows\\\\SysWOW64\\\\robocopy.exe, commandLine);                    int timeLimit = 120 + (60 * tries);                    for (int i = 0; i <= timeLimit; i++)                    {                        Thread.Sleep(1000 * 5);                        if (!robocopy.HasExited)                        {                            continue;                        }                        else                        {                            if (robocopy.ExitCode > 2)                            {                                Console.WriteLine(Robocopy exited with code:  + robocopy.ExitCode.ToString());                                Console.WriteLine(Retrying...);                                return -1;                            }                            else                            {                                Console.WriteLine(Robocopy exited with code:  + robocopy.ExitCode.ToString());                                Console.WriteLine(Robocopy Done!);                                return robocopy.ExitCode;                            }                        }                    }                    if (!robocopy.HasExited)                    {                        Console.WriteLine(Killing Robocopy. Took too much time. Try try again till you succeed...);                        robocopy.Kill();                        return -1;                    }                    else                    {                        if (robocopy.ExitCode > 2)                        {                            Console.WriteLine(Robocopy exited with code:  + robocopy.ExitCode.ToString());                            Console.WriteLine(Retrying...);                            return -1;                        }                        else                        {                            Console.WriteLine(Robocopy exited with code:  + robocopy.ExitCode.ToString());                            Console.WriteLine(Robocopy Done!);                            return robocopy.ExitCode;                        }                    }                }                catch(Exception ex)                {                    Console.WriteLine(Exception:  + ex.ToString());                    return -2;                }                finally                {                    robocopy.Close();                }            }        }    }",
    "target": "c#"
  },
  {
    "id": "_softwareengineering.278802",
    "source": "Calculating disk capacity and max data transfer rate of a hard drive? <eos> I am learning about hard drive concepts and I came across this question:Suppose we have a 10000 RPM disk has 8 heads and 480 cylinders. It is divided into 120-  cylinder zones with the cylinders in different zones containing 200, 240, 280, and 320 sectors. As- sume each sector contains 4096 bytes and a seek time between adjacent cylinders of 2 msec.what is the disk capacity?What is the maximum transfer rate?For the first question, I started off with these stepsAdd the sectors together for a 120 cylinder zone: (200+240+280+320) = 1040 sectorsSince there are 4 cylinder zones, there are a total of 4160 sectors. Multiply the sectors by 4096: 4160 * 4096 bytes = 17.03 MBThat seems incredibly small. Is this correct?For problem 2, I am not sure where to start.",
    "target": "storage"
  },
  {
    "id": "_codereview.141844",
    "source": "Divide and conquer approach in search for max element, take 2 <eos> Adopted some suggestions from the answer of my previous post. Here is the code:trait MaxElem<T> {    fn max_elem<'a>(&'a self) -> &'a T;}impl<T> MaxElem<T> for [T] where T: Ord {    fn max_elem<'a>(&'a self) -> &'a T {        max_elem_helper(self, 0, self.len())    }}fn max_elem_helper<'a, T>(array: &'a [T], left: usize, right: usize) -> &'a T     where T: Ord{    if right - left == 1 {        return &array[left];    }    let mid = (left + right) / 2;    let max1 = max_elem_helper(array, left, mid);    let max2 = max_elem_helper(array, mid, right);    if max1 > max2 {        max1    } else {        max2    }}#[cfg(test)]mod test {    use max_elem::MaxElem;    #[test]    fn test_max_elem() {        let array = [11, 2, 9, 1, 3, 88];         let m = array.max_elem();         assert_eq!(*m, 88);    }}All suggestions are welcome.",
    "target": "rust"
  },
  {
    "id": "_unix.8380",
    "source": "Truncate a file on a certain pattern <eos> How would I go about truncating a binary file when a certain pattern is found?For instance, I want to truncate the file at the first occurrence of the pattern 0xFFFFFFFF.I think something like awk could do the trick... but I'm not exactly sure how.thanks",
    "target": "awk"
  },
  {
    "id": "_softwareengineering.99814",
    "source": "Using snippets of open source code in my application <eos> I'm working on an internal company application(not built on Wordpress) that needs to have shortcode functionality similar to Wordpress (http://codex.wordpress.org/Shortcode_API).  Wordpress has a bunch of functions relating to handling short codes but the ones I was looking at were just the ones that handled the regex portion of the process.Is there something wrong with just using the few functions I need from Wordpress in my application?  If it is ok, how do I go about giving credit in those sections.I did a quick check and Wordpress is licensed under GPLv2. I'm using the Kohana Framework in my application which is licensed under BSD.  I'm not sure if that changes anything but I thought I'd include it just in case.",
    "target": "open source"
  },
  {
    "id": "_cstheory.9151",
    "source": "Capacitated multiple vehicle routing problem with handovers <eos> I'm looking for literature about a variant of the capacitated vehicle/fleet routing problem (a.k.a. VRP, CVRP, etc.) that takes into account the possibility of handovers between multiple vehicles, i.e. the ability to drop off an item from a vehicle and let another one pick it up. Put otherwise, we could say we are allowing an item to be transported (sequentially) by more than one vehicle, e.g.:at time $T^u$ vehicle $V_1$ takes the item from the pick-up location $P^u$ at time $T^d_1 \\geq T^u$ vehicle $V_1$ drops it off at an intermediate point $P_1$at time $T^u_1 \\geq T^d_1$ vehicle $V_2$ picks it up from the intermediate point $P_1$ at time $T^d_2 \\geq T^u_1$ vehicle $V_2$ drops it off at the intermediate point $P_2$ ... at time $T^u_{n-1} \\geq T^d_{n-1}$ vehicle $V_n$ picks it up from intermediate point $P_{n-1}$ at time $T^d \\geq T^u_{n-1}$ vehicle $V_n$ delivers it to the final destination $P^d$.In the VRP overviews I found this variant is not mentioned so I was wondering if anybody knew if it has been investigated at all. note: the term handover is something I came up with to describe the problem: it may not be the one commonly used to denote this kind of variant. The intended meaning, w.r.t. the example above is that e.g. when vehicle $V_1$ drops off the object $O_1$ at $P_1$ and $V_2$ picks it up we could say that $V_1$ hands over object $O_1$ to $V_2$ in $P_1$. update: Reworded to clarify that I'm talking about multiple vehicles (it was just kind-of implicit in the original wording). ",
    "target": "ds.algorithms;reference request;graph theory;graph algorithms;optimization"
  },
  {
    "id": "_unix.204353",
    "source": "Dual boot Opensuse13.2 and windows8.1 boot loader <eos> I installed Opensuse13.2 using dual boot on my system that originally had windows 8.1. If I was using UEFI boot option then my computer automatically logged onto the windows OS. So I was using legacy boot option which automatically logged into Opensuse and when I wanted to log into windows I changed it from the boot menu at the start up. The Grub boot loader was not showing windows8.1 at the startup as an option. In an attempt to correct this I followed a tutorial and used the following command. bcdedit /set {bootmgr} path \\EFI\\opensuse\\shim.efiAfter doing this now I can not log into my windows installation. It says that no boot option can be found. I am logged into my linux installation and have access to my windows OS files. Is there some way that I can manually edit some file to correct this?",
    "target": "dual boot;boot loader;uefi"
  },
  {
    "id": "_codereview.144192",
    "source": "PLZ HELP MEH IMPROVA MEH LOLCAT CODEZ, WHUCH CALCULUTS FAWCTORIALS <eos> SUNCE MEH BEEN WRUTEN CODEZ IN MUNY DIFFRNT PROGRAMMING LANGUAGES, MEH THOUGHTZ THAT ME TRY TO WRITE CODEZ IN AN ESOTERIC LANGUAGE. MEH CODEZ CALCULUTS A FAWCTORIAL OF UH USR INPUTTED NUMBAH IN LOLCODE, LOL.SOME OF MEH QUSTIONS:IZ MEH CODEZS A IDMITIC LOLCAT PROGUM?IZ THERE A GOODER WAY OF WRUTING MEH factorial FUNCSHUNS?TRANSLATION:Since I've been writing and trying programs in many different languages, I thought I'd give esoteric language a crack. So I used LOLCODE to write a program that calculates the  factorial of a user given number:Questions for consideration:Is my LOLCODE code idiomatic to the LOLCODE language?Is there a easier way to write my factorial function?LOLCAT.lolBTW Calculates the factorial for a user given integerBTW Author: PythonicBTW Version: 1.0HAI 1.2HOW DUZ I factorial YR n    BOTH SAEM n AN 0, O RLY?        YA RLY            FOUND YR 1        NO WAI            FOUND YR PRODUKT OF n AN factorial DIFF OF n AN 1    OICIF U SAY SOHOW DUZ I main    I HAS A user_input    VISIBLE ENTER AN NUMBAH    VISIBLE TO FINDZ ITZ FAWCTORIAL::     GIMMEH user_input    VISIBLE DE FAWCTORIAL OF  user_input  IZ::  factorial user_input    VISIBLE KTHXBYE!IF U SAY SOmainKTHXBYEFor those of you who are not fortunate enough to have a LOLCODE compiler, here is a link to a REPL.IT of the code.NOTE: All answer must be given in proper LOLCODE English, with an optional translation in regular English. Failure to do so will result in me releasing my LOLCATS upon you....",
    "target": "recursion;functional programming;lolcode"
  },
  {
    "id": "_softwareengineering.229923",
    "source": "Does it make sense to break fluid interface if a bad argument is passed? <eos> If I chain some setters together and one of them does not return $this, then I will get a fatal error. But maybe that is a good thing.$object = new object();$object->set('name','foo')->set('number',12)->set('color'=>'brown');class object {  protected $name;  protected $number;  protected $color;  protected $allowed_to_set = array('name','color');  public function set($property,$value) {    if(!in_array((string)$property,$this->allowed_to_set)) {      return false;    } else {      $this->$property = $value;      return $this;    }  }}",
    "target": "php;interfaces"
  },
  {
    "id": "_codereview.35845",
    "source": "Listening for values changed by the memory <eos> I'm fetching some values from the memory. I would like to create some custom events that I can listen to for each value. Since there are no existing events regarding memory changes, I've decided to go with a polling solution. I'm restarting the timer below manually just to make certain the work is finished.Would this be an okay solution (considering the circumstances) to my problem? Do you see any issues with creating multiple timers? As far as I know, each instance will run on its own thread.This was the best I could come up with right off the bat. I would like to hear your input regarding possible improvements:var vc = new ValueChange(1000, Blah.GetMemoryValue());vc.PropertyChanged += OnPropertyChanged;void OnPropertyChanged(object sender, PropertyChangedEventArgs e){    Console.WriteLine(prop change);}public class ValueChange : INotifyPropertyChanged{    private int _val;    private readonly System.Timers.Timer _timer;    private int Value    {        set        {           _val = value;            RaisePropertyChanged(Val);        }        get        {            return _val;        }   }   public ValueChange(double polingInterval, int val)   {        _val = val;       _timer = new System.Timers.Timer { AutoReset = false, Interval = polingInterval };       _timer.Elapsed += TimerElapsed;       _timer.Start();   }   private void TimerElapsed(object sender, ElapsedEventArgs e)   {       var newValue = Blah.GetMemoryValue();       if (Value != newValue)       {           Value = newValue;       }        _timer.Start();   }   public event PropertyChangedEventHandler PropertyChanged;    private void RaisePropertyChanged(string caller)    {       if (PropertyChanged != null)       {           PropertyChanged(this, new PropertyChangedEventArgs(caller));       }    }}",
    "target": "c#;multithreading;timer"
  },
  {
    "id": "_unix.162486",
    "source": "How can I list the patches of an installed package in SUSE? <eos> Let's say that I am using a program called hello which I have downloaded using the zypper. The question is how can I see if a specific .patch is included into this hello package?Basically, what I think it that I need the rpm source file (but how can I find it using zypper ?) and then do unrpm and check if the *.patch file is included. Is it correct or there's another way?",
    "target": "rpm;suse;patch;zypper"
  },
  {
    "id": "_webmaster.27753",
    "source": "Confusion over W3C POWDER standard (PICS alternative) <eos> Now that PICS is dead, I still need an easy way to tell users that my website is for mature audiences only. I intend to use PICS tags, but POWDER is said to be the new standard. Is it really used? And how do I set it up? Are there simple example XML files which I can copy for my own use?",
    "target": "meta tags;adult content"
  },
  {
    "id": "_unix.244168",
    "source": "How to remove non english chars from a string <eos> I have a BASH script I wrote that removes META data off mp3 (etc) then I chop them up to reform them if needed resample the mp3 and reasign the data to make a directory to corraspond to artist / album ... I got a hold of some mp3's that have non english chars in the middle of the song title. I need to know the best way to remove that middle part leaving both ends of the sting put back together to the title of the song. using exiftool I strip the META data off giving me this output placed into the var-name ARTIST1=`exiftool -Artist $FILENAME -p '$Artist'` TITLE1=`exiftool -Title  $FILENAME -p '$Title'` ALBUM1=`exiftool -Album  $FILENAME -p '$Album'`first strip... Artist is -> The Stranglers and Friendsfirst strip... Album is -> Live infirst strip... Title is -> The Raven  With Basil Gabbisong title in META DataThe Raven   With Basil Gabbihow would I strip what is between the META data song name to get this instead?The Raven With Basil Gabbiwhere the syntext would look something like this newSongName=$( what ever code goes here to strip out that non english sting part )so I can write the new string back into the file replacing the old META data with the new string. Thanks",
    "target": "shell script;string"
  },
  {
    "id": "_softwareengineering.151352",
    "source": "Is it a good programming practice to have a class with several .h files? <eos> I suppose the class have several different interfaces. Some it shows to some class, some it shows to other classes.Are there any good reason for that?One thing I can think of is with one .h per class, interface would either be public or private.What about if I want some interface to be available to some friends' class and some interface to be truly public?Sample:@interface listNewController:BadgerStandardViewViewController <UITableViewDelegate,UITableViewDataSource,UITextFieldDelegate,NSFetchedResultsControllerDelegate,UIScrollViewDelegate,UIGestureRecognizerDelegate> {}@property (nonatomic) IBOutlet NSFetchedResultsController *FetchController;@property (nonatomic) IBOutlet UITextField *searchBar1;@property (nonatomic) IBOutlet UITableView *tableViewA;+ (listNewController *) singleton; //For Easier Access-(void)collapseAll;-(void)TitleViewClicked:(TitleView *) theTitleView;-(NSUInteger) countOfEachSection:(NSInteger)section;@endMany of those public properties and function are only ever called by just one other classes. I wonder why I need to make them available to many classes.It's in Objective-c by the wayWhat do you mean? Interface is interface. In C++ you can declare some classes as friends. In Objective-c you cannot I think. Basically I want to emulate that. My friends can access some members that's not available too publicly,.",
    "target": "objective c;interfaces;inheritance"
  },
  {
    "id": "_reverseengineering.8616",
    "source": "How to verify if Firefox is actually sending zlib data over SPDY? <eos> I recently posted a StackOverflow bounty related to figuring out whether it is Wireshark, Firefox or just the data sample that is wrong, judging by the fact that latest Wireshark cannot dissect it. This is a continuation of the question.Assuming that the bounty linked above is correct, here is the full SYN_STREAM SPDY packet that Wireshark cannot dissect:800300010100015500000001000000004000783fe3c6a7c2003b01c4fe00000009000000073a6d6574686f6400000003474554000000053a70617468000000012f000000083a76657273696f6e00000008485454502f312e31000000053a686f73740000000d3139322e3136382e302e313734000000073a736368656d650000000568747470730000000a757365722d6167656e74000000414d6f7a696c6c612f352e30202857696e646f7773204e5420352e313b2072763a33302e3029204765636b6f2f32303130303130312046697265666f782f33302e30000000066163636570740000003f746578742f68746d6c2c6170706c69636174696f6e2f7868746d6c2b786d6c2c6170706c69636174696f6e2f786d6c3b713d302e392c2a2f2a3b713d302e380000000f6163636570742d6c616e67756167650000000e656e2d55532c656e3b713d302e3500000003646e740000000131000000ffffAccording to Wireshark, the compressed header should start at 783f. Unfortunately, I cannot decompress it:$ pythonPython 2.7.8 (default, Nov 10 2014, 08:19:18) [GCC 4.9.2 20141101 (Red Hat 4.9.2-1)] on linux2Type help, copyright, credits or license for more information.>>> import zlib>>> header = 783fe3c6a7c2003b01c4fe00000009000000073a6d6574686f6400000003474554000000053a70617468000000012f000000083a76657273696f6e00000008485454502f312e31000000053a686f73740000000d3139322e3136382e302e313734000000073a736368656d650000000568747470730000000a757365722d6167656e74000000414d6f7a696c6c612f352e30202857696e646f7773204e5420352e313b2072763a33302e3029204765636b6f2f32303130303130312046697265666f782f33302e30000000066163636570740000003f746578742f68746d6c2c6170706c69636174696f6e2f7868746d6c2b786d6c2c6170706c69636174696f6e2f786d6c3b713d302e392c2a2f2a3b713d302e380000000f6163636570742d6c616e67756167650000000e656e2d55532c656e3b713d302e3500000003646e740000000131000000ffff.decode('hex')>>> zlib.decompress(header)Traceback (most recent call last):  File <stdin>, line 1, in <module>zlib.error: Error 2 while decompressing dataIs it actually zlib? How can I prove it?",
    "target": "decompress;https protocol"
  },
  {
    "id": "_unix.232132",
    "source": "RedHat5 stop copy on select <eos> At work do we use RHEL5, with Gnome 2.28.2, we are also required to do development work in RHEL5.RHEL5 have this strange feature that it will replace the clipboard with anything i highlight. This is very unproductive for me and really slows me down when working.How can i disable this feature in RHEL5, i am not able to update to a newer version of RedHat or Gnome.",
    "target": "x11;clipboard"
  },
  {
    "id": "_softwareengineering.76500",
    "source": "How do cloud platforms-as-a-service measure CPU time? <eos> I'm currently assessing Google App Engine, and one of the answers from Hidden limitations of Google App Engine? stated:Performance will surprise you. GAE is  optimized for many tiny queries and  you get warned if a query takes any  CPU time at all. You get 6.5 (at last  check) free hours per day, but it's a  mystical number and you should test.You'll find that time as you measure  it doesn't relate to the CPU or  datastore CPU time, because (for  example) under the covers there might  be multiple machines updating indexes  during deletes/updates. Some users  have found huge CPU usage when  uploading bulk data - many hours of  usage for e.g. 20 min of real time.Your Java instance might need to be  powered-up if it hasn't been hit in (I  think) 20 minutes. The benefit is that  they can pass their smart management  on to you as cheaper costs, but it  does mean you'll experience a short  delay, and see a high CPU warning on  the first request in a while.For many cases, Python datastore  access is faster than Java JDO. You'll  likely find that using the low-level  API for Java faster.Some developers seem to have  experienced more datastore errors  thank you would expect (around 0.4-1%  maybe?). I haven't yet.I'm wondering what factors go into determining a PaaS's CPU time (like, in this case, the 6.5 hours free that you get with GAE). For example, does it include the total time it takes for the database to transfer data over to the client?Do the costs under this model increase dramatically as you get more users?",
    "target": "google app engine;hosting;google cloud datastore;paas"
  },
  {
    "id": "_softwareengineering.285117",
    "source": "Storing values in SQL whose types are determined in runtime <eos> I have come across a need of storing runtime determined values in a SQL database.For example, there is a GUI where a user can add new editable fields. So the user adds a field Name, chooses the value type String and fills in the value Arthur. Then the user adds a new field Money, chooses the value type Decimal and fills in the value 10.05.As seen above, the user is able to add any fields with any value types. My idea is to have a SQL table schema as follow:FieldName (varchar) - eg. 'Money' or 'IsAlive'FieldType (varchar) - eg 'Decimal' or 'Boolean'FieldValue (varchar) - eg. '10.5' or '1'This would mean that I can store any pre-defined data type in the table whether it's a string, boolean or long. The problem is that I am not sure it's the best approach to cast those values to string and then cast again when reading from the table.Another option would be to have a column of each type but that sounds even worse.Does my approach to cast everything to string sounds sensible or should I try something else?",
    "target": "sql;type casting"
  },
  {
    "id": "_unix.125252",
    "source": "openvpn server doesn't NAT the incoming traffic <eos> It's couple of days that I'm having hard time figuring out what's wrong with openVPN. Few days ago, I installed and configured openVPN on a Debian server and also on my Ubuntu client. I am facing a weird behavior: OpenVPN server NATs the incoming traffic whenever it wants, but not always! It looks that the iptables rules on the Debian server get deleted at some specified time every day (I'm not sure though), because the next day if I re-enter the iptable rules (for NAT & DNS queries forwarding) like following,iptables -t nat -A POSTROUTING -s 10.8.0.0/24 -o eth0 -j MASQUERADEiptables -t nat -A PREROUTING -i tun+ -p udp --dport 53 -j DNAT --to-destination 8.8.8.8and force-reload openvpn daemon and restart openvpn (at both ends), the traffic gets routed as it should. I've saved iptables rules in the file /etc/iptables.conf and I reload it at boot (/etc/rc.local), but nevertheless the problem still persists. Here is the content of my /etc/iptables.conf:# Generated by iptables-save v1.4.14 on Tue Apr 15 13:50:46 2014*security:INPUT ACCEPT [166249:16762540]:FORWARD ACCEPT [3659:1318578]:OUTPUT ACCEPT [165776:17724102]COMMIT# Completed on Tue Apr 15 13:50:46 2014# Generated by iptables-save v1.4.14 on Tue Apr 15 13:50:46 2014*raw:PREROUTING ACCEPT [169911:18081298]:OUTPUT ACCEPT [165776:17724102]COMMIT# Completed on Tue Apr 15 13:50:46 2014# Generated by iptables-save v1.4.14 on Tue Apr 15 13:50:46 2014*nat:PREROUTING ACCEPT [42:2524]:INPUT ACCEPT [1:40]:OUTPUT ACCEPT [24:1504]:POSTROUTING ACCEPT [24:1504]-A PREROUTING -i tun+ -p udp -m udp --dport 53 -j DNAT --to-destination 8.8.8.8-A POSTROUTING -s 10.8.0.0/24 -o eth0 -j MASQUERADECOMMIT# Completed on Tue Apr 15 13:50:46 2014# Generated by iptables-save v1.4.14 on Tue Apr 15 13:50:46 2014*mangle:PREROUTING ACCEPT [169911:18081298]:INPUT ACCEPT [166249:16762540]:FORWARD ACCEPT [3659:1318578]:OUTPUT ACCEPT [165776:17724102]:POSTROUTING ACCEPT [169435:19042680]COMMIT# Completed on Tue Apr 15 13:50:46 2014# Generated by iptables-save v1.4.14 on Tue Apr 15 13:50:46 2014*filter:INPUT ACCEPT [166249:16762540]:FORWARD ACCEPT [3659:1318578]:OUTPUT ACCEPT [165776:17724102]COMMIT# Completed on Tue Apr 15 13:50:46 2014Here I've posted my config files. The differences in my working client.conf & server.conf with those in that post are as follows:# client.confuser nobodygroup nogroup    redirect-gateway def1 #bypass-dns bypass-dhcpserver:# server.conf; duplicate-cn #not needed, commented out    user nobodygroup nogroup    I'll be deeply grateful if you save me from this chaos!",
    "target": "openvpn"
  },
  {
    "id": "_unix.324995",
    "source": "SAMBA/CIFS connection error <eos> I have been getting errors connecting to samba/cifs shares from like 3 weeks ago, I have 4 machines, one with Windows, 2 with Fedora 24 and one with Fedora 22. I have shares on the two fedora 24 machines and if I try to connect, for example, from one f24 machine to the other via thunar I get a No route to host. error. I also had configured a one-liner script on my fedora 22 box that connects to the f24 machine using the following command:# mount -t cifs -o username=****,password=**** '\\\\192.168.1.1\\share' remote/and it worked like a charm for a very long time, but recently it fails with this error:[  91.981816] CIFS VFS: Error connecting to socket. Aborting operation.[  91.981960] CIFS VFS: cifs_mount failed w/return code = -113Unable to find suitable address.I also tried to connect from one of my f24 machines to the other, and I get (on both machines, trying to connect to each other):Unable to find suitable address.But, if I try to connect using the same command from within the same target machine, it works without any issues, and it gets mounted correctly.The windows machine simply fails to connect. Why does this happen? How can I fix this? This is new to me since everything was working correctly until 2-3 weeks ago. Also I can ssh into any of them without any problem, the issue is completely on samba/cifs.",
    "target": "samba;cifs"
  },
  {
    "id": "_cstheory.4348",
    "source": "Collision Attacks, Message Digests and a Possible solution <eos> I've been doing some preliminary research in the area of message digests. Specifically collision attacks of cryptographic hash functions such as MD5 and SHA-1, such as the Postscript example and X.509 certificate duplicate.From what I can tell in the case of the postscript attack, specific data was generated and embedded within the header of the postscript (which is ignored during rendering) which brought about the internal state of the md5 to a state such that the modified wording of the document would lead to a final MD equivalent to the original. The X.509 took a similar approach where by data was injected within the comment/whitespace of the certificate.Ok so here is my question, and I can't seem to find anyone asking this question:Why isn't the length of ONLY the data being consumed added as a final block to the MD calculation?In the case of X.509 - Why is the whitespace and comments being taken into account as part of the MD?Wouldn't a simple processes such as one of the following be enough to resolve the proposed collision attacks:$MD(M + |M|) = xyz$$MD(M + |M| + |M| * magicseed_0 +...+ |M| * magicseed_n) = xyz$where :M : is the message|M| : size of the message in bitsMD : is the message digest function (eg: md5, sha, whirlpool etc)xyz : is the pairing of the acutal message digest value for the message M and |M|. <M,|M|>$magicseed_{i}$: Is a set of random values generated with seed based on the internal-state prior to the size being added.'+' : is a concatentation operation A+B+C = ABCThis technqiue should work, as to date all such collision attacks rely on adding more data to the original message.In short, the level of difficulty involved in generating a collision message such that:It not only generates the same MDBut is also comprehensible/parsible/compliantand is also the same size as the original message,is immensely difficult if not near impossible. Has this approach ever been discussed? Any links to papers etc would be nice.Further Question: What is the lower bound for collisions of messages of common length for a hash function H chosen randomly from U, where U is the set of universal hash functions ?Is it $1/N$ (where N is $2^{|M|}$) or is it greater? If it is greater, that implies there is more than 1 message of length |M| that will map to the same MD value for a given H.If that is the case, how practical is it to find these other messages? bruteforce would be of $O(2^N)$, is there a method of time complexity less than bruteforce?Links:Postscript: http://www.schneier.com/blog/archives/2005/06/more_md5_collis.htmlX.509: http://www.win.tue.nl/~bdeweger/CollidingCertificates/Note: This question is NOT as easy as it seems. Please read it very carefully and make sure you have understood exactly what is being asked. The answer will require understanding of martingales and distribution ensembles. If you are unsure what these are or how they apply to this particular problem then please do not post answers. Prior knowledge of this class of attack is required, please access the links above and the following: csse question. Please DO NOT focus on answers that relate to generating messages of length different from the original message as any such solution is invalid.",
    "target": "cr.crypto security;hash function"
  },
  {
    "id": "_unix.305984",
    "source": "core dumps for out of memory in linux <eos> How to create memory dumps for out of memory.If system is out of memory then oom-killer kills the process which occupies highest memory by some calculations.How can we get core dump of the process killed",
    "target": "linux;ubuntu;crash;core dump"
  },
  {
    "id": "_unix.71571",
    "source": "KDE how to remove Kickoff Application Launcher popup <eos> Every time I hover the cursor over K button, I get a popup: Kickoff Application Launcher. It irritates me a lot. I managed to remove task manager popups in it's properties. But for Kickoff there is no property to remove it.KDE version: 4.8.5.How to remove this popup?",
    "target": "kde"
  },
  {
    "id": "_softwareengineering.127300",
    "source": "I would like to improve in writing goal-oriented user stories/features <eos> I would like to improve my user stories writing abilities so I need your experience and guidance. I think that each variable part of a user story can be improved by following certain guidelines.1. RoleDefining possible roles may be the easiest part. The only problem is that user stories usually  just describe functional features that need development.Do you write non-functional stories? And I'm not thinking about technical stories that are related to other aspects of product planning like administrative things. I'm more thinking of additional supporting stories that support the same high-level goal. Like advertising related stories that are related to features?2. FeatureDefining features seems to be easy but it turns out it's not. Because I can see stories that are heavily related so certain roles can't be developed until others are finished. Example: User registration is a pillar user story that needs to be done first in order to develop other user stories that are related to registered user roles (logged in users and/or admins etc.). This one is very obvious but sometimes relationships are much more subtle.How do you avoid relationships between user stories? Is there a technique to break related stories apart so we can have better development parallelism? Breaking relationships also helps better sprint cycles because one story can't stall the whole sprint.3. BenefitThis one is the hardest part that I think I have least knowledge how to write good user stories with clear benefits.Do you actually write benefits per story or do you rather provide high level goals instead? Providing these instead of benefits makes it easy to see why certain user story is more important than the other? So it helps prioritisation.Is it wise to have shared benefits/goals between set of user stories?Do you write user stories without benefits part? Is that wise and what do you do instead?Do you write benefits in a way so they can be measurable? Can we do that and is it beneficial?4. User stories as a wholeHave you ever defined all user stories as epics? This would help filter out/prioritise those that give more to the common goals. Then split them into digestible chunks or per single feature user-stories.What additional metadata do you add to user stories? Also talking about user story grouping per higher feature or goal...",
    "target": "agile;product features;user story"
  },
  {
    "id": "_unix.254340",
    "source": "How to extend bash aliases <eos> How to create an alias that actually extends another alias of the same name inBash?Why:I used to have GREP_OPTIONS set on .bashrc to something like this:GREP_OPTIONS=-I --exclude=\\*~I also had a script (let us say, setup-java.sh) which I would call beforeworking on some Java projects. It would contain the line:GREP_OPTIONS=$GREP_OPTIONS --exclude-dir=classesIf I also use Sass, then I would call setup-sass.sh which contains the line:GREP_OPTIONS=$GREP_OPTIONS --exclude-dir=\\*/.sass-cacheBut GREP_OPTIONS wasdeprecated andapparently the standard solution is either create an alias or some script...",
    "target": "bash;grep;alias"
  },
  {
    "id": "_softwareengineering.290908",
    "source": "What uses does Smalltalks become: have? <eos> The become: message in Smalltalk causes one object to change into another, affecting all references to it.What uses does this language feature have? Does it get used in real code? Is it just a curiosity? Is it considered a good/bad practice to use it?",
    "target": "object oriented;memory;language features;smalltalk"
  },
  {
    "id": "_codereview.41215",
    "source": "Create news ticker animation <eos> I have this function in this fiddleJavaScript:var newsTicker = function (ele) {    var eles = ele.find('ul li'),        indexEle = 0,        dataEle = ele.find('.ticker-post'),        rotateChars = function (title) {            dataEle.text('');            indexCut = 0;            rotateCharsTimer = setInterval(function () {                if (dataEle.text().length == title.length) {                    clearInterval(rotateCharsTimer);                } else if (dataEle.text().length < title.length) {                    text = dataEle.text().concat(title.substr(indexCut, 1));                    dataEle.text(text);                };                if (title.length - 1 > indexCut) indexCut++;                else indexCut = 0;            }, 90);        },        loopLs = function () {            loopEle = eles.get(indexEle);            eleHref = $(loopEle).data('href');            eleTitle = $(loopEle).data('title');            dataEle.attr('href', eleHref);            if (typeof rotateCharsTimer != 'undefined') {                dataEle.fadeOut();                clearInterval(rotateCharsTimer);            }            dataEle.fadeIn();            rotateChars(eleTitle);            if (eles.length - 1 > indexEle) indexEle++;            else indexEle = 0;        }    loopLs();    setInterval(function (){loopLs()},9400);}HTML:<div id=news-ticker>    <div class=ticker-title>Breaking News:</div>    <ul>        <li data-href=#1 data-title=No 10 armed police arrested over hardcore pornography></li>        <li data-href=#2 data-title=EDF extends life of UK nuclear plants></li>        <li data-href=#3 data-title=Superwoman Stephanie Flanders on how to do it all></li>        <li data-href=#4 data-title=Will Liverpool deliver for Surez? Can Arsenal last?></li>    </ul>    <a class=ticker-post></a></div>Is this the best way to do this?",
    "target": "javascript;jquery"
  },
  {
    "id": "_unix.134915",
    "source": "How do I combine the -v and -B switches in grep? <eos> I have a list of currently installed kernels, and I'm trying to grep out both the currently installed kernel and the previously installed kernel. For this example, linux-image-3.2.0-60-generic is the currently running kernel, and these are the installed kernels:linux-image-3.2.0-49-genericlinux-image-3.2.0-51-genericlinux-image-3.2.0-52-genericlinux-image-3.2.0-53-genericlinux-image-3.2.0-54-genericlinux-image-3.2.0-55-genericlinux-image-3.2.0-56-genericlinux-image-3.2.0-57-genericlinux-image-3.2.0-58-genericlinux-image-3.2.0-59-genericlinux-image-3.2.0-60-genericlinux-image-3.2.0-61-genericlinux-image-3.2.0-63-genericlinux-image-3.2.0-64-genericI can use grep -v $(uname -r) to remove the currently running kernel from this list. However, I can't seem to use grep -v -B 1 $(uname -r) to remove current and previous kernel from the list. Is there a way to combine the -B and -v? Or am I approaching this entirely from the wrong direction?",
    "target": "grep"
  },
  {
    "id": "_ai.2106",
    "source": "How can one intuitively understand generative v/s discriminative models, specifically with respect to when each is useful? <eos> I'm trying to gain some intuition beyond definitions, in any possible dimension. I'd appreciate references to read.",
    "target": "machine learning;models"
  },
  {
    "id": "_webapps.80614",
    "source": "How discoverable is a phone-number-only Messenger user by full Facebook users (and vice versa)? <eos> Facebook's new Messenger app now lets you sign up with only a phone number, sidestepping the need for a full Facebook account. The docs are a bit sparse for those who want to be informed before signing up, so...If I sign up for a messenger-only account with a phone number:How am I discoverable by users with full Facebook accounts? (I.e. will they need my phone number to find me, or can they look me up by name in the global graph search and see my picture?)And how can I discover other contacts on the Messenger app to start chatting with them? (I.e. will the contact search bar search only contacts whose phone numbers I know, or will it search the global Facebook graph too - including Facebook users without phone numbers?)This seems an obvious enough thing to be in the messenger.com docs, but astonishingly this does not yet seem to be there",
    "target": "facebook;facebook chat"
  },
  {
    "id": "_softwareengineering.27328",
    "source": "RSpec vs Test::Unit in Rails <eos> I've never been really convinced of the advantages that you get by switching over to RSpec from Test::Unit in Ruby on Rails (despite reading from time to time about RSpec).What is it about RSpec that most Rails project seems to be using it?(some code examples clearly indicating advantages of one over the other would be much appreciated)",
    "target": "testing;unit testing;ruby on rails"
  },
  {
    "id": "_unix.375151",
    "source": "linuxbrew can not find `erl`(Erlang) command when I try to install `Elixir` on openSUSE Tumbleweed <eos> I don't know ruby language, but it seems there's no error on elixir.rb formulae script.Firstly depends_on Erlang18Requirement causes this error even erlang installed.And it can go to make phase if I delete that depends_on ... line with brew install elixir but also spit an error /bin/sh: erl: command not found.It looks like...==> Downloading https://github.com/elixir-lang/elixir/archive/v1.4.5.tar.gz  Already downloaded: /home/algorist/.cache/Homebrew/elixir-1.4.5.tar.gz    ==> make  Last 15 lines from /home/algorist/.cache/Homebrew/Logs/elixir/01.make:  2017-07-04 16:57:44 +0900  make/bin/sh: erl: command not found  At least Erlang 18.0 is required to build Elixir  make: *** [Makefile:62: lib/elixir/src/elixir.app.src] Error 1But erl command runs fine on terminal with any shells and irb(ruby interactive shell?) I don't know why erl command doesn't work with linuxbrew.Please help!",
    "target": "homebrew;brew"
  },
  {
    "id": "_webmaster.69289",
    "source": "Is it OK to redirect to a new address instead of showing 404 Error page? <eos> Here is my question, Recently I moved my site from blog.mysite.com to www.mysite.com.Then I added 301 permanent redirection using this code in .htaccess file.RewriteEngine onRewriteCond %{HTTP_HOST} ^blog\\.mysite\\.com$ [OR]RewriteCond %{HTTP_HOST} ^www\\.blog\\.mysite\\.com$RewriteRule ^/?$ http\\:\\/\\/www\\.mysite\\.com\\/ [R=301,L]Everything was OK, and when I go to my site by typing blog.mysite.com it automatically redirected to www.mysite.com.But, I found that when I click a Google search result of my old site  doesn't redirect to the new site. Guess Google result URL is http://blog.mysite.com/how-to-create-simple-but-fully-styled-navigationThough it doesn't redirect to http://www.mysite.com/how-to-create-simple-but-fully-styled-navigationIt only goes to the old URL which is http://blog.mysite.com/how-to-create-simple-but-fully-styled-navigationwhich shows my hosting provider's 404 Error page. So, then what I did was creating a custom 404 error page and added a php code to get the  Google's search result URL and replace the word 'blog' with 'www' then redirecting to http://www.mysite.com/how-to-create-simple-but-fully-styled-navigationSo, now everything's working perfectly and no any error pages. But I want to know if what I've done is OK with SEO logics. I've heard that 301 permanent redirection tells the Search engines that the site has moved. And where the new site is.I want to know if there's no damage to 301 redirection after I've created custom 404 page and added a tricky redirection...Thanks... Hope you understand. :-)",
    "target": "redirects;seo"
  },
  {
    "id": "_codereview.83637",
    "source": "Creating an enumerator based on an ATL collection <eos> I am designing a COM wrapper for a C++ library using ATL. Currently I am a little bit confused about enumerators that are based on ATL collections. I already wrote several enumerators based on STL collections, but since there is no ICollectionOnATL-interface (such as the ICollectionOnSTL-interface), I am a little bit confused if my implementation is correct.Here is how I am creating the enumerator at the moment:STDMETHODIMP CCollectionOnATL::get_NewEnum(IEnumITEM** enumerator){    // IItem implements IUnknown.    typedef CInterfaceArray<IItem> Container;    typedef CComEnum<IEnumITEM, &IID_IEnumITEM, IItem*, _CopyInterface<IItem>> CComEnumITEM;    // Copy all elements to an array that can be enumerated.    Container items;     auto elements = m_coll.GetCount();    //items.SetCount(elements);    // See below for the definition of m_coll.    POSITION pos = m_coll.GetHeadPosition();    for (size_t element = 0; element < elements; element++)    {        auto current = m_coll.GetNext(pos);        // Automatically calls AddRef!        items.Add(current->m_value);    }    // Create an enumerator over the array.    // Using `new` is valid here (since enumerators do not implement FinalConstruct).    CComObject<CComEnumITEM>* pEnum = new CComObject<CComEnumITEM>();    pEnum->Init(&items[0], &items[elements - 1], nullptr, ATL::AtlFlagTakeOwnership);    // Return the enumerator.    return pEnum->QueryInterface(enumerator);}The member m_coll is defined as CRBMap:CRBMap<ULONG, IItem*> m_coll;There are some points with this implementation, where I am not really sure if I understood them correctly:Iterating the CRBMap should give me an ordered list, where the lowest key is the first and the highest key is the last element. However, I am not sure if there's a better (in terms of simplicity) way to perform the iteration.Usage of CInterfaceArray to initialize the enumerator:pEnum->Init(&items[0], &items[elements - 1], nullptr, ATL::AtlFlagTakeOwnership);Is the initialization correct? Especially I am wondering about the third parameter, that references an IUnknown-instance to keep alive for as long as the enumerator lives. Currently I am passing nullptr, but I think the right value should be the items-array, which however does not implement IUnknown.Regarding the enumerator initialization: Was my choose of ATL::AtlFlagTakeOwnership correct in here? I am not completely sure, because the actual ownership of the instances is taken by m_coll.Since the size of the final array is known, I could initialize it (and therefor prevent relocations/copy-steps) using items.SetCount(elements);. However, the MSDN only states that CInterfaceArray::Add automatically calls AddRef. There's no information about SetAt or operator[]. Could I simply change the way I add items to the array to items[element] = current->m_value; without any change in the behaviour of reference counting?Also if you have any suggestions on how I can further improve this code, please let me know!",
    "target": "c++;atl"
  },
  {
    "id": "_unix.355445",
    "source": "is it possible to run process that use only 2 CPU from 16 CPU in my linux machine <eos> is it possible to run process that use only 2 CPU from 16 CPU in my linux machinewe have red-hat machine version 6and we have 16 CPUbut because license cost money and if we limit the script that will run only on 2 CPU then we can save the money ",
    "target": "linux;rhel;process;cpu"
  },
  {
    "id": "_unix.279298",
    "source": "keychain can't add gpg key <eos> I'm setting up keychain to manage gpg-agent, with keychain --eval --agents gpg MYGPGKEYI get the following:* keychain 2.8.1 ~ http://www.funtoo.org * Starting gpg-agent... * Adding 1 gpg key(s): DF1A7077 * Error: Problem adding (is pinentry installed?); giving upI've checked that pinentry is indeed installed (link to pinentry-gnome3).Digging through /usr/bin/keychain, the line causing trouble is:gpg --no-options --use-agent --no-tty --sign --local-user LOCALUSER -o >/dev/null 2>&1I can call this command, when gpg-agent is running; pinentry-gnome3 prompts for my gpg passphrase, but after I close it, the gpg command doesn't finish.What is the right way to get gpg working with keychain ?",
    "target": "gpg agent"
  },
  {
    "id": "_cstheory.18875",
    "source": "Completeness spanning trees <eos> A spanning tree of a graph is called a completeness tree if the set of its leaves induces a complete subgraph in the host graph. Given a graph $G$ and an integer $k$, what is the complexity of deciding if $G$ contains a completeness tree with at most $k$ leaves?A reason for asking this question is that the corresponding problem for independency trees is NP-complete, here an independency tree is a spanning tree such that the set of its leaves is an independent set in the host graph. Another reason is this question (and the corresponding answers). It turns out that every spanning tree of $G$ is a completeness tree if and only if $G$ is a complete graph or a cycle.   ",
    "target": "cc.complexity theory;graph theory;graph algorithms"
  },
  {
    "id": "_webmaster.98425",
    "source": "Should a business create social media accounts for founders in addiion to a company social media account? <eos> Is it a good idea to have a company profile on social media as well as individual accounts of people that are involved in the company, for example the founders, CEO, etc.?I am thinking of a business that is in a specific niche, let us say for example bicycles (and everything else related to bicycles). It has a website (e-commerce and blog)and social media profiles on all the major social media channels like Facebook, Twitter, Google+, Instagram, etc. This just for the business side of things.The blog posts are written by 2 people - they both are founders of this bicycle company. At the end of each post (as is the norm) is a photo of the author and a link to his social media profiles (for example to Google+).So this brings me back to my question. Do you need social media profiles for the company and the founders?I just can't get my head around things. Something tells me that you need to separate your business profile for the profiles of the founders, each 1 has their own presence.I also read in a book that you need to be intimate as possible - when reaching out to people (for example in forums) that you need respond as a person, and not a business. This is why I am thinking of the 2 separate profiles.So if this is the case how do you differentiate between the 2 profiles seeing that you have to generate the content on the social media profiles? What would you post on the one and not the other?",
    "target": "blog;social media;social networks;social networking"
  },
  {
    "id": "_webapps.27162",
    "source": "How can I get a transcript of a YouTube video? <eos> Possible Duplicate:Downloading YouTube TranscriptionsHow do I download subtitles from a YouTube video?I see options for Closed Captions for some videos. Is there anyway to get the full transcript of a video?",
    "target": "youtube"
  },
  {
    "id": "_softwareengineering.190339",
    "source": "Performance and other issues with using floating point types in C++ <eos> Being interested in C++ performance programming there is one aspect I really have no clue about- and that is the implications of using floating point calculations vs doubles vs normal integer mathematics? What performance issues with these types of calculations should I consider? What other issues need to be considered when deciding which kind of operators to use? All I currently know is that doubles are probably the most expensive because they are larger, floating point is next and then integer calculations are usually the fastest on a CPU because they are much simpler.",
    "target": "c++;performance;optimization;floating point;arithmetic"
  },
  {
    "id": "_codereview.44168",
    "source": "Streamlined for-loop for comparing two lists <eos> I'm new to Python and I'm wondering is there a way to streamline this clunky code I've written. Maybe a built-in function I've never come across before?I run through two lists of binary numbers and if the same number appears at the same index in list one and two, do x.So in the example below the number 1 appears at index 2 in both lists.list1 = [0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]list2 = [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0]for position, binary in enumerate(list1):    for placement, number in enumerate(list2):            if position == placement and binary == 1 and binary == number:                do x",
    "target": "python;beginner;python 2.7"
  },
  {
    "id": "_unix.12021",
    "source": "Automatic kerberos ticket initialization on login <eos> I'm using ksshaskpass to add my password protected keys into ssh-agent upon logging into KDE, is there something similar for kerberos?",
    "target": "kde;login;kerberos"
  },
  {
    "id": "_unix.324230",
    "source": "Do not open a new instance of an application, if it's already open in another workspace in Mint <eos> I am using Linux Mint and I enabled multiple workspaces. Suppose I have an instance of an application (i.e., Google Chrome) open on Workspace 1. When I switch to Workspace 2 and I open Google Chrome, I would like to be redirected to the instance already open on WorkSpace 1, while Linux makes me open another (new) window on Workspace 2. This is a bit annoying.Is there a way to prevent Linux Mint to open a new instance of an application, if there is another one already open in another Workspace?",
    "target": "linux mint;window;workspaces"
  },
  {
    "id": "_unix.162030",
    "source": "List of links to images in website with wget <eos> I have a question, as much as I think I cannot think of the way to put all links of pictures in a list, I asked this question before but it was marked as duplicate to post where OP asked to download all pictures.I tried wget -r -P /save/location -A jpeg,jpg http://www.domain.com but it's only downloading to computer. How can I extract a list of  all images to a file?",
    "target": "wget;web"
  },
  {
    "id": "_computergraphics.5327",
    "source": "How to describe a position of a point w.r.t the position and orientation of 3 other points <eos> Is it possible to describe a position of a point $A$ (in 3D) w.r.t. the position and orientation of 3 other points? If so, how?FYI, the 3 other points lie on a plane, whereas the point $A$ is not on the plane.Just to elaborate, initially I have the info for all four points. My goal is to find where point $A$ is when the other three points changing position and orientation.",
    "target": "computational geometry"
  },
  {
    "id": "_cogsci.7649",
    "source": "If one is flexing a muscle, for any given motoneuron involved, how many action potentials occur per second to keep the muscle flexed? <eos> Also, will the axon terminals in a given motoneuron ever run out of neurotransmitters to release if they are constantly undergoing action potentials (say in the situation outlined above where a muscle is being kept flexed)? Or is there always enough reuptake to ensure that this could never happen?",
    "target": "neurobiology"
  },
  {
    "id": "_unix.359182",
    "source": "How to spawn a shell using netcat on the client side? <eos> I know I can spawn the shell on server side using: nc -l 1111 -e /bin/bashBut I want to spawn the shell on the client side.I tried doing: nc 127.0.0.1 1111 | /bin/bashIt works but I can't see the output of the executed commands.So the question is, is there any way to spawn the shell on the client side using netcat?",
    "target": "shell;netcat"
  },
  {
    "id": "_codereview.96707",
    "source": "Class modelling for a shogi notation reader <eos> I have made GPL software in GitHub whose purpose is reading shogi notations (shogi is Japanese chess). I have been told that my software modelling is underdeveloped in this question and advised to post a question about the classes I made to manage the board, so here I go:The main concern is about the file managers.py, which contains the classes that I call managers. Two of those managers are for handling the board's coords for pieces.One of them is the class coords_manager - managers.py line 27:class coords_manager:    def __init__(self):        # Pieces arrays        self.lista_pn = None        self.lista_spn = None        self.cnt_pn = None        self.rpn = None        self.lista_pb = None        self.lista_spb = None        self.cnt_pb = None        self.rpb = None        self.lista_ln = None        self.lista_sln = None        self.cnt_ln = None        self.rln = None        self.lista_lb = None        self.lista_slb = None        self.cnt_lb = None        self.rlb = None        self.lista_nn = None        self.lista_snn = None        self.cnt_nn = None        self.rnn = None        self.lista_nb = None        self.lista_snb = None        self.cnt_nb = None        self.rnb = None        self.lista_sn = None        self.lista_ssn = None        self.cnt_sn = None        self.rsn = None        self.lista_sb = None        self.lista_ssb = None        self.cnt_sb = None        self.rsb = None        self.lista_gn = None        self.cnt_gn = None        self.rgn = None        self.lista_gb = None        self.cnt_gb = None        self.rgb = None        self.lista_tn = None        self.lista_stn = None        self.cnt_tn = None        self.rtn = None        self.lista_tb = None        self.lista_stb = None        self.cnt_tb = None        self.rtb = None        self.lista_bn = None        self.lista_sbn = None        self.cnt_bn = None        self.rbn = None        self.lista_bb = None        self.lista_sbb = None        self.cnt_bb = None        self.rbb = None        self.rey_n = None        self.rey_b = None        self.reverted = 1 #1 OR -1        self.coords_ax = {            '1': 837,            '2': 766,            '3': 695,            '4': 624,            '5': 553,            '6': 482,            '7': 411,            '8': 340,            '9': 269        }        self.coords_ay = {            'i': 589,            'h': 518,            'g': 447,            'f': 376,            'e': 305,            'd': 234,            'c': 163,            'b': 92,            'a': 21        }        self.coords_bx = {            '1': 269,            '2': 340,            '3': 411,            '4': 482,            '5': 553,            '6': 624,            '7': 695,            '8': 766,            '9': 837        }        self.coords_by = {            'a': 589,            'b': 518,            'c': 447,            'd': 376,            'e': 305,            'f': 234,            'g': 163,            'h': 92,            'i': 21        }        self.coords_x = None        self.coords_y = None        self.update()        self.begin()    def begin(self):        self.lista_pn = {1:[self.coords_x['1'],self.coords_y['g']],2:[self.coords_x['2'],self.coords_y['g']],3:[self.coords_x['3'],self.coords_y['g']],4:[self.coords_x['4'],self.coords_y['g']],5:[self.coords_x['5'],self.coords_y['g']],6:[self.coords_x['6'],self.coords_y['g']],7:[self.coords_x['7'],self.coords_y['g']],8:[self.coords_x['8'],self.coords_y['g']],9:[self.coords_x['9'],self.coords_y['g']]}        self.lista_spn = {}        self.cnt_pn = 10        self.rpn = 0        self.lista_pb = {1:[self.coords_x['1'],self.coords_y['c']],2:[self.coords_x['2'],self.coords_y['c']],3:[self.coords_x['3'],self.coords_y['c']],4:[self.coords_x['4'],self.coords_y['c']],5:[self.coords_x['5'],self.coords_y['c']],6:[self.coords_x['6'],self.coords_y['c']],7:[self.coords_x['7'],self.coords_y['c']],8:[self.coords_x['8'],self.coords_y['c']],9:[self.coords_x['9'],self.coords_y['c']]}        self.lista_spb = {}        self.cnt_pb = 10        self.rpb = 0        self.lista_ln = {1:[self.coords_x['1'],self.coords_y['i']],2:[self.coords_x['9'],self.coords_y['i']]}        self.lista_sln = {}        self.cnt_ln = 3        self.rln = 0        self.lista_lb = {1:[self.coords_x['1'],self.coords_y['a']],2:[self.coords_x['9'],self.coords_y['a']]}        self.lista_slb = {}        self.cnt_lb = 3        self.rlb = 0        self.lista_nn = {1:[self.coords_x['2'],self.coords_y['i']],2:[self.coords_x['8'],self.coords_y['i']]}        self.lista_snn = {}        self.cnt_nn = 3        self.rnn = 0        self.lista_nb = {1:[self.coords_x['2'],self.coords_y['a']],2:[self.coords_x['8'],self.coords_y['a']]}        self.lista_snb = {}        self.cnt_nb = 3        self.rnb = 0        self.lista_sn = {1:[self.coords_x['3'],self.coords_y['i']],2:[self.coords_x['7'],self.coords_y['i']]}        self.lista_ssn = {}        self.cnt_sn = 3        self.rsn = 0        self.lista_sb = {1:[self.coords_x['3'],self.coords_y['a']],2:[self.coords_x['7'],self.coords_y['a']]}        self.lista_ssb = {}        self.cnt_sb = 3        self.rsb = 0        self.lista_gn = {1:[self.coords_x['4'],self.coords_y['i']],2:[self.coords_x['6'],self.coords_y['i']]}        self.cnt_gn = 3        self.rgn = 0        self.lista_gb = {1:[self.coords_x['4'],self.coords_y['a']],2:[self.coords_x['6'],self.coords_y['a']]}        self.cnt_gb = 3        self.rgb = 0        self.lista_tn = {1:[self.coords_x['2'],self.coords_y['h']]}        self.lista_stn = {}        self.cnt_tn = 2        self.rtn = 0        self.lista_tb = {1:[self.coords_x['8'],self.coords_y['b']]}        self.lista_stb = {}        self.cnt_tb = 2        self.rtb = 0        self.lista_bn = {1:[self.coords_x['8'],self.coords_y['h']]}        self.lista_sbn = {}        self.cnt_bn = 2        self.rbn = 0        self.lista_bb = {1:[self.coords_x['2'],self.coords_y['b']]}        self.lista_sbb = {}        self.cnt_bb = 2        self.rbb = 0        self.rey_n = [self.coords_x['5'],self.coords_y['i']]        self.rey_b = [self.coords_x['5'],self.coords_y['a']]    def update(self):        if self.reverted == 1:            self.coords_x = self.coords_ax            self.coords_y = self.coords_ay        else:            self.coords_x = self.coords_bx            self.coords_y = self.coords_by    def revert(self):        self.reverted *= -1        revert_x = {            269: 837,            340: 766,            411: 695,            482: 624,            553: 553,            624: 482,            695: 411,            766: 340,            837: 269        }        revert_y = {            21: 589,            92: 518,            163: 447,            234: 376,            305: 305,            376: 234,            447: 163,            518: 92,            589: 21        }        for k, e in self.lista_pn.items():            self.lista_pn[k] = [revert_x[e[0]],revert_y[e[1]]]        for k, e in self.lista_spn.items():            self.lista_spn[k] = [revert_x[e[0]],revert_y[e[1]]]        for k, e in self.lista_pb.items():            self.lista_pb[k] = [revert_x[e[0]],revert_y[e[1]]]        for k, e in self.lista_spb.items():            self.lista_spb[k] = [revert_x[e[0]],revert_y[e[1]]]        for k, e in self.lista_ln.items():            self.lista_ln[k] = [revert_x[e[0]],revert_y[e[1]]]        for k, e in self.lista_sln.items():            self.lista_sln[k] = [revert_x[e[0]],revert_y[e[1]]]        for k, e in self.lista_lb.items():            self.lista_lb[k] = [revert_x[e[0]],revert_y[e[1]]]        for k, e in self.lista_slb.items():            self.lista_slb[k] = [revert_x[e[0]],revert_y[e[1]]]        for k, e in self.lista_nn.items():            self.lista_nn[k] = [revert_x[e[0]],revert_y[e[1]]]        for k, e in self.lista_snn.items():            self.lista_snn[k] = [revert_x[e[0]],revert_y[e[1]]]        for k, e in self.lista_nb.items():            self.lista_nb[k] = [revert_x[e[0]],revert_y[e[1]]]        for k, e in self.lista_snb.items():            self.lista_snb[k] = [revert_x[e[0]],revert_y[e[1]]]        for k, e in self.lista_sn.items():            self.lista_sn[k] = [revert_x[e[0]],revert_y[e[1]]]        for k, e in self.lista_ssn.items():            self.lista_ssn[k] = [revert_x[e[0]],revert_y[e[1]]]        for k, e in self.lista_sb.items():            self.lista_sb[k] = [revert_x[e[0]],revert_y[e[1]]]        for k, e in self.lista_ssb.items():            self.lista_ssb[k] = [revert_x[e[0]],revert_y[e[1]]]        for k, e in self.lista_gn.items():            self.lista_gn[k] = [revert_x[e[0]],revert_y[e[1]]]        for k, e in self.lista_gb.items():            self.lista_gb[k] = [revert_x[e[0]],revert_y[e[1]]]        for k, e in self.lista_tn.items():            self.lista_tn[k] = [revert_x[e[0]],revert_y[e[1]]]        for k, e in self.lista_stn.items():            self.lista_stn[k] = [revert_x[e[0]],revert_y[e[1]]]        for k, e in self.lista_tb.items():            self.lista_tb[k] = [revert_x[e[0]],revert_y[e[1]]]        for k, e in self.lista_stb.items():            self.lista_stb[k] = [revert_x[e[0]],revert_y[e[1]]]        for k, e in self.lista_bn.items():            self.lista_bn[k] = [revert_x[e[0]],revert_y[e[1]]]        for k, e in self.lista_sbn.items():            self.lista_sbn[k] = [revert_x[e[0]],revert_y[e[1]]]        for k, e in self.lista_bb.items():            self.lista_bb[k] = [revert_x[e[0]],revert_y[e[1]]]        for k, e in self.lista_sbb.items():            self.lista_sbb[k] = [revert_x[e[0]],revert_y[e[1]]]        self.rey_n = [revert_x[self.rey_n[0]],revert_y[self.rey_n[1]]]        self.rey_b = [revert_x[self.rey_b[0]],revert_y[self.rey_b[1]]]        self.update()The other one is matrix_manager - managers.py line 436:class matrix_manager:    def __init__(self):        self.ADAPTX = {'9':0,'8':1,'7':2,'6':3,'5':4,'4':5,'3':6,'2':7,'1':8}        self.ADAPTY = {'a':0,'b':1,'c':2,'d':3,'e':4,'f':5,'g':6,'h':7,'i':8}        self.coords_hx = {            837:'1',            766:'2',            695:'3',            624:'4',            553:'5',            482:'6',            411:'7',            340:'8',            269:'9'        }        self.coords_hy = {            589:'i',            518:'h',            447:'g',            376:'f',            305:'e',            234:'d',            163:'c',            92:'b',            21:'a'        }        # X es el 1er ndice        self.matrix = [                [1,1,1,1,1,1,1,1,1],                [0,1,0,0,0,0,0,1,0],                [1,1,1,1,1,1,1,1,1],                [0,0,0,0,0,0,0,0,0],                [0,0,0,0,0,0,0,0,0],                [0,0,0,0,0,0,0,0,0],                [1,1,1,1,1,1,1,1,1],                [0,1,0,0,0,0,0,1,0],                [1,1,1,1,1,1,1,1,1]        ]    def empty(self, coords_h):        self.matrix[self.ADAPTY[coords_h[1]]][self.ADAPTX[coords_h[0]]] = False    def fill(self, coords_h):        self.matrix[self.ADAPTY[coords_h[1]]][self.ADAPTX[coords_h[0]]] = True    def get_hcoords(self, coords):        return str(self.coords_hx[coords[0]])+str(self.coords_hy[coords[1]])    def check_ln(self, h_begin, h_destiny):        cursorx = self.ADAPTX[h_begin[0]]        cursory = self.ADAPTY[h_begin[1]]        while cursory != self.ADAPTY[h_destiny[1]]+1:            cursory -= 1            if self.matrix[cursory][cursorx] == True:                return False        return True    def check_lb(self, h_begin, h_destiny):        cursorx = self.ADAPTX[h_begin[0]]        cursory = self.ADAPTY[h_begin[1]]        while cursory != self.ADAPTY[h_destiny[1]]-1:            cursory += 1            if self.matrix[cursory][cursorx] == True:                return False        return True    def check_t(self, h_begin, h_destiny):        cursorx = self.ADAPTX[h_begin[0]]        cursory = self.ADAPTY[h_begin[1]]        destx = self.ADAPTX[h_destiny[0]]        desty = self.ADAPTY[h_destiny[1]]        if cursorx == destx:            mod = 1 if cursory < desty else -1            while cursory != desty - mod:                cursory += mod                if self.matrix[cursory][cursorx] == True:                    return False            return True        else:            mod = 1 if cursorx < destx else -1            while cursorx != destx - mod:                cursorx += mod                if self.matrix[cursory][cursorx] == True:                    return False            return True    def check_b(self, h_begin, h_destiny):        cursorx = self.ADAPTX[h_begin[0]]        cursory = self.ADAPTY[h_begin[1]]        destx = self.ADAPTX[h_destiny[0]]        desty = self.ADAPTY[h_destiny[1]]        modx = 1 if cursorx < destx else -1        mody = 1 if cursory < desty else -1        while (cursorx != destx - modx) or (cursory != desty - mody):            cursorx += modx            cursory += mody            if self.matrix[cursory][cursorx] == True:                return False        return Truecoords_manager handles dictionaries of coords of pieces that are present on the board. It also handles revertion of board. There is a list for each kind of piece (promoted pieces count as kind of piece for this) for each player. Doing it like this (instead of a global list for all pieces with a parameter to determine the kind of piece) allows me to make loops to iterate only over certain kind of piece. Another secondary function of coords_manager is to provide dictionaries to translate human-readable coords in numeric coords to blit the sprites. Every list of pieces gets the coords in numeric version.Kinds of pieces are abbreviated this way:s -> if present, it would mean promoted piecep -> english abbreviature for the kind of piece - pawn in this casen -> player's color (n if 'black' or 'sente', b if 'white' or 'gote')When I noticed that I needed a way to prevent pieces jumping over other pieces, I created matrix_manager to resolve the problem. It basically handles a matrix of boolean values to keep in account which squares are filled by a piece.The point I'm trying to make is that I want to make a Move class to clean up the code to prevent abuse of exec statements and regexp matching, as pointed in my previous question. But I'm convinced that, before doing such a thing, I should improve the managers first, as @200_success suggested me in the previous question.Which ways would you try to improve the board managers? Should I join those classes into a single one for a better modelling? Which deficiencies or redundancies am I not noticing in these managers?I started this project at first just because I wanted a way to read my shogi notations. When the basic functionality worked, I decided to make the code public under GPL license for sharing, and with the hope that some entusiasts would join me to suggest improvements or even to work on the code if they felt willing to. So, you will find extensive general information in the README section in GitHub. Any little contribution is highly appreciated.",
    "target": "python;object oriented;python 2.7;pygame;chess"
  },
  {
    "id": "_cs.77437",
    "source": "Problems understanding the Union functionality of the Union-Find Algorithm <eos> I am currently doing a course based on algorithms (Coursera). I've come across an algorithm called quick find. The course does have reference to Big O Notation. Despite the fact that I do not have much knowledge of Big O, I have been doing some basic reading.Implementation (Java):Initializes the array:public QuickFindUF(int N){    id = new int[N];    for (int i = 0; i < N; i++)    id[i] = i;}Checks if two input values are connected:public boolean connected(int p, int q){     return id[p] == id[q];}Union Implementation:public void union(int p, int q){    int pid = id[p];    int qid = id[q];    for (int i = 0; i < id.length; i++)    {        if (id[i] == pid)        {            id[i] = qid;        }    }}The id variable is a private instance variable.My Problem:1) In the study material it says:It takes N2 array accesses to process a sequence of N union  commands on N objectsHow can it take N2 if the union method only has a single for loop?2) It also says that the union method takes at most 2N + 2 array accessesWhat does this mean? My speculation is that 2N could mean that the array is accessed twice (line 7 and line 9 of the union method). I have no idea what + 2 refers to though.I apologize if I have incorrectly stated something.Any help would be highly appreciated. Thank You.",
    "target": "algorithms;asymptotics;union find"
  },
  {
    "id": "_webmaster.47182",
    "source": "How reliable is the number of hits provided by Google site: command? <eos> A partner of my company (not sure whether i can tell their name here - ill use example.com instead) asked me yesterday, why there is such a big difference when they enter the site command at google at first with www and then without www, to check the number of indexed pages.First of all, the Google Webmaster Tools show about 9.000.000 indexed pages.site:example.com provides me about 10.000.000 hits.site:www.example.com are only about 4.000.000 hits.I first thought that they have some subdomains registered, such as blog.example.com, or test.example.com ...But entering site:example.com -site:www.example.com to detect pages from subdomains other than www, brings up exactly 2 hits.Where are the other 6.000.000 ?The next thing is, providing google a little bit more in the query such as site:www.example.com in (or other linking words) brings me more hits than the blank site command with www (site:www.example.com). Sometimes about 2.000.000 more than the blank www query...Is the number of hits really that inaccurate?",
    "target": "google;google search console;google search"
  },
  {
    "id": "_softwareengineering.213886",
    "source": "ASP.NET MVC create a draft without persisting to DB <eos> I have a requirement to allow users to suggest updates to their profiles on a site I'm working. They would be able to view their profile details, then click on and edit button, which would basically make a copy of all their data contained in a handful of one-to-many related DB tables. They can then add or remove items and update various text fields before saving the draft. Upon saving, an administrator would have to approve this change before the new data is actually published onto the live site.I currently have an identical set of tables for live data and drafts (and history, but that's not important). My difficulty is that the client doesn't want an actual draft entry created in the drafts db structure until the user has hit save. A user would be able to perform CRUD operations against all the data, including uploading new images, but I am not allowed to touch the DB unless they're ready to commit these updates.My great problem is that I have no idea how to begin developing what seems to the client to be a very simple thing, even though it's technically quite challenging. I also can't seem to make the client understand that hitting the Cancel button next to the save button would remove the entry plus all its related data from the DB, making the problem moot in my humble opinion.So, the question is such: is there a way to phrase my objection in such a way that the client can understand what I'm getting at. Or failing that, what would be a good way of developing such a session-stored object?",
    "target": "c#;asp.net mvc"
  },
  {
    "id": "_webapps.67499",
    "source": "Watching Facebook videos without Flash <eos> I do not have Flash installed on my computer.  Is there any way to watch videos on Facebook without using Flash?",
    "target": "facebook;video"
  },
  {
    "id": "_softwareengineering.142144",
    "source": "while(true) and loop-breaking - anti-pattern? <eos> Consider the following code:public void doSomething(int input){   while(true)   {      TransformInSomeWay(input);      if(ProcessingComplete(input))         break;      DoSomethingElseTo(input);   }}Assume that this process involves a finite but input-dependent number of steps; the loop is designed to terminate on its own as a result of the algorithm, and is not designed to run indefinitely (until cancelled by an outside event). Because the test to see if the loop should end is in the middle of a logical set of steps, the while loop itself currently doesn't check anything meaningful; the check is instead performed at the proper place within the conceptual algorithm.I was told that this is bad code, because it is more bug-prone due to the ending condition not being checked by the loop structure. It's more difficult to figure out how you'd exit the loop, and could invite bugs as the breaking condition might be bypassed or omitted accidentally given future changes.Now, the code could be structured as follows:public void doSomething(int input){   TransformInSomeWay(input);   while(!ProcessingComplete(input))   {      DoSomethingElseTo(input);      TransformInSomeWay(input);   }}However, this duplicates a call to a method in code, violating DRY; if TransformInSomeWay were later replaced with some other method, both calls would have to be found and changed (and the fact that there are two may be less obvious in a more complex piece of code).You could also write it like:public void doSomething(int input){   var complete = false;   while(!complete)   {      TransformInSomeWay(input);      complete = ProcessingComplete(input);      if(!complete)       {         DoSomethingElseTo(input);                }   }}... but you now have a variable whose only purpose is to shift the condition-checking to the loop structure, and also has to be checked multiple times to provide the same behavior as the original logic.For my part, I say that given the algorithm this code implements in the real world, the original code is the most readable. If you were going through it yourself, this is the way you'd think about it, and so it would be intuitive to people familiar with the algorithm.So, which is better? is it better to give the responsibility of condition checking to the while loop by structuring the logic around the loop? Or is it better to structure the logic in a natural way as indicated by requirements or a conceptual description of the algorithm, even though that may mean bypassing the loop's built-in capabilities?",
    "target": "programming practices;language agnostic;readability"
  },
  {
    "id": "_unix.88387",
    "source": "Find or create kernel configuration of kernel binary <eos> I've downloaded a kernel binary which I am using now. In order to use the watchdog on my system I must recompile the kernel with watchdog support. Is it possible to obtain the current kernel configuration of the binary?The binary is obtained from this page. I've used version R5.",
    "target": "kernel;configuration"
  },
  {
    "id": "_codereview.121741",
    "source": "Parsing a complex number using regular expressions <eos> Requirements were to create a constructor for a complex number, that receives a string. For example: \\$3+5i\\$. The regex extracts positive or negative numbers from the string with optional decimal.My professor told me that my regex was beyond wrong:public Complex(String str) {        ArrayList<Double> list = new             ArrayList<Double>();        Pattern p = Pattern.compile([-+]?[0-9]*\\\\.?[0-9]);        // toString() handles the letter i        // find positive and negative doubles in string and add to list        Matcher m = p.matcher(str);        while (m.find()) {            double num = Double.parseDouble(m.group());            list.add(num);        }        this.re = list.get(0);        this.im = list.get(1);}Here is a link to the class if you need a better understanding of the code.He then posted his chosen correct solution, which I found to be repetitive. He may argue that I am not checking for i, but I see no point of storing i if we are not using it later.In addition, if he argues that I am not checking for and storing i, that would mean that if I did store them, I would explicitly have to go exclude the i from the string when I perform mathematical operations on the numbers. It seems counter-productive.Here is the solution he preferred:public Complex(String c) {      String numberNoWhiteSpace = c.replaceAll(\\\\s,);      // Matches complex number with BOTH real AND imaginary parts.        // Ex: -3-2.0i      Pattern patternA = Pattern.compile(([-]?[0-9]+\\\\.?[0-9]?)([-|+]+[0-9]+\\\\.?[0-9]?)[i$]+);      // Matches ONLY real number.      // Ex: 3.145      Pattern patternB = Pattern.compile(([-]?[0-9]+\\\\.?[0-9]?)$);      // Matches ONLY imaginary number.      // Ex: -10i      Pattern patternC = Pattern.compile(([-]?[0-9]+\\\\.?[0-9]?)[i$]);      Matcher matcherA = patternA.matcher(numberNoWhiteSpace);      Matcher matcherB = patternB.matcher(numberNoWhiteSpace);      Matcher matcherC = patternC.matcher(numberNoWhiteSpace);      if (matcherA.find()) {          real = Double.parseDouble(matcherA.group(1));          imaginary = Double.parseDouble(matcherA.group(2));      } else if (matcherB.find()) {          real = Double.parseDouble(matcherB.group(1));          imaginary = 0;      } else if (matcherC.find()) {          real = 0;          imaginary = Double.parseDouble(matcherC.group(1));      }   }",
    "target": "java;parsing;regex;comparative review;constructor"
  },
  {
    "id": "_codereview.5400",
    "source": "Scraping PubMed query results <eos> How can I make the following PHP code better, more efficient, shorter, elegant, etc?  While it already works, I am still learning PHP and want to improve upon my current code:<?php$query = 'psoriasis';$eSearchQueryParameters = array(    'db' => 'pubmed',    'term' => $query,    'retmode' => 'xml',    'retstart' => '0',    'retmax' => '500',    'usehistory' => 'y',);$eSearchQueryResults = simplexml_load_file('http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?' . http_build_query($eSearchQueryParameters));$eFetchQueryParameters = array(    'db' => 'pubmed',    'retmax' => '500',    'query_key' => (string) $eSearchQueryResults->QueryKey,    'WebEnv' => (string) $eSearchQueryResults->WebEnv,);$eFetchURL = 'http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?' . http_build_query($eFetchQueryParameters);$matches = array();preg_match_all('/[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,4}/', file_get_contents($eFetchURL), $matches);foreach ($matches[0] as $key => $value) {    echo $value . <br />;}?>",
    "target": "php;web scraping;url"
  },
  {
    "id": "_unix.248280",
    "source": "Apache 2.4 basic auth don't work <eos> I have a problem with basic auth in apache 2.4. I have these lines:<VirtualHost *:80>    ServerAdmin email@email.com    DocumentRoot /var/www/html/foo    ServerName my.domain.com<Directory /var/www/html/foo/>        Options FollowSymLinks        Require all granted        DirectoryIndex index.php        AuthType Basic        AuthName Authentication Required        AuthUserFile /etc/httpd/.htpasswd        Require valid-user</Directory></VirtualHost>Authentication is bypassed and shows the site without a password request.",
    "target": "apache httpd;authentication"
  },
  {
    "id": "_webmaster.81505",
    "source": "Can sitemaps for multiple sites be added to Google Webmaster Tools through a single universal account? <eos> I had a lot of client websites and recently I had to do SEO for about 3-4 websites simultaneously.  It was all simple on page SEO, but I have a question is about XML map submission. I realize that creating the XML sitemap and adding it to the root directory is critical.  After that, you submit the XML sitemap to Google. For each website sitemap, do I need a NEW webmaster account?  Or can I have a universal account from which I can submit the sitemap for each of my client websites? ",
    "target": "google search console;xml sitemap"
  },
  {
    "id": "_cs.73895",
    "source": "How to prove that algorithm returns the value which appears more than $n/2$ times in the array? <eos> Given the following algorithm (pseudocode):alg1(A[1,..,n])    i <- 1    candidate <- NULL    count <- 0    while(i <= n)        if(count = 0)            candidate <- A[i]            count <- count + 1        else if(candidate = A[i])            count <- count + 1        else            count <- count - 1        i <- i + 1    return candidateI need to prove that if a value appears more than $n \\over 2$ times (let the value be named $M$) in the array then it will be returned. $\\mathbf{EDIT:}$ here's my 2 attempt. First we assume that the array $A$ contains at least 3 elements (if less then the proof is trivial). The element which appears more than $n/2$ times is $M$ else it's $M'$. Let a two-element combination of $MM'$ or $M'M$ be called $C$. Every time we traverse a $C$ the count decreases by one. CASE 1: If the pattern is strictly alternating combinations of type $C$  then the first and the last element must be $M$ (otherwise $M$ will not appear more than $n/2$ times) and this means that after the last iteration the candidate is $M$.CASE 2: We can see that after any number of adjacent $C$'s the counter will be $0$ and the candidate will be either $M$ or $M'$. It is given that more than $n/2$ elements of $M$ do exist in the array, so the number of $C$ combinations must be supplemented by at least $1$ occurrence of $k$ adjacent elements of $M$ either before $C$'s or after $C$'s. If it's after, then the next candidate is $M$ and it will continue to be so as long as we keep traversing $k$ elements of adjacent $M$'s. If it's before than the count will be at least $1$ before it proceeds to iterate through $C$'s and essentially it'll behave just like CASE 1.I'm still aware that the proof is not perfect but I feel like it's an improvement. Suggestions/advice is very welcome.",
    "target": "correctness proof"
  },
  {
    "id": "_softwareengineering.314956",
    "source": "Send server side file as attachment in a web application <eos> In our web application development project, we need a feature that lets the users to email themselves an attachment (~1MB) which resides on the server.I was considering two alternatives. Upon clicking on the email buttonDownload the attachment to local folder and attach it to a new email window in outlook. The flaw with this approach is that we are assuming user has Outlook installed on their machine. I am also doubtful if browsers others than IE support this feature of being able to open Outlook message and attach a file.Send the attachment from middleware code to the user using a programmatic API for sending email. The downside of this approach is that it doesn't give the flexibility to the user to use the out of the box Outlook features such as being able to add more recipients / cc / bcc, edit the message etc, though it is possible to let the user do the same by providing a UI which lets them do all that.  What would be the recommended approach to this requirement?",
    "target": "email"
  },
  {
    "id": "_unix.374634",
    "source": "Why does cp not set source attributes and fail with -p? <eos> I have these files:-rw-rw-r-- 1 root   adm    0 Jun 22 11:25 a-rw-rw-r-- 1 wilmes wilmes 0 Jun 22 11:23 bWhen I cp b over to a as user wilmes why does it keep the original owner of a (root)?I use this command (no aliases): cp b aWhy does it fail when I use -p in command cp -p b a ?cp: preserving times for 'a': Operation not permittedI noticed this on Ubuntu 17.04 with ext4. User wilmes is member of group adm and the containing directory looks like this:drwxrwxr-x 2 wilmes wilmes 4,0K Jun 22 12:09 ../user/And most important: Where is this documented?",
    "target": "cp"
  },
  {
    "id": "_unix.120986",
    "source": "How to automatically launch a lxc container on ssh connection? <eos> I'm attempting to setup a system that automatically creates a new sandbox on a ssh login to use as a temporary jump box into my server. So to do this I was wonder how to setup lxc to spin up a new shell in the container once there is a ssh connection then destroy that container after the session is closed.What would be the best way to go about this?EDIT:Thanks to everyone that has placed their input. I have been able to devise the method to do this same setup as follows:/etc/ssh/sshd_config:match group ssh        forceCommand sudo docker run --rm -t -i busybox /bin/shWhat this does is forces the user session to instantly go into a busybox container then delete the changes on exit. One could change or create their own image and specify this in place of busybox. Though this is included here since the only thing the default busybox container offers is wget and telnet which is good enough for most OOB testing/jump-boxes and this was the use case goal with this design.",
    "target": "shell;ssh;lxc;deployment;docker"
  },
  {
    "id": "_unix.345898",
    "source": "Set initramfs to prompt for luks passowrd on startup on Mint 18? <eos> After updating to Mint 18.1, I can't get initramfs to prompt for a password to unlock the volume with the root file system on it. I have to wait until initramfs times out to a prompt then run cryptsetup luksOpen manually.I've tried running update-initramfs while the system is mounted and running (as well as from the live CD in chroot) and I have an entry in /etc/cryptab.This was working for me before the Mint 18 upgrade, but for some reason I'm still not getting a password prompt now no matter what I try.What should I check?",
    "target": "linux mint;boot;grub;initramfs"
  },
  {
    "id": "_codereview.66556",
    "source": "Finding 10-unique-digit number with i-first-digits divisible by i <eos> I was posed this question by a friend:I am a natural number written with 10 different digits such that for all \\$i  {1, . . ., 10}\\$ the number formed by my \\$i\\$ first digits (from left to right) is divisible by \\$i\\$. Who am I?I came up with a brute-force solution over the next hour or so (a few attempts failed) and came eventually finished with this:# !/usr/bin/python# -*- coding: utf-8 -*-# build all possible permutationsimport itertoolsbase_number = ['1','2','3','4','5','6','7','8','9','0']perms = itertools.permutations(base_number)# join the permutation lists into single numbers by joining each into a stringall_nums = [''.join(item[0:10]) for item in perms]''' Check whether each item is divisible by i (from 10-->2) for subset of item, item[0:i]. For example;    i = 10, number = 1234567890    number[0:10]   = 1234567890         is this divisible by i(10)? Yes.    i = 9, number = 1234567890    number[0:9]   = 123456789        is this divisible by i(9)? Yes.    i = 8, number = 1234567890    number[0:8]   = 12345678        is this divisible by i(8)? No.We do not check whether the number is divisible by 1 as all integers are divisible by 1.'''  for i in range(10,1,-1):    legits = [x for x in all_nums if int(x[0:i])%i==0]    all_nums = legits    print %-10d # of result can be divided by %d % (len(legits),i)print legitsI considered that a recursive algorithm could perform this task much more efficiently but have not considered how to actually code the pseudo-code'ish solution I was shown;f(1) = {1, 2, 3, 4, 5, 6, 7, 8, 9}f(2) = for n in f(1):       find solutions to i for $$n * 10 + i = 0 (mod 2)$$       where i isn't a digit of n.I welcome all feedback, but I'm specifically hoping to hear about my coding-style/practices and the algorithm I developed.",
    "target": "python;algorithm;python 2.7"
  },
  {
    "id": "_unix.299531",
    "source": "Compare two input and merge the difference <eos> How can I compare two input strings and merge differences and get the result string like below with tools like diff?e.g. When I have two stringsunix&linux stackoverflow unix&linuxand UnixAndLinux stackexchangeI'd like to get a string uUnix&AndlLinux stackoverflowexchange unix&linux",
    "target": "diff"
  },
  {
    "id": "_codereview.24783",
    "source": "Printing all binary strings of length n <eos> I have completed my homework with directions as follows:Declare and implement a class named Binary. This class will have a  method named printB(int n) that prints all binary strings of length n.  For n = 3, it will print000001010011100101110111in this order.Here is my code:import java.util.Scanner;class Binary{    String B;    int temp;    void printB(int n)    {        for(int i = 0; i < Math.pow(2,n); i++)        {            B = ;            int temp = i;            for (int j = 0; j < n; j++)            {                if (temp%2 == 1)                    B = '1'+B;                else                    B = '0'+B;                    temp = temp/2;            }            System.out.println(B);         }    } }class Runner{    public static void main(String [] args)    {        Scanner in = new Scanner(System.in);        System.out.print(Enter n:);        int n = in.nextInt();        Binary myB = new Binary();        myB.printB(n);    }}My question is...is there anyway to make this shorter or more efficient?",
    "target": "java;homework;combinatorics;formatting;number systems"
  },
  {
    "id": "_unix.138862",
    "source": "Command-line incremental backup tools <eos> Which command line backup tool(s) has the best compression ratio? I want to backup my entire system, including media files, text files etc. I found this list on the Arch wiki site but I don't know how these tools compare to each other and which one would offer the best compression ratio overall. I realize that different tools might give better results for specific file types, but which tool and using which settings would result in the smallest archive given a mix of various input files?",
    "target": "command line;backup;compression"
  },
  {
    "id": "_cs.2971",
    "source": "Solving the recurrence relation $T(n) = 2T(\\lfloor n/2 \\rfloor) + n$ <eos> Solving the recurrence relation $T(n) = 2T(\\lfloor n/2 \\rfloor) + n$.The book from which this example is, falsely claims that $T(n) = O(n)$ by guessing $T(n) \\leq cn$ and then arguing  $\\qquad \\begin{align*} T(n) & \\leq 2(c \\lfloor n/2 \\rfloor ) + n \\\\ &\\leq cn +n \\\\ &=O(n) \\quad \\quad \\quad \\longleftarrow \\text{ wrong!!} \\end{align*}$  since $c$ is constant.The error is that we have not proved the exact form of the inductive hypothesis.Above I have exactly quoted what the book says. Now my question is why cannot we write $cn+n=dn$ where $d=c+1$ and now we have $T(n) \\leq dn$ and hence $T(n) = O(n)$?Note: The correct answer is $T(n) =O(n \\log n).$  The book I am referring here is Introduction to algorithms by Cormen et al., page 86, 3rd edition.",
    "target": "proof techniques;asymptotics;recurrence relation;landau notation;induction"
  },
  {
    "id": "_codereview.123710",
    "source": "Java 8 Stream to produce all permutations of an array using recursion <eos> I want to write a class that returns a Stream of permutations of an int[].public class Permutations {    public static Stream<int[]> of(int[] array) {        return permute(array, array.length);    }    public static Stream<int[]> permute(int[] array, int n) {        if (n == 1) {            return Stream.of(Arrays.copyOf(array, array.length));        } else {            Stream tmp = Stream.empty();            for (int i = 0; i < n; i++) {                swap(array, i, n - 1);                tmp = Stream.concat(permute(array, n - 1), tmp);                swap(array, i, n - 1);            }            return tmp;        }    }    private static void swap(int[] a, int i, int j) {        if (i != j) {            int tmp = a[i]; a[i] = a[j]; a[j] = tmp;        }    }}Problem with my solution is that it is nesting a lot of Streams with concat, many of them being just empty ones. Another issue is that it creates all permutations before returning the Stream, so it not really streaming...  :- )I saw Minborg's solution, but I wanted to make something simpler, here based on  Sedgewick and Wayne's algorithm.Can above code be improved?",
    "target": "java;recursion;combinatorics;stream"
  },
  {
    "id": "_codereview.145232",
    "source": "Creating JavaFX bindable property readed from joystick <eos> I'm lately messing up with handling joystick in java.So here is the thing. I wrote a simple class that handle input from joystick, but I'm no certain if I'm doing it well. Here is what I want to achieve. So i have joypad, I'm using jinput from LWJGL 2, and want to bind axis and buttons state to Javafx application, and than send it to my arduino rc car. It's working, but I'm just wondering is there more efficient way to read joystick input? Now I have that thread which never ends and read joystick value. I was looking for some event handler but non of them works. If anyone have some suggesions I would appreciate it.  If none of above is clear so here is TODO list:I have joypad which I'm reading data.I'm wonder what is most efficient way to read data from joystick?I'm using LWJGL 2 jInput.Is there any way to get rid of that thread?Controller.classpackage wcc;import java.util.ArrayList;import org.lwjgl.input.Controller;import javafx.beans.property.SimpleBooleanProperty;import javafx.beans.property.SimpleFloatProperty;public class FXController implements Runnable{    private boolean threadAlive = true;    private Controller controller;    private ArrayList<SimpleFloatProperty> axis = new ArrayList<>();    private ArrayList<SimpleBooleanProperty> buttons = new ArrayList<>();    public FXController(Controller controller){        this.controller = controller;        for(int i = 0; i < this.controller.getAxisCount(); i++){            this.axis.add(new SimpleFloatProperty(0));        }        for(int i = 0; i < this.controller.getButtonCount(); i++){            this.buttons.add(new SimpleBooleanProperty(false));        }    }    public ArrayList<SimpleFloatProperty> getAxisProperty(){        return this.axis;    }    public ArrayList<SimpleBooleanProperty> getButtonProperty(){        return this.buttons;    }    public Controller getController(){        return this.controller;    }    public void stopThread(){        this.threadAlive = false;    }    public boolean isThreadAlive(){        return this.threadAlive;    }    @Override    public void run() {        while(threadAlive){            for(int i = 0; i < this.controller.getAxisCount(); i++){                this.axis.get(i).set(this.controller.getAxisValue(i)+1);            }            for(int i = 0; i < this.controller.getButtonCount(); i++){                this.buttons.get(i).set(this.controller.isButtonPressed(i));            }            this.controller.poll();        }    }}@FXML Controllerpackage wcc;import java.net.URL;import java.util.ResourceBundle;import org.lwjgl.input.Controllers;import javafx.fxml.FXML;import javafx.fxml.Initializable;import javafx.geometry.Insets;import javafx.scene.control.ComboBox;import javafx.scene.control.ProgressBar;import javafx.scene.control.TitledPane;import javafx.scene.control.ToggleButton;import javafx.scene.image.Image;import javafx.scene.image.ImageView;import javafx.scene.layout.GridPane;import javafx.scene.layout.TilePane;import javafx.scene.layout.VBox;public class wccController implements Initializable{    @FXML GridPane _ROOT;    @FXML ComboBox<String> _CONTROLLERS;    @FXML VBox _AXISBOX;    @FXML TilePane _BUTTONSGRID;    @FXML ImageView _CAMERAVIEW;    FXController selected = null;    @Override public void initialize(URL arg0, ResourceBundle arg1) {        try{            Controllers.create();            for(int i = 0; i < Controllers.getControllerCount(); i++){                this._CONTROLLERS.getItems().addAll(Controllers.getController(i).getName());            }            new Thread(new Runnable(){                @Override                public void run() {                    while(true){                        _CAMERAVIEW.setImage(new Image(http://192.168.1.171:8080/shot.jpg));                    }                }            },CameraThread).start();;        } catch(Exception ex){            ex.printStackTrace();        }    }    @FXML private void onControllerSelectionChanged(){        this._AXISBOX.getChildren().clear();        if(this.selected != null){            this.selected.stopThread();        }        this.selected = new FXController(Controllers.getController(this._CONTROLLERS.getSelectionModel().getSelectedIndex()));        new Thread(this.selected, Controller thread.).start();        for(int i = 0; i < this.selected.getController().getAxisCount(); i++){            ProgressBar axisValue = new ProgressBar();                axisValue.setPadding(new Insets(8));                axisValue.progressProperty().bind(this.selected.getAxisProperty().get(i).divide(2));            TitledPane axisName = new TitledPane();                axisName.setText(AXIS: [  + this.selected.getController().getAxisName(i) +  ]);                axisName.setCollapsible(false);                axisName.setContent(axisValue);            this._AXISBOX.getChildren().add(axisName);        }        this._BUTTONSGRID.getChildren().clear();        this._BUTTONSGRID.setPrefColumns(4);        for(int i = 0; i < this.selected.getController().getButtonCount(); i++){            ToggleButton buttonState = new ToggleButton([O]);                buttonState.setPadding(new Insets(8));                buttonState.setDisable(true);                buttonState.selectedProperty().bind(this.selected.getButtonProperty().get(i));            TitledPane buttonName = new TitledPane();                buttonName.setText([  + this.selected.getController().getButtonName(i) +  ]);                buttonName.setCollapsible(false);                buttonName.setContent(buttonState);            this._BUTTONSGRID.getChildren().add(buttonName);        }    }}",
    "target": "java;controller;javafx"
  },
  {
    "id": "_webapps.62992",
    "source": "How can I access GMX calendar outside of web UI? <eos> GMX provides:a mail service accessible through IMAP, a file service accessible through WebDAV,a calendar service.But I've never found if there is any way of accessing that calendar service through a standard protocol (CalDAV or iCal). Is there such an access?",
    "target": "calendar;gmx"
  },
  {
    "id": "_cs.49851",
    "source": "Data structures for ordering noisy data <eos> In a certain robotics application, I encountered a problem in which we need to determine the order of positions of several robots on $\\mathbb{R}$. Each measurement that we take of robot positions is subject to random errors beyond our control. I've formalised the algorithmic part of the problem as follows. This part has been reformulated as per D.W.'s comments.The positions of $n$ robots are given to us in a $3\\times n$ array, each row being of the form $[i, A, \\epsilon]$.This row states   that the position of the robot with id $i$ is uniformly distributed on the interval $A \\pm \\epsilon$.Problem : Output the most probable ordering (MPO) of the robot positions,or one such if this is non-unique.Example Input: $\\begin{bmatrix} \\mathrm{id} & A & \\epsilon \\\\ \\hline  1 & 1& 0.5 \\\\ 2& 1.5 & 2 \\end{bmatrix}$. Associate the two robot positions with random variables $X_1$ and $X_2$. Note that the pair $(X_1,X_2)$ is uniform on the rectangle $[0.5,1.5] \\times [-0.5,3.5]$.  The probability $p_1$ (resp. $p_2$) that $X_1\\leq X_2$ (resp. $X_1 \\geq X_2$) is the area of this rectangle below (resp. above) the line $x_1\\leq x_2$. If $p_1 \\leq p_2$, then the MPO is $[1,2]$ , else $[2,1]$. What data structure efficiently computes the MPO? I'm most interested in the range $n\\in [10,1000]$.Simple idea that doesn't work (thanks to D.W.): When $n\\geq 3$, the MPO isn't equal to the sorted order of the means $A_i$. For example, the input $(1, 0.4\\pm0), (2,0.5\\pm 0.5), (3,0.7 \\pm 0)$ has the MPO $[2,1,3]$ and not $[1,2,3]$ as the $A$'s would have us think. One possible approach uses the Sweep Line algorithm. Think of a robot position as a rectangle corresponding to its uniform pdf. Compute all intersecting rectangles using the Priority Queue of the sweep line, and reorder them as per the probability calculation above. (It may be possible to reduce the $O(n^2)$ pairwise comparison of probabilities to $O(n \\log n)$; I haven't checked this though.) Non-overlapping rectangles leave their ordering intact.Intuitively, large error bounds lead to long rectangles and potentially more overlaps, consequently increasing the running time. Likewise, small error bounds cause few overlaps, speeding up computations. This fact will be reflected in the sweep line.",
    "target": "data structures;randomized algorithms;permutations"
  },
  {
    "id": "_cs.23880",
    "source": "Is the language $L = \\{a^nb^m : n = 2^m\\}$ context-free? <eos> Is the language $L = \\{a^nb^m : n = 2^m\\}$ context-free?Assume L is a context-free language. Then $\\ \\exists p\\in \\mathbb{Z}^{+}:\\forall s\\in L\\left | s \\right |\\geq p. s = uvxyz,\\left | vy \\right |\\geq 1,\\left | vxy \\right |\\leq p. s_i = uv^{i}xy^{i}z\\in L\\forall i\\geq 0\\ $.Let s = $\\ a^{2^p}b^{p}\\ $Pumping i times will give a string of length $\\ 2^{p} + (i - 1)*j\\ $ a's and $\\ p + (i - 1)*k\\ $ b's where $\\ 1 \\leq j + k \\leq p\\ $Case 1: $\\ j \\neq 0\\ $ $\\ k \\neq 0\\ $??Case 2: $\\ j = 0\\ $ $\\ k \\neq 0\\ $??Case 3: $\\ j \\neq 0\\ $ $\\ k = 0\\ $??It can be concluded from this that L is not a context-free language.",
    "target": "pumping lemma"
  },
  {
    "id": "_unix.106608",
    "source": "WiFi USB stick not recognised by BeagleBone Black <eos> I'm trying to set up a TP-LINK TL-WL725N v2 WiFi USB stick on my BeagleBone Black.However, it doesn't even appear to be recognised, i.e. it doesn't show up in the output of lsusb:$ lsusb  Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub  Bus 002 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hubNeither dmesg nor the syslog contain any new messages when the stick is plugged in or unplugged.Oddly enough, the stick even seems to break the USB port for the rest of the session: after plugging and unplugging the WiFi stick, a memory stick that previously worked fine was no longer recognised until I rebooted the BeagleBone.The same WiFi stick works flawlessly on a laptop running Ubuntu 12.04.3 with a 3.11.0 kernel and a Raspberry Pi running Raspbian with a 3.10.24 kernel.Relevant lsusb line:  Bus 001 Device 006: ID 0bda:8179 Realtek Semiconductor Corp.However, the Raspberry reboots whenever I plug in the stick, so it might be drawing too much current.I'm not quite sure how to proceed:does this indicate a hardware failure (presumably of the WiFi stick)? Or is there anything else I could try to at least get the stick recognised on the BeagleBone?(I'm aware that I will have to compile the necessary kernel module myself, just like on the Raspberry Pi, but that's no use if the stick isn't even recognised...)EditI've checked the supply voltage on the USB port and it is actually switched off the moment I connect the WiFi stick. I tried forcing it back on by pulling the !EN pin on the TPS2051 switch IC low, but that didn't help (i.e. the voltage came back on, but the system didn't seem to poll the bus anymore).I've googled for the USB1_DRVVBUS output on the processor that drives the input of the switch IC and it seems that the supply for the USB host port is automatically disabled when an over-current condition is detected.That explains why the stick crahes the Raspberry Pi and fails to work on the BeagleBone, but leaves me to wonder if it might be broken, since several Raspberry users have reported that it worked for them without a powered hub.Second EditI perused the schematic some more and bypassed the switch IC and current sensing resistor, but even then the the USB host section is disabled as soon as the WiFi stick is connected.",
    "target": "usb;wifi"
  },
  {
    "id": "_cs.2332",
    "source": "Expression Problem  looking for a similar standard problem <eos> The Expression Problem, populated by Philip Wadler,  is a often used to standard problem to evaluate programming languages.I think it is a very clear and popular example and I wonder if there are any similar standard problems that are possibly also as widely used and as clear.So, are there any similar standard problems?(In the case of Feature Oriented Programming (link link) I found some standard problems, like:- implementation of a stack with different features- implementation of linked lists- implementation of a calculator- the graph product line- stock broker and bank account examples- hierarchical display)",
    "target": "reference request;programming languages;software engineering"
  },
  {
    "id": "_datascience.9471",
    "source": "Asking a specific question from a general one <eos> SettingI have data about a board game which has been played multiple times with different players per game (though players reoccur in all kinds of different constellations). During the game one can score points in one of seven categories. The general question is: What is the best strategy? On what category should players concentrate?Details about the data and performed transformationsThe original data has the variables:game - the number of the gamename - the name of the playermilitary pointsmoney pointsworld wonder points... pointssum of pointswhich I transferred intogamenamesum of points (a little repetitive, since its the same for a game and name)place in game (a little repetitive, since its the same for a game and name)type of points (one of the seven categories)number of pointspercentage this type of points contributed to the total amount of points of this player for this gameMy QuestionAsking the right question is been said to be the most important thing in Data Science and in most situations I managed to find a good concrete (programmable) question, but this one seems tough to me.So: How do I ask a specific question to answer the general question?Of course I have already asked/answered simple questions regarding the winning players of each game. For example: What is the type of points that contributes most to the total points for winning players (whose success proved them right)?Now I'd like to make analyses over the entire field of players.An even more advanced question would consider that player reoccur across games.I have no idea what tag to use here.",
    "target": "simulation"
  },
  {
    "id": "_webmaster.99297",
    "source": "Which HTTP/HTTPS www/no-www versions should be registered in Search Console when using Cloudflare Flexible SSL <eos> I have a question about the use of Cloudflare Flexible SSL and the settings in Google Search Console. Say I use Flexible SSL on my website example.com. I have wrote a redirect from http to https in my .htaccess so every request on http://example.com redirects to https://example.com.What do I need to register on Search Console? Right now I have registered all four possible URLs, meaning http://example.com, https://example.com, http://www.example.com and https://www.example.com.",
    "target": "seo;google;https;search;cloudflare"
  },
  {
    "id": "_softwareengineering.84599",
    "source": "What do you believe is a better of method of learning languages: using books or jumping straight into a project? <eos> Do you find that it is better to learn through reading books or to just jump straight into a project and pick up what you need to know using the web, or some combination of both?",
    "target": "programming languages;learning;books"
  },
  {
    "id": "_softwareengineering.340487",
    "source": "Framework logs on client application <eos> We are currently building a framework (closed source static library) that will communicate with some Smart home devices via Wi-Fi. This framework will be used by 3rd party developer to build their own applications (mainly mobile application) in order to communicate with those devices.Currently, we have split opinions on if the framework should generate any visible logs (say a log file, or event logger) on a release version (we will supply a debug and a release version to 3rd party developers).Reasons to have logs:Logs are always helpful if we need to find out the root cause of unexpected error.Any form of logs is always goodGetting the logs information from mobile phone should be easy. (By app user or support desk technician)We can prove it is application developers' fault if they blame it to us.Some issues may only happen in production that cannot be reproduce on test environment.Log files are not big anyway. A small log file that use some of the device storage shouldn't be an issue.All servers application/API always have logs.Reverse engineer is always possible via decompile, so it shouldn't really matters.Reasons to not have logs:Framework doesn't own the application. Most users have no idea how to get the log files out of application's storage (hence less likely to be able to get it), so don't add something that will not be usedApplication developer should be able to pinpoint the problem by their own logs/debug method before coming to usRisk of exposing too much information to end users.No other frameworks seems to do it (e.g. Facebook SDK/Google SDK)Taking up device storage. Every byte count.It is the responsible of the framework user (developer) to have their own logs/crash reporting if they want to.Debug version with console/debugger logs should be enough for developers.So basically we are not able to get into an agreement. Just wondering what does the wider community think about this if you are the developer that use a closed source static library on a client application.",
    "target": "android;ios;logging;third party libraries"
  },
  {
    "id": "_codereview.77459",
    "source": "Regex for matching a US phone number <eos> I have written my first regex:static void Main(string[] args){    string phoneNumber= Console.ReadLine();    Regex pattern = new Regex((1-)?\\\\p{N}{3}-\\\\p{N}{3}-\\\\p{N}{4}\\\\b);    MatchCollection collection = pattern.Matches(phoneNumber);    Console.WriteLine(phoneNumber +  is  + (collection.Count == 1 && collection[0].ToString() == phoneNumber ?  : not ) + a valid US number.);}It needs to match the entire input string, and it can work for any US phone number with or without country code 1-. It can most likely be improved; any suggestions?",
    "target": "c#;.net;regex"
  },
  {
    "id": "_unix.216582",
    "source": "record daily internet bandwidth usage <eos> I am using internet connection with data cap. I want to record my daily internet usage in a file, is there any tool for this or perhaps you can suggest a script that would run as daemon?(I am not pro in bash scripting or with linux administrating software so a simple script will be recommended)",
    "target": "internet;bandwidth"
  },
  {
    "id": "_unix.215243",
    "source": "Unable to login as a newly created user <eos> I have a dual boot Kali Linux along with windows 7.  Now when I installed Kali it logs me in as root.  I do not have a login in my name.  So I created a user with the following steps.  However when I log off and login, there is an  Authentication Failure with the new login.  Where am I going wrong? laa@aa-lu:~$ sudo useradd testinguser    alaa@aa-lu:~$ sudo passwd testinguser    Enter new UNIX password:    Retype new UNIX password:    passwd: password updated successfully    alaa@aa-lu:~$ sudo ls -l /home    total 20    drwxr-xr-x 55 alaa alaa  4096 Aug 22 22:00 alaa    drwx------  2 root root 16384 Jun  5 09:46 lost+found    alaa@aa-lu:~$ sudo mkdir /home/testinguser    alaa@aa-lu:~$ sudo chown testinguser:testinguser /home/testinguser    alaa@aa-lu:~$ ls -l /home    total 24    drwxr-xr-x 55 alaa        alaa         4096 Aug 22 22:00 alaa    drwx------  2 root        root        16384 Jun  5 09:46 lost+found    drwxr-xr-x  2 testinguser testinguser  4096 Aug 23 10:03 testinguser    alaa@aa-lu:~$ ls -l /home/testinguser/    total 0    alaa@aa-lu:~$",
    "target": "users;kali linux"
  },
  {
    "id": "_cs.29667",
    "source": "NP-hardness proof, what is wrong with it? <eos> My question is the following: If we have a problem divided into two versions, weighted and unweighted. Can we prove that the unweighted problem is NP-hard from the fact that the weighted problem is NP-hard ?For example let say I have the knapsack problem (the weighted version):$$\\max \\sum_{i}^n w_i x_i$$$$\\text{s.t.} \\sum_{i=1}^n p_i x_i\\leqslant W,\\quad(WP)$$$$x_i\\in\\{0,1\\}.$$This problem is know to be NP-hard problem. However, the unweighted version of this problem is given by:$$\\max \\sum_{i}^nx_i$$$$\\text{s.t.} \\sum_{i=1}^n p_i x_i\\leqslant W,\\quad(P)$$$$x_i\\in\\{0,1\\}.$$is not NP-hard since the optimal solution is to sort the items in the ascending order with respect to $p_i$ and start filling the bag until the capacity $W$ is reached.The problem is the following: I used the unweighted version of this problem as a special case of the weighted version and I showed that unweighted is an NP-hard problem. What is my mistake? Here is my steps: I will reduce $(WP)$ to $(P)$ in polynomial time. So, an instance of $(P)$ is constructed easily by taking $w_i=1$. And I am done and hence $(P)$ is NP-hard which is obviously wrong.Thank you to correct me and give me if possible some good references that deal with such weighted and unweighted problems?",
    "target": "complexity theory;optimization;np hard"
  },
  {
    "id": "_softwareengineering.355187",
    "source": "Kiosk Mode on non Chrome OS <eos> My team is working on a progressive web app. We've been searching for a solution to so that viewers of our app cannot exit the app (it's an in shop app, which we use at our stores that shows content related to the store). I've found several solutions involving putting physical covers over the devices back/home buttons, as well as installing third party software that disables usage of all other apps/locks the screen to one specific app. I've also found the solution of adding kiosked_enabled:true to the manifest.json file. However, upon viewing this link (https://developer.chrome.com/apps/manifest/kiosk_enabled#kiosk_enabled) I see that this seems to be a solution specific to Chrome OS/Chrome devices.So my question is: Do progressive web apps support kiosk mode on non-Chrome devices.?If so, how can this be implemented? If not, what is a solution that my team can implement with our code base to lock the device to only use our application that doesn't use a physical cover over the hardware or a third party app (would love to know how these third party applications do this)?",
    "target": "web applications;chrome"
  },
  {
    "id": "_unix.255252",
    "source": "Create the same PNG with ImageMagick 2 times: Binaries differ <eos> I create two images that should be identical, but their binaries are different:$ convert -size 1x1 xc:white out1/w.png$ sleep 1$ convert -size 1x1 xc:white out2/w.png$ diff out1/w.png out2/w.png Binary files out1/w.png and out2/w.png differProbably because of a timestamp in embedded metadata.QUESTION: How to make ImageMagick create a binary that will always be the same?ContextI have a big ImageMagick script that creates many images that are then saved to Git (because most developers don't have the environment necessary to run the script).I often edit the script (ex:define a new image) and then run it to regenerate all images. But I don't want to have Git differences for images that have not changed.Apparently some compression algorithms produce slightly different results on different architectures. Not a big problem since I always generate on the same machine. But even on the same machine, the files always all differ.ImageMagick 6.8.9-9 Q16 x86_64 2015-08-06, on Ubuntu 2015.10",
    "target": "binary;imagemagick;version control;png"
  },
  {
    "id": "_unix.356659",
    "source": "Kill an existing TCP connection quickly <eos> I'm working on a pentesting project, and I have the following setup: I have  an SSH daemon that is trying to log all of the activity happening on SSH connections out to another server. I'm trying to disable this logging, and in particular, do so in a way that avoids being detected. Thus, I have the following requirements:I need to be able to kill an existing TCP connection, and ideally with as little buffered data sent as possible. That is, if there's outbound data buffered in the kernel, it would be ideal if this data were dropped without being sent.In order to achieve this, it's best if the command that I need to type in is as short as possible so that the entire command can be buffered either in the logging application or in the kernel TCP buffer. This way, if the first bullet point is achieved, the logging server will never receive information about the fact that logging was disabled; it will just appear as a network outage.I've tried iptables -A OUTPUT -d <ip of logging server> -j DROP, but that doesn't do the trick - the text of the command itself manages to get sent before the rule is enforced. I've also tried tcpkill, similarly to no avail.",
    "target": "ssh;kernel;logs;tcp;socket"
  },
  {
    "id": "_datascience.5684",
    "source": "How Mllib in Spark select variables in logistic regression <eos> I have a question about MLlib in Spark.(with Scala)I'm trying to understand how LogisticRegressionWithLBFGS and LogisticRegressionWithSGD work. I usually use SAS or R to do logistic regressions but I now have to do it on Spark to be able to analyze Big Data.How is the variable selection done? Is there any try of different variable combinations in LogisticRegressionWithLBFGS or LogisticRegressionWithSGD? Something like a test of significance of variable one by one? Or a correlation calculation with the variable of interest? Is there any calculation of BIC, AIC to choose the best model?Because the model only returns weights and intercept...How can I understand those Spark functions and compare to what I'm used to with SAS or R ?",
    "target": "machine learning;bigdata;logistic regression;scala;apache spark"
  },
  {
    "id": "_codereview.124011",
    "source": "UVA #10258 - Contest Scoreboard <eos> The problem statement is here.Problem DescriptionThe task is to rank the contestants in the contest based on following criteriaContestants are ranked first by the number of problems solved (the more the better)then by decreasing amounts of penalty timeIf two or more contestants are tied in both problems solved and penalty time, they are displayed in order of increasing team numbers.How Penalty time is calculatedPenalty time is computed as the number of minutes it took for the first correct submission for a problem to be received plus 20 minutes for each incorrect submission received prior to the correct solution. The penalty time will be considered only if the problem is solved. There will not be any penalty if the problem is not solved even if the several Incorrect submissions were made. A problem is solved if any of the submissions for that problem is judged correct. InputThe input begins with a single positive integer on a line by itself indicating the number of the cases following, each of them as described below. This line is followed by a blank line, and there is also ablank line between two consecutive inputs.Input consists of a snapshot of the judging queue, containing entries from some or all of contestants 1 through 100 solving problems 1 through 9. Each line of input will consist of three numbers and a letter in the format contestant problem time Lwhere L can be C, I, R, U or E. These stand for Correct, Incorrect, clarification Request, Unjudged and Erroneous submission. The last three cases do not affect scoring.Lines of input are in the order in which submissions were received.OutputFor each test case, the output must follow the description below. The outputs of two consecutive cases will be separated by a blank line.Output will consist of a scoreboard sorted as previously described. Each line of output will contain a contestant number, the number of problems solved by the contestant and the time penalty accumulated by the contestant. Since not all of contestants 1-100 are actually participating, display only the contestants that have made a submission.Algorithmfor every test_case    for every submission        If a new contestant submitted a solution to a problem            consider the user for the rest of the contest            judge the solution to the problem        else            if the problem has not already been solved                judge the solution to the problem    calculate the penalty time for solved problems for every contestant    print itData Structurestruct boardcontestant: id of the contestantnproblem: no of problem solved by the contestantproblem[1..9]: 1 if ith problem is solved by the contestant else 0penalty[1..9]: total penalty time for the problem to be solved by contestanttime: total penalty time for whole contest awarded to the contestantAny suggestions for improving efficiency or readability?#include <iostream>#include <algorithm>#include <sstream>#include <vector>using namespace std;struct board{  int contestant;  int nproblem;  int problem[10];  int penalty[10];  int time;  board(int c): contestant(c), nproblem(0)  {    time = 0;    for ( int i = 0; i < 10; ++i )      {    problem[i] = 0;    penalty[i] = 0;      }  }};inline void init(int index[]){  for ( int i = 0; i < 101; ++i )    index[i] = -1;}void judge(board &b, const int &problem, const int &time, const char &L){  if ( L == 'C' )    {      ++b.nproblem;      b.problem[problem] = 1;      b.penalty[problem] += time;    }  else if ( L == 'I' )    {      b.penalty[problem] += 20;    }}bool operator<(const board &b1, const board &b2){  if ( b1.nproblem > b2.nproblem )    return true;  if ( b1.nproblem == b2.nproblem && b1.time < b2.time )    return true;  if ( b1.nproblem == b2.nproblem && b1.time == b2.time       && b1.contestant < b2.contestant )    return true;  return false;}void calc_time(vector<board> &v){  for ( vector<board>::iterator it = v.begin(); it != v.end(); ++it )    {      for ( int i = 1; i < 10; ++i )    {      if ( it->problem[i] == 1 )        it->time += it->penalty[i];    }    }}int main(){  int T;  string s;  int contestant, problem, time;  char L;  cin >> T;  getline(cin, s);  getline(cin, s);  for ( int t = 1; t <= T; ++t )    {      int index[101];      init(index);      vector<board> v;      while( getline(cin, s) )    {      if ( s ==  ) break;      istringstream iss(s);      iss >> contestant >> problem >> time >> L;      if ( index[contestant] == -1 )        {          v.push_back(*new board(contestant));          index[contestant] = (int)v.size() - 1;          judge(v[index[contestant]], problem, time, L);        }      else        {          if ( v[index[contestant]].problem[problem] == 0 )        {          judge(v[index[contestant]], problem, time, L);        }        }    }      calc_time(v);      sort(v.begin(), v.end());      for ( vector<board>::iterator it = v.begin(); it != v.end(); ++it )    cout << it->contestant << ' ' << it->nproblem << ' ' << it->time << endl;      if ( t < T )    cout << endl;    }  return 0;}Refactored CodeThe changes in the code is suggested by vnp#include <iostream>#include <algorithm>#include <sstream>#include <vector>struct board{  int contestant;  int nproblem;  int problem[10];  int penalty[10];  int time;  board(int c): contestant(c), nproblem(0)  {    time = 0;    for ( int i = 0; i < 10; ++i )      {          problem[i] = 0;          penalty[i] = 0;      }  }  void calc_time()  {    for ( int i = 1; i < 10; ++i )      {          if ( problem[i] == 1 )          time += penalty[i];      }  }};inline void init(int index[]){  for ( int i = 0; i < 101; ++i )    index[i] = -1;}void judge(board &b, const int &problem, const int &time, const char &L){  if (b.problem[problem] == 1)    {      return;    }  if ( L == 'C' )    {      ++b.nproblem;      b.problem[problem] = 1;      b.penalty[problem] += time;    }  else if ( L == 'I' )    {      b.penalty[problem] += 20;    }}bool operator<(const board &b1, const board &b2){  if ( b1.nproblem > b2.nproblem )    return true;  if ( b1.nproblem == b2.nproblem && b1.time < b2.time )    return true;  if ( b1.nproblem == b2.nproblem && b1.time == b2.time       && b1.contestant < b2.contestant )    return true;  return false;}int main(){  int T;  std::string s;  int contestant, problem, time;  char L;  std::cin >> T;  getline(std::cin, s);  getline(std::cin, s);  for ( int t = 1; t <= T; ++t )    {      int index[101];      std::fill(index, index + 101, -1);      std::vector<board> v;      while( getline(std::cin, s) )    {      if ( s ==  ) break;      std::istringstream iss(s);      iss >> contestant >> problem >> time >> L;      if ( index[contestant] == -1 )        {          v.push_back(*new board(contestant));          index[contestant] = (int)v.size() - 1;        }      judge(v[index[contestant]], problem, time, L);    }      for ( std::vector<board>::iterator it = v.begin(); it != v.end(); ++it )          it->calc_time();      sort(v.begin(), v.end());      for ( std::vector<board>::iterator it = v.begin(); it != v.end(); ++it )          std::cout << it->contestant << ' ' << it->nproblem << ' ' << it->time << std::endl;      if ( t < T )          std::cout << std::endl;    }  return 0;}",
    "target": "c++;algorithm;programming challenge;sorting"
  },
  {
    "id": "_datascience.1185",
    "source": "What are some best papers on gradient descent for NN implementation? <eos> I'm trying to implement GD for standard task of NN training :) The best papers for practioneer I've founded so far are:1) Efficient BackProp by Yann LeCun et al.2) Stochastic Gradient Descent Tricks by Leon BottouAre there some other must read papers on this topic?Thank you!",
    "target": "neural network;gradient descent"
  },
  {
    "id": "_unix.151990",
    "source": "NTPD fails to sync <eos> I'm transferring from one server to another.  Identical configuration, newer hardware, same data center.  The new machine CAN speak NTP:$ sudo ntpdate -d ntp.jentfoo.comPassword:24 Aug 14:50:59 ntpdate[10935]: ntpdate 4.2.6p5@1.2349-o Sun Aug 24 17:40:33 UTC 2014 (1)Looking for host ntp.jentfoo.com and service ntphost found : stripes.jentfoo.comtransmit(173.203.211.73)receive(173.203.211.73)transmit(173.203.211.73)receive(173.203.211.73)transmit(173.203.211.73)receive(173.203.211.73)transmit(173.203.211.73)receive(173.203.211.73)server 173.203.211.73, port 123stratum 2, precision -20, leap 00, trust 000refid [173.203.211.73], delay 0.04141, dispersion 0.00014transmitted 4, in filter 4reference time:    d7a4aec6.c2942e94  Sun, Aug 24 2014 14:34:46.760originate timestamp: d7a4b299.ef951806  Sun, Aug 24 2014 14:51:05.935transmit timestamp:  d7a4b29a.0400cdfd  Sun, Aug 24 2014 14:51:06.015filter delay:  0.04141  0.04160  0.04147  0.04152         0.00000  0.00000  0.00000  0.00000filter offset: -0.08754 -0.08769 -0.08770 -0.08774         0.000000 0.000000 0.000000 0.000000delay 0.04141, dispersion 0.00014offset -0.08754324 Aug 14:51:06 ntpdate[10935]: adjust time server 173.203.211.73 offset -0.087543 secSo there's no firewall issue.  But no matter how long I leave it running, the ntpd server never synchronizes with its peers:$ ntpq 127.0.0.1ntpq> pe     remote           refid      st t when poll reach   delay   offset  jitter============================================================================== andromeda.cs.pu .INIT.          16 -    - 1024    0    0.000    0.000   0.000 ns.nts.umn.edu  .INIT.          16 -    - 1024    0    0.000    0.000   0.000 stan.greyware.c .INIT.          16 -    - 1024    0    0.000    0.000   0.000 stripes.jentfoo .INIT.          16 -    - 1024    0    0.000    0.000   0.000ntpq> asind assid status  conf reach auth condition  last_event cnt===========================================================  1 18223  8011   yes    no  none    reject    mobilize  1  2 18224  8011   yes    no  none    reject    mobilize  1  3 18225  8011   yes    no  none    reject    mobilize  1  4 18226  8011   yes    no  none    reject    mobilize  1ntpq> rvassocid=0 status=c012 leap_alarm, sync_unspec, 1 event, freq_set,version=ntpd 4.2.6p5@1.2349-o Sun Aug 24 17:40:33 UTC 2014 (1),processor=x86_64, system=Linux/3.15.5-hardened-r2, leap=11,stratum=16, precision=-23, rootdelay=0.000, rootdisp=355.605, refid=INIT,reftime=00000000.00000000  Sun, Dec 31 1899 19:00:00.000,clock=d7a510c6.0be8b4ee  Sun, Aug 24 2014 21:32:54.046, peer=0, tc=3,mintc=4, offset=0.000, frequency=0.000, sys_jitter=0.000,clk_jitter=0.000, clk_wander=0.000ntpq> rv 18226associd=18226 status=8011 conf, sel_reject, 1 event, mobilize,srcadr=stripes.jentfoo.com, srcport=123, dstadr=0.0.0.0, dstport=0,leap=11, stratum=16, precision=-23, rootdelay=0.000, rootdisp=0.000,refid=INIT, reftime=00000000.00000000  Sun, Dec 31 1899 19:00:00.000,rec=00000000.00000000  Sun, Dec 31 1899 19:00:00.000, reach=000,unreach=34, hmode=3, pmode=0, hpoll=10, ppoll=10, headway=0,flash=1600 peer_stratum, peer_dist, peer_unreach, keyid=0, offset=0.000,delay=0.000, dispersion=15937.500, jitter=0.000,filtdelay=     0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00,filtoffset=    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00,filtdisp=   16000.0 16000.0 16000.0 16000.0 16000.0 16000.0 16000.0 16000.0And I can't figure out why.  The old server is using the exact same configuration, and it works fine.  I don't know what to do.Update: ntpd has been running overnight and:2014-08-24 14:57:46.244875500 Starting ntpd ...2014-08-24 14:57:46.246304500 Finished Parsing!!... normal startup status ...2014-08-25 01:24:53.871674500 receive: at 975 0.0.0.0<-212.1.209.194 mode 3 len 482014-08-25 01:24:53.871699500 transmit: at 975 0.0.0.0->212.1.209.194 mode 4 len 482014-08-25 01:24:53.871700500 receive: at 1117 0.0.0.0<-212.1.209.194 mode 3 len 482014-08-25 01:24:53.871700500 transmit: at 1117 0.0.0.0->212.1.209.194 mode 4 len 482014-08-25 01:24:53.871700500 receive: at 1300 0.0.0.0<-198.23.230.118 mode 3 len 482014-08-25 01:24:53.871701500 transmit: at 1300 0.0.0.0->198.23.230.118 mode 4 len 482014-08-25 01:24:53.871701500 receive: at 2115 0.0.0.0<-66.172.12.144 mode 3 len 482014-08-25 01:24:53.871725500 transmit: at 2115 0.0.0.0->66.172.12.144 mode 4 len 482014-08-25 01:24:53.871725500 auth_agekeys: at 4096 keys 1 expired 02014-08-25 01:24:53.871725500 auth_agekeys: at 8192 keys 1 expired 02014-08-25 01:24:53.871726500 auth_agekeys: at 12288 keys 1 expired 0...  more of the same ...It does appear to be transmitting/recieving.  All the ntpq output is identical except rv 18226 answers unreach=69 now.",
    "target": "ntpd"
  },
  {
    "id": "_unix.67950",
    "source": "How can I update this sed oneliner? <eos> INPUT:  $ echo -e 'AAAART5530408XXXX\\nAAAAZE6530408XXXX\\nAAAART12345678XXXX'AAAART5530408XXXXAAAAZE6530408XXXXAAAART12345678XXXX$OUTPUT: $ echo -e 'AAAART5530408XXXX\\nAAAAZE6530408XXXX\\nAAAART12345678XXXX' | sed -e 's/\\(AAAA[A-Z]\\{2\\}[0-9]\\{7\\}\\)XXXX/\\n\\1/g'AAAART5530408AAAAZE6530408AAAART12345678XXXX$   How can I extend the: sed -e 's/\\(AAAA[A-Z]\\{2\\}[0-9]\\{7\\}\\)XXXX/\\n\\1/g'sed oneliner, so that it would optionally accept sed -e 's/\\(AAAA[A-Z]\\{2\\}[0-9]\\{8\\}\\)XXXX/\\n\\1/g'8 numbers too? (not just 7) Is it possible with only 1 sed?",
    "target": "sed"
  },
  {
    "id": "_cs.42317",
    "source": "Defining function for arithmetic expressions <eos> I've got these arithmetic expressions a  ::=  n  |  x  |  a1 + a2  |  a1 ? a2  |  a1  a2  which are a part of language.An undefined element is allowed  which extends the set of intergers to Z{}.Problem:I need to define the function A: Aexp  (State  Z{})by defining equations for each form of the arithmetic expression a.Now I've tried to come up with an solution but I am pretty sure I am wrong and I gotta admit I am pretty stuck.Some help understanding this problem would be great.",
    "target": "semantics;denotational semantics"
  },
  {
    "id": "_softwareengineering.127753",
    "source": "Defining classes in JavaScript that exist in your back-end <eos> Doesn't it seem relatively duplicative to define your Models in your backend code AND on your front end for a rich internet application?I'm porting a GUI application I had written to have a web interface, which is all grand and nice any all, but things like Spine, SproutCore, JavascriptMVC would have you define your models and views and implement specific controllers.Being that I've got a well defined MVC pattern on my backend code (which is making this super easy to port; the views in my app took python dicts and returned python dicts to the controllers which could easy interface with the models; I can just convert these to JSON back and forth to speak to the web front end), why would I want to recreate the entire pattern again on the front end?What are good ways to work around this?Should I just say screw this and use something like http://pyjs.org?Should I write a bunch of code to export my models into JSON and then write some JavaScript code to build the Models on the front-end automatically so I'm still only defining them once?What would be the best approach to this?",
    "target": "javascript;mvc;methodology;front end"
  },
  {
    "id": "_unix.28175",
    "source": "System hanging when it runs out of memory <eos> I've got an eeePC 900a: it has a 8GB flash as disk and only 1GB of RAM. The Linux distribution installed on it is ArchLinux.When the system runs out of memory it becomes extremely unresponsive: it takes several seconds/minutes to do things like switching to TTY1 or even moving the mouse pointer. Sometimes it looks like the system just freezes: three ours ago I let it alone and nothing at all is changed so far.I'd rather avoid creating a swap partition/file on this eeePC since the disk is already that small, and also because the many writes on the swap space would shorten a lot the flash card life.Moreover I think that a swap file/partition would just move the problem, rather than definitely fixing it.Isn't the kernel supposed to kill some random applications when it runs out of memory? Why does it fail (or takes ages) at doing that?A few months/years ago I already tried to look further into this, but couldn't find anything that would actually work...",
    "target": "linux;memory;freeze"
  },
  {
    "id": "_scicomp.21824",
    "source": "Divide and Conquer division algorithm explained (as used in GMP bignum) <eos> I am trying to understand the divide and conquer division algorithm that is used in the GMP bignum arithmetic library.The code is very optimised and that makes it somewhat hard to understand. the doc does not really offer an explanation of how it is done, (and the references do not point to an actual algorithm, not one that I could see anyway).I understand the concept of divide and conquer for sorting, but I am not sure I understand how it can be used in a division.How can $x \\over y$ be calculated using divide and conquer?Can someone give a small example of how it is done?",
    "target": "optimization;algorithms;computer arithmetic"
  },
  {
    "id": "_softwareengineering.291200",
    "source": "Is it ok to avoid testing base classes? <eos> I have a base class with a fair amount of meta programming to give it the flexibility/abstraction it needs to be rather generic.I do have a lot of subclasses using the common methods in the base class, and I have behavior oriented unit tests covering all of the cases in each subclass.Is it ok to skip testing the base class?",
    "target": "unit testing;testing"
  },
  {
    "id": "_vi.8856",
    "source": "Mapping Ctrl with equal sign <eos> I am trying to map my Ctrl and plus sign together. This is what I am trying in my vimrc:nnoremap <C-=>    : echo Hello <CR> However it seems like the mapping is not being triggered.Any suggestions on what I might be doing wrong? I am using macvim.",
    "target": "key bindings;macvim"
  },
  {
    "id": "_unix.131272",
    "source": "Falling to git checkout on non-found bash commands <eos> When I type (in bash) a command which linux does not find, it usually does something like this:$ xx: command not foundbut when I type a command which is not found but which is similar in some sense to other possible commands, the reply may look like this:$ pypNo command 'pyp' found, did you mean: Command 'pcp' from package 'pcp' (universe) Command 'pype' from package 'pype' (universe) Command 'pgp' from package 'pgpgpg' (universe) Command 'pp' from package 'libpar-packer-perl' (universe) Command 'php' from package 'php5-cli' (main) Command 'gyp' from package 'gyp' (universe) Command 'pip' from package 'python-pip' (universe) Command 'pap' from package 'netatalk' (universe)pyp: command not foundThat means that some hook checked pyp before it let bash reply with pyp: command not found.I'd like to write a hook like that, that will check if the command is a name of a branch in a current repository (if we're indeed in a repository), and will try to checkout into it before replying with command not found, but only if the command was really not found.To this end, I need to understand something about the flow; when I type the command (and press enter), where does it go to? What is the program which replies with did you mean, and how does it get the command string from bash?",
    "target": "bash;hook"
  },
  {
    "id": "_unix.298589",
    "source": "How to allocate a process specific amount of CPU power? <eos> I would like to allocate certain number of CPU cores to a specific process for performance improvement.How can I do this?",
    "target": "cpu;process management"
  },
  {
    "id": "_codereview.163433",
    "source": "Elixir - Relay between Telegram and Discord - Small project <eos> I built a relay bot (Well, they're two bots acting as one, you get it) between two specifics channels in Discord and Telegram, I want this to be reviewed because I have some concerns about code-style, probably I could have more elegant code but who knows.This is the project and the two things that I don't know if should be done that way are multi-line parameters on the Dispatcher module on lib/kass/gram/dispatcher.ex:def dispatch(updates) do    Enum.each(updates,              &Task.Supervisor.start_child(                                           Kass.TaskSupervisor,                                           Kass.Gram.Bot,                                           :handle_message,                                           [&1.message]))  endAnd the handle_message function on lib/kass/gram/bot.ex:def handle_message(%Message{chat: %Chat{type: group},                   from: %User{first_name: first_name, last_name:                   last_name, id: id},                   text: text}) do  ...endMaybe this could be done differently? I just didn't want to exceed the 80 legth limit from the style guide. Anyway, besides that, feel free to check it and criticize as much as possible, thanks ^-^",
    "target": "elixir"
  },
  {
    "id": "_unix.259829",
    "source": "Bash: #: command not found <eos> I just moved to Arch Linux with KDE a week ago. Everything worked well until I installed ibus-unikey and ibus-qt, after that, whenever I open konsole, this error appears:bash: #: command not foundI doubt that # is a usual command because when I type it in konsole, nothing happens. But when I run pacman -Ss #, a ton of things appear.My question: what is the # command and what should I do to fix this error? Here are my .bashrc, .bash_profile and PATH$ cat .bashrc   #   # ~/.bashrc   #   # If not running interactively, don't do anything   [[ $- != *i* ]] && return$ cat .bash_profile   #   # ~/.bash_profile   #   [[ -f ~/.bashrc ]] && . ~/.bashrc   alias ls='ls --color=auto'   PS1='[\\u@\\h \\W]\\$ '$ echo $PATH   /usr/local/texlive/2015/bin/x86_64-linux:/usr/local/sbin:/usr/local/bin:/usr/bin:/usr/bin/site_perl:/usr/bin/vendor_perl:/usr/bin/core_perlAddition 1: As @terdon suggest, I run$ grep -FH '\\#' ~/.bashrc ~/.profile ~/.bash_profile ~/bash.login ~/.bash_aliases /etc/bash.bashrc /etc/profile /etc/profile.d/* /etc/environment 2>/dev/nulland receive nothing. But the later command give me$ grep -P '(^|\\s+)(\\.|source) .' ~/.bashrc ~/.profile ~/.bash_profile ~/bash.login ~/.bash_aliases /etc/bash.bashrc /etc/profile /etc/profile.d/* /etc/environment 2>/dev/null   /home/thuyenarc/.bash_profile:[[ -f ~/.bashrc ]] && . ~/.bashrc   /etc/bash.bashrc:[ -r /usr/share/bash-completion/bash_completion   ] && . /usr/share/bash-completion/bash_completion   /etc/profile:           test -r $profile && . $profile   /etc/profile:   . /etc/bash.bashrc   /etc/profile.d/locale.sh:    . $XDG_CONFIG_HOME/locale.conf   /etc/profile.d/locale.sh:    . $HOME/.config/locale.conf   /etc/profile.d/locale.sh:    . /etc/locale.confAddition 2: I tried renaming the .bashrc file, then opened konsole, the error had gone. I suspect that the errors must come from .bashrc. Any ideas?",
    "target": "bash;bashrc"
  },
  {
    "id": "_softwareengineering.308406",
    "source": "Handling null-references in C# logic <eos> Let's say I have an API method with can be used to calculate the sum of all orders made by a specific customer:Amount CalculateOrderSum(int customerId){    // Perform authentication to make sure caller has access to customerId    // Retrieve customer with id customerId    // Retrieve all orders related to the customer    // Retrieve details for different orders (not always, depending on state)}At any point in this function, some system administrator may purge old items from the system. This means that one of the below can happen while the method above is running:The authentication will fail, because the customer no longer existsThe customer can't be loaded, since it was deletedThe customer can be loaded, but a millisecond later the orders are deleted and cannot be retrieved.Retrieving order details works for some orders, but fails for others since they have been deleted mid-processing.I want the application to return a friendly error message when any of this happens, rather than returning a NullReferenceException or similar.As I see it, there's some different approaches to add error-handling for this logic:I could introduce a lot of null-checks throughout the code for example: if (customer != null) throw OrderRetrievalFailedException(customer is a goner.). Since all the data in the database can be purged at any time, this would lead to quite a lot of if's spread throughout the code (which seems to get messy)I could change the purging functionality to mark customers or orders as deleted (rather than actually removing the database rows). This way the function could still do its work because the data will still be there. The issue here is that we actually want to purge old data for different reasons (less attack surface and performance considerations for example).I could change all methods to throw if an object can't be loaded (so GetOrders(customerId) could throw CustomerNotFoundException if the customer cannot be loaded) which would be catched in the CalculateOrderSum function and an error given to the user. So basically the code would have to be littered with if (something == null) throw new SomeException.I could introduce some global locking mechanism, so that a customer can't be deleted while any one is reading any of its data. The issue here is that our system is distributed so we would need to implement a central locking mechanism. Also, I have a bad experience with locking of database rows in use-cases like this in high-traffic database.All of these approaches feels quite convoluted and tricky to get right to me, and it means that the main success flow of the code will be littered with handling of exception scenarios. I'm leaning towards alternative 3, but I would to hear if there's some other standard and robust way of handling this.(I'm using C#, but I assume that the same issue would apply to users of for example Java or C++)",
    "target": "c#;error handling;null"
  },
  {
    "id": "_softwareengineering.83263",
    "source": "Deprecation considered harmful? <eos> I've just been compiling some of my own code with the -std=c++0x flag in GCC, as I want to vaguely keep up with what all the young folks are doing (provided they stay of my lawn), and I ended up with a load of warnings about auto_ptr being deprecated. Of course, I knew that auto_ptr was deprecated in C++0x, but...Isn't deprecation a waste of time and effort? Reasons for not deprecating (with auto_ptr as an example):there is an ocean of code out there that still needs to be supported, producing millions of warnings will only tempt people to turn warnings off.auto_ptr is a bit naff, but it does actually do what it says on the tin.if we really want to deprecate things, I nominate printf(). But just imagine the squeals that would ensue. auto_ptr doesn't have too many friends, but in at least my C++ code it is used more than printf, which isn't used at all.the committee have a bad record of getting this right - they deprecated static at namespace scope, and now it seems to have been undeprecated  - I wouldn't be surprised if auto_ptr made a similar come-backlastly, whatever the committee say, the compiler implementers ignore them - they simply can't risk breaking their customers code, all they can do is issue irritating warnings.So my question - do you consider deprecation (of anything, not just auto_ptrs, and not just in C++) a good idea, and if so, why?",
    "target": "c++;c++11;standardization"
  },
  {
    "id": "_unix.47749",
    "source": "Cannot add new mode in xrandr for external monitor <eos> Today I was trying to connect my second monitor to my notebook. I have:nvidia graphic card304.43 drivers [support xrandr 1.2]archlinux [up-to-date]awesome wmxrandr 1.3My problem is with bigger resolution than 640x480 for my external monitor (VGA).xrandr -q:Screen 0: minimum 8 x 8, current 1920 x 800, maximum 8192 x 8192VGA-0 connected 640x480+1280+0 (normal left inverted right x axis y axis) 0mm   640x480        59.9*+   320x240       120.1  LVDS-0 connected 1280x800+0+0 (normal left inverted right x axis y axis) 331m   1280x800       59.9*+HDMI-0 disconnected (normal left inverted right x axis y axis)As we can see the is no higher resolution fo VGA, so I add new mode:xrandr --newmode $(gtf 1280 1024 70.4 | grep Modeline | sed s/Modeline\\ // | tr -d '')I checked avaible resolution and refresh rate under windows: one of them was 1024x768x70 (OSD of my monitor said that it is 70.4HZ). After create new mode, I wanted to add it:xrandr --addmode VGA-0 1280x1024_70.40And... It failed:X Error of failed request:  BadMatch (invalid parameter attributes)  Major opcode of failed request:  153 (RANDR)  Minor opcode of failed request:  18 (RRAddOutputMode)  Serial number of failed request:  29  Current serial number in output stream:  30From google I learned that in older xrandr / nvidia drivers was problem with list of avaible modes, but now with support of xrandr 1.2 by nvidia drivers it should be better. I also try with lower resolution and refresh rate (eg. 1024x768x50), but I've got the same error.I'm out of ideas what to do with this problem...",
    "target": "xorg;arch linux;nvidia;xrandr;awesome"
  },
  {
    "id": "_codereview.49358",
    "source": "Breakout-Clone built in SFML <eos> After reading the SFML Game Development book, I decided to put what was learned to the test by creating a simple Breakout clone. I have posted the source code to GitHub: https://github.com/andrewd440/breakoutsfmlI wanted to see if I could get any sort of feedback on the general code structure that I used or any programming techniques that I could improve on before I proceed to my next project.Application.h/// <summary>/// Initializing class for the game app/// </summary>class Application : sf::NonCopyable{public:                                Application();    void                        run();private:    void                        update(sf::Time dt);    void                        processEvents();    void                        render();    void                        registerStates();    void                        loadResources();private:    FontHolder                  mFonts;    TextureHolder               mTextures;    sf::RenderWindow            mWindow;    StateStack                  mStateStack;    static const sf::Time       mTimePerFrame;    SoundPlayer                 mSoundPlayer;};  Application.cpp    const sf::Time Application::mTimePerFrame = sf::seconds(1.f / 60.f);/// <summary>/// Initializes a new instance of the <see cref=Application/> class./// </summary>Application::Application(): mWindow(sf::VideoMode(865, 956), Drewski's Block Breaker, sf::Style::Close), mStateStack(mWindow), mFonts(), mTextures(), mSoundPlayer(){    registerStates();    loadResources();    // Start statestack at title screen    mStateStack.pushState(States::Title);}/// <summary>/// Starts the main game loop./// </summary>void Application::run(){    sf::Clock clock;    sf::Time elapsedTime = sf::Time::Zero;    while (mWindow.isOpen())    {        elapsedTime += clock.restart();        while (elapsedTime >= mTimePerFrame)        {            update(mTimePerFrame);            processEvents();            elapsedTime -= mTimePerFrame;        }        render();    }}/// <summary>/// Updates all game objects./// </summary>/// <param name=dt>The delta time.</param>void Application::update(sf::Time dt){    mStateStack.update(dt);    mSoundPlayer.removeInactiveSounds();}/// <summary>/// Processes the events./// </summary>void Application::processEvents(){    sf::Event event;    while (mWindow.pollEvent(event))    {        mStateStack.handleEvent(event);        switch (event.type)        {            case sf::Event::Closed:                mWindow.close();        }    }    if (mStateStack.isEmpty())        mWindow.close();}/// <summary>/// Renders this all game objects./// </summary>void Application::render(){    mWindow.clear();    mStateStack.draw();    mWindow.display();}/// <summary>/// Registers the game states./// </summary>void Application::registerStates(){    mStateStack.registerState<GameState>(States::Game);    mStateStack.registerState<TitleState>(States::Title);    mStateStack.registerState<PauseState>(States::Pause);}/// <summary>/// Loads fonts and textures used in the game./// </summary>void Application::loadResources(){    // Set ServiceLocator window    ServiceLocator::setWindow(mWindow);    // Load all game fonts and set ServiceLocator font holder    mFonts.load(Fonts::Main, Media/Fonts/Sansation.ttf);    ServiceLocator::setFontHolder(mFonts);    // Load all game textures and set ServiceLocator texture holder    mTextures.load(Textures::Title, Media/Textures/TitleScreen.png);    mTextures.load(Textures::Paddle, Media/Textures/Paddles.png);    mTextures.load(Textures::Ball, Media/Textures/Ball.png);    mTextures.load(Textures::Bricks, Media/Textures/BrickTextures.png);    mTextures.load(Textures::Particle, Media/Textures/Particle.png);    ServiceLocator::setTextureHolder(mTextures);    // Set ServiceLocator SoundPlayer    ServiceLocator::setSoundPlayer(mSoundPlayer);}StateStack.h/// <summary>/// Used to manage various states in the game/// </summary>class StateStack : public sf::NonCopyable{public:    // Actions for the statestack    enum Action    {        Pop,        Push,        Clear,    };    explicit                    StateStack(sf::RenderWindow& window);    void                        update(sf::Time dt);    void                        handleEvent(const sf::Event& event);    void                        draw();    template <typename T>    void registerState(States::ID id);    // Called by outside code for changing the current statestack    void                        popState();    void                        pushState(States::ID id);    void                        clearStates();    bool                        isEmpty() const;private:    void                        applyPendingChanges();    // Called from applyPendingChanges when a state is pushed    State::Ptr                  createState(States::ID);private:    // Structure for applying actions to the statestack at the correct time during game update    struct PendingAction    {                                            PendingAction(Action a, States::ID i);        Action                              action;        States::ID                          id;    };private:    sf::RenderWindow&                       mWindow;    std::vector<State::Ptr>                 mStack;    std::vector<PendingAction>              mPendingList;    std::map<States::ID,        std::function<State::Ptr()>>        mFactories;};/// <summary>/// Registers the game state./// </summary>/// <param name=id>The state identifier.</param>template <typename T>void StateStack::registerState(States::ID id){    // Map functors for states that are registered    mFactories[id] = [this]()    {        return State::Ptr(new T(*this, mWindow));    };}StateStack.cppStateStack::PendingAction::PendingAction(Action a, States::ID i = States::None): action(a), id(i){}StateStack::StateStack(sf::RenderWindow& window): mWindow(window), mPendingList(), mStack(), mFactories(){}void StateStack::popState(){    mPendingList.push_back(PendingAction(Pop));}void StateStack::pushState(States::ID id){    mPendingList.push_back(PendingAction(Push, id));}void StateStack::clearStates(){    mPendingList.push_back(PendingAction(Clear));}/// <summary>/// Applies the pending changes./// </summary>void StateStack::applyPendingChanges(){    // We only update the statestack at optimal times,     // so all requests go through a pending list and are then executed    for (auto change : mPendingList)    {        switch (change.action)        {            case Push:                mStack.push_back(createState(change.id));                break;            case Pop:                mStack.pop_back();                break;            case Clear:                mStack.clear();                break;        }    }    mPendingList.clear();}/// <summary>/// Find the functor for the state and return the instantiated state/// </summary>/// <param name=id>The state identifier.</param>/// <returns>Pointer to the new state</returns>State::Ptr StateStack::createState(States::ID id){    auto found = mFactories.find(id);    assert(found != mFactories.end());    return found->second();}void StateStack::update(sf::Time dt){    // Update each state until one returns false in it's update function    for (auto state = mStack.rbegin(); state != mStack.rend(); state++)    {        if (!(*state)->update(dt))            break;    }    applyPendingChanges();}void StateStack::handleEvent(const sf::Event& event){    for (auto state = mStack.rbegin(); state != mStack.rend(); state++)    {        if (!(*state)->processEvent(event))            break;    }    applyPendingChanges();}void StateStack::draw(){    for (auto state = mStack.begin(); state != mStack.end(); state++)        (*state)->draw();}bool StateStack::isEmpty() const{    return mStack.size() <= 0;}GameState.h/// <summary>/// Represents main gameplay state/// </summary>class GameState :    public State{public:    GameState(StateStack& stack, sf::RenderWindow& window);    virtual bool                update(sf::Time dt);    virtual bool                processEvent(const sf::Event& event);    virtual void                draw();private:    void                        displayCompletionStatus() const;private:    World                       mWorld;    sf::Text                    mCompletionStatusText;    sf::Time                    mCompletionDisplayTimer;};GameState.cpp// Used for displaying success/failure text at end of gameconst sf::Time CompletionDisplayInterval = sf::seconds(3.f);GameState::GameState(StateStack& stack, sf::RenderWindow& window): State(stack, window), mWorld(window), mCompletionStatusText(), mCompletionDisplayTimer(sf::Time::Zero){    mCompletionStatusText.setFont(ServiceLocator::getFontHolder().get(Fonts::Main));    mCompletionStatusText.setPosition(window.getSize().x / 2.f, window.getSize().y / 2.f);    mCompletionStatusText.setCharacterSize(30);}bool GameState::update(sf::Time dt){    if (!mWorld.isWorldComplete())        mWorld.update(dt);    else    {        // If World is complete, show result text        mCompletionDisplayTimer += dt;        if (mWorld.getMissionStatus() == World::Success)            mCompletionStatusText.setString(You won!!!);        else            mCompletionStatusText.setString(Sorry, you failed.);    }    if (mCompletionDisplayTimer > CompletionDisplayInterval)    {        requestStackClear();        requestStackPush(States::Title);    }    return true;}bool GameState::processEvent(const sf::Event& event){    mWorld.handleInput(event);    if (event.type == sf::Event::KeyPressed && event.key.code == sf::Keyboard::Escape)        requestStackPush(States::Pause);    return true;}void GameState::draw(){    mWorld.draw();    if (mWorld.isWorldComplete())    {        sf::RenderWindow& window = getWindow();        centerOrigin(mCompletionStatusText);        window.draw(mCompletionStatusText);    }}World.h/// <summary>/// Represents the game world/// </summary>class World{public:    enum MissionStatus    {        Running,        Success,        Failed    };                                                                World(sf::RenderWindow& window);    void                                                        handleInput(const sf::Event& event);    void                                                        update(sf::Time dt);    void                                                        draw();    bool                                                        isWorldComplete() const;    World::MissionStatus                                        getMissionStatus() const;private:    void                                                        handleCollisions();    void                                                        loadNextLevel();    void                                                        loadBalls(Levels::ID level);    void                                                        removeDestroyedBalls();    void                                                        updateRemainingBalls();private:    sf::RenderWindow&                                           mWindow;    Player                                                      mPlayer;    std::vector<std::unique_ptr<Ball>>                          mBalls;    std::vector<std::unique_ptr<Brick>>                         mBricks;    unsigned int                                                mCurrentLevel;    bool                                                        mIsChangingLevel;    sf::Time                                                    mLevelTransitionTimer;    bool                                                        mSpawnedNewBricks;    sf::Text                                                    mLevelChangeText;    int                                                         mRemainingBalls;    sf::Text                                                    mBallDisplayText;    bool                                                        mIsWorldComplete;    World::MissionStatus                                        mMissionStatus;    ParticleSystem                                              mBallTrails;    ParticleSystem                                              mBackgroundBounceParticles;    ParticleEmitter                                             mBounceParticleEmitter;};World.cppconst sf::Time LevelTransitionInterval = sf::seconds(4.f);namespace{    // Sets up table indexed by Level::ID, provides: Max Balls and Lives Per Ball    const std::vector<LevelInfo> LevelTable = initializeLevelTable();}World::World(sf::RenderWindow& window): mWindow(window), mPlayer(), mBalls(), mBricks(), mCurrentLevel(0), mIsChangingLevel(false), mLevelTransitionTimer(sf::Time::Zero), mSpawnedNewBricks(false), mLevelChangeText(), mBallDisplayText(), mRemainingBalls(0), mIsWorldComplete(false), mMissionStatus(World::Running), mBallTrails(Particle::Trail), mBackgroundBounceParticles(Particle::BackgroudBouncers), mBounceParticleEmitter(mBackgroundBounceParticles){    auto windowBounds = mWindow.getSize();    mPlayer.setPosition(windowBounds.x / 2.f, windowBounds.y - 50.f);    // Set position for background particles    mBounceParticleEmitter.setPosition(windowBounds.x / 2.f, windowBounds.y / 2.f);    // Text to display on level changes    mLevelChangeText.setFont(ServiceLocator::getFontHolder().get(Fonts::Main));    mLevelChangeText.setPosition(window.getSize().x  / 2.f, window.getSize().y / 2.f);    mLevelChangeText.setCharacterSize(30);    // Balls Remaining display    mBallDisplayText.setFont(ServiceLocator::getFontHolder().get(Fonts::Main));    mBallDisplayText.setPosition(window.getSize().x - 200, window.getSize().y - 30);    mBallDisplayText.setCharacterSize(20);    loadNextLevel();}/// <summary>/// Handles events and input for the game world./// </summary>/// <param name=event>Game event.</param>void World::handleInput(const sf::Event& event){    mPlayer.handleInput();}/// <summary>/// Updates the game world./// </summary>/// <param name=dt>The delta time.</param>void World::update(sf::Time dt){    updateRemainingBalls();    handleCollisions();    removeDestroyedBalls();    // If there are no more ball, but still bricks left, you lose    if (mRemainingBalls <= 0 && !mBricks.empty())    {        mMissionStatus = World::Failed;        mIsWorldComplete = true;    }    // If bricks are cleared and world is not complete, load next level    if ((mBricks.empty() || mIsChangingLevel) && !mIsWorldComplete)    {        mIsChangingLevel = true;        mLevelTransitionTimer += dt;        loadNextLevel();    }    mPlayer.update(dt);    for (auto& ball : mBalls)    {        ball->update(dt);    }    mBallTrails.update(dt);    mBounceParticleEmitter.update(dt);    mBackgroundBounceParticles.update(dt);    for (auto& brick : mBricks)        brick->update(dt);}/// <summary>/// Draws the game world./// </summary>void World::draw(){    mWindow.draw(mBackgroundBounceParticles);    for (auto& ball : mBalls)    {        mWindow.draw(*ball);    }    mWindow.draw(mPlayer);    mWindow.draw(mBallDisplayText);    mWindow.draw(mBallTrails);    for (auto& brick : mBricks)        mWindow.draw(*brick);    if (mIsChangingLevel)    {        centerOrigin(mLevelChangeText);        mWindow.draw(mLevelChangeText);    }}/// <summary>/// Determines whether the World is complete./// </summary>/// <returns></returns>bool World::isWorldComplete() const{    return mIsWorldComplete;}World::MissionStatus World::getMissionStatus() const{    return mMissionStatus;}/// <summary>/// Handles collisions with all game objects./// </summary>void World::handleCollisions(){    for (auto& ball : mBalls)    {        auto ballRect = ball->getBoundingRect();        float ballWidth = ballRect.width;        float ballHeight = ballRect.height;        float ballLeft = ballRect.left;        float ballTop = ballRect.top;        // Create four contact points for the ball        sf::Vector2f ballLeftPoint(ballLeft, ballTop + (ballHeight / 2.f));                 // Middle of left side        sf::Vector2f ballRightPoint(ballLeft + ballWidth, ballTop + (ballHeight / 2.f));    // Middle of right side        sf::Vector2f ballTopPoint(ballLeft + (ballWidth / 2.f), ballTop);                   // Middle of top        sf::Vector2f ballBottomPoint(ballLeft + (ballWidth / 2.f), ballTop + ballHeight);   // Middle of bottom        // Ball/Paddle collisions        auto playerRect = mPlayer.getBoundingRect();        if (ballRect.intersects(playerRect))        {            // How the paddle velocity will affect the ball bounce            float angleChangeFactor = 0;            if (mPlayer.getVelocity().x > 0)                angleChangeFactor = -10.f;            else if (mPlayer.getVelocity().x < 0)                angleChangeFactor = 10.f;            // Adjust Ball angle for bounce            if (playerRect.contains(ballBottomPoint))            {                ball->setAngle(360.f - ball->getAngle() + angleChangeFactor);                ball->setPosition(ball->getPosition().x, mPlayer.getPosition().y - (mPlayer.getBoundingRect().height / 2.f) - (ballHeight / 2.f));            }            else if (playerRect.contains(ballLeftPoint) || playerRect.contains(ballRightPoint))                ball->setAngle(180.f - ball->getAngle() + angleChangeFactor);        }        // Ball/Brick collisions        for (auto itr = mBricks.begin(); itr != mBricks.end();)        {            auto brickRect = (*itr)->getBoundingRect();            float ballAngle(ball->getAngle());            if (ballRect.intersects(brickRect))            {                // If contact is on the left or right of the ball, adjust angle properly                if (brickRect.contains(ballLeftPoint) || brickRect.contains(ballRightPoint))                    ball->setAngle(180.f - ball->getAngle());                // If contact is on the top or top of the ball, adjust angle properly                else if (brickRect.contains(ballTopPoint) || brickRect.contains(ballBottomPoint))                    ball->setAngle(360.f - ball->getAngle());            }            // If the angle of the ball changed, then we know a brick was hit. We damage that brick and if it is destroyed,            // if so, we remove the brick from our brick container.            if (ballAngle != ball->getAngle())            {                // Play a random bounce sound                ServiceLocator::getSoundPlayer().play(static_cast<Sounds::ID>(randomInt(Sounds::BallCount)));                (*itr)->damage(ball->getPower());                if ((*itr)->isDestroyed())                    mBricks.erase(itr);                break;            }            else                itr++;        }    }}/// <summary>/// Loads the next level./// </summary>void World::loadNextLevel(){    // Show level completed text at beginning of level transition    if (mCurrentLevel > 0 && mLevelTransitionTimer < LevelTransitionInterval / 2.f )         mLevelChangeText.setString(Level complete!);    // Spawn the bricks in at half the level transition interval    if (mLevelTransitionTimer >= LevelTransitionInterval / 2.f && !mSpawnedNewBricks)    {        mSpawnedNewBricks = true;        mBalls.clear();        mCurrentLevel++;        // Set loading level text        mLevelChangeText.setString(Loading level  + toString(mCurrentLevel));        // Load new bricks and spawn balls        switch (mCurrentLevel)        {        case 1:            mBricks = spawnLevelOne();            loadBalls(Levels::One);            break;        case 2:            mBricks = spawnLevelTwo();            loadBalls(Levels::Two);            break;        case 3:            mBricks = spawnLevelThree();            loadBalls(Levels::Three);            break;        default:            mLevelChangeText.setString();        }    }    // Close out level transition when the interval is closed    if (mLevelTransitionTimer >= LevelTransitionInterval)    {        mIsChangingLevel = false;        mSpawnedNewBricks = false;        mLevelTransitionTimer = sf::Time::Zero;        // If we passed to last level, we win        if (mCurrentLevel > Levels::Count)        {            mIsWorldComplete = true;            mMissionStatus = World::Success;        }    }}/// <summary>/// Load Balls./// </summary>/// <param name=number>The number of balls to load.</param>void World::loadBalls(Levels::ID level){    for (int i = 0; i < LevelTable[level].maxBalls; i++)    {        std::unique_ptr<Ball> ball(new Ball(LevelTable[level].livesPerBall, mBallTrails));        mBalls.push_back(std::move(ball));    }}/// <summary>/// Removes the destroyed balls./// </summary>void World::removeDestroyedBalls(){    for (auto itr = mBalls.begin(); itr != mBalls.end();)    {        if ((*itr)->isDestroyed())            itr = mBalls.erase(itr);        else            itr++;    }}/// <summary>/// Updates the remaining balls and updates ball display./// </summary>void World::updateRemainingBalls(){    int sum = 0;    for (auto& ball : mBalls)    {        sum += ball->getLives();    }    mRemainingBalls = sum;    mBallDisplayText.setString(Balls Remaining:  + toString(mRemainingBalls));}Ball.h/// <summary>/// Represents the Ball object/// </summary>class Ball :    public Entity{public:                            Ball(int lives, ParticleSystem& particlSystem);    float                   getAngle() const;    void                    setAngle(float angle);    void                    update(sf::Time dt);    void                    resetPosition();    sf::FloatRect           getBoundingRect() const;    unsigned int            getPower() const;    unsigned int            getLives() const;    bool                    isDestroyed() const;    void                    markForDestroyed();    void                    reactToBounce();private:    void                    handleWallCollision();    void                    checkIfBallIsLive();    void                    draw(sf::RenderTarget& target, sf::RenderStates states) const;    float                   linearVelocityX() const;    float                   linearVelocityY() const;private:    float                   mAngle;    sf::Vector2f            mSpawnPoint;    sf::Sprite              mSprite;    unsigned int            mPower;    float                   mDefaultVelocity;    sf::Time                mMovementTimer;    int                     mLives;    bool                    mIsDestroyed;    ParticleEmitter         mBallTrailEmitter;};Ball.cppconst sf::Time MovementDelayInterval = sf::seconds(.1f);Ball::Ball(int lives, ParticleSystem& particlSystem): Entity(), mSprite(ServiceLocator::getTextureHolder().get(Textures::Ball)), mSpawnPoint(ServiceLocator::getWindow().getSize().x / 2.f, ServiceLocator::getWindow().getSize().y / 2.f), mDefaultVelocity(500.f), mPower(1), mLives(lives), mMovementTimer(sf::Time::Zero), mIsDestroyed(false), mAngle(), mBallTrailEmitter(particlSystem){    centerOrigin(mSprite);      resetPosition();}void Ball::draw(sf::RenderTarget& target, sf::RenderStates states) const{    states.transform *= getTransform();    target.draw(mSprite, states);}void Ball::resetPosition(){    // Reset the movement timer for a delay after the reset    mMovementTimer = sf::Time::Zero;    setPosition(mSpawnPoint);    mAngle = randomInt(361);}unsigned int Ball::getLives() const{    return mLives;}void Ball::update(sf::Time dt){    mMovementTimer += dt;    // Provide updates to ball trail particles    mBallTrailEmitter.setPosition(getPosition());    mBallTrailEmitter.update(dt);    if (mMovementTimer >= MovementDelayInterval)    {        checkIfBallIsLive();        handleWallCollision();        sf::Vector2f velocity;        velocity.x = linearVelocityX() * mDefaultVelocity;        velocity.y = linearVelocityY() * mDefaultVelocity;        setVelocity(velocity);        Entity::update(dt);    }}/// <summary>/// Handles the ball collisions with the wall./// </summary>void Ball::handleWallCollision(){    sf::RenderWindow& window = ServiceLocator::getWindow();    // If the ball hits the sides of the window, rebound its angle by 180    if (getPosition().x + (mSprite.getLocalBounds().width / 2.f) > window.getSize().x        || getPosition().x - (mSprite.getLocalBounds().width / 2.f) < 0.f)    {        setAngle(180.f - getAngle());        // Play collision sound        ServiceLocator::getSoundPlayer().play(Sounds::Wall1);        // Make sure ball is inside the screen        if (getPosition().x + (mSprite.getLocalBounds().width / 2.f) > window.getSize().x)            setPosition(window.getSize().x - mSprite.getLocalBounds().width / 2.f, getPosition().y);        else            setPosition(mSprite.getLocalBounds().width / 2.f, getPosition().y);        // If angle is too flat, make it wider        if ((getAngle() < 190.f && getAngle() > 170.f))            setAngle(getAngle() - 20.f);        else if (getAngle() < 10.f || getAngle() > 350.f)            setAngle(getAngle() + 20.f);    }    // If the ball hits the top of the window, rebound angle by 360    else if (getPosition().y - (mSprite.getLocalBounds().height / 2.f) < 0.f)    {        setAngle(360.f - getAngle());        ServiceLocator::getSoundPlayer().play(Sounds::Wall2);        if (getPosition().y + (mSprite.getLocalBounds().height / 2.f) < 0)            setPosition(getPosition().x, 0);    }    // Keep angle from 0-360    if (getAngle() > 360)        setAngle( getAngle() - 360);    else if (getAngle() < 0)        setAngle(getAngle() + 360);}/// <summary>/// Checks if ball is inbounds./// </summary>void Ball::checkIfBallIsLive(){    sf::RenderWindow& window = ServiceLocator::getWindow();    if (getPosition().y - (mSprite.getLocalBounds().height / 2.f) > window.getSize().y)    {        mLives--;        if (mLives > 0)            resetPosition();        else            markForDestroyed();    }}sf::FloatRect Ball::getBoundingRect() const{    return getTransform().transformRect(mSprite.getGlobalBounds());}Brick.h/// <summary>/// Represents a Brick object./// </summary>class Brick :    public Entity{public:    enum Type    {        None,        Green,        Blue,        Purple,        Red,        Count    };                            Brick(Brick::Type type, float x, float y);    unsigned int            getType() const;    sf::FloatRect           getBoundingRect() const;    unsigned int            getHitpoints() const;    void                    setHitpoints(unsigned int hitpoints);    void                    damage(unsigned int damage);    bool                    isDestroyed() const;    void                    update(sf::Time dt);private:    void                    draw(sf::RenderTarget& target, sf::RenderStates states) const;private:    Brick::Type             mType;    sf::Sprite              mSprite;    unsigned int            mHitpoints;};Brick.cppnamespace{    // Setup brick table indexed by Brick::Type that provides: hitpoints and texture rect.    const std::vector<BrickInfo> Table = initializeBrickTable();}Brick::Brick(Brick::Type type, float positionX, float positionY): Entity(), mSprite(ServiceLocator::getTextureHolder().get(Textures::Bricks), Table[type].textureRect), mType(type), mHitpoints(Table[type].hitpoints){    setPosition(positionX, positionY);    centerOrigin(mSprite);    //updateTexture();}bool Brick::isDestroyed() const{    return mHitpoints <= 0;}void Brick::draw(sf::RenderTarget& target, sf::RenderStates states) const{    states.transform *= getTransform();    target.draw(mSprite, states);}void Brick::update(sf::Time dt){    Entity::update(dt);}sf::FloatRect Brick::getBoundingRect() const{    return getTransform().transformRect(mSprite.getGlobalBounds());}",
    "target": "c++;game;sfml"
  },
  {
    "id": "_webmaster.101844",
    "source": "Client has set up a mirror on DreamHost, but original site is hosted elsewhere <eos> Sorry. Newbie here. Picked up a client that needs has a blog through LexBlog. They want to recreate it on DreamHost and move all of the information over.She puchased her hosting through DreamHost and added the current domain. Then set up a mirror site. I have never used DreamHost or a mirror. Question is, will the mirror even work since the original site is hosted elsewhere? Or should a basic subdomain be set up to build the new site on before we make the switch over. ",
    "target": "subdomain;dreamhost;mirror"
  },
  {
    "id": "_unix.347250",
    "source": "how to get tty from current pts <eos> The system is centos 7 x64 running at level 3 mode which is no GUI. I am connecting remotely to the machine. I use tmate and teamviewer. I run who and I can view who is login on ttys.usera tty1     2017-02-24 11:47userb tty2     2017-02-24 12:00userc tty6     2017-02-24 02:00The result is same in tmate session and teamviewer session. But when I type tty. tmate session returns /dev/pts/1 while teamviewer return /dev/tty6. It seems teamviewer returns tty number which is same with terminal number opened by Ctrl-Shift-Fn, and here is Ctrl-Alt-F6.I have read several article which describes tty and pty. what-is-the-exact-difference-between-a-terminal-a-shell-a-tty-and-a-con, difference-between-pts-and-ttyWhat I would like to do is that how to get current tty number from pty session? In my specific case, I want to get tty number in tmate session. So which tty does pts running on? In the case above tmate is started on teamviewer session. so I type tty get /dev/pts/1 and then I exit tmate session by typing exit and back to teamviewer session and type tty again get /dev/tty6. It seems means that /dev/pts/1 working on /dev/tty6. And I want to get tty6 in tmate session without exit to the session. It should nothing related to tmate and teamviewer. It should same when ssh to a physic machine. So there should a solution to get tty number back in pty.Manay solutions how-to-get-the-tty-in-which-bash-is-running, returns the filename of the terminal connected to standard input, get-current-terminal-name only get pty number. But I would like to get tty number.How to do that? Thanks.",
    "target": "centos;tty;pty"
  },
  {
    "id": "_unix.375265",
    "source": "How can I install Mint without a DVD? <eos> I am running Debian, but lack of driver support for stuff I want has made me decide to switch to Mint.  Unfortunately, I don't have a DVD and the Mint community seems to have decided I really, really need a DVD.  I have a USB, but I'm not sure how to burn the .iso image, rather than the file, to said USB in order to then boot from it in order to install the OS.  I'm also not convinced this is necessarily the best/simplest way to go about installing Mint.  I just want to wipe everything and get a clean install of Mint.  What do I need to do to do that without a DVD?",
    "target": "debian;linux mint;usb;system installation"
  },
  {
    "id": "_datascience.13556",
    "source": "Is there an image classification dataset which has objects in varying distances? <eos> I would like to analyze / estimate the influence of the architecture on scale invariance in photos.To clarify: It is possible that a network can classify objects well if they are close, but totally fails when they are far away. Although the main object of the photo is still the same. Is there a dataset which is suitable for this task?",
    "target": "dataset;image classification"
  },
  {
    "id": "_softwareengineering.345559",
    "source": "Who should read an external resource <eos> I am often in the following situation: I have a config file, specifying the path to a resource fileThis config file gets parsed and the values (e.g., file path) are stored in a ConfigStore objectA business logic object needs to content of the resource file. Now who should actually read the resource file? ConfigStoreThe Business Logic ObjectA special parser?I don't like any of the 3 options: Both 1 and 2 violate the single responsibility principle, on the other hand, since file io is only a few lines, introducing a special parser class for this also seems like an overkill. So who should read the file?",
    "target": "design;configuration;resources"
  },
  {
    "id": "_webmaster.93514",
    "source": "Does https affect adsense? <eos> I am starting a new guest blog where I write posts and ask others to write as well. I will be using adsense with my website very soon and I want to know if the SSL I'm using will affect the performance of the ads. Also if it is going to affect it, is it better to https with login and submission screens only or it wont make a difference?",
    "target": "google;https;google adsense"
  },
  {
    "id": "_webmaster.99506",
    "source": "Should an ecommerce website be translated when moving into a new country, or a new site built from scratch? <eos> I have a friend whose eCommerce is working very well in one language.He would like to have me translating the website into Italian and to manage all the Italian customers.From a SEO point-of-view, since the website right now is not ranked for Italian language at all, wouldn't it be better if I used a new new site with a new geographic domain .it containing some relevant keyword, rather than translating the original one? The original one has no SEO strategy in place anyway.",
    "target": "seo;multilingual;internationalization;translation"
  },
  {
    "id": "_unix.231537",
    "source": "VS Code not working on Elementary OS <eos> I have downloaded VS Code on Elementary OS, and I followed the setup instruction of Setting up Visual Studio Code on linux.The executable file code seems to be unknown, it is not opening, Any ideas?",
    "target": "linux;ubuntu;executable;elementary os"
  },
  {
    "id": "_softwareengineering.341538",
    "source": "Designing an asynchronous polling service in Java <eos> I am currently writing a Java bridge to a eyetracking library written in C. The whole thing works very well, but building an actual application with it is hard, since eyetracking is done by polling for new data.Polling becomes a problem as soon as you have a graphical user interface, as a poll-loop blocks the main event loop, freezing the gui. This also makes it impossible to stop the polling loop through user input.My goal is to build a polling service that is generic enough to be used for a lot of different applications. It has to be asynchronous and has to have some kind of callback mechanism to use any relevant data.This is my idea (pseudocode):PollService {  // The filterFunction decides if a eyetracking event is relevant or can be ignored  setFilterFunction(filterFunction);  // The callbackFunction is executed if a relevant eyetracking event is polled  setCallbackFunction(callbackFunction);  start();  stop();}The PollService itself only manages the asynchronous polling process. It is supplied a couple of functions to perform the two basic steps:Filter if a eyetracking event is relevant, skip event if notPerform some kind of operation on any event that is relevantPossible callback operations might be:Perform a long running computation with the eyetracking event dataPrint something to the screenStore something to a databaseCommunicate the event to another thread (using a messaging queue for example)Update a GUI (using Platform.runLater() for example)The filterFunction and callbackFunction would be implemented as functional interfaces, so Java 8 users can easily supply these functions using lambdas or method references.What do you think about this design? Are there any obvious flaws i am not seeing?",
    "target": "java;design"
  },
  {
    "id": "_unix.39886",
    "source": "From df device name to physical drive name (vendor / type) <eos> Seeing the device name by df, is it somehow possible to resolve it to the physical drive name such as vendor / type./dev/sda3               915.4G     34.9G    880.0G   4% /share/HDA_DATA/dev/sdd3                 1.8T    668.1G      1.1T  36% /share/HDD_DATAI have learnt that I find some info in sys/block, but I do not find the vendor's type name in there?-- Added --My system is a Linux based QNAP NAS, so things might be a little different there. For me as a non Linux expert hard to tell, what is standard, and what not.-- Added as of Steven's answer --[~] # hdparm -I /dev/sdb3/dev/sdb3: HDIO_DRIVE_CMD(identify) failed: Invalid argument",
    "target": "linux;hard disk;block device;df"
  },
  {
    "id": "_softwareengineering.349645",
    "source": "Strategies to manage unruly system environments <eos> In our IT dept we develop multiple systems in parallel, the systems are deployed to different environments, and they talk to each other using SOAP and REST. It's all ASP.NET but we're not in the cloud. I'm trying to find a way of streamlining environments to reduce complexity.Simplified view, let's say there are 3 systems in production: A,B,C. They communicate like this:Prod: A 1.0 => B 1.0 => C 1.0We mirror that in a test environment like this:Test: A 1.0 => B 1.0 => C 1.0If there's an urgent production bug in B, we would make a fix to B and deploy it to the test environment. Test: A 1.0 => B 1.1 => C 1.0and if integration tests pass we can release it to production:Prod: A 1.0 => B 1.1 => C 1.0Now let's say we develop a new feature which means A and B both need to change. Both A and B are being deployed to test.Test: A 2.0 => B 2.0 => C 1.0During this development period, if an urgent production bug is found in B, we would have to make a fix to B and deploy it to test environment:Test: A 2.0 => B 1.2 => C 1.0Obviously this is shaky ground now because the test environment does not resemble production. And what about when B 2.0 has a breaking change - in this case the A 2.0 will fail when pointing to B 1.2.So what we've done is create another environment for emergency fixes, called Patch. So we can have:Test: A 2.0 => B 2.0 => C 1.0Patch: A 1.0 => B 1.2 => C 1.0Now A, B and C each have different delivery cycles, so what tends to happen is that at different stages of the project, the Patch environment is abused in order to test different versions of each component for the current release or for the next release. We end up doing crazy stuff like pointing Test A to Patch B, or pointing Patch B to Test C. And this obviously generates huge confusion. Not to mention that this is a massively simplified version, in reality we have at least 8 systems involved here, with 6 environments. The TeamCity summary page is like spaghetti junction. Also some environments talk to each other (in my example above it would be like A => B => C => A).Please help me understand how this type of scenario can work.",
    "target": "deployment;configuration;release management;environment"
  },
  {
    "id": "_unix.246312",
    "source": "Why is my bind mount visible outside its mount namespace? <eos> So I'm trying to get a handle on how Linux's mount namespace works.  So, I did a little experiment and opened up two terminals and ran the following:Terminal 1root@goliath:~# mkdir a broot@goliath:~# touch a/foo.txtroot@goliath:~# unshare --mount -- /bin/bashroot@goliath:~# mount --bind a broot@goliath:~# ls bfoo.txtTerminal 2root@goliath:~# ls bfoo.txtHow come the mount is visible in Terminal 2? Since it is not part of the mount namespace I expected the directory to appear empty here.  I also tried passing -o shared=no and using --make-private options with mount, but I got the same result.What am I missing and how can I make it actually private?",
    "target": "linux;namespace;bind mount"
  },
  {
    "id": "_webapps.25509",
    "source": "Cleaned Wikipedia content used on Google Maps - dump available? <eos> On Google, there are pages such as the following which provide a summary of the place in question taken from Wikipedia: http://local.google.co.uk/maps/place?q=Canterbury+Cathedral&cid=15406428664599496982I am not a lawyer, but I assume that as Google has obviously gone to the trouble of extracting/cleaning the data from the dump files provided by Wikipedia, this constitutes a derived work, which I think means that Google must provide the cleaned data for download.Is providing the content online (at the link above) enough to meet that requirement, or is there a dump file of the cleaned data available somewhere?I only need the first paragraph or two for certain Wikipedia pages, and downloading a cleaned dump from Google would save me a lot of time and trouble :)",
    "target": "google maps;wikipedia;copyright"
  },
  {
    "id": "_softwareengineering.297854",
    "source": "Dependency ordering algorithm of a compiler <eos> Let's say, hypothetically, I'm writing a Java compiler. And we assume that in my case a class can't be fully compiled until all signatures of dependencies (imports and other used classes) are known. Because I don't want to keep the source code and AST of all classes in memory at the same time, I'll need an algorithm to manage those dependencies and process them all in the right order.What would be a good algorithm for ordering all dependencies?That:is not recursivedoes not keep all source code and/or ast nodes in memoryis linear in both space and timecan handle cyclical dependencies Or maybe more general, how is this normally done?My approach looks like the following:abstract class Compiler {    TypeSystem ts;    Type compile(String className) {        if (ts.containsType(className)) {            return ts.getType(className);        }        // Create skeleton type for this class:        Type type = ts.createType(className);        // Parse the class file:        Node ast = parse(className);        // Create signature:        for (Node attribute : ast.findAll(AttributeDeclaration)) {            // Get the text value of the name of the attribute:            String attributeName = attribute.find(Identifier).text();            // Get the text value of the type of the attribute:            String attributeTypeName = attribute.find(Type).text();            // Call compile recursive!            Type attributeType = compile(attributeTypeName);            type.createAttribute(attributeName, attributeType);        }        return type;    }    abstract Node parse(String className); // This method can find the file by class name.}                For sake of simplicity, does this code only process attributes and simple structs.Note that this algorithm is recursive!",
    "target": "java;algorithms;compiler;graph;dependencies"
  },
  {
    "id": "_datascience.12263",
    "source": "how to choose classifer <eos> is the best way to create the most accurate classifier to train a bunch of classifying algorithms like ANN, SVM, KNN, etc, and test different parameters to get optimal parameters for each classifier, and see which classifier has the least testing error?Or is it better to use ensemble method and choose the majority decision of different kinds of trained classifiers?",
    "target": "classification;ensemble modeling"
  },
  {
    "id": "_softwareengineering.96478",
    "source": "Dealing with coworkers when developing, need advice <eos> I developed our current project architecture and started developing it on my own (reaching something like, revision 40).We're developing a simple subway routing framework and my design seemed to be done extremely well - several main models, corresponding views, main logic and data structures were modeled as they should be and fully separated from rendering, algorithmic part was also implemented apart from the main models and had a minor number of intersection points.I would call that design scalable, customizable, easy-to-implement, interacting mostly based on the black box interaction and, well, very nice.Now, what was done:I started some implementations of the corresponding interfaces, ported some convenient libraries and wrote implementation stubs for some application parts.I had the document describing coding style and examples of that coding style usage (my own written code).I forced the usage of more or less modern C++ development techniques, including no-delete code (wrapped via smart pointers) and etc.I documented the purpose of concrete interface implementations and how they should be used.Unit tests (mostly, integration tests, because there wasn't a lot of actual code) and  a set of mocks for all the core abstractions. I was absent for 12 days.What do we have now (the project was developed by 4 other members of the team):3 different coding styles all over the project (I guess, two of them agreed to use the same style :), same applies to the naming of our abstractions (e.g CommonPathData.h, SubwaySchemeStructures.h), which are basically headers declaring some data structures.Absolute lack of documentation for the recently implemented parts.What I could recently call a single-purpose-abstraction now handles at least 2 different types of events, has tight coupling with other parts and so on.Half of the used interfaces now contain member variables (sic!).Raw pointer usage almost everywhere.Unit tests disabled, because (Rev.57) They are unnecessary for this project.... (that's probably not everything).Commit history shows that my design was interpreted as an overkill and people started combining it with personal bicycles and reimplemented wheels and then had problems integrating code chunks.Now - the project still does only a small amount of what it has to do, we have severe integration problems, I assume some memory leaks.Is there anything possible to do in this case?I do realize that all my efforts didn't have any benefit, but the deadline is pretty soon and we have to do something. Did someone have a similar situation?Basically I thought that a good (well, I did everything that I could) start for the project would probably lead to something nice, however, I understand that I'm wrong.",
    "target": "c++;project management;refactoring;teamwork"
  },
  {
    "id": "_codereview.65311",
    "source": "Check image dimensions, calculate aspect ratio, set image dimensions, resize <eos> I have created a set of functions to calculate the aspect ratio of an image, set a height/width on document.ready and on window.resize resize the image. Now, I have got these functions working, however I feel like they could be more efficient/clean. So far I have to use cases. First, an image gallery I have setup and now, Iframes.The below scriptfile includes the issue above, and some functionality for mobile, and an overlay.Note: all these functions work (I do have an error imageResize('.com-background > img', ratio1); ratio1 is not defined within the window.resize function.scriptfile.jsfunction mobile() {    var ua = navigator.userAgent; var event = (ua.match(/iPad/i)) ? 'touchstart' : 'click';    jQuery('.mobile-contain > a').bind(event, function() {        jQuery('#menu-main').slideToggle(500);      });};  function overlay() {    jQuery('.com-block').mouseenter(function() {        jQuery(this).find('.com-title').css('display', 'none');        jQuery(this).find('.com-desc').css('display', 'table-cell');    });    jQuery('.com-block').mouseleave(function() {        jQuery(this).find('.com-title').css('display', 'table-cell');        jQuery(this).find('.com-desc').css('display', 'none');    });}function imageCalc(selector) {    var obj=$(selector);    var $imgWidth = obj.width();    var $imgHeight = obj.height();    var $imgAspectRatio =  $imgHeight / $imgWidth;    // $(selector).css('margin-left', function( calcMargin ) { return parseInt($('.main-content').css('padding')) * -1 + px; }); fix for ie    obj.css('margin-left', '-10px' );    return $imgAspectRatio;}function setImageDims(selector, content_area, $imgAspectRatio) {    var container = $(content_area);    $(selector).css('height', function() { return $imgAspectRatio * container.width(); });    $(selector).css('width', function() { return container.width() + 20; });    }function imageResize(selector, $imgAspectRatio) {    $(selector).css('width', function() { return $(body).width() });    $(selector).css('height', function() { return $imgAspectRatio * $(selector).width();  });}function cycleImages(){  var $active = $('.com-background .active');  var $next = ($active.next('img').length > 0) ? $active.next('img') : $('.com-background > img:first');  $next.css('z-index',2);  if ($('.com-background > img').length > 1) {      $active.fadeOut(1500,function(){      $active.css('z-index',1).show().removeClass('active');          $next.css('z-index',3).addClass('active');      });  };}function setContainHeight() {    var biggestHeight = 0;    $(.com-background *).each(function(){     if ($(this).height() > biggestHeight ) {       biggestHeight = $(this).height();     }    });    $(.com-background).height(biggestHeight);}function setImgMaxHeight() {    var smallestHeight = 0;    $(.com-background *).each(function(){     if ($(this).height() > smallestHeight ) {       smallestHeight = $(this).height();     }    });    // Set the container height    $(.com-background img).css('max-height', smallestHeight);}$( document ).ready(function() {    $('.com-wrap').hide();    ratio1 = imageCalc('.com-background > img');    setImageDims('.com-background > img', '#main-content', ratio1);    ratio2 = imageCalc('.blog-entry-content iframe');    setImageDims('.blog-entry-content iframe', '#content', ratio2);    // imageCalc('.com-background > img');    // setImageDims('.com-background > img', '#main-content');    // imageCalc('.blog-entry-content iframe');    // setImageDims('.blog-entry-content iframe');    setImgMaxHeight();});$(window).bind(load, function() {    setContainHeight();$('.com-more a').click(function(){    $('.com-wrap').toggle();    $('html, body').animate({        scrollTop: $( $(this).attr('href') ).offset().top    }, 500);    return false;});     setInterval(function(){cycleImages()}, 7000);    mobile();    overlay();});$(window).resize(function() {    setContainHeight();    if ($(body).width() < 980 ) {         imageResize('.com-background > img', ratio1);        // var ratio1 = imageCalc('.com-background > img');        //  setImageDims('.com-background > img', '#main-content', ratio1);    } else {        setImageDims('.com-background > img', '#main-content');    }  if ($(body).width() < 770 ) {    jQuery('.menu-main-container').css('display', 'none');  }  if ($(body).width() > 770 ) {    jQuery('.menu-main-container').css('display', 'block');  }}).resize(); I have also created a rudimentary fiddle to illustrate the imageCalc(), setImageDims(), and imageResize() functionality here.",
    "target": "javascript;jquery;image;animation"
  },
  {
    "id": "_datascience.5279",
    "source": "How to select topology for neural network? <eos> I was given a target function to design neural network and train: (y = (x1  x2)  (x3  x4))The number of input and number of output seems obvious (4 and 1). And the training data can use truth table.However, in order to train as a multilayer artificial neural network, I need to choose number of hidden units. May I know where can I find some general guideline for this?Thank you!",
    "target": "neural network"
  },
  {
    "id": "_softwareengineering.26801",
    "source": "Natural Language Processing (NLP) open source algorithms <eos> I am looking for a way to give an algorithm (service) a sentence, and it will tell me if its positive context or negative or even neutral.Does such a service exist?",
    "target": "algorithms"
  },
  {
    "id": "_unix.192073",
    "source": "Postfix alias for root not working in SUSE <eos> First tryI've set up multiple servers running Postfix.To get a general grasp of the state of the machine I usually redirect e-mail for root to my normal adress.I recently installed SUSE and tried to do the same. Opened /etc/aliases, added a line like this root:    user@mailserver.domain.com and ran newaliases. But messages are still delivered locally.I've tried doing the same configuration using yast2. It seems to do the same thing, but it does not deliver the message to my other machine.While troubleshooting something else broke, so now messages are no longer delivered locally, but rather the server refuses to create them:# telnet localhost 25Trying ::1...Connected to localhost.Escape character is '^]'.220 localhost ESMTPHELO localhost250 localhostMAIL FROM: user@suse-server.domain.com250 2.1.0 OkRCPT TO: root451 4.3.0 <user@suse-server.domain.com>: Temporary lookup failurequit221 2.0.0 ByeConnection closed by foreign host.Second tryI've tried nuking the installation:# zypper rm postfixLoading repository data...Reading installed packages...Resolving package dependencies...The following package is going to be REMOVED:  postfix1 package to remove.After the operation, 4.8 MiB will be freed.Continue? [y/n/? shows all options] (y):(1/1) Removing postfix-2.11.4-2.1 ........................................[done]Additional rpm output:warning: /etc/postfix/virtual saved as /etc/postfix/virtual.rpmsavewarning: /etc/postfix/sender_canonical saved as /etc/postfix/sender_canonical.rpmsavewarning: /etc/postfix/master.cf saved as /etc/postfix/master.cf.rpmsavewarning: /etc/postfix/main.cf saved as /etc/postfix/main.cf.rpmsaveThere are some running programs that might use files deleted by recent upgrade. You may wish to check and restart some of them. Run 'zypper ps' to list these programs.# rm -rf /etc/postfix# rm -rf /etc/aliasesand starting over, using only yast2:# zypper in postfixLoading repository data...Reading installed packages...Resolving package dependencies...The following NEW package is going to be installed:  postfix1 new package to install.Overall download size: 1007.1 KiB. Already cached: 0 B  After the operation, additional 4.8 MiB will be used.Continue? [y/n/? shows all options] (y):Retrieving package postfix-2.11.4-2.1.x86_64                                                                                                   (1/1), 1007.1 KiB (  4.8 MiB unpacked)Retrieving: postfix-2.11.4-2.1.x86_64.rpm .......................................................................................................................[done (799.0 KiB/s)]Checking for file conflicts: ..................................................................................................................................................[done](1/1) Installing: postfix-2.11.4-2.1 ..........................................................................................................................................[done]# yast2 mailBut mail to root does not get sent to my other machine:# telnet localhost 25Trying ::1...Connected to localhost.Escape character is '^]'.220 suse-server.domain.com ESMTPHELO localhost250 suse-server.domain.comMAIL FROM: user@suse-server.domain.com250 2.1.0 OkRCPT TO: root451 4.3.0 <user@suse-server.domain.com>: Temporary lookup failurequit221 2.0.0 ByeConnection closed by foreign host.The same connection looks like this in the mail.logMar 23 21:12:56 suse-server postfix/smtpd[22842]: connect from unknown[::1]Mar 23 21:13:22 suse-server postfix/trivial-rewrite[22844]: error: open database /etc/postfix/virtual.db: No such file or directoryMar 23 21:13:22 suse-server postfix/trivial-rewrite[22844]: error: open database /etc/postfix/relay.db: No such file or directoryMar 23 21:13:22 suse-server postfix/trivial-rewrite[22844]: error: open database /etc/postfix/relocated.db: No such file or directoryMar 23 21:13:22 suse-server postfix/trivial-rewrite[22844]: error: open database /etc/postfix/transport.db: No such file or directoryMar 23 21:13:22 suse-server postfix/trivial-rewrite[22844]: warning: hash:/etc/postfix/transport is unavailable. open database /etc/postfix/transport.db: No such file or directory  Mar 23 21:13:22 suse-server postfix/trivial-rewrite[22844]: warning: hash:/etc/postfix/transport lookup error for * Mar 23 21:13:22 suse-server postfix/trivial-rewrite[22844]: warning: hash:/etc/postfix/transport is unavailable. open database /etc/postfix/transport.db: No such file or directory  Mar 23 21:13:22 suse-server postfix/trivial-rewrite[22844]: warning: hash:/etc/postfix/transport lookup error for *Mar 23 21:13:22 suse-server postfix/trivial-rewrite[22844]: warning: hash:/etc/postfix/virtual is unavailable. open database /etc/postfix/virtual.db: No such file or directoryMar 23 21:13:22 suse-server postfix/trivial-rewrite[22844]: warning: hash:/etc/postfix/virtual: table lookup problemMar 23 21:13:22 suse-server postfix/trivial-rewrite[22844]: warning: hash:/etc/postfix/transport is unavailable. open database /etc/postfix/transport.db: No such file or directory  Mar 23 21:13:22 suse-server postfix/trivial-rewrite[22844]: warning: hash:/etc/postfix/transport lookup error for user@suse-server.domain.comMar 23 21:13:22 suse-server postfix/trivial-rewrite[22844]: warning: transport_maps lookup failureMar 23 21:13:26 suse-server postfix/trivial-rewrite[22844]: warning: hash:/etc/postfix/virtual is unavailable. open database /etc/postfix/virtual.db: No such file or directoryMar 23 21:13:26 suse-server postfix/trivial-rewrite[22844]: warning: hash:/etc/postfix/virtual: table lookup problemMar 23 21:13:26 suse-server postfix/trivial-rewrite[22844]: warning: hash:/etc/postfix/transport is unavailable. open database /etc/postfix/transport.db: No such file or directory  Mar 23 21:13:26 suse-server postfix/trivial-rewrite[22844]: warning: hash:/etc/postfix/transport lookup error for root@suse-server.domain.comMar 23 21:13:26 suse-server postfix/trivial-rewrite[22844]: warning: transport_maps lookup failureMar 23 21:13:26 suse-server postfix/smtpd[22842]: NOQUEUE: reject: RCPT from unknown[::1]: 451 4.3.0 <user@suse-server.domain.com>: Temporary lookup failure; from=<user@suse-server.domain.com> to=<root> proto=SMTP helo=<localhost>Mar 23 21:13:29 suse-server postfix/smtpd[22842]: disconnect from unknown[::1]Please help.Keep troubleshootingAbout my system# cat /etc/os-releaseNAME=openSUSEVERSION=20150319 (Tumbleweed)VERSION_ID=20150319PRETTY_NAME=openSUSE 20150319 (Tumbleweed) (x86_64)ID=opensuseANSI_COLOR=0;32CPE_NAME=cpe:/o:opensuse:opensuse:20150319BUG_REPORT_URL=https://bugs.opensuse.orgHOME_URL=https://opensuse.org/ID_LIKE=suseAnother errorLeft the machine in a broken state over night, log is filled with lines like the following:Mar 24 06:48:28 suse-server postfix/pickup[25006]: 6B0DE6FD: uid=0 from=<root>Mar 24 06:48:28 suse-server postfix/cleanup[25051]: warning: hash:/etc/postfix/sender_canonical is unavailable. open database /etc/postfix/sender_canonical.db: No such file or directoryMar 24 06:48:28 suse-server postfix/cleanup[25051]: warning: hash:/etc/postfix/sender_canonical lookup error for root@suse-server.domain.comMar 24 06:48:28 suse-server postfix/cleanup[25051]: warning: 6B0DE6FD: sender_canonical_maps map lookup problem for root@suse-server.domain.com -- message not accepted, try again laterMar 24 06:48:28 suse-server postfix/cleanup[25051]: warning: hash:/etc/postfix/canonical is unavailable. open database /etc/postfix/canonical.db: No such file or directoryMar 24 06:48:28 suse-server postfix/cleanup[25051]: warning: hash:/etc/postfix/canonical lookup error for root@suse-server.domain.comMar 24 06:48:28 suse-server postfix/cleanup[25051]: warning: 6B0DE6FD: canonical_maps map lookup problem for root@suse-server.domain.com -- message not accepted, try again laterMar 24 06:48:28 suse-server postfix/pickup[25006]: warning: maildrop/80E795FC: error writing 6B0DE6FD: queue file write errorCleaning up the logsThe numerous lookup errors can be silenced with postman (why yast2 mail does not run postmap is beyond me to understand):suse-server:~ # postmap /etc/postfix/transportsuse-server:~ # postmap /etc/postfix/sender_canonicalsuse-server:~ # postmap /etc/postfix/canonicalsuse-server:~ # postmap /etc/postfix/virtualsuse-server:~ # postmap /etc/postfix/relaysuse-server:~ # postmap /etc/postfix/relocatedsuse-server:~ # systemctl restart postfix.serviceNew errorsPostmapping is not the solution to the problem however:Mar 24 15:18:02 suse-server echo[27096]: Starting mail service (Postfix)Mar 24 15:18:02 suse-server postfix/postfix-script[27178]: starting the Postfix mail systemMar 24 15:18:02 suse-server postfix/master[27180]: daemon started -- version 2.11.4, configuration /etc/postfixMar 24 15:18:02 suse-server postfix/pickup[27182]: C9084931: uid=0 from=<root>Mar 24 15:18:02 suse-server postfix/cleanup[27187]: C9084931: message-id=<20150324141802.C9084931@suse-server.domain.com>Mar 24 15:18:02 suse-server postfix/qmgr[27183]: C9084931: from=<root@suse-server.domain.com>, size=785, nrcpt=1 (queue active)Mar 24 15:18:02 suse-server postfix/cleanup[27187]: D6A16932: message-id=<20150324141802.C9084931@suse-server.domain.com>Mar 24 15:18:02 suse-server postfix/qmgr[27183]: D6A16932: from=<root@suse-server.domain.com>, size=910, nrcpt=1 (queue active)Mar 24 15:18:02 suse-server postfix/local[27189]: C9084931: to=<root@suse-server.domain.com>, orig_to=<root>, relay=local, delay=45656, delays=45656/0.01/0/0.03, dsn=2.0.0, status=sent (forwarded as D6A16932)Mar 24 15:18:02 suse-server postfix/qmgr[27183]: C9084931: removedMar 24 15:18:02 suse-server postfix/smtp[27190]: fatal: valid hostname or network address required in server description: []Mar 24 15:18:03 suse-server postfix/qmgr[27183]: warning: private/smtp socket: malformed responseMar 24 15:18:03 suse-server postfix/qmgr[27183]: warning: transport smtp failure -- see a previous warning/fatal/panic logfile record for the problem descriptionMar 24 15:18:03 suse-server postfix/master[27180]: warning: process /usr/lib/postfix/smtp pid 27190 exit status 1Mar 24 15:18:03 suse-server postfix/master[27180]: warning: /usr/lib/postfix/smtp: bad command startup -- throttlingMar 24 15:18:03 suse-server postfix/error[27191]: D6A16932: to=<user@mail-server.domain.com>, orig_to=<root>, relay=none, delay=1.1, delays=0.03/1/0/0.04, dsn=4.3.0, status=deferred (unknown mail transport error)Mar 24 15:23:02 suse-server postfix/qmgr[27183]: D6A16932: from=<root@suse-server.domain.com>, size=910, nrcpt=1 (queue active)Mar 24 15:23:02 suse-server postfix/smtp[27196]: fatal: valid hostname or network address required in server description: []Mar 24 15:23:03 suse-server postfix/qmgr[27183]: warning: private/smtp socket: malformed responseMar 24 15:23:03 suse-server postfix/qmgr[27183]: warning: transport smtp failure -- see a previous warning/fatal/panic logfile record for the problem descriptionMar 24 15:23:03 suse-server postfix/master[27180]: warning: process /usr/lib/postfix/smtp pid 27196 exit status 1Mar 24 15:23:03 suse-server postfix/master[27180]: warning: /usr/lib/postfix/smtp: bad command startup -- throttlingMar 24 15:23:03 suse-server postfix/error[27198]: D6A16932: to=<user@mail-server.domain.com>, orig_to=<root>, relay=none, delay=300, delays=299/1/0/0.03, dsn=4.3.0, status=deferred (unknown mail transport error)Mar 24 15:23:48 suse-server postfix/smtpd[27202]: error: open database /etc/postfix/access.db: No such file or directoryMar 24 15:23:48 suse-server postfix/smtpd[27202]: connect from unknown[::1]Mar 24 15:24:11 suse-server postfix/smtpd[27202]: warning: hash:/etc/postfix/access is unavailable. open database /etc/postfix/access.db: No such file or directoryMar 24 15:24:11 suse-server postfix/smtpd[27202]: warning: hash:/etc/postfix/access: table lookup problemMar 24 15:24:11 suse-server postfix/smtpd[27202]: NOQUEUE: reject: RCPT from unknown[::1]: 451 4.3.5 <user>: Sender address rejected: Server configuration error; from=<user> to=<root> proto=SMTP helo=<localhost>Mar 24 15:24:18 suse-server postfix/smtpd[27202]: disconnect from unknown[::1]I do start to believe that postfix on suse is blessed with rather insane defaults, with the pile of logged errors not getting any smaller even though a lot of the errors has been removed.Mail accepted after another postmapFound another file to postmap, after which postfix accepts the message.suse-server:~ # postmap /etc/postfix/accesssuse-server:~ # systemctl restart postfix.servicesuse-server:~ # telnet localhost 25Trying ::1...Connected to localhost.Escape character is '^]'.220 suse-server.domain.com ESMTPHELO localhost250 suse-server.domain.comMAIL FROM: user250 2.1.0 OkRCPT TO: root250 2.1.5 OkDATA354 End data with <CR><LF>.<CR><LF>Subject: testasd.250 2.0.0 Ok: queued as 4797894Fquit221 2.0.0 ByeConnection closed by foreign host.Unfortunately it still tosses the message in the bin:suse-server:~ # journalctl | tail -18Mar 24 15:35:18 suse-server echo[27287]: Starting mail service (Postfix)Mar 24 15:35:19 suse-server postfix/postfix-script[27369]: starting the Postfix mail systemMar 24 15:35:19 suse-server postfix/master[27371]: daemon started -- version 2.11.4, configuration /etc/postfixMar 24 15:35:45 suse-server postfix/smtpd[27380]: connect from unknown[::1]Mar 24 15:35:59 suse-server postfix/smtpd[27380]: 4797894F: client=unknown[::1]Mar 24 15:36:12 suse-server postfix/cleanup[27383]: 4797894F: message-id=<20150324143559.4797894F@suse-server.domain.com>Mar 24 15:36:12 suse-server postfix/qmgr[27374]: 4797894F: from=<user@suse-server.domain.com>, size=299, nrcpt=1 (queue active)Mar 24 15:36:12 suse-server postfix/cleanup[27383]: E8C94950: message-id=<20150324143559.4797894F@suse-server.domain.com>Mar 24 15:36:12 suse-server postfix/qmgr[27374]: E8C94950: from=<user@suse-server.domain.com>, size=424, nrcpt=1 (queue active)Mar 24 15:36:12 suse-server postfix/local[27384]: 4797894F: to=<root@suse-server.domain.com>, orig_to=<root>, relay=local, delay=18, delays=18/0.01/0/0.03, dsn=2.0.0, status=sent (forwarded as E8C94950)Mar 24 15:36:12 suse-server postfix/qmgr[27374]: 4797894F: removedMar 24 15:36:12 suse-server postfix/smtp[27385]: fatal: valid hostname or network address required in server description: []Mar 24 15:36:14 suse-server postfix/qmgr[27374]: warning: private/smtp socket: malformed responseMar 24 15:36:14 suse-server postfix/qmgr[27374]: warning: transport smtp failure -- see a previous warning/fatal/panic logfile record for the problem descriptionMar 24 15:36:14 suse-server postfix/master[27371]: warning: process /usr/lib/postfix/smtp pid 27385 exit status 1Mar 24 15:36:14 suse-server postfix/master[27371]: warning: /usr/lib/postfix/smtp: bad command startup -- throttlingMar 24 15:36:14 suse-server postfix/error[27386]: E8C94950: to=<user@mail-server.domain.com>, orig_to=<root>, relay=none, delay=1.1, delays=0.03/1/0/0.03, dsn=4.3.0, status=deferred (unknown mail transport error)Mar 24 15:36:14 suse-server postfix/smtpd[27380]: disconnect from unknown[::1]valid hostnameyast2 sets relayhost = [] in /etc/postfix/main.cf, removing that line removes the error:fatal: valid hostname or network address required in server description: []fatal: unknown service: smtp/tcpThat gives way to the error:postfix/smtp[6108]: fatal: unknown service: smtp/tcpwhich can be solved by disabling chroot on smtp by changing master.cf from:# grep ^smtp master.cf smtp      inet  n       -       y       -       -       smtpdsmtp      unix  -       -       y       -       -       smtpto# grep ^smtp master.cf smtp      inet  n       -       n       -       -       smtpdsmtp      unix  -       -       n       -       -       smtpAfter disabling the chroot I do get root's e-mail to my expected mailbox.So the question now is probably why postfix is installed without a working chroot for smtp?",
    "target": "email;opensuse;postfix;suse"
  },
  {
    "id": "_webmaster.90527",
    "source": "File limit on shared hosting - does the issue still apply? <eos> I've heard that shared hosting often imposes a limit on files per directory, though obviously this would be different per host.Generally speaking, is number of files still an issue on modern hosts? I am creating a static-page generator meant to be distributed -- yet if someone has a 500k pages (files, even if small) and this passes some arbitrary shared-hosting file limit, then a dynamic solution would be preferred.At our current time, do many shared hosts impose file limits?",
    "target": "web hosting;files"
  },
  {
    "id": "_unix.304539",
    "source": "Apache: how to access files using the requesting user's credentials? <eos> I have a domain-joined (via samba/sssd) CentOS 7 server, acting as a SFTP server, which has a mountpoint mapped to a Windows' share:SFTP Client -> Linux SFTP Server -> Windows File ServerMy goal here is to eliminate Linux-sided permissions and configs as much as possible.The mount is configured with multiuser and sec=krb5 options. Users logging into the SFTP server are authenticated against AD database, and everything works great: for each user logging in and accessing the mounted/shared folder, the multiuser+krb5 settings kick in and folder permissions are fully controlled by the Windows File Server holding the files, since each user mounts this share using their own kerberos ticket obtained upon logon to the SFTP server.Great. Now onto the sad part of the story.I have to provide HTTPS access to the same files mentioned above. The problem is that I couldn't find a way to make Apache/httpd access files using the authenticated user's credentials, which would cause the share to be mounted with the right (requesting user's) credentials, instead of Apache's user.I could work around this by setting mod ldap's group authorization, but I REALLY wanted to control everything using Windows' permissions, just as I do with SFTP access. Any ideas aside from using IIS (which does exactly what I want by default)?I can already use Single Sign-On through Apache, and even cache the kerberos tickets. So what's stopping me (aside from my lack of programming skills) from using that same ticket (and username info) to call automount with it?",
    "target": "mount;apache httpd;samba;automounting;kerberos"
  },
  {
    "id": "_webapps.33975",
    "source": "Using google drive (Google Docs) in offline mode <eos> I want to have a copy of my Microsoft Excel and Word documents in offline mode. Is there way to to copy or backup those files with scheduling tools everyday or another  automatic sync software that do it for me?",
    "target": "google drive"
  },
  {
    "id": "_softwareengineering.264700",
    "source": "Paid software includes MIT licensed library, does that put my app under MIT too? <eos> If I include MIT licensed source code in my program, am I obliged to provide my whole software under MIT?The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.How is substantial determined?  The wording is not very specific.",
    "target": "licensing;mit license"
  },
  {
    "id": "_webapps.69701",
    "source": "How do I find out who has already reserved a resource i.e. conference room in Google Calendar? <eos> Scenario:A small group of employees has reserved the conference room via a Google Calendar event through Gmail. At a later date a meeting with a bunch of executives is scheduled only to find the conference room is already reserved.  How can I find out who originally reserved the room so that we can negotiate a swap?If I'm not mistaken a calendar is created behind the scenes when you add an asset that you can check out with calendar events.  Is there an easy way to hook directly into that calendar?The image below shows an asset added to an event, which makes it a guest.  If I hover over that guest I can see there appears to be a calendar URL.  Unfortunately I don't see any way to copy that or otherwise get to the calendar without writing it down by hand and then manually typing it into Google Calendar to search.",
    "target": "google apps;google calendar"
  },
  {
    "id": "_unix.144895",
    "source": "How to see what processes WERE running? <eos> Is there a chance to get the processes that RAN before my system crash?EDITWhat I really want is to see the past processes.My system crashed & I want to know if a specific process was the main reason.I search into all /var/log logs, but nothing, the only suspect in this were some apache logs, where I found some kind of scans... So now I want to check out for all processes running at that time.",
    "target": "monitoring;ps;crash"
  },
  {
    "id": "_webapps.15911",
    "source": "How to show all archived messages in Gmail? <eos> How do we search for all our archived messages in Gmail?Non-archived messages should not be displayed,Only the archived messages should be shown.",
    "target": "gmail;gmail archive"
  },
  {
    "id": "_cs.32310",
    "source": "Are if statements unnecessary if a program is represented as an explicit state machine? <eos> This question occurred to me some time ago when I was thinking about whether or not if statements are fundamental in computation.Consider a program that manages a single bank account (for the sake of simplicity). The bank account could be defined as something likeAccount {    int balance; // current amount of Money    boolean withdraw(int n)    {       if (balance >= n)       {           balance = balance -n;           return true;       }       else           return false;    }    void deposit(int n)    {       amount = amount + n;    }}Since the program has no way to known in which state it currently is unless it performs validations using if statements, as in the withdraw operation, if statements are unavoidable.However, over the course of time, the program will pass through a finite set of states that can be known beforehand. In this particular case, a state is defined solely by the value of the balance variable, hence we would have states: {balance = 0 , balance = 1, balance = 2...}.If we assign each state a number, say state {0,1,2,....} with a 1-1 correspondence to the above set of states, and assign to each operation a number identifier as well (say deposit = 0 and withdraw = 1), we could model the program as an explicit transition between states and therefore remove every if statement from the code.Consider that state = 0 is the state where balance = 0 and we want to perform a deposit of 50 dollars, if we coded every single possible execution of the deposit function, we could just define the deposit function asvoid deposit (int n){   deposit[state][n]; // ndex deposit instance for state = 0, amount = n;}deposit[][] would be a matrix of pointers for a set of functions that represent each possible execution of deposit, likedeposit[0][0] -> balance = balance + 0; state = 0;deposit[0][1] -> balance = balance + 1; state = 1;....In the case of withdrawal, it would be like:boolean withdraw (int n){    // ndex withdraw instance for the current state and amount=n    return withdraw[state][n]; }withdraw[][] would be a matrix of pointers for a set of functions that represent each possible execution of withdraw, like:deposit[0][100] -> return false; state = state;...deposit[200][100] -> balance = balance - 100; return true; state = 100;In this situation, the program the managers the single bank account can be written without using a single if statement!As a consequence however, we have to use A LOT more memory, which may make the solution unreasonable. Also one may put the question of how did we fill the deposit[][] and withdraw[][] matrices? By hand? It somehow implies that a previous computation that used ifs as necessary to determine and possible states and transitions.All in all, are ifs fundamental or does my example prove that they aren't? If they are, can you provide me an example where this does not work? If they are not, why dont we use solutions like these more often?Is there some law of computation which states that if statements are unavoidable?",
    "target": "programming languages;computation models"
  },
  {
    "id": "_unix.371502",
    "source": "Keep metadata or edit metadata with tar <eos> I have a tarball. This tarball containsof coursevarious files and directories. When I extract the tar, some of these files already exist, while others don't.What I would like to know is this: how can I extract a tarball to keep the metadata of already existing files intact (ownership, group, read, write, execute etc.), regardless who executes the command and what was the original directory layout upon tar creation?So far what I have found are these:--mode='555' --owner=owner --group=groupWhen I use these flags when creating the tarball, it actually does change the metadata of all the files in the tar accordingly. However I don't know how could I change it for a small set of files which should have other permissions.--no-overwrite-dirAs I understand this flag is used when extracting the tarball and should keep the metadata of already existing files, but I don't get the expected results.",
    "target": "permissions;tar;compression;file metadata"
  },
  {
    "id": "_codereview.109821",
    "source": "Simple C++ class for storing and manipulations with money <eos> ProblemI want to create a simple class for storing money - I will be storing dollars/cents as just ints for this model.Idea is to implement various operations on Money class - to be able to add/subtract/multiply/divide money by constant (division is integer for our model - so we don't support money less then a penny - for simplification).Please, comment on the correctness of implementations in terms of - operators overloading, copy/move constructors/numbers manipulations and general code style and quality.I have a few tests passing for my class here - so this is fully functional (except overflow checks - marked as TODO - would be great if someone could recommend industry standard for overflow/underflow checks in cpp which is used everywhere, safe and fast).Money.h#ifndef CHANGE_MONEY_H_#define CHANGE_MONEY_H_#include <exception>#include <iostream>#include <string>namespace change {    class Money {    private:        int32_t whole;        int8_t fraction;        void swap(Money other);    public:        Money(const Money& other);        Money(const Money&& other);        Money(int32_t _whole, int8_t _fraction);        ~Money();        int32_t getWhole() const { return whole; }        int8_t getFraction() const { return fraction; }        Money& operator=(const Money& other) {            if (&other != this) {                whole = other.whole;                fraction = other.fraction;            }            return *this;        }        bool operator==(const Money& other) const {            return whole == other.whole && fraction == other.fraction;        }        bool operator!=(const Money& other) const {            return !(*this == other);        }        bool operator>(const Money& other) const {            if (whole > other.whole) {                return true;            } else if (whole == other.whole) {                return fraction > other.fraction;            } else{                return false;            }        }        bool operator>=(const Money& other) const {            return (*this == other || *this > other);        }        bool operator<(const Money& other) const {            return !(*this == other || *this > other);        }        bool operator<=(const Money& other) const {            return (*this == other || *this < other);        }        Money operator+(Money& other) const {            Money result(0, 0);            int16_t sum = fraction + other.fraction;            int16_t newFrac = static_cast<int16_t>(sum) % 100;            int64_t carry = sum > 100 ? 1 : 0;            // TODO: overflow check            result.whole =  whole + other.whole + carry;            result.fraction = static_cast<int8_t>(newFrac);            return result;        }        Money operator+=(Money other) {            *this = *this + other;            return *this;        }        Money operator-(const Money& other) const {            Money result(0, 0);            int8_t newFrac = (fraction - other.fraction) % 100;            int32_t carry = newFrac < 0 ? -1 : 0;            newFrac = newFrac < 0 ? 100 + newFrac : newFrac;            // TODO: overflow            result.whole = whole - other.whole + carry;            result.fraction = newFrac;            return result;        }        Money operator-=(Money other) {            *this = *this - other;            return *this;        }        template <class T>        Money operator*(T number) const {            // TODO: overflow check            int64_t fracMult = static_cast<int64_t>(fraction) * number;            int8_t newFrac =  static_cast<int8_t>(fracMult % 100);            // TODO: overflow check            int32_t newWhole = whole * number + (fracMult / 100);            Money tmp(newWhole, newFrac);            return tmp;        }        template <class T>        Money operator/(T number) const {            if (number == 0) {                throw std::invalid_argument(Division by zero);            }            // TODO: overflow check            int64_t total = (100 * static_cast<int64_t>(whole)) + fraction;            int64_t result = total / number;            int8_t newFrac = static_cast<int8_t>(result % 100);            int32_t newWhole = static_cast<int32_t>(result / 100);            Money tmp(newWhole, newFrac);            return tmp;        }        friend std::ostream& operator<<(std::ostream& os, const Money& money);    };}#endif //CHANGE_MONEY_H_Money.cpp#include Money.h#include <iomanip>namespace change {    Money::Money(const Money& other) {        whole = other.whole;        fraction = other.fraction;    }    Money::Money(const Money&& other) {        *this = std::move(other);    }    Money::Money(int32_t _whole, int8_t _fraction) {        whole = _whole;        fraction = _fraction;    }    Money::~Money() {        // nothing for now    }    void Money::swap(Money other) {        std::swap(whole, other.whole);        std::swap(fraction, other.fraction);    }    // this is just for test purposes - print in dollars always    std::ostream& operator<<(std::ostream& os, const Money& money)  {        return os << '$' << std::to_string(money.whole) << '.' << std::setw(2) << std::setfill('0') << static_cast<int16_t>(money.fraction);    }}",
    "target": "c++;c++11"
  }
]